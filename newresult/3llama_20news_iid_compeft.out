nohup: ignoring input
Map:   0%|          | 0/11314 [00:00<?, ? examples/s]Map:   9%|▉         | 1000/11314 [00:00<00:03, 2984.82 examples/s]Map:  18%|█▊        | 2000/11314 [00:00<00:02, 3228.95 examples/s]Map:  27%|██▋       | 3000/11314 [00:00<00:02, 3828.18 examples/s]Map:  35%|███▌      | 4000/11314 [00:01<00:02, 3453.60 examples/s]Map:  44%|████▍     | 5000/11314 [00:01<00:02, 3126.15 examples/s]Map:  53%|█████▎    | 6000/11314 [00:01<00:01, 3158.86 examples/s]Map:  62%|██████▏   | 7000/11314 [00:02<00:01, 3463.00 examples/s]Map:  71%|███████   | 8000/11314 [00:02<00:00, 3717.35 examples/s]Map:  80%|███████▉  | 9000/11314 [00:02<00:00, 3774.80 examples/s]Map:  88%|████████▊ | 10000/11314 [00:02<00:00, 3891.56 examples/s]Map:  97%|█████████▋| 11000/11314 [00:03<00:00, 3878.36 examples/s]Map: 100%|██████████| 11314/11314 [00:03<00:00, 3578.97 examples/s]
Map:   0%|          | 0/7532 [00:00<?, ? examples/s]Map:  13%|█▎        | 1000/7532 [00:00<00:01, 5434.44 examples/s]Map:  27%|██▋       | 2000/7532 [00:00<00:01, 5470.74 examples/s]Map:  40%|███▉      | 3000/7532 [00:00<00:01, 2995.07 examples/s]Map:  53%|█████▎    | 4000/7532 [00:01<00:00, 3606.95 examples/s]Map:  66%|██████▋   | 5000/7532 [00:01<00:00, 4142.93 examples/s]Map:  80%|███████▉  | 6000/7532 [00:01<00:00, 2939.95 examples/s]Map:  93%|█████████▎| 7000/7532 [00:01<00:00, 3584.85 examples/s]Map: 100%|██████████| 7532/7532 [00:02<00:00, 3747.02 examples/s]Map: 100%|██████████| 7532/7532 [00:02<00:00, 3670.75 examples/s]
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at ./model/models--llama-3.2-1b/ and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
trainable params: 1,703,936 || all params: 1,237,559,296 || trainable%: 0.1377
the model architecture is 
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): LlamaForSequenceClassification(
      (model): LlamaModel(
        (embed_tokens): Embedding(128256, 2048)
        (layers): ModuleList(
          (0-15): 16 x LlamaDecoderLayer(
            (self_attn): LlamaAttention(
              (q_proj): lora.Linear(
                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=2048, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2048, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (k_proj): Linear(in_features=2048, out_features=512, bias=False)
              (v_proj): lora.Linear(
                (base_layer): Linear(in_features=2048, out_features=512, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=2048, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=512, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)
              (up_proj): Linear(in_features=2048, out_features=8192, bias=False)
              (down_proj): Linear(in_features=8192, out_features=2048, bias=False)
              (act_fn): SiLU()
            )
            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
          )
        )
        (norm): LlamaRMSNorm((2048,), eps=1e-05)
        (rotary_emb): LlamaRotaryEmbedding()
      )
      (score): Linear(in_features=2048, out_features=20, bias=False)
    )
  )
)
the number of packet is  152
ROUND:0
CLIENT:85
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:35,  1.10it/s]                                              {'loss': 5.5097, 'grad_norm': 32.419132232666016, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:35,  1.10it/s]  5%|▌         | 2/40 [00:01<00:21,  1.78it/s]                                              {'loss': 4.0718, 'grad_norm': 34.440311431884766, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:01<00:21,  1.78it/s]  8%|▊         | 3/40 [00:01<00:16,  2.22it/s]                                              {'loss': 4.3322, 'grad_norm': 27.869909286499023, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:16,  2.22it/s] 10%|█         | 4/40 [00:01<00:14,  2.53it/s]                                              {'loss': 4.495, 'grad_norm': 33.29704284667969, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:14,  2.53it/s] 12%|█▎        | 5/40 [00:02<00:12,  2.76it/s]                                              {'loss': 4.3468, 'grad_norm': 30.02499771118164, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:02<00:12,  2.76it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.88it/s]                                              {'loss': 3.8366, 'grad_norm': 31.72100257873535, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.88it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 6.1833, 'grad_norm': 33.399375915527344, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 6.809, 'grad_norm': 112.09236145019531, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:03<00:08,  3.83it/s]                                              {'loss': 2.0576, 'grad_norm': 23.017311096191406, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:03<00:08,  3.83it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.63it/s]                                               {'loss': 1.6342, 'grad_norm': 27.404321670532227, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.63it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.49it/s]                                               {'loss': 1.9925, 'grad_norm': 24.384483337402344, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.49it/s] 30%|███       | 12/40 [00:04<00:08,  3.43it/s]                                               {'loss': 1.8056, 'grad_norm': 22.06407356262207, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:04<00:08,  3.43it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.33it/s]                                               {'loss': 1.2896, 'grad_norm': 22.32105827331543, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.33it/s] 35%|███▌      | 14/40 [00:04<00:07,  3.30it/s]                                               {'loss': 1.4824, 'grad_norm': 21.560522079467773, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:07,  3.30it/s] 38%|███▊      | 15/40 [00:05<00:07,  3.32it/s]                                               {'loss': 0.942, 'grad_norm': 13.936179161071777, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:05<00:07,  3.32it/s]                                               {'loss': 0.2081, 'grad_norm': 21.873794555664062, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:05<00:07,  3.32it/s] 42%|████▎     | 17/40 [00:05<00:05,  4.06it/s]                                               {'loss': 0.3001, 'grad_norm': 10.082590103149414, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  4.06it/s] 45%|████▌     | 18/40 [00:05<00:05,  3.79it/s]                                               {'loss': 0.3932, 'grad_norm': 13.145511627197266, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:05,  3.79it/s] 48%|████▊     | 19/40 [00:06<00:05,  3.60it/s]                                               {'loss': 0.2045, 'grad_norm': 7.3014960289001465, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:06<00:05,  3.60it/s] 50%|█████     | 20/40 [00:06<00:05,  3.50it/s]                                               {'loss': 0.3257, 'grad_norm': 8.55801010131836, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:05,  3.50it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.41it/s]                                               {'loss': 0.3353, 'grad_norm': 9.408638000488281, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.41it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.36it/s]                                               {'loss': 0.491, 'grad_norm': 9.29429817199707, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.36it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.31it/s]                                               {'loss': 0.6191, 'grad_norm': 10.193538665771484, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.31it/s]                                               {'loss': 0.6667, 'grad_norm': 62.2125244140625, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:04,  3.31it/s] 62%|██████▎   | 25/40 [00:07<00:03,  4.05it/s]                                               {'loss': 0.0101, 'grad_norm': 0.47089889645576477, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  4.05it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.79it/s]                                               {'loss': 0.0989, 'grad_norm': 4.8340911865234375, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.79it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.61it/s]                                               {'loss': 0.1521, 'grad_norm': 6.813000202178955, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.61it/s] 70%|███████   | 28/40 [00:08<00:03,  3.49it/s]                                               {'loss': 0.3692, 'grad_norm': 11.978391647338867, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.49it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.4764, 'grad_norm': 10.848248481750488, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.39it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.33it/s]                                               {'loss': 0.0586, 'grad_norm': 6.56384801864624, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.33it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.29it/s]                                               {'loss': 0.4676, 'grad_norm': 9.076958656311035, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.29it/s]                                               {'loss': 0.0049, 'grad_norm': 0.6229186654090881, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.29it/s] 82%|████████▎ | 33/40 [00:09<00:01,  4.02it/s]                                               {'loss': 0.2181, 'grad_norm': 5.387361526489258, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  4.02it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.78it/s]                                               {'loss': 0.1114, 'grad_norm': 4.495094299316406, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.78it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.62it/s]                                               {'loss': 0.2983, 'grad_norm': 7.031520366668701, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.62it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.49it/s]                                               {'loss': 0.0425, 'grad_norm': 3.3513400554656982, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.49it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.39it/s]                                               {'loss': 0.2217, 'grad_norm': 7.321456432342529, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.39it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.29it/s]                                               {'loss': 0.0121, 'grad_norm': 0.6570857167243958, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.29it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.24it/s]                                               {'loss': 0.2672, 'grad_norm': 5.667941570281982, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.24it/s]                                               {'loss': 0.0055, 'grad_norm': 0.6265314221382141, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.24it/s]                                               {'train_runtime': 12.0599, 'train_samples_per_second': 46.849, 'train_steps_per_second': 3.317, 'train_loss': 1.4286655163974502, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.24it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:64
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.25it/s]                                              {'loss': 3.4732, 'grad_norm': 4.005622863769531, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.25it/s]  5%|▌         | 2/40 [00:00<00:12,  3.13it/s]                                              {'loss': 3.7144, 'grad_norm': 3.824928045272827, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.13it/s]  8%|▊         | 3/40 [00:00<00:11,  3.13it/s]                                              {'loss': 3.8079, 'grad_norm': 3.978579521179199, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.13it/s] 10%|█         | 4/40 [00:01<00:11,  3.11it/s]                                              {'loss': 4.1515, 'grad_norm': 4.061783313751221, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.11it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.09it/s]                                              {'loss': 3.4072, 'grad_norm': 5.310849189758301, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.09it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.08it/s]                                              {'loss': 3.4948, 'grad_norm': 5.702140808105469, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.08it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.10it/s]                                              {'loss': 2.8491, 'grad_norm': 6.447327613830566, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.10it/s]                                              {'loss': 0.953, 'grad_norm': 19.106433868408203, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.10it/s] 22%|██▎       | 9/40 [00:02<00:07,  3.92it/s]                                              {'loss': 1.2015, 'grad_norm': 4.8152265548706055, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:07,  3.92it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.67it/s]                                               {'loss': 1.5594, 'grad_norm': 5.548511028289795, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.67it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.50it/s]                                               {'loss': 1.7569, 'grad_norm': 5.017794609069824, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.50it/s] 30%|███       | 12/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.5109, 'grad_norm': 5.283202171325684, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.39it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.30it/s]                                               {'loss': 1.2019, 'grad_norm': 5.078705310821533, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.30it/s] 35%|███▌      | 14/40 [00:04<00:07,  3.25it/s]                                               {'loss': 1.2188, 'grad_norm': 5.9097394943237305, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:07,  3.25it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.20it/s]                                               {'loss': 1.8787, 'grad_norm': 7.6872711181640625, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.20it/s]                                               {'loss': 2.8315, 'grad_norm': 46.77996063232422, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.20it/s] 42%|████▎     | 17/40 [00:04<00:05,  3.96it/s]                                               {'loss': 0.6974, 'grad_norm': 5.575667858123779, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:04<00:05,  3.96it/s] 45%|████▌     | 18/40 [00:05<00:05,  3.70it/s]                                               {'loss': 0.4719, 'grad_norm': 4.351563453674316, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:05,  3.70it/s] 48%|████▊     | 19/40 [00:05<00:05,  3.52it/s]                                               {'loss': 0.5846, 'grad_norm': 4.583250522613525, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:05,  3.52it/s] 50%|█████     | 20/40 [00:05<00:05,  3.40it/s]                                               {'loss': 0.4088, 'grad_norm': 6.676316738128662, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:05<00:05,  3.40it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.31it/s]                                               {'loss': 0.3652, 'grad_norm': 3.8232386112213135, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.31it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.25it/s]                                               {'loss': 1.1914, 'grad_norm': 3.5207245349884033, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.25it/s] 57%|█████▊    | 23/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.5102, 'grad_norm': 9.134957313537598, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.0293, 'grad_norm': 1.077791690826416, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:06<00:04,  3.21it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.93it/s]                                               {'loss': 0.1179, 'grad_norm': 2.5742900371551514, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.93it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.68it/s]                                               {'loss': 0.3688, 'grad_norm': 5.35922908782959, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.68it/s] 68%|██████▊   | 27/40 [00:07<00:03,  3.51it/s]                                               {'loss': 0.1212, 'grad_norm': 2.1748385429382324, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:07<00:03,  3.51it/s] 70%|███████   | 28/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.8831, 'grad_norm': 1.2519737482070923, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.40it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.0735, 'grad_norm': 1.3638815879821777, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.31it/s] 75%|███████▌  | 30/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.1543, 'grad_norm': 3.5043604373931885, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:08<00:03,  3.23it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.19it/s]                                               {'loss': 0.2108, 'grad_norm': 2.820796489715576, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.19it/s]                                               {'loss': 0.0123, 'grad_norm': 0.8129672408103943, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.19it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.93it/s]                                               {'loss': 0.4263, 'grad_norm': 1.107052206993103, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.93it/s] 85%|████████▌ | 34/40 [00:09<00:01,  3.69it/s]                                               {'loss': 0.0909, 'grad_norm': 1.810058355331421, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:09<00:01,  3.69it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.0564, 'grad_norm': 1.424574375152588, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.50it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.1791, 'grad_norm': 4.907200813293457, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.37it/s] 92%|█████████▎| 37/40 [00:10<00:00,  3.33it/s]                                               {'loss': 0.0595, 'grad_norm': 1.3752788305282593, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:10<00:00,  3.33it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.26it/s]                                               {'loss': 0.2252, 'grad_norm': 7.358489036560059, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.26it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.4576, 'grad_norm': 1.3167140483856201, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0506, 'grad_norm': 2.3204517364501953, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.21it/s]                                               {'train_runtime': 11.7415, 'train_samples_per_second': 48.12, 'train_steps_per_second': 3.407, 'train_loss': 1.168924356927164, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.21it/s]100%|██████████| 40/40 [00:11<00:00,  3.41it/s]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 4.2911, 'grad_norm': 4.40300989151001, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]                                              {'loss': 3.3247, 'grad_norm': 3.479703187942505, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 3.2381, 'grad_norm': 4.499151229858398, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 3.5592, 'grad_norm': 4.324974060058594, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s]                                              {'loss': 2.9977, 'grad_norm': 5.077786445617676, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.07it/s]                                              {'loss': 3.9326, 'grad_norm': 7.244582653045654, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.07it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 3.0113, 'grad_norm': 7.24152135848999, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 7.4039, 'grad_norm': 30.938962936401367, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.06it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 1.6651, 'grad_norm': 6.9199042320251465, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 2.1273, 'grad_norm': 7.521032333374023, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.44it/s]                                               {'loss': 1.7813, 'grad_norm': 7.33143424987793, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.44it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 1.4944, 'grad_norm': 6.172784805297852, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.26it/s]                                               {'loss': 1.1375, 'grad_norm': 3.870227813720703, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.26it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.21it/s]                                               {'loss': 2.0324, 'grad_norm': 6.449129581451416, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.21it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.17it/s]                                               {'loss': 1.404, 'grad_norm': 4.956944942474365, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.17it/s]                                               {'loss': 1.5382, 'grad_norm': 23.697065353393555, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.17it/s] 42%|████▎     | 17/40 [00:04<00:05,  3.95it/s]                                               {'loss': 0.7278, 'grad_norm': 3.6722068786621094, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:04<00:05,  3.95it/s] 45%|████▌     | 18/40 [00:05<00:05,  3.71it/s]                                               {'loss': 0.5102, 'grad_norm': 4.285852432250977, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:05,  3.71it/s] 48%|████▊     | 19/40 [00:05<00:05,  3.52it/s]                                               {'loss': 0.461, 'grad_norm': 3.41402530670166, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:05,  3.52it/s] 50%|█████     | 20/40 [00:05<00:05,  3.38it/s]                                               {'loss': 0.169, 'grad_norm': 2.5769593715667725, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:05<00:05,  3.38it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.28it/s]                                               {'loss': 0.7355, 'grad_norm': 9.158284187316895, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.28it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.7888, 'grad_norm': 9.95787525177002, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.21it/s] 57%|█████▊    | 23/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.6309, 'grad_norm': 7.324507713317871, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.2932, 'grad_norm': 14.100432395935059, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:06<00:05,  3.17it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.94it/s]                                               {'loss': 0.1886, 'grad_norm': 2.6377012729644775, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.94it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.69it/s]                                               {'loss': 0.2149, 'grad_norm': 1.8249032497406006, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.69it/s] 68%|██████▊   | 27/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.1562, 'grad_norm': 2.231365919113159, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:07<00:03,  3.52it/s] 70%|███████   | 28/40 [00:08<00:03,  3.38it/s]                                               {'loss': 0.2745, 'grad_norm': 3.1993932723999023, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.38it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.0824, 'grad_norm': 1.774184226989746, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.29it/s] 75%|███████▌  | 30/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1347, 'grad_norm': 3.503180503845215, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:08<00:03,  3.22it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.17it/s]                                               {'loss': 0.2769, 'grad_norm': 9.940094947814941, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.17it/s]                                               {'loss': 0.1578, 'grad_norm': 18.993364334106445, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.17it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.95it/s]                                               {'loss': 0.0422, 'grad_norm': 0.8097946643829346, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.95it/s] 85%|████████▌ | 34/40 [00:09<00:01,  3.70it/s]                                               {'loss': 0.0666, 'grad_norm': 1.9875041246414185, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:09<00:01,  3.70it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.1681, 'grad_norm': 1.0842725038528442, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.50it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0565, 'grad_norm': 1.154727816581726, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.37it/s] 92%|█████████▎| 37/40 [00:10<00:00,  3.27it/s]                                               {'loss': 0.0587, 'grad_norm': 0.9219081997871399, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:10<00:00,  3.27it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.0504, 'grad_norm': 1.1934961080551147, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.19it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0457, 'grad_norm': 1.199833869934082, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0055, 'grad_norm': 0.6023461222648621, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.15it/s]                                               {'train_runtime': 11.8424, 'train_samples_per_second': 47.71, 'train_steps_per_second': 3.378, 'train_loss': 1.2808761680847964, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.15it/s]100%|██████████| 40/40 [00:11<00:00,  3.38it/s]
CLIENT:80
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]                                              {'loss': 3.0611, 'grad_norm': 3.123884916305542, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]  5%|▌         | 2/40 [00:00<00:12,  3.10it/s]                                              {'loss': 4.5866, 'grad_norm': 4.085151195526123, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.10it/s]  8%|▊         | 3/40 [00:00<00:11,  3.09it/s]                                              {'loss': 3.9192, 'grad_norm': 4.646786689758301, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.09it/s] 10%|█         | 4/40 [00:01<00:11,  3.07it/s]                                              {'loss': 3.6062, 'grad_norm': 4.780840873718262, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.07it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 4.2814, 'grad_norm': 8.966139793395996, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.7697, 'grad_norm': 5.043391227722168, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 2.6845, 'grad_norm': 6.6623053550720215, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 4.1813, 'grad_norm': 26.957950592041016, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s]                                              {'loss': 1.4817, 'grad_norm': 7.56878137588501, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 1.6981, 'grad_norm': 5.866373062133789, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s]                                               {'loss': 1.1964, 'grad_norm': 6.205358505249023, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s] 30%|███       | 12/40 [00:03<00:08,  3.20it/s]                                               {'loss': 1.2734, 'grad_norm': 6.280422687530518, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.20it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.1728, 'grad_norm': 4.917076110839844, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 1.809, 'grad_norm': 8.688411712646484, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 2.3466, 'grad_norm': 12.266633033752441, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.0264, 'grad_norm': 2.2436587810516357, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.8305, 'grad_norm': 3.8209640979766846, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 1.4116, 'grad_norm': 8.74702262878418, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.7841, 'grad_norm': 2.9829440116882324, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.7725, 'grad_norm': 4.9774980545043945, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.6768, 'grad_norm': 7.033771991729736, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.3258, 'grad_norm': 5.312541484832764, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.5335, 'grad_norm': 8.637906074523926, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.1497, 'grad_norm': 5.66689395904541, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s]                                               {'loss': 0.7488, 'grad_norm': 5.768129348754883, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s]                                               {'loss': 0.0646, 'grad_norm': 1.6503273248672485, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.4782, 'grad_norm': 3.313897132873535, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.4742, 'grad_norm': 4.347368240356445, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0646, 'grad_norm': 1.4597861766815186, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.2993, 'grad_norm': 9.98025131225586, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0815, 'grad_norm': 1.7492305040359497, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 6.0254, 'grad_norm': 4.838568210601807, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0116, 'grad_norm': 0.28562742471694946, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s]                                               {'loss': 0.3831, 'grad_norm': 0.8470500707626343, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s]                                               {'loss': 0.0293, 'grad_norm': 0.6511658430099487, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.33it/s]                                               {'loss': 0.5155, 'grad_norm': 2.233341693878174, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.33it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.1368, 'grad_norm': 2.8537752628326416, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0695, 'grad_norm': 2.6399431228637695, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.3855, 'grad_norm': 1.4242055416107178, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0148, 'grad_norm': 1.2194368839263916, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.1067, 'train_samples_per_second': 46.669, 'train_steps_per_second': 3.304, 'train_loss': 1.384041292942129, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:6
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 3.3302, 'grad_norm': 3.407243490219116, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]                                              {'loss': 4.847, 'grad_norm': 3.450558662414551, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.9751, 'grad_norm': 4.110311031341553, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 4.5215, 'grad_norm': 5.081755638122559, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.0355, 'grad_norm': 5.788843631744385, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s]                                              {'loss': 2.5442, 'grad_norm': 6.745741367340088, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 2.7547, 'grad_norm': 8.03587818145752, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 4.5313, 'grad_norm': 42.16334915161133, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.98it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s]                                              {'loss': 0.97, 'grad_norm': 5.3267998695373535, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 1.6646, 'grad_norm': 7.443818092346191, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 1.4972, 'grad_norm': 4.473812103271484, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.5411, 'grad_norm': 5.458197116851807, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.3287, 'grad_norm': 5.6731390953063965, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.1712, 'grad_norm': 5.610681533813477, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 1.7514, 'grad_norm': 7.158877372741699, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 4.0423, 'grad_norm': 39.891441345214844, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.05it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.5177, 'grad_norm': 3.273503541946411, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.532, 'grad_norm': 5.20681095123291, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s]                                               {'loss': 0.757, 'grad_norm': 2.0957560539245605, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.5684, 'grad_norm': 3.2640693187713623, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s]                                               {'loss': 0.616, 'grad_norm': 4.609193325042725, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.6372, 'grad_norm': 2.173179864883423, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.3136, 'grad_norm': 6.9282002449035645, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.0189, 'grad_norm': 0.9489348530769348, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.06it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.1687, 'grad_norm': 1.3351688385009766, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.0849, 'grad_norm': 1.5750728845596313, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s]                                               {'loss': 0.5071, 'grad_norm': 2.0380635261535645, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s] 70%|███████   | 28/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.0831, 'grad_norm': 1.5889899730682373, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.24it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.12it/s]                                               {'loss': 0.5222, 'grad_norm': 1.8498990535736084, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.12it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s]                                               {'loss': 0.0912, 'grad_norm': 2.513214588165283, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.03it/s]                                               {'loss': 0.2594, 'grad_norm': 2.8729729652404785, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.03it/s]                                               {'loss': 0.0971, 'grad_norm': 4.811411380767822, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.03it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s]                                               {'loss': 0.0519, 'grad_norm': 0.8288702368736267, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.47it/s]                                               {'loss': 0.0314, 'grad_norm': 0.8569032549858093, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.47it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s]                                               {'loss': 0.5466, 'grad_norm': 0.736724317073822, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.19it/s]                                               {'loss': 0.0287, 'grad_norm': 0.6772885918617249, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.19it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.132, 'grad_norm': 0.6083125472068787, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.10it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.4408, 'grad_norm': 3.032933235168457, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.06it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.02it/s]                                               {'loss': 0.0553, 'grad_norm': 1.3273444175720215, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.02it/s]                                               {'loss': 0.0016, 'grad_norm': 0.07777142524719238, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.02it/s]                                               {'train_runtime': 12.3186, 'train_samples_per_second': 45.866, 'train_steps_per_second': 3.247, 'train_loss': 1.2642140613752417, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.02it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
CLIENT:12
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.92it/s]                                              {'loss': 4.0327, 'grad_norm': 4.195858478546143, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.92it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 4.7461, 'grad_norm': 4.126097679138184, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:01<00:12,  2.98it/s]                                              {'loss': 3.8579, 'grad_norm': 4.104744911193848, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.98it/s] 10%|█         | 4/40 [00:01<00:12,  2.97it/s]                                              {'loss': 4.301, 'grad_norm': 5.1630473136901855, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.97it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s]                                              {'loss': 2.6936, 'grad_norm': 4.992299556732178, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s]                                              {'loss': 3.0639, 'grad_norm': 5.596804141998291, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 3.0537, 'grad_norm': 5.222098350524902, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 2.8869, 'grad_norm': 21.10659408569336, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.97it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 2.1225, 'grad_norm': 6.6073455810546875, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 1.737, 'grad_norm': 4.2086920738220215, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 0.9352, 'grad_norm': 5.797799587249756, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.23it/s]                                               {'loss': 1.3064, 'grad_norm': 5.425283908843994, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.23it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.598, 'grad_norm': 5.844926834106445, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.1005, 'grad_norm': 5.663321018218994, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 1.2538, 'grad_norm': 7.0079755783081055, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.2258, 'grad_norm': 7.578365802764893, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s]                                               {'loss': 0.4653, 'grad_norm': 6.644822120666504, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.50it/s]                                               {'loss': 0.2527, 'grad_norm': 2.992086410522461, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.50it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.34it/s]                                               {'loss': 1.0122, 'grad_norm': 2.4004640579223633, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.34it/s] 50%|█████     | 20/40 [00:06<00:06,  3.22it/s]                                               {'loss': 0.3689, 'grad_norm': 8.914076805114746, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.22it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.5958, 'grad_norm': 8.443166732788086, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.5161, 'grad_norm': 5.171742916107178, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.4014, 'grad_norm': 4.138257026672363, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.2301, 'grad_norm': 10.022412300109863, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.75it/s]                                               {'loss': 0.0635, 'grad_norm': 1.0024487972259521, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.75it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.1221, 'grad_norm': 1.7181029319763184, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.1359, 'grad_norm': 2.355869770050049, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.5268, 'grad_norm': 2.0731308460235596, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.7298, 'grad_norm': 4.938488960266113, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.1047, 'grad_norm': 2.5822463035583496, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.2707, 'grad_norm': 5.775442123413086, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.0034, 'grad_norm': 0.1439855843782425, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.70it/s]                                               {'loss': 0.4554, 'grad_norm': 1.1163358688354492, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.70it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s]                                               {'loss': 0.0222, 'grad_norm': 0.3210068941116333, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0501, 'grad_norm': 1.2345495223999023, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.21it/s]                                               {'loss': 0.0427, 'grad_norm': 1.427489995956421, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.21it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.4986, 'grad_norm': 1.2581615447998047, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0479, 'grad_norm': 1.2863948345184326, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.06it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.01it/s]                                               {'loss': 0.0782, 'grad_norm': 1.908225417137146, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.01it/s]                                               {'loss': 0.0184, 'grad_norm': 1.1334255933761597, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.01it/s]                                               {'train_runtime': 12.3348, 'train_samples_per_second': 45.806, 'train_steps_per_second': 3.243, 'train_loss': 1.1482012535212562, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.01it/s]100%|██████████| 40/40 [00:12<00:00,  3.24it/s]
CLIENT:43
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.93it/s]                                              {'loss': 2.9102, 'grad_norm': 4.003530025482178, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.93it/s]  5%|▌         | 2/40 [00:00<00:13,  2.91it/s]                                              {'loss': 3.749, 'grad_norm': 3.398791551589966, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:13,  2.91it/s]  8%|▊         | 3/40 [00:01<00:12,  2.99it/s]                                              {'loss': 4.0519, 'grad_norm': 4.284541606903076, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.99it/s] 10%|█         | 4/40 [00:01<00:12,  2.98it/s]                                              {'loss': 3.5546, 'grad_norm': 4.474362373352051, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.98it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s]                                              {'loss': 3.4529, 'grad_norm': 5.80678653717041, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s]                                              {'loss': 3.0682, 'grad_norm': 5.835208415985107, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.94it/s]                                              {'loss': 3.181, 'grad_norm': 7.785178184509277, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.94it/s]                                              {'loss': 5.2085, 'grad_norm': 31.787750244140625, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.94it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s]                                              {'loss': 1.4743, 'grad_norm': 6.341180801391602, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.46it/s]                                               {'loss': 1.3325, 'grad_norm': 6.324694633483887, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.46it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.31it/s]                                               {'loss': 1.7159, 'grad_norm': 6.678854465484619, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.31it/s] 30%|███       | 12/40 [00:03<00:08,  3.22it/s]                                               {'loss': 2.2154, 'grad_norm': 10.343058586120605, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.22it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.6342, 'grad_norm': 6.146773815155029, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.9645, 'grad_norm': 7.155757904052734, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.5824, 'grad_norm': 4.7790846824646, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.2541, 'grad_norm': 6.918476581573486, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.873, 'grad_norm': 5.764878749847412, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s]                                               {'loss': 0.4562, 'grad_norm': 4.4936652183532715, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s]                                               {'loss': 0.9667, 'grad_norm': 4.550989151000977, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s] 50%|█████     | 20/40 [00:06<00:06,  3.23it/s]                                               {'loss': 0.6383, 'grad_norm': 5.277395248413086, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.23it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.5891, 'grad_norm': 1.9982726573944092, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.3112, 'grad_norm': 2.688530206680298, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.03it/s]                                               {'loss': 0.7488, 'grad_norm': 6.890556335449219, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.03it/s]                                               {'loss': 0.159, 'grad_norm': 4.714382171630859, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.03it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s]                                               {'loss': 0.3801, 'grad_norm': 5.937298774719238, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s]                                               {'loss': 0.1354, 'grad_norm': 1.9988439083099365, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.32it/s]                                               {'loss': 0.5908, 'grad_norm': 3.368077516555786, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.32it/s] 70%|███████   | 28/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.606, 'grad_norm': 4.215972900390625, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.22it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s]                                               {'loss': 0.3188, 'grad_norm': 5.257776737213135, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s]                                               {'loss': 0.0553, 'grad_norm': 0.8018673658370972, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.02it/s]                                               {'loss': 0.3402, 'grad_norm': 5.435207366943359, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.02it/s]                                               {'loss': 0.0655, 'grad_norm': 3.002676486968994, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.02it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.73it/s]                                               {'loss': 0.4464, 'grad_norm': 1.0608267784118652, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.73it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.0858, 'grad_norm': 1.5373547077178955, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0576, 'grad_norm': 1.2015291452407837, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.21it/s]                                               {'loss': 0.4668, 'grad_norm': 2.6369268894195557, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.21it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.098, 'grad_norm': 2.292097330093384, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.2044, 'grad_norm': 5.4704413414001465, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.05it/s] 98%|█████████▊| 39/40 [00:12<00:00,  2.98it/s]                                               {'loss': 0.2232, 'grad_norm': 2.02520751953125, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  2.98it/s]100%|██████████| 40/40 [00:12<00:00,  3.73it/s]                                               {'loss': 0.06, 'grad_norm': 4.339295387268066, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.73it/s]                                               {'train_runtime': 12.5268, 'train_samples_per_second': 45.103, 'train_steps_per_second': 3.193, 'train_loss': 1.2056542092002929, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.73it/s]100%|██████████| 40/40 [00:12<00:00,  3.19it/s]
CLIENT:17
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]                                              {'loss': 4.2947, 'grad_norm': 4.048521041870117, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 3.7364, 'grad_norm': 3.361276388168335, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  2.94it/s]                                              {'loss': 2.4485, 'grad_norm': 2.9035849571228027, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.94it/s] 10%|█         | 4/40 [00:01<00:12,  2.97it/s]                                              {'loss': 3.7176, 'grad_norm': 4.602209091186523, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.97it/s] 12%|█▎        | 5/40 [00:01<00:12,  2.90it/s]                                              {'loss': 2.9191, 'grad_norm': 5.861562252044678, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:12,  2.90it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.91it/s]                                              {'loss': 3.3227, 'grad_norm': 5.957695484161377, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.91it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.91it/s]                                              {'loss': 2.5558, 'grad_norm': 5.939383029937744, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.91it/s]                                              {'loss': 6.1594, 'grad_norm': 32.34744644165039, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.91it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s]                                              {'loss': 1.8592, 'grad_norm': 5.270320415496826, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s]                                               {'loss': 1.1846, 'grad_norm': 5.9294209480285645, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s]                                               {'loss': 1.3825, 'grad_norm': 4.883949279785156, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s] 30%|███       | 12/40 [00:03<00:08,  3.20it/s]                                               {'loss': 1.2146, 'grad_norm': 5.770567893981934, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.20it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.224, 'grad_norm': 6.178366184234619, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.10it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.03it/s]                                               {'loss': 1.0063, 'grad_norm': 5.191737174987793, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.03it/s] 38%|███▊      | 15/40 [00:04<00:08,  2.98it/s]                                               {'loss': 1.3206, 'grad_norm': 7.937144756317139, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  2.98it/s]                                               {'loss': 0.0318, 'grad_norm': 1.7574316263198853, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:08,  2.98it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.69it/s]                                               {'loss': 0.7952, 'grad_norm': 3.1367318630218506, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.69it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.45it/s]                                               {'loss': 0.3228, 'grad_norm': 3.739741563796997, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.45it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.28it/s]                                               {'loss': 0.4176, 'grad_norm': 4.359410762786865, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.28it/s] 50%|█████     | 20/40 [00:06<00:06,  3.17it/s]                                               {'loss': 0.7663, 'grad_norm': 6.186360836029053, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.17it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.08it/s]                                               {'loss': 0.2521, 'grad_norm': 3.890604257583618, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.08it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.04it/s]                                               {'loss': 0.6003, 'grad_norm': 6.200778961181641, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.04it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s]                                               {'loss': 0.5717, 'grad_norm': 4.751101493835449, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s]                                               {'loss': 0.2339, 'grad_norm': 11.024656295776367, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.02it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s]                                               {'loss': 0.1737, 'grad_norm': 2.9351561069488525, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s] 65%|██████▌   | 26/40 [00:08<00:03,  3.51it/s]                                               {'loss': 0.2403, 'grad_norm': 1.5387428998947144, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:08<00:03,  3.51it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.3316, 'grad_norm': 6.676177978515625, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s] 70%|███████   | 28/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.5091, 'grad_norm': 5.495706558227539, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.22it/s] 72%|███████▎  | 29/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.1344, 'grad_norm': 2.238529920578003, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:09<00:03,  3.12it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s]                                               {'loss': 0.4321, 'grad_norm': 1.1303319931030273, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.01it/s]                                               {'loss': 0.2665, 'grad_norm': 1.1307039260864258, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.01it/s]                                               {'loss': 0.0485, 'grad_norm': 1.7236741781234741, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.01it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.72it/s]                                               {'loss': 0.0437, 'grad_norm': 0.8499739170074463, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.72it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.49it/s]                                               {'loss': 0.404, 'grad_norm': 0.6511175036430359, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.49it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.0293, 'grad_norm': 0.8620190024375916, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.31it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.20it/s]                                               {'loss': 0.3601, 'grad_norm': 2.9291155338287354, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.20it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.3037, 'grad_norm': 1.6419672966003418, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.12it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.0425, 'grad_norm': 1.33868408203125, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.05it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.00it/s]                                               {'loss': 0.0375, 'grad_norm': 0.8404830694198608, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.00it/s]                                               {'loss': 0.0129, 'grad_norm': 0.6162480115890503, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.00it/s]                                               {'train_runtime': 12.4973, 'train_samples_per_second': 45.21, 'train_steps_per_second': 3.201, 'train_loss': 1.142685428704135, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.00it/s]100%|██████████| 40/40 [00:12<00:00,  3.20it/s]
CLIENT:7
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.92it/s]                                              {'loss': 4.1754, 'grad_norm': 4.493886470794678, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.92it/s]  5%|▌         | 2/40 [00:00<00:12,  2.95it/s]                                              {'loss': 3.349, 'grad_norm': 3.3857715129852295, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.95it/s]  8%|▊         | 3/40 [00:01<00:12,  3.01it/s]                                              {'loss': 4.374, 'grad_norm': 5.5653276443481445, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 4.6542, 'grad_norm': 4.813882827758789, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.96it/s]                                              {'loss': 2.9173, 'grad_norm': 5.1959919929504395, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.96it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s]                                              {'loss': 2.1343, 'grad_norm': 6.091527938842773, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 4.0358, 'grad_norm': 7.879971981048584, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 0.3523, 'grad_norm': 9.311988830566406, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.97it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s]                                              {'loss': 1.9685, 'grad_norm': 6.3450608253479, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 1.2607, 'grad_norm': 4.733999729156494, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 1.2787, 'grad_norm': 7.776546478271484, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.22it/s]                                               {'loss': 0.8449, 'grad_norm': 5.369333267211914, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.22it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.13it/s]                                               {'loss': 2.3537, 'grad_norm': 10.79895305633545, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.13it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.8656, 'grad_norm': 8.902442932128906, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.06it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 2.6805, 'grad_norm': 10.664519309997559, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.3991, 'grad_norm': 10.669198036193848, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 1.1629, 'grad_norm': 5.777310371398926, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s]                                               {'loss': 0.3378, 'grad_norm': 6.529853820800781, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.33it/s]                                               {'loss': 1.0761, 'grad_norm': 5.7154669761657715, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.33it/s] 50%|█████     | 20/40 [00:06<00:06,  3.22it/s]                                               {'loss': 1.3623, 'grad_norm': 7.075964450836182, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.22it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s]                                               {'loss': 0.8665, 'grad_norm': 7.23858118057251, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.05it/s]                                               {'loss': 0.7025, 'grad_norm': 8.909956932067871, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.05it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s]                                               {'loss': 0.7999, 'grad_norm': 5.113103866577148, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s]                                               {'loss': 0.1045, 'grad_norm': 6.159769535064697, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.02it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.65it/s]                                               {'loss': 0.3666, 'grad_norm': 6.253191947937012, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.65it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.44it/s]                                               {'loss': 0.8887, 'grad_norm': 11.262391090393066, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.44it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.5009, 'grad_norm': 10.164546966552734, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.27it/s] 70%|███████   | 28/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.7407, 'grad_norm': 10.233736991882324, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.16it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.09it/s]                                               {'loss': 0.0953, 'grad_norm': 1.8419933319091797, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.09it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.03it/s]                                               {'loss': 0.4285, 'grad_norm': 5.279602527618408, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.03it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.00it/s]                                               {'loss': 0.5407, 'grad_norm': 2.164680004119873, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.00it/s]                                               {'loss': 0.0656, 'grad_norm': 2.308519124984741, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.00it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.71it/s]                                               {'loss': 0.1881, 'grad_norm': 2.423274278640747, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.71it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.3799, 'grad_norm': 3.056157350540161, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s]                                               {'loss': 0.1489, 'grad_norm': 3.747846841812134, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.20it/s]                                               {'loss': 0.5309, 'grad_norm': 4.732675075531006, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.20it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.5123, 'grad_norm': 3.960918426513672, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.10it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.1495, 'grad_norm': 2.6254820823669434, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.04it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.01it/s]                                               {'loss': 0.1042, 'grad_norm': 2.5520009994506836, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.01it/s]                                               {'loss': 0.2283, 'grad_norm': 8.520661354064941, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.01it/s]                                               {'train_runtime': 12.4356, 'train_samples_per_second': 45.434, 'train_steps_per_second': 3.217, 'train_loss': 1.2731426691636443, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.01it/s]100%|██████████| 40/40 [00:12<00:00,  3.22it/s]
CLIENT:8
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.91it/s]                                              {'loss': 3.7552, 'grad_norm': 4.156091213226318, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.91it/s]  5%|▌         | 2/40 [00:00<00:13,  2.91it/s]                                              {'loss': 3.2903, 'grad_norm': 3.7179884910583496, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:13,  2.91it/s]  8%|▊         | 3/40 [00:01<00:12,  2.95it/s]                                              {'loss': 3.0594, 'grad_norm': 3.4276695251464844, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.95it/s] 10%|█         | 4/40 [00:01<00:12,  2.97it/s]                                              {'loss': 4.1795, 'grad_norm': 4.447932243347168, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.97it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s]                                              {'loss': 3.9063, 'grad_norm': 5.641319751739502, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s]                                              {'loss': 3.198, 'grad_norm': 5.316339492797852, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.94it/s]                                              {'loss': 2.8658, 'grad_norm': 6.3663105964660645, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.94it/s]                                              {'loss': 1.1715, 'grad_norm': 20.019981384277344, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.94it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s]                                              {'loss': 1.0802, 'grad_norm': 4.921961784362793, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.46it/s]                                               {'loss': 0.9504, 'grad_norm': 4.6000075340271, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.46it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s]                                               {'loss': 1.2618, 'grad_norm': 5.612311363220215, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s] 30%|███       | 12/40 [00:03<00:08,  3.20it/s]                                               {'loss': 1.9951, 'grad_norm': 6.906793594360352, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.20it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.9267, 'grad_norm': 7.081954002380371, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.12it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s]                                               {'loss': 2.0972, 'grad_norm': 6.510212421417236, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s]                                               {'loss': 1.4236, 'grad_norm': 6.081068992614746, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s]                                               {'loss': 0.4321, 'grad_norm': 14.63045597076416, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.03it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.5965, 'grad_norm': 3.33746600151062, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s]                                               {'loss': 0.7454, 'grad_norm': 4.819118976593018, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s]                                               {'loss': 0.3876, 'grad_norm': 3.2011542320251465, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s] 50%|█████     | 20/40 [00:06<00:06,  3.23it/s]                                               {'loss': 0.4088, 'grad_norm': 4.2873053550720215, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.23it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s]                                               {'loss': 0.7369, 'grad_norm': 6.76901388168335, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s]                                               {'loss': 0.5529, 'grad_norm': 8.646735191345215, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 1.036, 'grad_norm': 6.097874164581299, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.3102, 'grad_norm': 19.543642044067383, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.04it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.3673, 'grad_norm': 15.888202667236328, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.2667, 'grad_norm': 12.298824310302734, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.1885, 'grad_norm': 6.081087112426758, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.6309, 'grad_norm': 5.252040386199951, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.24it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.14it/s]                                               {'loss': 0.2582, 'grad_norm': 8.395418167114258, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.14it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.07it/s]                                               {'loss': 0.0815, 'grad_norm': 1.6127673387527466, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.07it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.02it/s]                                               {'loss': 0.1251, 'grad_norm': 2.5707039833068848, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.02it/s]                                               {'loss': 0.0276, 'grad_norm': 1.3358370065689087, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.02it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.72it/s]                                               {'loss': 0.0987, 'grad_norm': 1.240570068359375, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.72it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.47it/s]                                               {'loss': 0.3937, 'grad_norm': 1.4963278770446777, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.47it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.0532, 'grad_norm': 0.8618552684783936, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.31it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.17it/s]                                               {'loss': 0.0411, 'grad_norm': 0.6080962419509888, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.17it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.1727, 'grad_norm': 3.2353780269622803, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.08it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.1511, 'grad_norm': 3.07142972946167, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.04it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.02it/s]                                               {'loss': 0.1594, 'grad_norm': 4.031628608703613, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.02it/s]                                               {'loss': 0.0052, 'grad_norm': 0.4731141924858093, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.02it/s]                                               {'train_runtime': 12.3822, 'train_samples_per_second': 45.63, 'train_steps_per_second': 3.23, 'train_loss': 1.1097071772324854, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.02it/s]100%|██████████| 40/40 [00:12<00:00,  3.23it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:43, 10.74it/s]  1%|          | 4/471 [00:00<01:09,  6.73it/s]  1%|          | 5/471 [00:00<01:14,  6.21it/s]  1%|▏         | 6/471 [00:00<01:18,  5.91it/s]  1%|▏         | 7/471 [00:01<01:21,  5.72it/s]  2%|▏         | 8/471 [00:01<01:22,  5.60it/s]  2%|▏         | 9/471 [00:01<01:23,  5.51it/s]  2%|▏         | 10/471 [00:01<01:24,  5.45it/s]  2%|▏         | 11/471 [00:01<01:25,  5.40it/s]  3%|▎         | 12/471 [00:02<01:25,  5.36it/s]  3%|▎         | 13/471 [00:02<01:25,  5.34it/s]  3%|▎         | 14/471 [00:02<01:25,  5.33it/s]  3%|▎         | 15/471 [00:02<01:25,  5.32it/s]  3%|▎         | 16/471 [00:02<01:25,  5.30it/s]  4%|▎         | 17/471 [00:03<01:25,  5.30it/s]  4%|▍         | 18/471 [00:03<01:25,  5.29it/s]  4%|▍         | 19/471 [00:03<01:25,  5.29it/s]  4%|▍         | 20/471 [00:03<01:25,  5.29it/s]  4%|▍         | 21/471 [00:03<01:25,  5.28it/s]  5%|▍         | 22/471 [00:03<01:25,  5.27it/s]  5%|▍         | 23/471 [00:04<01:24,  5.28it/s]  5%|▌         | 24/471 [00:04<01:24,  5.27it/s]  5%|▌         | 25/471 [00:04<01:24,  5.29it/s]  6%|▌         | 26/471 [00:04<01:24,  5.29it/s]  6%|▌         | 27/471 [00:04<01:24,  5.29it/s]  6%|▌         | 28/471 [00:05<01:24,  5.26it/s]  6%|▌         | 29/471 [00:05<01:23,  5.29it/s]  6%|▋         | 30/471 [00:05<01:23,  5.28it/s]  7%|▋         | 31/471 [00:05<01:23,  5.28it/s]  7%|▋         | 32/471 [00:05<01:22,  5.30it/s]  7%|▋         | 33/471 [00:06<01:22,  5.33it/s]  7%|▋         | 34/471 [00:06<01:21,  5.33it/s]  7%|▋         | 35/471 [00:06<01:22,  5.32it/s]  8%|▊         | 36/471 [00:06<01:21,  5.32it/s]  8%|▊         | 37/471 [00:06<01:21,  5.31it/s]  8%|▊         | 38/471 [00:06<01:21,  5.30it/s]  8%|▊         | 39/471 [00:07<01:21,  5.30it/s]  8%|▊         | 40/471 [00:07<01:21,  5.29it/s]  9%|▊         | 41/471 [00:07<01:21,  5.28it/s]  9%|▉         | 42/471 [00:07<01:21,  5.28it/s]  9%|▉         | 43/471 [00:07<01:20,  5.28it/s]  9%|▉         | 44/471 [00:08<01:20,  5.30it/s] 10%|▉         | 45/471 [00:08<01:20,  5.30it/s] 10%|▉         | 46/471 [00:08<01:20,  5.29it/s] 10%|▉         | 47/471 [00:08<01:19,  5.30it/s] 10%|█         | 48/471 [00:08<01:19,  5.30it/s] 10%|█         | 49/471 [00:09<01:19,  5.29it/s] 11%|█         | 50/471 [00:09<01:19,  5.28it/s] 11%|█         | 51/471 [00:09<01:19,  5.28it/s] 11%|█         | 52/471 [00:09<01:19,  5.28it/s] 11%|█▏        | 53/471 [00:09<01:19,  5.27it/s] 11%|█▏        | 54/471 [00:10<01:19,  5.27it/s] 12%|█▏        | 55/471 [00:10<01:18,  5.27it/s] 12%|█▏        | 56/471 [00:10<01:18,  5.26it/s] 12%|█▏        | 57/471 [00:10<01:18,  5.27it/s] 12%|█▏        | 58/471 [00:10<01:18,  5.27it/s] 13%|█▎        | 59/471 [00:10<01:18,  5.26it/s] 13%|█▎        | 60/471 [00:11<01:17,  5.27it/s] 13%|█▎        | 61/471 [00:11<01:17,  5.27it/s] 13%|█▎        | 62/471 [00:11<01:17,  5.27it/s] 13%|█▎        | 63/471 [00:11<01:17,  5.27it/s] 14%|█▎        | 64/471 [00:11<01:17,  5.27it/s] 14%|█▍        | 65/471 [00:12<01:17,  5.27it/s] 14%|█▍        | 66/471 [00:12<01:16,  5.26it/s] 14%|█▍        | 67/471 [00:12<01:16,  5.26it/s] 14%|█▍        | 68/471 [00:12<01:16,  5.26it/s] 15%|█▍        | 69/471 [00:12<01:16,  5.26it/s] 15%|█▍        | 70/471 [00:13<01:16,  5.25it/s] 15%|█▌        | 71/471 [00:13<01:16,  5.25it/s] 15%|█▌        | 72/471 [00:13<01:15,  5.27it/s] 15%|█▌        | 73/471 [00:13<01:15,  5.26it/s] 16%|█▌        | 74/471 [00:13<01:15,  5.27it/s] 16%|█▌        | 75/471 [00:14<01:15,  5.25it/s] 16%|█▌        | 76/471 [00:14<01:14,  5.27it/s] 16%|█▋        | 77/471 [00:14<01:14,  5.26it/s] 17%|█▋        | 78/471 [00:14<01:14,  5.27it/s] 17%|█▋        | 79/471 [00:14<01:14,  5.25it/s] 17%|█▋        | 80/471 [00:14<01:14,  5.25it/s] 17%|█▋        | 81/471 [00:15<01:13,  5.27it/s] 17%|█▋        | 82/471 [00:15<01:13,  5.29it/s] 18%|█▊        | 83/471 [00:15<01:13,  5.26it/s] 18%|█▊        | 84/471 [00:15<01:13,  5.28it/s] 18%|█▊        | 85/471 [00:15<01:13,  5.28it/s] 18%|█▊        | 86/471 [00:16<01:12,  5.28it/s] 18%|█▊        | 87/471 [00:16<01:12,  5.29it/s] 19%|█▊        | 88/471 [00:16<01:12,  5.29it/s] 19%|█▉        | 89/471 [00:16<01:12,  5.28it/s] 19%|█▉        | 90/471 [00:16<01:12,  5.27it/s] 19%|█▉        | 91/471 [00:17<01:11,  5.28it/s] 20%|█▉        | 92/471 [00:17<01:11,  5.28it/s] 20%|█▉        | 93/471 [00:17<01:11,  5.28it/s] 20%|█▉        | 94/471 [00:17<01:11,  5.28it/s] 20%|██        | 95/471 [00:17<01:11,  5.29it/s] 20%|██        | 96/471 [00:17<01:11,  5.27it/s] 21%|██        | 97/471 [00:18<01:10,  5.27it/s] 21%|██        | 98/471 [00:18<01:10,  5.27it/s] 21%|██        | 99/471 [00:18<01:10,  5.28it/s] 21%|██        | 100/471 [00:18<01:09,  5.30it/s] 21%|██▏       | 101/471 [00:18<01:09,  5.29it/s] 22%|██▏       | 102/471 [00:19<01:09,  5.28it/s] 22%|██▏       | 103/471 [00:19<01:09,  5.26it/s] 22%|██▏       | 104/471 [00:19<01:09,  5.25it/s] 22%|██▏       | 105/471 [00:19<01:09,  5.25it/s] 23%|██▎       | 106/471 [00:19<01:09,  5.28it/s] 23%|██▎       | 107/471 [00:20<01:08,  5.28it/s] 23%|██▎       | 108/471 [00:20<01:08,  5.27it/s] 23%|██▎       | 109/471 [00:20<01:08,  5.28it/s] 23%|██▎       | 110/471 [00:20<01:08,  5.29it/s] 24%|██▎       | 111/471 [00:20<01:08,  5.29it/s] 24%|██▍       | 112/471 [00:21<01:08,  5.27it/s] 24%|██▍       | 113/471 [00:21<01:07,  5.29it/s] 24%|██▍       | 114/471 [00:21<01:07,  5.26it/s] 24%|██▍       | 115/471 [00:21<01:07,  5.26it/s] 25%|██▍       | 116/471 [00:21<01:07,  5.27it/s] 25%|██▍       | 117/471 [00:21<01:07,  5.26it/s] 25%|██▌       | 118/471 [00:22<01:07,  5.24it/s] 25%|██▌       | 119/471 [00:22<01:07,  5.25it/s] 25%|██▌       | 120/471 [00:22<01:06,  5.25it/s] 26%|██▌       | 121/471 [00:22<01:06,  5.25it/s] 26%|██▌       | 122/471 [00:22<01:06,  5.27it/s] 26%|██▌       | 123/471 [00:23<01:06,  5.27it/s] 26%|██▋       | 124/471 [00:23<01:06,  5.25it/s] 27%|██▋       | 125/471 [00:23<01:05,  5.26it/s] 27%|██▋       | 126/471 [00:23<01:05,  5.25it/s] 27%|██▋       | 127/471 [00:23<01:05,  5.27it/s] 27%|██▋       | 128/471 [00:24<01:05,  5.27it/s] 27%|██▋       | 129/471 [00:24<01:04,  5.27it/s] 28%|██▊       | 130/471 [00:24<01:04,  5.26it/s] 28%|██▊       | 131/471 [00:24<01:04,  5.26it/s] 28%|██▊       | 132/471 [00:24<01:04,  5.25it/s] 28%|██▊       | 133/471 [00:25<01:04,  5.26it/s] 28%|██▊       | 134/471 [00:25<01:04,  5.25it/s] 29%|██▊       | 135/471 [00:25<01:03,  5.25it/s] 29%|██▉       | 136/471 [00:25<01:03,  5.25it/s] 29%|██▉       | 137/471 [00:25<01:03,  5.26it/s] 29%|██▉       | 138/471 [00:25<01:03,  5.25it/s] 30%|██▉       | 139/471 [00:26<01:03,  5.26it/s] 30%|██▉       | 140/471 [00:26<01:03,  5.25it/s] 30%|██▉       | 141/471 [00:26<01:02,  5.27it/s] 30%|███       | 142/471 [00:26<01:02,  5.28it/s] 30%|███       | 143/471 [00:26<01:02,  5.27it/s] 31%|███       | 144/471 [00:27<01:02,  5.26it/s] 31%|███       | 145/471 [00:27<01:01,  5.27it/s] 31%|███       | 146/471 [00:27<01:01,  5.27it/s] 31%|███       | 147/471 [00:27<01:01,  5.27it/s] 31%|███▏      | 148/471 [00:27<01:01,  5.27it/s] 32%|███▏      | 149/471 [00:28<01:01,  5.25it/s] 32%|███▏      | 150/471 [00:28<01:01,  5.25it/s] 32%|███▏      | 151/471 [00:28<01:00,  5.25it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.25it/s] 32%|███▏      | 153/471 [00:28<01:00,  5.25it/s] 33%|███▎      | 154/471 [00:29<01:00,  5.27it/s] 33%|███▎      | 155/471 [00:29<00:59,  5.27it/s] 33%|███▎      | 156/471 [00:29<00:59,  5.28it/s] 33%|███▎      | 157/471 [00:29<00:59,  5.28it/s] 34%|███▎      | 158/471 [00:29<00:59,  5.30it/s] 34%|███▍      | 159/471 [00:29<00:59,  5.28it/s] 34%|███▍      | 160/471 [00:30<00:58,  5.28it/s] 34%|███▍      | 161/471 [00:30<00:58,  5.27it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.25it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.25it/s] 35%|███▍      | 164/471 [00:30<00:58,  5.26it/s] 35%|███▌      | 165/471 [00:31<00:58,  5.27it/s] 35%|███▌      | 166/471 [00:31<00:58,  5.25it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.25it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.25it/s] 36%|███▌      | 169/471 [00:31<00:57,  5.24it/s] 36%|███▌      | 170/471 [00:32<00:57,  5.25it/s] 36%|███▋      | 171/471 [00:32<00:57,  5.26it/s] 37%|███▋      | 172/471 [00:32<00:56,  5.26it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.25it/s] 37%|███▋      | 174/471 [00:32<00:56,  5.24it/s] 37%|███▋      | 175/471 [00:32<00:56,  5.24it/s] 37%|███▋      | 176/471 [00:33<00:56,  5.24it/s] 38%|███▊      | 177/471 [00:33<00:56,  5.24it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.25it/s] 38%|███▊      | 179/471 [00:33<00:55,  5.25it/s] 38%|███▊      | 180/471 [00:33<00:55,  5.25it/s] 38%|███▊      | 181/471 [00:34<00:55,  5.25it/s] 39%|███▊      | 182/471 [00:34<00:55,  5.25it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.26it/s] 39%|███▉      | 184/471 [00:34<00:54,  5.26it/s] 39%|███▉      | 185/471 [00:34<00:54,  5.25it/s] 39%|███▉      | 186/471 [00:35<00:54,  5.24it/s] 40%|███▉      | 187/471 [00:35<00:54,  5.24it/s] 40%|███▉      | 188/471 [00:35<00:53,  5.24it/s] 40%|████      | 189/471 [00:35<00:53,  5.25it/s] 40%|████      | 190/471 [00:35<00:53,  5.26it/s] 41%|████      | 191/471 [00:36<00:53,  5.23it/s] 41%|████      | 192/471 [00:36<00:53,  5.24it/s] 41%|████      | 193/471 [00:36<00:52,  5.28it/s] 41%|████      | 194/471 [00:36<00:52,  5.28it/s] 41%|████▏     | 195/471 [00:36<00:52,  5.27it/s] 42%|████▏     | 196/471 [00:36<00:52,  5.26it/s] 42%|████▏     | 197/471 [00:37<00:51,  5.27it/s] 42%|████▏     | 198/471 [00:37<00:51,  5.28it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.27it/s] 42%|████▏     | 200/471 [00:37<00:51,  5.27it/s] 43%|████▎     | 201/471 [00:37<00:51,  5.28it/s] 43%|████▎     | 202/471 [00:38<00:51,  5.27it/s] 43%|████▎     | 203/471 [00:38<00:51,  5.25it/s] 43%|████▎     | 204/471 [00:38<00:50,  5.26it/s] 44%|████▎     | 205/471 [00:38<00:50,  5.27it/s] 44%|████▎     | 206/471 [00:38<00:50,  5.27it/s] 44%|████▍     | 207/471 [00:39<00:50,  5.26it/s] 44%|████▍     | 208/471 [00:39<00:49,  5.28it/s] 44%|████▍     | 209/471 [00:39<00:49,  5.30it/s] 45%|████▍     | 210/471 [00:39<00:49,  5.30it/s] 45%|████▍     | 211/471 [00:39<00:49,  5.29it/s] 45%|████▌     | 212/471 [00:40<00:49,  5.28it/s] 45%|████▌     | 213/471 [00:40<00:49,  5.26it/s] 45%|████▌     | 214/471 [00:40<00:48,  5.27it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.26it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.25it/s] 46%|████▌     | 217/471 [00:40<00:48,  5.25it/s] 46%|████▋     | 218/471 [00:41<00:48,  5.24it/s] 46%|████▋     | 219/471 [00:41<00:48,  5.24it/s] 47%|████▋     | 220/471 [00:41<00:47,  5.24it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.23it/s] 47%|████▋     | 222/471 [00:41<00:47,  5.24it/s] 47%|████▋     | 223/471 [00:42<00:47,  5.25it/s] 48%|████▊     | 224/471 [00:42<00:47,  5.24it/s] 48%|████▊     | 225/471 [00:42<00:46,  5.25it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.24it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.25it/s] 48%|████▊     | 228/471 [00:43<00:46,  5.25it/s] 49%|████▊     | 229/471 [00:43<00:46,  5.24it/s] 49%|████▉     | 230/471 [00:43<00:45,  5.24it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.24it/s] 49%|████▉     | 232/471 [00:43<00:45,  5.26it/s] 49%|████▉     | 233/471 [00:44<00:45,  5.27it/s] 50%|████▉     | 234/471 [00:44<00:45,  5.25it/s] 50%|████▉     | 235/471 [00:44<00:45,  5.24it/s] 50%|█████     | 236/471 [00:44<00:44,  5.25it/s] 50%|█████     | 237/471 [00:44<00:44,  5.24it/s] 51%|█████     | 238/471 [00:44<00:44,  5.25it/s] 51%|█████     | 239/471 [00:45<00:44,  5.27it/s] 51%|█████     | 240/471 [00:45<00:43,  5.27it/s] 51%|█████     | 241/471 [00:45<00:43,  5.25it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.24it/s] 52%|█████▏    | 243/471 [00:45<00:43,  5.25it/s] 52%|█████▏    | 244/471 [00:46<00:43,  5.25it/s] 52%|█████▏    | 245/471 [00:46<00:43,  5.25it/s] 52%|█████▏    | 246/471 [00:46<00:42,  5.27it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.28it/s] 53%|█████▎    | 248/471 [00:46<00:42,  5.27it/s] 53%|█████▎    | 249/471 [00:47<00:42,  5.25it/s] 53%|█████▎    | 250/471 [00:47<00:41,  5.26it/s] 53%|█████▎    | 251/471 [00:47<00:41,  5.26it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.27it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.25it/s] 54%|█████▍    | 254/471 [00:48<00:41,  5.24it/s] 54%|█████▍    | 255/471 [00:48<00:41,  5.25it/s] 54%|█████▍    | 256/471 [00:48<00:40,  5.25it/s] 55%|█████▍    | 257/471 [00:48<00:40,  5.24it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.24it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.23it/s] 55%|█████▌    | 260/471 [00:49<00:40,  5.23it/s] 55%|█████▌    | 261/471 [00:49<00:40,  5.24it/s] 56%|█████▌    | 262/471 [00:49<00:39,  5.25it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.24it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.24it/s] 56%|█████▋    | 265/471 [00:50<00:39,  5.24it/s] 56%|█████▋    | 266/471 [00:50<00:39,  5.24it/s] 57%|█████▋    | 267/471 [00:50<00:38,  5.24it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.24it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.24it/s] 57%|█████▋    | 270/471 [00:51<00:38,  5.24it/s] 58%|█████▊    | 271/471 [00:51<00:38,  5.24it/s] 58%|█████▊    | 272/471 [00:51<00:37,  5.25it/s] 58%|█████▊    | 273/471 [00:51<00:37,  5.26it/s] 58%|█████▊    | 274/471 [00:51<00:37,  5.28it/s] 58%|█████▊    | 275/471 [00:52<00:37,  5.28it/s] 59%|█████▊    | 276/471 [00:52<00:36,  5.27it/s] 59%|█████▉    | 277/471 [00:52<00:36,  5.27it/s] 59%|█████▉    | 278/471 [00:52<00:36,  5.25it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.26it/s] 59%|█████▉    | 280/471 [00:52<00:36,  5.25it/s] 60%|█████▉    | 281/471 [00:53<00:36,  5.24it/s] 60%|█████▉    | 282/471 [00:53<00:36,  5.24it/s] 60%|██████    | 283/471 [00:53<00:35,  5.24it/s] 60%|██████    | 284/471 [00:53<00:35,  5.26it/s] 61%|██████    | 285/471 [00:53<00:35,  5.24it/s] 61%|██████    | 286/471 [00:54<00:35,  5.26it/s] 61%|██████    | 287/471 [00:54<00:35,  5.24it/s] 61%|██████    | 288/471 [00:54<00:34,  5.24it/s] 61%|██████▏   | 289/471 [00:54<00:34,  5.28it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.27it/s] 62%|██████▏   | 291/471 [00:55<00:34,  5.25it/s] 62%|██████▏   | 292/471 [00:55<00:34,  5.26it/s] 62%|██████▏   | 293/471 [00:55<00:33,  5.27it/s] 62%|██████▏   | 294/471 [00:55<00:33,  5.27it/s] 63%|██████▎   | 295/471 [00:55<00:33,  5.27it/s] 63%|██████▎   | 296/471 [00:56<00:33,  5.28it/s] 63%|██████▎   | 297/471 [00:56<00:33,  5.27it/s] 63%|██████▎   | 298/471 [00:56<00:32,  5.26it/s] 63%|██████▎   | 299/471 [00:56<00:32,  5.25it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.25it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.26it/s] 64%|██████▍   | 302/471 [00:57<00:32,  5.26it/s] 64%|██████▍   | 303/471 [00:57<00:31,  5.26it/s] 65%|██████▍   | 304/471 [00:57<00:31,  5.27it/s] 65%|██████▍   | 305/471 [00:57<00:31,  5.26it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.25it/s] 65%|██████▌   | 307/471 [00:58<00:31,  5.24it/s] 65%|██████▌   | 308/471 [00:58<00:31,  5.24it/s] 66%|██████▌   | 309/471 [00:58<00:30,  5.23it/s] 66%|██████▌   | 310/471 [00:58<00:30,  5.25it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.25it/s] 66%|██████▌   | 312/471 [00:59<00:30,  5.26it/s] 66%|██████▋   | 313/471 [00:59<00:30,  5.26it/s] 67%|██████▋   | 314/471 [00:59<00:29,  5.26it/s] 67%|██████▋   | 315/471 [00:59<00:29,  5.26it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.27it/s] 67%|██████▋   | 317/471 [01:00<00:29,  5.27it/s] 68%|██████▊   | 318/471 [01:00<00:29,  5.26it/s] 68%|██████▊   | 319/471 [01:00<00:28,  5.25it/s] 68%|██████▊   | 320/471 [01:00<00:28,  5.24it/s] 68%|██████▊   | 321/471 [01:00<00:28,  5.24it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.25it/s] 69%|██████▊   | 323/471 [01:01<00:28,  5.25it/s] 69%|██████▉   | 324/471 [01:01<00:28,  5.23it/s] 69%|██████▉   | 325/471 [01:01<00:27,  5.25it/s] 69%|██████▉   | 326/471 [01:01<00:27,  5.25it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.27it/s] 70%|██████▉   | 328/471 [01:02<00:27,  5.25it/s] 70%|██████▉   | 329/471 [01:02<00:27,  5.25it/s] 70%|███████   | 330/471 [01:02<00:26,  5.26it/s] 70%|███████   | 331/471 [01:02<00:26,  5.26it/s] 70%|███████   | 332/471 [01:02<00:26,  5.24it/s] 71%|███████   | 333/471 [01:03<00:26,  5.25it/s] 71%|███████   | 334/471 [01:03<00:26,  5.25it/s] 71%|███████   | 335/471 [01:03<00:25,  5.24it/s] 71%|███████▏  | 336/471 [01:03<00:25,  5.25it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.26it/s] 72%|███████▏  | 338/471 [01:04<00:25,  5.26it/s] 72%|███████▏  | 339/471 [01:04<00:25,  5.25it/s] 72%|███████▏  | 340/471 [01:04<00:24,  5.26it/s] 72%|███████▏  | 341/471 [01:04<00:24,  5.24it/s] 73%|███████▎  | 342/471 [01:04<00:24,  5.26it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.24it/s] 73%|███████▎  | 344/471 [01:05<00:24,  5.27it/s] 73%|███████▎  | 345/471 [01:05<00:23,  5.25it/s] 73%|███████▎  | 346/471 [01:05<00:23,  5.25it/s] 74%|███████▎  | 347/471 [01:05<00:23,  5.27it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.25it/s] 74%|███████▍  | 349/471 [01:06<00:23,  5.26it/s] 74%|███████▍  | 350/471 [01:06<00:23,  5.26it/s] 75%|███████▍  | 351/471 [01:06<00:22,  5.27it/s] 75%|███████▍  | 352/471 [01:06<00:22,  5.26it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.25it/s] 75%|███████▌  | 354/471 [01:07<00:22,  5.25it/s] 75%|███████▌  | 355/471 [01:07<00:22,  5.25it/s] 76%|███████▌  | 356/471 [01:07<00:21,  5.25it/s] 76%|███████▌  | 357/471 [01:07<00:21,  5.25it/s] 76%|███████▌  | 358/471 [01:07<00:21,  5.26it/s] 76%|███████▌  | 359/471 [01:08<00:21,  5.25it/s] 76%|███████▋  | 360/471 [01:08<00:21,  5.25it/s] 77%|███████▋  | 361/471 [01:08<00:20,  5.25it/s] 77%|███████▋  | 362/471 [01:08<00:20,  5.25it/s] 77%|███████▋  | 363/471 [01:08<00:20,  5.25it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.27it/s] 77%|███████▋  | 365/471 [01:09<00:20,  5.26it/s] 78%|███████▊  | 366/471 [01:09<00:20,  5.24it/s] 78%|███████▊  | 367/471 [01:09<00:19,  5.25it/s] 78%|███████▊  | 368/471 [01:09<00:19,  5.25it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.27it/s] 79%|███████▊  | 370/471 [01:10<00:19,  5.25it/s] 79%|███████▉  | 371/471 [01:10<00:19,  5.26it/s] 79%|███████▉  | 372/471 [01:10<00:18,  5.25it/s] 79%|███████▉  | 373/471 [01:10<00:18,  5.25it/s] 79%|███████▉  | 374/471 [01:10<00:18,  5.27it/s] 80%|███████▉  | 375/471 [01:11<00:18,  5.26it/s] 80%|███████▉  | 376/471 [01:11<00:18,  5.26it/s] 80%|████████  | 377/471 [01:11<00:17,  5.27it/s] 80%|████████  | 378/471 [01:11<00:17,  5.29it/s] 80%|████████  | 379/471 [01:11<00:17,  5.28it/s] 81%|████████  | 380/471 [01:12<00:17,  5.25it/s] 81%|████████  | 381/471 [01:12<00:17,  5.26it/s] 81%|████████  | 382/471 [01:12<00:16,  5.25it/s] 81%|████████▏ | 383/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 384/471 [01:12<00:16,  5.25it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.24it/s] 82%|████████▏ | 386/471 [01:13<00:16,  5.24it/s] 82%|████████▏ | 387/471 [01:13<00:16,  5.24it/s] 82%|████████▏ | 388/471 [01:13<00:15,  5.23it/s] 83%|████████▎ | 389/471 [01:13<00:15,  5.25it/s] 83%|████████▎ | 390/471 [01:13<00:15,  5.24it/s] 83%|████████▎ | 391/471 [01:14<00:15,  5.24it/s] 83%|████████▎ | 392/471 [01:14<00:15,  5.25it/s] 83%|████████▎ | 393/471 [01:14<00:14,  5.25it/s] 84%|████████▎ | 394/471 [01:14<00:14,  5.24it/s] 84%|████████▍ | 395/471 [01:14<00:14,  5.25it/s] 84%|████████▍ | 396/471 [01:15<00:14,  5.25it/s] 84%|████████▍ | 397/471 [01:15<00:14,  5.26it/s] 85%|████████▍ | 398/471 [01:15<00:13,  5.26it/s] 85%|████████▍ | 399/471 [01:15<00:13,  5.24it/s] 85%|████████▍ | 400/471 [01:15<00:13,  5.24it/s] 85%|████████▌ | 401/471 [01:16<00:13,  5.25it/s] 85%|████████▌ | 402/471 [01:16<00:13,  5.26it/s] 86%|████████▌ | 403/471 [01:16<00:12,  5.25it/s] 86%|████████▌ | 404/471 [01:16<00:12,  5.24it/s] 86%|████████▌ | 405/471 [01:16<00:12,  5.23it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.26it/s] 86%|████████▋ | 407/471 [01:17<00:12,  5.27it/s] 87%|████████▋ | 408/471 [01:17<00:11,  5.27it/s] 87%|████████▋ | 409/471 [01:17<00:11,  5.25it/s] 87%|████████▋ | 410/471 [01:17<00:11,  5.26it/s] 87%|████████▋ | 411/471 [01:17<00:11,  5.27it/s] 87%|████████▋ | 412/471 [01:18<00:11,  5.27it/s] 88%|████████▊ | 413/471 [01:18<00:11,  5.27it/s] 88%|████████▊ | 414/471 [01:18<00:10,  5.26it/s] 88%|████████▊ | 415/471 [01:18<00:10,  5.26it/s] 88%|████████▊ | 416/471 [01:18<00:10,  5.24it/s] 89%|████████▊ | 417/471 [01:19<00:10,  5.25it/s] 89%|████████▊ | 418/471 [01:19<00:10,  5.25it/s] 89%|████████▉ | 419/471 [01:19<00:09,  5.26it/s] 89%|████████▉ | 420/471 [01:19<00:09,  5.28it/s] 89%|████████▉ | 421/471 [01:19<00:09,  5.26it/s] 90%|████████▉ | 422/471 [01:20<00:09,  5.26it/s] 90%|████████▉ | 423/471 [01:20<00:09,  5.27it/s] 90%|█████████ | 424/471 [01:20<00:08,  5.25it/s] 90%|█████████ | 425/471 [01:20<00:08,  5.27it/s] 90%|█████████ | 426/471 [01:20<00:08,  5.25it/s] 91%|█████████ | 427/471 [01:20<00:08,  5.26it/s] 91%|█████████ | 428/471 [01:21<00:08,  5.25it/s] 91%|█████████ | 429/471 [01:21<00:07,  5.26it/s] 91%|█████████▏| 430/471 [01:21<00:07,  5.24it/s] 92%|█████████▏| 431/471 [01:21<00:07,  5.24it/s] 92%|█████████▏| 432/471 [01:21<00:07,  5.24it/s] 92%|█████████▏| 433/471 [01:22<00:07,  5.24it/s] 92%|█████████▏| 434/471 [01:22<00:07,  5.24it/s] 92%|█████████▏| 435/471 [01:22<00:06,  5.24it/s] 93%|█████████▎| 436/471 [01:22<00:06,  5.25it/s] 93%|█████████▎| 437/471 [01:22<00:06,  5.25it/s] 93%|█████████▎| 438/471 [01:23<00:06,  5.25it/s] 93%|█████████▎| 439/471 [01:23<00:06,  5.24it/s] 93%|█████████▎| 440/471 [01:23<00:05,  5.26it/s] 94%|█████████▎| 441/471 [01:23<00:05,  5.27it/s] 94%|█████████▍| 442/471 [01:23<00:05,  5.28it/s] 94%|█████████▍| 443/471 [01:23<00:05,  5.27it/s] 94%|█████████▍| 444/471 [01:24<00:05,  5.25it/s] 94%|█████████▍| 445/471 [01:24<00:04,  5.23it/s] 95%|█████████▍| 446/471 [01:24<00:04,  5.25it/s] 95%|█████████▍| 447/471 [01:24<00:04,  5.26it/s] 95%|█████████▌| 448/471 [01:24<00:04,  5.28it/s] 95%|█████████▌| 449/471 [01:25<00:04,  5.26it/s] 96%|█████████▌| 450/471 [01:25<00:04,  5.24it/s] 96%|█████████▌| 451/471 [01:25<00:03,  5.25it/s] 96%|█████████▌| 452/471 [01:25<00:03,  5.26it/s] 96%|█████████▌| 453/471 [01:25<00:03,  5.26it/s] 96%|█████████▋| 454/471 [01:26<00:03,  5.25it/s] 97%|█████████▋| 455/471 [01:26<00:03,  5.24it/s] 97%|█████████▋| 456/471 [01:26<00:02,  5.26it/s] 97%|█████████▋| 457/471 [01:26<00:02,  5.26it/s] 97%|█████████▋| 458/471 [01:26<00:02,  5.27it/s] 97%|█████████▋| 459/471 [01:27<00:02,  5.29it/s] 98%|█████████▊| 460/471 [01:27<00:02,  5.28it/s] 98%|█████████▊| 461/471 [01:27<00:01,  5.27it/s] 98%|█████████▊| 462/471 [01:27<00:01,  5.27it/s] 98%|█████████▊| 463/471 [01:27<00:01,  5.27it/s] 99%|█████████▊| 464/471 [01:27<00:01,  5.27it/s] 99%|█████████▊| 465/471 [01:28<00:01,  5.27it/s] 99%|█████████▉| 466/471 [01:28<00:00,  5.26it/s] 99%|█████████▉| 467/471 [01:28<00:00,  5.26it/s] 99%|█████████▉| 468/471 [01:28<00:00,  5.25it/s]100%|█████████▉| 469/471 [01:28<00:00,  5.26it/s]100%|█████████▉| 470/471 [01:29<00:00,  5.27it/s]100%|██████████| 471/471 [01:29<00:00,  5.62it/s]100%|██████████| 471/471 [01:29<00:00,  5.28it/s]
{'eval_loss': 4.09418249130249, 'eval_model_preparation_time': 0.0052, 'eval_acc': 0.15122145512480084, 'eval_runtime': 89.4538, 'eval_samples_per_second': 84.2, 'eval_steps_per_second': 5.265}
ROUND:1
CLIENT:26
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.91it/s]                                              {'loss': 2.954, 'grad_norm': 3.2907538414001465, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.91it/s]  5%|▌         | 2/40 [00:00<00:12,  2.93it/s]                                              {'loss': 4.4885, 'grad_norm': 3.910400867462158, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.93it/s]  8%|▊         | 3/40 [00:01<00:12,  2.96it/s]                                              {'loss': 3.4487, 'grad_norm': 4.005368709564209, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.96it/s] 10%|█         | 4/40 [00:01<00:12,  2.98it/s]                                              {'loss': 2.9291, 'grad_norm': 4.7347002029418945, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.98it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s]                                              {'loss': 3.4423, 'grad_norm': 5.509767055511475, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s]                                              {'loss': 3.1089, 'grad_norm': 5.634138584136963, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.96it/s]                                              {'loss': 3.0066, 'grad_norm': 6.5640363693237305, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.96it/s]                                              {'loss': 2.9262, 'grad_norm': 27.161338806152344, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.96it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 1.6267, 'grad_norm': 5.916955471038818, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s]                                               {'loss': 1.1773, 'grad_norm': 5.626498699188232, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s]                                               {'loss': 1.7663, 'grad_norm': 8.196358680725098, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s] 30%|███       | 12/40 [00:03<00:08,  3.20it/s]                                               {'loss': 1.2413, 'grad_norm': 6.476011753082275, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.20it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s]                                               {'loss': 1.2675, 'grad_norm': 6.248321533203125, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 1.6604, 'grad_norm': 5.877796649932861, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.3751, 'grad_norm': 6.210226058959961, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.2579, 'grad_norm': 7.60624361038208, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.4874, 'grad_norm': 3.9194180965423584, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.766, 'grad_norm': 4.277359962463379, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.3287, 'grad_norm': 2.933415651321411, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.4942, 'grad_norm': 5.954893112182617, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.5387, 'grad_norm': 4.623207092285156, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.2008, 'grad_norm': 2.492514133453369, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.3491, 'grad_norm': 4.005773544311523, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.2398, 'grad_norm': 11.174327850341797, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.04it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.72it/s]                                               {'loss': 0.0626, 'grad_norm': 1.1795700788497925, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.72it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s]                                               {'loss': 0.1005, 'grad_norm': 1.5803849697113037, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.32it/s]                                               {'loss': 0.0734, 'grad_norm': 1.3326116800308228, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.32it/s] 70%|███████   | 28/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1955, 'grad_norm': 1.3895670175552368, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.22it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.1217, 'grad_norm': 2.4413318634033203, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.0603, 'grad_norm': 2.4535913467407227, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0932, 'grad_norm': 2.4907984733581543, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0179, 'grad_norm': 0.8025355339050293, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s]                                               {'loss': 0.0365, 'grad_norm': 1.073232650756836, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.0365, 'grad_norm': 1.0436538457870483, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.0225, 'grad_norm': 0.5726128220558167, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.1482, 'grad_norm': 0.8790077567100525, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0207, 'grad_norm': 0.5289068818092346, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.1018, 'grad_norm': 4.1491594314575195, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.03it/s]                                               {'loss': 0.037, 'grad_norm': 0.6885581612586975, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.03it/s]                                               {'loss': 0.0068, 'grad_norm': 0.4336633086204529, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.03it/s]                                               {'train_runtime': 12.2935, 'train_samples_per_second': 45.959, 'train_steps_per_second': 3.254, 'train_loss': 1.0304112319950947, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.03it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
CLIENT:80
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  ddp_find_unused_parameters=False,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.91it/s]                                              {'loss': 3.0604, 'grad_norm': 3.2512035369873047, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.91it/s]  5%|▌         | 2/40 [00:00<00:13,  2.90it/s]                                              {'loss': 4.5694, 'grad_norm': 4.349667072296143, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:13,  2.90it/s]  8%|▊         | 3/40 [00:01<00:12,  2.95it/s]                                              {'loss': 3.8619, 'grad_norm': 5.0502753257751465, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.95it/s] 10%|█         | 4/40 [00:01<00:12,  2.95it/s]                                              {'loss': 3.557, 'grad_norm': 5.08267879486084, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.95it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.96it/s]                                              {'loss': 4.2007, 'grad_norm': 9.766593933105469, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.96it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.93it/s]                                              {'loss': 2.6957, 'grad_norm': 5.276918411254883, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.93it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.94it/s]                                              {'loss': 2.6023, 'grad_norm': 7.1794867515563965, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.94it/s] 20%|██        | 8/40 [00:02<00:08,  3.72it/s]                                              {'loss': 3.8976, 'grad_norm': 29.324649810791016, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:08,  3.72it/s] 22%|██▎       | 9/40 [00:02<00:09,  3.43it/s]                                              {'loss': 1.4087, 'grad_norm': 7.89773416519165, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:09,  3.43it/s] 25%|██▌       | 10/40 [00:03<00:09,  3.23it/s]                                               {'loss': 1.6515, 'grad_norm': 6.252534866333008, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:09,  3.23it/s] 28%|██▊       | 11/40 [00:03<00:09,  3.14it/s]                                               {'loss': 1.0685, 'grad_norm': 5.924478054046631, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:09,  3.14it/s] 30%|███       | 12/40 [00:03<00:09,  3.08it/s]                                               {'loss': 1.2301, 'grad_norm': 6.454887390136719, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:09,  3.08it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.07it/s]                                               {'loss': 1.1166, 'grad_norm': 4.755280017852783, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.07it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.7062, 'grad_norm': 8.75495433807373, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.06it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 2.3391, 'grad_norm': 13.79562759399414, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.0229, 'grad_norm': 1.7199419736862183, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.7549, 'grad_norm': 3.2889256477355957, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 1.3708, 'grad_norm': 8.147570610046387, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.7753, 'grad_norm': 3.0783166885375977, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.6887, 'grad_norm': 4.559341907501221, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.5707, 'grad_norm': 6.35350227355957, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.2846, 'grad_norm': 4.160967826843262, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.3939, 'grad_norm': 8.637635231018066, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.1714, 'grad_norm': 6.514501571655273, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.72it/s]                                               {'loss': 0.7118, 'grad_norm': 4.854639053344727, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.72it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.50it/s]                                               {'loss': 0.0533, 'grad_norm': 1.500102162361145, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.50it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s]                                               {'loss': 0.4148, 'grad_norm': 2.442539691925049, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s] 70%|███████   | 28/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.4736, 'grad_norm': 4.759133338928223, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.24it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.0443, 'grad_norm': 0.9255558252334595, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.2425, 'grad_norm': 12.28489875793457, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0699, 'grad_norm': 1.665022611618042, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 5.9089, 'grad_norm': 5.570985794067383, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.78it/s]                                               {'loss': 0.0118, 'grad_norm': 0.23405851423740387, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.3703, 'grad_norm': 0.7827070951461792, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0648, 'grad_norm': 2.142155885696411, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.29it/s]                                               {'loss': 0.5, 'grad_norm': 1.9551026821136475, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.1255, 'grad_norm': 3.6400182247161865, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0753, 'grad_norm': 3.0578999519348145, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.08it/s]                                               {'loss': 0.3726, 'grad_norm': 0.9585623145103455, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.08it/s]                                               {'loss': 0.0107, 'grad_norm': 0.9941860437393188, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]                                               {'train_runtime': 12.3241, 'train_samples_per_second': 45.845, 'train_steps_per_second': 3.246, 'train_loss': 1.3362209990154952, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
CLIENT:82
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 5.3994, 'grad_norm': 5.05961799621582, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]                                              {'loss': 3.5354, 'grad_norm': 3.7880806922912598, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]  8%|▊         | 3/40 [00:00<00:12,  3.06it/s]                                              {'loss': 2.9799, 'grad_norm': 4.095865249633789, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.06it/s] 10%|█         | 4/40 [00:01<00:11,  3.10it/s]                                              {'loss': 3.153, 'grad_norm': 7.150810241699219, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.10it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.683, 'grad_norm': 5.249338626861572, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.7927, 'grad_norm': 5.202072620391846, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.7341, 'grad_norm': 7.31471586227417, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.8917, 'grad_norm': 16.68617820739746, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 1.8237, 'grad_norm': 6.238264560699463, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 1.1557, 'grad_norm': 5.175539970397949, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.3062, 'grad_norm': 6.096219539642334, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 1.1501, 'grad_norm': 6.942240238189697, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 1.8971, 'grad_norm': 6.393112659454346, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.3887, 'grad_norm': 6.051580429077148, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.2358, 'grad_norm': 5.788449764251709, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.8499, 'grad_norm': 0.9942179322242737, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.4671, 'grad_norm': 3.1981594562530518, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.6181, 'grad_norm': 3.7813470363616943, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.4738, 'grad_norm': 4.556605339050293, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.785, 'grad_norm': 3.9939322471618652, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.7096, 'grad_norm': 5.700549602508545, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.6094, 'grad_norm': 6.895415782928467, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.7839, 'grad_norm': 6.214322566986084, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.1008, 'grad_norm': 5.274636268615723, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s]                                               {'loss': 0.4556, 'grad_norm': 1.5931363105773926, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s]                                               {'loss': 0.0859, 'grad_norm': 2.2525463104248047, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s]                                               {'loss': 0.1576, 'grad_norm': 5.111660003662109, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.145, 'grad_norm': 10.127893447875977, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.4213, 'grad_norm': 1.8251022100448608, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.6927, 'grad_norm': 5.076385021209717, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.2396, 'grad_norm': 4.459624767303467, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.2649, 'grad_norm': 10.47479248046875, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.1203, 'grad_norm': 2.781020164489746, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.0903, 'grad_norm': 1.5997129678726196, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.1833, 'grad_norm': 1.7798807621002197, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.0728, 'grad_norm': 2.8337857723236084, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.3396, 'grad_norm': 1.5722593069076538, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.376, 'grad_norm': 5.960198879241943, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.5571, 'grad_norm': 1.7601864337921143, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.1647, 'grad_norm': 7.193526744842529, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1158, 'train_samples_per_second': 46.633, 'train_steps_per_second': 3.301, 'train_loss': 1.1222649382427334, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:68
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 3.279, 'grad_norm': 4.30336332321167, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 4.0226, 'grad_norm': 4.365334987640381, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.5729, 'grad_norm': 3.8857147693634033, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.8341, 'grad_norm': 5.498085021972656, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.9568, 'grad_norm': 6.102945327758789, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.0687, 'grad_norm': 6.466294765472412, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 2.654, 'grad_norm': 7.526759147644043, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 0.9671, 'grad_norm': 21.528488159179688, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.06it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s]                                              {'loss': 1.0519, 'grad_norm': 6.517442226409912, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.63it/s]                                               {'loss': 1.3961, 'grad_norm': 6.5040717124938965, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.63it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s]                                               {'loss': 1.5525, 'grad_norm': 5.995852470397949, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 1.8703, 'grad_norm': 5.422260761260986, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s]                                               {'loss': 0.7986, 'grad_norm': 5.896302700042725, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.326, 'grad_norm': 6.67938232421875, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.8293, 'grad_norm': 5.0464372634887695, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.4146, 'grad_norm': 28.70722007751465, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.7819, 'grad_norm': 5.2101521492004395, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.7549, 'grad_norm': 5.113086700439453, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s]                                               {'loss': 0.3513, 'grad_norm': 3.441991090774536, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.4659, 'grad_norm': 3.7991061210632324, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.4044, 'grad_norm': 4.205506324768066, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.8383, 'grad_norm': 5.9910736083984375, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.5655, 'grad_norm': 9.635470390319824, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 1.3742, 'grad_norm': 53.333797454833984, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.1026, 'grad_norm': 1.7977252006530762, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.1105, 'grad_norm': 1.4323912858963013, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.1224, 'grad_norm': 1.6572246551513672, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.5285, 'grad_norm': 2.935148239135742, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.1345, 'grad_norm': 2.3792800903320312, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.0938, 'grad_norm': 2.4440202713012695, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.3339, 'grad_norm': 7.47313928604126, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.079, 'grad_norm': 3.5924806594848633, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.87it/s]                                               {'loss': 0.541, 'grad_norm': 9.699700355529785, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.87it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.0365, 'grad_norm': 0.7542677521705627, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0665, 'grad_norm': 1.6890289783477783, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.0625, 'grad_norm': 1.5452477931976318, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0397, 'grad_norm': 0.8979822397232056, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0696, 'grad_norm': 2.70334529876709, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.4902, 'grad_norm': 2.369976758956909, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0278, 'grad_norm': 1.1358345746994019, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.0949, 'train_samples_per_second': 46.714, 'train_steps_per_second': 3.307, 'train_loss': 1.0742382102180272, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:77
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 4.0612, 'grad_norm': 4.058945178985596, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 4.2061, 'grad_norm': 4.057849884033203, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:01<00:12,  3.00it/s]                                              {'loss': 3.4904, 'grad_norm': 4.578238010406494, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  3.00it/s] 10%|█         | 4/40 [00:01<00:11,  3.07it/s]                                              {'loss': 3.3391, 'grad_norm': 4.819295406341553, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.07it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 3.4971, 'grad_norm': 6.470065116882324, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.1195, 'grad_norm': 5.676257610321045, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.6683, 'grad_norm': 8.284582138061523, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 0.4952, 'grad_norm': 13.815905570983887, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 1.1658, 'grad_norm': 5.001093864440918, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 1.4155, 'grad_norm': 5.341320037841797, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 0.8297, 'grad_norm': 5.769656658172607, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 1.9962, 'grad_norm': 6.6504716873168945, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.4566, 'grad_norm': 6.581463813781738, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.5625, 'grad_norm': 4.989714622497559, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.9951, 'grad_norm': 7.449558258056641, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.5913, 'grad_norm': 13.156152725219727, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s]                                               {'loss': 0.819, 'grad_norm': 3.5204837322235107, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.3121, 'grad_norm': 2.4778010845184326, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s]                                               {'loss': 0.281, 'grad_norm': 3.5946531295776367, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s] 50%|█████     | 20/40 [00:06<00:06,  3.21it/s]                                               {'loss': 0.4855, 'grad_norm': 6.225956439971924, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.21it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.11it/s]                                               {'loss': 0.3222, 'grad_norm': 4.5572285652160645, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.11it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.2347, 'grad_norm': 2.358336925506592, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.7794, 'grad_norm': 3.3279073238372803, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s] 60%|██████    | 24/40 [00:07<00:04,  3.73it/s]                                               {'loss': 0.1624, 'grad_norm': 5.279958248138428, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:04,  3.73it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.49it/s]                                               {'loss': 0.0672, 'grad_norm': 0.6712856888771057, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.49it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.35it/s]                                               {'loss': 0.0334, 'grad_norm': 0.6297879219055176, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.35it/s] 68%|██████▊   | 27/40 [00:08<00:04,  3.25it/s]                                               {'loss': 0.5612, 'grad_norm': 1.543986201286316, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:04,  3.25it/s] 70%|███████   | 28/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.5034, 'grad_norm': 3.0707085132598877, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.18it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.11it/s]                                               {'loss': 0.0339, 'grad_norm': 0.7224357724189758, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.11it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s]                                               {'loss': 0.1187, 'grad_norm': 3.1144659519195557, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.03it/s]                                               {'loss': 0.0841, 'grad_norm': 3.1208279132843018, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.03it/s]                                               {'loss': 0.1666, 'grad_norm': 14.648053169250488, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.03it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.72it/s]                                               {'loss': 0.0298, 'grad_norm': 1.5914186239242554, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.72it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s]                                               {'loss': 0.4037, 'grad_norm': 0.7658151388168335, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s]                                               {'loss': 0.037, 'grad_norm': 0.7961221933364868, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.22it/s]                                               {'loss': 0.0394, 'grad_norm': 1.1275391578674316, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.22it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.4523, 'grad_norm': 1.247994303703308, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.015, 'grad_norm': 0.32685986161231995, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.05it/s]                                               {'loss': 0.0363, 'grad_norm': 0.5694805979728699, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.05it/s]                                               {'loss': 0.0798, 'grad_norm': 4.156360626220703, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]                                               {'train_runtime': 12.2762, 'train_samples_per_second': 46.024, 'train_steps_per_second': 3.258, 'train_loss': 0.9986888543702662, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.06it/s]                                              {'loss': 3.6275, 'grad_norm': 4.384875774383545, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.06it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 4.2391, 'grad_norm': 4.777913570404053, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.8851, 'grad_norm': 4.4049859046936035, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.5273, 'grad_norm': 4.326589107513428, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.3532, 'grad_norm': 6.22684907913208, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.9642, 'grad_norm': 6.902273654937744, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 3.1553, 'grad_norm': 7.648937225341797, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 0.4018, 'grad_norm': 12.28943157196045, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.05it/s] 22%|██▎       | 9/40 [00:02<00:07,  3.90it/s]                                              {'loss': 1.8109, 'grad_norm': 7.618624687194824, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:07,  3.90it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.63it/s]                                               {'loss': 0.9659, 'grad_norm': 4.678339958190918, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.63it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.44it/s]                                               {'loss': 2.0214, 'grad_norm': 6.799029350280762, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.44it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 1.8882, 'grad_norm': 7.331227779388428, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s]                                               {'loss': 1.9649, 'grad_norm': 6.2667646408081055, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.3358, 'grad_norm': 5.830286979675293, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.15it/s]                                               {'loss': 1.1301, 'grad_norm': 4.571925640106201, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.15it/s]                                               {'loss': 2.5322, 'grad_norm': 38.0357666015625, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.15it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.89it/s]                                               {'loss': 0.6028, 'grad_norm': 2.608534574508667, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.89it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s]                                               {'loss': 0.3143, 'grad_norm': 2.185166358947754, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s]                                               {'loss': 0.9921, 'grad_norm': 5.580544948577881, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s] 50%|█████     | 20/40 [00:06<00:06,  3.33it/s]                                               {'loss': 0.5315, 'grad_norm': 3.235265016555786, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.33it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s]                                               {'loss': 0.7077, 'grad_norm': 4.5411057472229, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.4909, 'grad_norm': 3.4759111404418945, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s] 57%|█████▊    | 23/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.7885, 'grad_norm': 6.292620658874512, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:06<00:05,  3.12it/s]                                               {'loss': 2.2538, 'grad_norm': 129.69607543945312, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.12it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s]                                               {'loss': 0.4672, 'grad_norm': 1.7184078693389893, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s]                                               {'loss': 0.098, 'grad_norm': 2.6943929195404053, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.46it/s]                                               {'loss': 0.5682, 'grad_norm': 5.641498565673828, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.46it/s] 70%|███████   | 28/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.18, 'grad_norm': 3.114746570587158, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.33it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.3398, 'grad_norm': 8.299922943115234, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.1039, 'grad_norm': 1.8640190362930298, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.1155, 'grad_norm': 2.0826363563537598, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0151, 'grad_norm': 0.6274343132972717, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.0369, 'grad_norm': 0.6075893044471741, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.0376, 'grad_norm': 0.906238853931427, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.1224, 'grad_norm': 1.3962763547897339, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0792, 'grad_norm': 2.042466640472412, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.038, 'grad_norm': 1.0168401002883911, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1319, 'grad_norm': 2.998063325881958, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.7465, 'grad_norm': 1.3384989500045776, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0097, 'grad_norm': 0.4810846745967865, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.075, 'train_samples_per_second': 46.791, 'train_steps_per_second': 3.313, 'train_loss': 1.1893560842145234, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:3
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 3.2552, 'grad_norm': 4.097994804382324, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 3.0247, 'grad_norm': 3.865692138671875, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  2.98it/s]                                              {'loss': 3.9043, 'grad_norm': 3.556933879852295, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.98it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 3.1388, 'grad_norm': 4.7733540534973145, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 3.3034, 'grad_norm': 5.311096668243408, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s]                                              {'loss': 3.1573, 'grad_norm': 5.218350887298584, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 3.925, 'grad_norm': 7.866579055786133, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 2.6433, 'grad_norm': 23.143402099609375, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.98it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 2.0317, 'grad_norm': 7.7584075927734375, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 2.1951, 'grad_norm': 11.822524070739746, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 2.6409, 'grad_norm': 11.126823425292969, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.4279, 'grad_norm': 6.756563663482666, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.4635, 'grad_norm': 4.665362358093262, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.1326, 'grad_norm': 7.043843746185303, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.2249, 'grad_norm': 6.212038040161133, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 2.0791, 'grad_norm': 40.75970458984375, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s]                                               {'loss': 0.9197, 'grad_norm': 3.8072636127471924, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s]                                               {'loss': 0.4494, 'grad_norm': 4.163788795471191, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 1.0586, 'grad_norm': 4.542027473449707, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.9081, 'grad_norm': 4.94841194152832, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.3091, 'grad_norm': 3.458641767501831, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.6274, 'grad_norm': 10.358449935913086, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.7644, 'grad_norm': 5.362243175506592, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.0597, 'grad_norm': 2.7374138832092285, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.1529, 'grad_norm': 2.433622360229492, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.0665, 'grad_norm': 1.2451914548873901, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.0573, 'grad_norm': 1.9686322212219238, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.2469, 'grad_norm': 2.4542949199676514, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1109, 'grad_norm': 1.8379364013671875, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.18it/s]                                               {'loss': 0.3499, 'grad_norm': 6.034788131713867, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.18it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.15it/s]                                               {'loss': 0.6237, 'grad_norm': 4.915228366851807, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.15it/s]                                               {'loss': 0.0062, 'grad_norm': 0.38471540808677673, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.15it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.87it/s]                                               {'loss': 0.4629, 'grad_norm': 0.7556269764900208, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.87it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s]                                               {'loss': 0.0336, 'grad_norm': 0.6739068627357483, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s]                                               {'loss': 0.0512, 'grad_norm': 1.0898549556732178, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s]                                               {'loss': 0.0635, 'grad_norm': 2.424938201904297, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s]                                               {'loss': 0.1484, 'grad_norm': 0.7975645065307617, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.1605, 'grad_norm': 0.7469043135643005, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.18it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0196, 'grad_norm': 0.6197507977485657, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.011, 'grad_norm': 0.9557173848152161, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.14it/s]                                               {'train_runtime': 12.0467, 'train_samples_per_second': 46.901, 'train_steps_per_second': 3.32, 'train_loss': 1.20523129561916, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.14it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:55
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.00it/s]                                              {'loss': 4.3109, 'grad_norm': 4.481363296508789, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 4.9128, 'grad_norm': 4.137853622436523, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 3.2667, 'grad_norm': 4.513086318969727, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.0741, 'grad_norm': 4.619251251220703, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.5338, 'grad_norm': 6.828461647033691, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.9698, 'grad_norm': 5.075816631317139, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 2.1086, 'grad_norm': 6.427015781402588, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 3.994, 'grad_norm': 33.164676666259766, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 1.3984, 'grad_norm': 8.31039047241211, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 1.1566, 'grad_norm': 6.474765777587891, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 1.258, 'grad_norm': 7.184361457824707, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.1466, 'grad_norm': 6.5105366706848145, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.2694, 'grad_norm': 5.446262359619141, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.9671, 'grad_norm': 4.1423821449279785, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.8917, 'grad_norm': 4.776889324188232, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.2023, 'grad_norm': 7.203435897827148, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.2807, 'grad_norm': 2.162874460220337, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.5607, 'grad_norm': 2.8442351818084717, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.6637, 'grad_norm': 4.652176380157471, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.4393, 'grad_norm': 3.331660270690918, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.4191, 'grad_norm': 4.5031561851501465, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.1547, 'grad_norm': 2.187920331954956, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.2985, 'grad_norm': 4.136485576629639, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0066, 'grad_norm': 0.5432835221290588, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.1549, 'grad_norm': 4.496819496154785, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.1388, 'grad_norm': 4.395573139190674, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.3743, 'grad_norm': 16.979942321777344, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.2737, 'grad_norm': 7.85474157333374, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.414, 'grad_norm': 2.6918864250183105, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.1013, 'grad_norm': 2.104682683944702, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1343, 'grad_norm': 2.602202892303467, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0067, 'grad_norm': 0.40686213970184326, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.2013, 'grad_norm': 3.199749231338501, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0601, 'grad_norm': 1.6678441762924194, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.3545, 'grad_norm': 8.778347969055176, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.0762, 'grad_norm': 1.4111638069152832, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.097, 'grad_norm': 2.7535269260406494, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.1289, 'grad_norm': 3.470339775085449, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0451, 'grad_norm': 1.1612968444824219, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0687, 'grad_norm': 4.121188163757324, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.1597, 'train_samples_per_second': 46.465, 'train_steps_per_second': 3.29, 'train_loss': 1.0228469606954604, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:20
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.89it/s]                                              {'loss': 3.4311, 'grad_norm': 4.523103713989258, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.89it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 3.8356, 'grad_norm': 4.467280387878418, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:11,  3.11it/s]                                              {'loss': 4.0875, 'grad_norm': 5.732494354248047, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.11it/s] 10%|█         | 4/40 [00:01<00:11,  3.07it/s]                                              {'loss': 3.7462, 'grad_norm': 4.969063758850098, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.07it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.368, 'grad_norm': 6.567533016204834, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.0866, 'grad_norm': 7.816727638244629, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.2963, 'grad_norm': 6.720012664794922, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 4.1867, 'grad_norm': 36.7647705078125, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 2.0543, 'grad_norm': 11.014973640441895, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 1.8616, 'grad_norm': 7.958017349243164, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 1.6064, 'grad_norm': 8.509154319763184, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 2.5351, 'grad_norm': 8.418608665466309, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 1.5257, 'grad_norm': 4.868866920471191, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.7483, 'grad_norm': 5.3746232986450195, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.9504, 'grad_norm': 5.632168292999268, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 3.192, 'grad_norm': 40.929874420166016, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 1.6221, 'grad_norm': 3.356865644454956, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.6769, 'grad_norm': 2.555881977081299, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s]                                               {'loss': 1.4583, 'grad_norm': 7.67142915725708, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.5634, 'grad_norm': 6.34999942779541, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s]                                               {'loss': 0.4297, 'grad_norm': 3.8087143898010254, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.7107, 'grad_norm': 4.18364953994751, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.5543, 'grad_norm': 8.758270263671875, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.0097, 'grad_norm': 0.5248551368713379, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.1903, 'grad_norm': 5.156766891479492, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.5048, 'grad_norm': 2.4849064350128174, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.5108, 'grad_norm': 2.352160692214966, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.8027, 'grad_norm': 2.7053027153015137, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.6117, 'grad_norm': 3.1586415767669678, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.6436, 'grad_norm': 7.523177146911621, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.2477, 'grad_norm': 4.209500789642334, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0163, 'grad_norm': 0.857201337814331, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.4162, 'grad_norm': 1.3193825483322144, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.0656, 'grad_norm': 1.2977081537246704, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.3815, 'grad_norm': 0.828349769115448, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.2925, 'grad_norm': 1.0158112049102783, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.4124, 'grad_norm': 0.962995707988739, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.7004, 'grad_norm': 2.3725080490112305, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1628, 'grad_norm': 4.988067626953125, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0331, 'grad_norm': 1.819244146347046, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]                                               {'train_runtime': 12.0607, 'train_samples_per_second': 46.846, 'train_steps_per_second': 3.317, 'train_loss': 1.3882351828971877, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.13it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:17
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]                                              {'loss': 4.2942, 'grad_norm': 4.237892150878906, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.7109, 'grad_norm': 3.5390305519104004, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:01<00:12,  2.92it/s]                                              {'loss': 2.4274, 'grad_norm': 3.014308452606201, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.92it/s] 10%|█         | 4/40 [00:01<00:12,  2.97it/s]                                              {'loss': 3.6376, 'grad_norm': 4.835752487182617, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.97it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 2.8284, 'grad_norm': 6.106221675872803, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:02<00:11,  3.02it/s]                                              {'loss': 3.3131, 'grad_norm': 6.228297233581543, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 2.4957, 'grad_norm': 6.237869739532471, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 5.8825, 'grad_norm': 32.872802734375, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s]                                              {'loss': 1.8433, 'grad_norm': 5.6198883056640625, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s]                                               {'loss': 1.0892, 'grad_norm': 6.179555892944336, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 1.288, 'grad_norm': 4.6769256591796875, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 1.1687, 'grad_norm': 5.66028356552124, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.1943, 'grad_norm': 6.208780765533447, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.8986, 'grad_norm': 4.7643938064575195, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.2597, 'grad_norm': 7.579710483551025, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.0374, 'grad_norm': 2.1622750759124756, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.72it/s]                                               {'loss': 0.7527, 'grad_norm': 2.7626969814300537, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.72it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.50it/s]                                               {'loss': 0.2601, 'grad_norm': 3.0782670974731445, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.50it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s]                                               {'loss': 0.3952, 'grad_norm': 4.290139198303223, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.6344, 'grad_norm': 5.640018463134766, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.2032, 'grad_norm': 4.851284027099609, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.5604, 'grad_norm': 6.332334995269775, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.5116, 'grad_norm': 4.13252592086792, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.1289, 'grad_norm': 6.188655853271484, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.04it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s]                                               {'loss': 0.163, 'grad_norm': 2.714611291885376, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s]                                               {'loss': 0.2343, 'grad_norm': 1.6826092004776, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s]                                               {'loss': 0.3914, 'grad_norm': 7.515356063842773, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.5145, 'grad_norm': 5.881049156188965, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.116, 'grad_norm': 2.048583507537842, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.4355, 'grad_norm': 1.4909498691558838, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.2648, 'grad_norm': 1.1262847185134888, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0453, 'grad_norm': 1.5492974519729614, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.71it/s]                                               {'loss': 0.039, 'grad_norm': 0.6940836906433105, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.71it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.4095, 'grad_norm': 0.6608852744102478, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0484, 'grad_norm': 1.8801785707473755, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s]                                               {'loss': 0.3372, 'grad_norm': 1.9144487380981445, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.2966, 'grad_norm': 1.121278166770935, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0552, 'grad_norm': 1.9761828184127808, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.06it/s]                                               {'loss': 0.0378, 'grad_norm': 0.8362780809402466, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.06it/s]                                               {'loss': 0.0295, 'grad_norm': 1.5159873962402344, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]                                               {'train_runtime': 12.3004, 'train_samples_per_second': 45.934, 'train_steps_per_second': 3.252, 'train_loss': 1.1058338623028248, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:42, 10.92it/s]  1%|          | 4/471 [00:00<01:07,  6.88it/s]  1%|          | 5/471 [00:00<01:13,  6.38it/s]  1%|▏         | 6/471 [00:00<01:17,  6.03it/s]  1%|▏         | 7/471 [00:01<01:19,  5.84it/s]  2%|▏         | 8/471 [00:01<01:21,  5.70it/s]  2%|▏         | 9/471 [00:01<01:22,  5.63it/s]  2%|▏         | 10/471 [00:01<01:22,  5.57it/s]  2%|▏         | 11/471 [00:01<01:23,  5.52it/s]  3%|▎         | 12/471 [00:02<01:23,  5.49it/s]  3%|▎         | 13/471 [00:02<01:23,  5.46it/s]  3%|▎         | 14/471 [00:02<01:23,  5.44it/s]  3%|▎         | 15/471 [00:02<01:23,  5.48it/s]  3%|▎         | 16/471 [00:02<01:23,  5.44it/s]  4%|▎         | 17/471 [00:02<01:23,  5.44it/s]  4%|▍         | 18/471 [00:03<01:23,  5.43it/s]  4%|▍         | 19/471 [00:03<01:23,  5.42it/s]  4%|▍         | 20/471 [00:03<01:23,  5.42it/s]  4%|▍         | 21/471 [00:03<01:23,  5.42it/s]  5%|▍         | 22/471 [00:03<01:23,  5.40it/s]  5%|▍         | 23/471 [00:04<01:22,  5.41it/s]  5%|▌         | 24/471 [00:04<01:22,  5.41it/s]  5%|▌         | 25/471 [00:04<01:22,  5.42it/s]  6%|▌         | 26/471 [00:04<01:22,  5.41it/s]  6%|▌         | 27/471 [00:04<01:22,  5.40it/s]  6%|▌         | 28/471 [00:04<01:21,  5.41it/s]  6%|▌         | 29/471 [00:05<01:21,  5.41it/s]  6%|▋         | 30/471 [00:05<01:21,  5.39it/s]  7%|▋         | 31/471 [00:05<01:21,  5.39it/s]  7%|▋         | 32/471 [00:05<01:21,  5.42it/s]  7%|▋         | 33/471 [00:05<01:20,  5.45it/s]  7%|▋         | 34/471 [00:06<01:20,  5.45it/s]  7%|▋         | 35/471 [00:06<01:20,  5.43it/s]  8%|▊         | 36/471 [00:06<01:20,  5.42it/s]  8%|▊         | 37/471 [00:06<01:20,  5.41it/s]  8%|▊         | 38/471 [00:06<01:20,  5.40it/s]  8%|▊         | 39/471 [00:07<01:19,  5.41it/s]  8%|▊         | 40/471 [00:07<01:19,  5.39it/s]  9%|▊         | 41/471 [00:07<01:19,  5.40it/s]  9%|▉         | 42/471 [00:07<01:19,  5.38it/s]  9%|▉         | 43/471 [00:07<01:19,  5.38it/s]  9%|▉         | 44/471 [00:07<01:19,  5.40it/s] 10%|▉         | 45/471 [00:08<01:19,  5.38it/s] 10%|▉         | 46/471 [00:08<01:18,  5.39it/s] 10%|▉         | 47/471 [00:08<01:18,  5.39it/s] 10%|█         | 48/471 [00:08<01:18,  5.41it/s] 10%|█         | 49/471 [00:08<01:18,  5.38it/s] 11%|█         | 50/471 [00:09<01:18,  5.37it/s] 11%|█         | 51/471 [00:09<01:18,  5.38it/s] 11%|█         | 52/471 [00:09<01:17,  5.38it/s] 11%|█▏        | 53/471 [00:09<01:17,  5.38it/s] 11%|█▏        | 54/471 [00:09<01:17,  5.37it/s] 12%|█▏        | 55/471 [00:09<01:17,  5.37it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.38it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.37it/s] 12%|█▏        | 58/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 59/471 [00:10<01:16,  5.38it/s] 13%|█▎        | 60/471 [00:10<01:16,  5.38it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.38it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.37it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.36it/s] 14%|█▎        | 64/471 [00:11<01:15,  5.37it/s] 14%|█▍        | 65/471 [00:11<01:15,  5.36it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.36it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.36it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.37it/s] 15%|█▍        | 69/471 [00:12<01:14,  5.36it/s] 15%|█▍        | 70/471 [00:12<01:14,  5.36it/s] 15%|█▌        | 71/471 [00:12<01:14,  5.35it/s] 15%|█▌        | 72/471 [00:13<01:14,  5.34it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.35it/s] 16%|█▌        | 74/471 [00:13<01:13,  5.37it/s] 16%|█▌        | 75/471 [00:13<01:13,  5.36it/s] 16%|█▌        | 76/471 [00:13<01:13,  5.38it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.36it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.36it/s] 17%|█▋        | 81/471 [00:14<01:12,  5.37it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.38it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.36it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.35it/s] 18%|█▊        | 85/471 [00:15<01:11,  5.36it/s] 18%|█▊        | 86/471 [00:15<01:12,  5.35it/s] 18%|█▊        | 87/471 [00:15<01:11,  5.35it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.37it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.35it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.34it/s] 19%|█▉        | 91/471 [00:16<01:10,  5.37it/s] 20%|█▉        | 92/471 [00:16<01:10,  5.36it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.35it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.38it/s] 20%|██        | 95/471 [00:17<01:10,  5.37it/s] 20%|██        | 96/471 [00:17<01:09,  5.37it/s] 21%|██        | 97/471 [00:17<01:09,  5.36it/s] 21%|██        | 98/471 [00:18<01:09,  5.35it/s] 21%|██        | 99/471 [00:18<01:09,  5.37it/s] 21%|██        | 100/471 [00:18<01:08,  5.39it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.40it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.37it/s] 22%|██▏       | 103/471 [00:18<01:08,  5.35it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.34it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.34it/s] 23%|██▎       | 106/471 [00:19<01:07,  5.37it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.37it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.38it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.37it/s] 23%|██▎       | 110/471 [00:20<01:06,  5.40it/s] 24%|██▎       | 111/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 112/471 [00:20<01:06,  5.37it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.41it/s] 24%|██▍       | 114/471 [00:20<01:06,  5.39it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.38it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.38it/s] 25%|██▍       | 117/471 [00:21<01:05,  5.39it/s] 25%|██▌       | 118/471 [00:21<01:05,  5.37it/s] 25%|██▌       | 119/471 [00:21<01:05,  5.36it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.36it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.36it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.37it/s] 26%|██▌       | 123/471 [00:22<01:04,  5.38it/s] 26%|██▋       | 124/471 [00:22<01:04,  5.35it/s] 27%|██▋       | 125/471 [00:23<01:04,  5.34it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.34it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.37it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.36it/s] 27%|██▋       | 129/471 [00:23<01:03,  5.38it/s] 28%|██▊       | 130/471 [00:23<01:03,  5.36it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.35it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.35it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.34it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.33it/s] 29%|██▊       | 135/471 [00:24<01:03,  5.33it/s] 29%|██▉       | 136/471 [00:25<01:02,  5.34it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.35it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.34it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.35it/s] 30%|██▉       | 140/471 [00:25<01:01,  5.36it/s] 30%|██▉       | 141/471 [00:26<01:01,  5.36it/s] 30%|███       | 142/471 [00:26<01:01,  5.37it/s] 30%|███       | 143/471 [00:26<01:01,  5.37it/s] 31%|███       | 144/471 [00:26<01:01,  5.36it/s] 31%|███       | 145/471 [00:26<01:00,  5.39it/s] 31%|███       | 146/471 [00:26<01:00,  5.36it/s] 31%|███       | 147/471 [00:27<01:00,  5.36it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.37it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.35it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.34it/s] 32%|███▏      | 151/471 [00:27<00:59,  5.34it/s] 32%|███▏      | 152/471 [00:28<00:59,  5.35it/s] 32%|███▏      | 153/471 [00:28<00:59,  5.34it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.37it/s] 33%|███▎      | 155/471 [00:28<00:58,  5.37it/s] 33%|███▎      | 156/471 [00:28<00:58,  5.36it/s] 33%|███▎      | 157/471 [00:29<00:58,  5.36it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.38it/s] 34%|███▍      | 159/471 [00:29<00:57,  5.39it/s] 34%|███▍      | 160/471 [00:29<00:57,  5.37it/s] 34%|███▍      | 161/471 [00:29<00:57,  5.35it/s] 34%|███▍      | 162/471 [00:29<00:57,  5.34it/s] 35%|███▍      | 163/471 [00:30<00:57,  5.34it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.36it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.35it/s] 35%|███▌      | 166/471 [00:30<00:56,  5.35it/s] 35%|███▌      | 167/471 [00:30<00:56,  5.35it/s] 36%|███▌      | 168/471 [00:31<00:56,  5.35it/s] 36%|███▌      | 169/471 [00:31<00:56,  5.34it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.37it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.35it/s] 37%|███▋      | 172/471 [00:31<00:55,  5.35it/s] 37%|███▋      | 173/471 [00:31<00:55,  5.36it/s] 37%|███▋      | 174/471 [00:32<00:55,  5.35it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.34it/s] 37%|███▋      | 176/471 [00:32<00:54,  5.37it/s] 38%|███▊      | 177/471 [00:32<00:54,  5.35it/s] 38%|███▊      | 178/471 [00:32<00:54,  5.35it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.37it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.36it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.35it/s] 39%|███▊      | 182/471 [00:33<00:53,  5.36it/s] 39%|███▉      | 183/471 [00:33<00:53,  5.35it/s] 39%|███▉      | 184/471 [00:34<00:53,  5.36it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.37it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.35it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.35it/s] 40%|███▉      | 188/471 [00:34<00:53,  5.34it/s] 40%|████      | 189/471 [00:34<00:52,  5.35it/s] 40%|████      | 190/471 [00:35<00:52,  5.35it/s] 41%|████      | 191/471 [00:35<00:52,  5.35it/s] 41%|████      | 192/471 [00:35<00:52,  5.34it/s] 41%|████      | 193/471 [00:35<00:51,  5.36it/s] 41%|████      | 194/471 [00:35<00:51,  5.37it/s] 41%|████▏     | 195/471 [00:36<00:51,  5.36it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.35it/s] 42%|████▏     | 197/471 [00:36<00:50,  5.39it/s] 42%|████▏     | 198/471 [00:36<00:50,  5.37it/s] 42%|████▏     | 199/471 [00:36<00:50,  5.35it/s] 42%|████▏     | 200/471 [00:37<00:50,  5.36it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.38it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.37it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.36it/s] 43%|████▎     | 204/471 [00:37<00:49,  5.34it/s] 44%|████▎     | 205/471 [00:37<00:49,  5.35it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.37it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.35it/s] 44%|████▍     | 208/471 [00:38<00:48,  5.38it/s] 44%|████▍     | 209/471 [00:38<00:48,  5.38it/s] 45%|████▍     | 210/471 [00:38<00:48,  5.37it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.37it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.37it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.36it/s] 45%|████▌     | 214/471 [00:39<00:48,  5.35it/s] 46%|████▌     | 215/471 [00:39<00:47,  5.36it/s] 46%|████▌     | 216/471 [00:40<00:47,  5.35it/s] 46%|████▌     | 217/471 [00:40<00:47,  5.33it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.33it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.34it/s] 47%|████▋     | 220/471 [00:40<00:47,  5.33it/s] 47%|████▋     | 221/471 [00:40<00:46,  5.33it/s] 47%|████▋     | 222/471 [00:41<00:46,  5.34it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.36it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.35it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.34it/s] 48%|████▊     | 226/471 [00:41<00:45,  5.34it/s] 48%|████▊     | 227/471 [00:42<00:45,  5.32it/s] 48%|████▊     | 228/471 [00:42<00:45,  5.32it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.32it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.32it/s] 49%|████▉     | 231/471 [00:42<00:45,  5.33it/s] 49%|████▉     | 232/471 [00:43<00:44,  5.34it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.34it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.32it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.32it/s] 50%|█████     | 236/471 [00:43<00:44,  5.34it/s] 50%|█████     | 237/471 [00:43<00:43,  5.33it/s] 51%|█████     | 238/471 [00:44<00:43,  5.33it/s] 51%|█████     | 239/471 [00:44<00:43,  5.34it/s] 51%|█████     | 240/471 [00:44<00:43,  5.33it/s] 51%|█████     | 241/471 [00:44<00:43,  5.31it/s] 51%|█████▏    | 242/471 [00:44<00:43,  5.32it/s] 52%|█████▏    | 243/471 [00:45<00:42,  5.31it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.37it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.35it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.34it/s] 52%|█████▏    | 247/471 [00:45<00:41,  5.35it/s] 53%|█████▎    | 248/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 249/471 [00:46<00:41,  5.32it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.32it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.32it/s] 54%|█████▎    | 252/471 [00:46<00:41,  5.32it/s] 54%|█████▎    | 253/471 [00:46<00:40,  5.33it/s] 54%|█████▍    | 254/471 [00:47<00:40,  5.31it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.30it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.31it/s] 55%|█████▍    | 257/471 [00:47<00:40,  5.31it/s] 55%|█████▍    | 258/471 [00:47<00:40,  5.32it/s] 55%|█████▍    | 259/471 [00:48<00:39,  5.32it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.31it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.30it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.31it/s] 56%|█████▌    | 263/471 [00:48<00:39,  5.31it/s] 56%|█████▌    | 264/471 [00:49<00:38,  5.32it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.32it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.30it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.30it/s] 57%|█████▋    | 268/471 [00:49<00:38,  5.29it/s] 57%|█████▋    | 269/471 [00:49<00:38,  5.31it/s] 57%|█████▋    | 270/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.33it/s] 58%|█████▊    | 273/471 [00:50<00:37,  5.31it/s] 58%|█████▊    | 274/471 [00:50<00:36,  5.34it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.36it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.35it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.34it/s] 59%|█████▉    | 278/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 279/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 280/471 [00:52<00:35,  5.33it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.32it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.33it/s] 60%|██████    | 283/471 [00:52<00:35,  5.33it/s] 60%|██████    | 284/471 [00:52<00:35,  5.32it/s] 61%|██████    | 285/471 [00:52<00:35,  5.31it/s] 61%|██████    | 286/471 [00:53<00:34,  5.30it/s] 61%|██████    | 287/471 [00:53<00:34,  5.30it/s] 61%|██████    | 288/471 [00:53<00:34,  5.30it/s] 61%|██████▏   | 289/471 [00:53<00:34,  5.33it/s] 62%|██████▏   | 290/471 [00:53<00:33,  5.34it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.31it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.31it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.33it/s] 62%|██████▏   | 294/471 [00:54<00:33,  5.34it/s] 63%|██████▎   | 295/471 [00:54<00:32,  5.34it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.35it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.33it/s] 63%|██████▎   | 299/471 [00:55<00:32,  5.33it/s] 64%|██████▎   | 300/471 [00:55<00:32,  5.33it/s] 64%|██████▍   | 301/471 [00:55<00:31,  5.33it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.34it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.33it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.33it/s] 65%|██████▍   | 305/471 [00:56<00:31,  5.34it/s] 65%|██████▍   | 306/471 [00:56<00:30,  5.33it/s] 65%|██████▌   | 307/471 [00:57<00:30,  5.32it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.31it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.31it/s] 66%|██████▌   | 310/471 [00:57<00:30,  5.33it/s] 66%|██████▌   | 311/471 [00:57<00:30,  5.33it/s] 66%|██████▌   | 312/471 [00:58<00:29,  5.33it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.33it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.33it/s] 67%|██████▋   | 315/471 [00:58<00:29,  5.34it/s] 67%|██████▋   | 316/471 [00:58<00:28,  5.35it/s] 67%|██████▋   | 317/471 [00:58<00:28,  5.35it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.34it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.33it/s] 68%|██████▊   | 320/471 [00:59<00:28,  5.31it/s] 68%|██████▊   | 321/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 322/471 [00:59<00:28,  5.32it/s] 69%|██████▊   | 323/471 [01:00<00:27,  5.32it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.31it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.32it/s] 69%|██████▉   | 326/471 [01:00<00:27,  5.32it/s] 69%|██████▉   | 327/471 [01:00<00:27,  5.33it/s] 70%|██████▉   | 328/471 [01:01<00:26,  5.33it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.32it/s] 70%|███████   | 330/471 [01:01<00:26,  5.34it/s] 70%|███████   | 331/471 [01:01<00:26,  5.33it/s] 70%|███████   | 332/471 [01:01<00:26,  5.31it/s] 71%|███████   | 333/471 [01:01<00:25,  5.32it/s] 71%|███████   | 334/471 [01:02<00:25,  5.33it/s] 71%|███████   | 335/471 [01:02<00:25,  5.31it/s] 71%|███████▏  | 336/471 [01:02<00:25,  5.32it/s] 72%|███████▏  | 337/471 [01:02<00:25,  5.33it/s] 72%|███████▏  | 338/471 [01:02<00:24,  5.34it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.33it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.34it/s] 72%|███████▏  | 341/471 [01:03<00:24,  5.33it/s] 73%|███████▎  | 342/471 [01:03<00:24,  5.34it/s] 73%|███████▎  | 343/471 [01:03<00:24,  5.31it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.33it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.33it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.33it/s] 74%|███████▎  | 347/471 [01:04<00:23,  5.34it/s] 74%|███████▍  | 348/471 [01:04<00:23,  5.33it/s] 74%|███████▍  | 349/471 [01:04<00:22,  5.32it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.31it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.35it/s] 75%|███████▍  | 352/471 [01:05<00:22,  5.34it/s] 75%|███████▍  | 353/471 [01:05<00:22,  5.32it/s] 75%|███████▌  | 354/471 [01:05<00:22,  5.31it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.30it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.32it/s] 76%|███████▌  | 357/471 [01:06<00:21,  5.33it/s] 76%|███████▌  | 358/471 [01:06<00:21,  5.32it/s] 76%|███████▌  | 359/471 [01:06<00:21,  5.31it/s] 76%|███████▋  | 360/471 [01:07<00:20,  5.30it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 362/471 [01:07<00:20,  5.34it/s] 77%|███████▋  | 363/471 [01:07<00:20,  5.33it/s] 77%|███████▋  | 364/471 [01:07<00:20,  5.33it/s] 77%|███████▋  | 365/471 [01:08<00:19,  5.30it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.30it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.31it/s] 78%|███████▊  | 368/471 [01:08<00:19,  5.32it/s] 78%|███████▊  | 369/471 [01:08<00:19,  5.32it/s] 79%|███████▊  | 370/471 [01:08<00:19,  5.30it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 373/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 374/471 [01:09<00:18,  5.32it/s] 80%|███████▉  | 375/471 [01:09<00:18,  5.31it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.31it/s] 80%|████████  | 377/471 [01:10<00:17,  5.31it/s] 80%|████████  | 378/471 [01:10<00:17,  5.33it/s] 80%|████████  | 379/471 [01:10<00:17,  5.33it/s] 81%|████████  | 380/471 [01:10<00:17,  5.31it/s] 81%|████████  | 381/471 [01:11<00:16,  5.30it/s] 81%|████████  | 382/471 [01:11<00:16,  5.30it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.29it/s] 82%|████████▏ | 384/471 [01:11<00:16,  5.27it/s] 82%|████████▏ | 385/471 [01:11<00:16,  5.28it/s] 82%|████████▏ | 386/471 [01:11<00:16,  5.27it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.27it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.27it/s] 83%|████████▎ | 389/471 [01:12<00:15,  5.29it/s] 83%|████████▎ | 390/471 [01:12<00:15,  5.29it/s] 83%|████████▎ | 391/471 [01:12<00:15,  5.30it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.30it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.31it/s] 84%|████████▎ | 394/471 [01:13<00:14,  5.30it/s] 84%|████████▍ | 395/471 [01:13<00:14,  5.29it/s] 84%|████████▍ | 396/471 [01:13<00:14,  5.29it/s] 84%|████████▍ | 397/471 [01:14<00:13,  5.30it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.30it/s] 85%|████████▍ | 399/471 [01:14<00:13,  5.29it/s] 85%|████████▍ | 400/471 [01:14<00:13,  5.30it/s] 85%|████████▌ | 401/471 [01:14<00:13,  5.30it/s] 85%|████████▌ | 402/471 [01:14<00:13,  5.30it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.30it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.31it/s] 86%|████████▌ | 405/471 [01:15<00:12,  5.29it/s] 86%|████████▌ | 406/471 [01:15<00:12,  5.30it/s] 86%|████████▋ | 407/471 [01:15<00:12,  5.32it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.30it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.30it/s] 87%|████████▋ | 410/471 [01:16<00:11,  5.30it/s] 87%|████████▋ | 411/471 [01:16<00:11,  5.32it/s] 87%|████████▋ | 412/471 [01:16<00:11,  5.30it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.31it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.30it/s] 88%|████████▊ | 415/471 [01:17<00:10,  5.32it/s] 88%|████████▊ | 416/471 [01:17<00:10,  5.29it/s] 89%|████████▊ | 417/471 [01:17<00:10,  5.31it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.29it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.30it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.33it/s] 89%|████████▉ | 421/471 [01:18<00:09,  5.32it/s] 90%|████████▉ | 422/471 [01:18<00:09,  5.33it/s] 90%|████████▉ | 423/471 [01:18<00:09,  5.33it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.30it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.32it/s] 90%|█████████ | 426/471 [01:19<00:08,  5.32it/s] 91%|█████████ | 427/471 [01:19<00:08,  5.32it/s] 91%|█████████ | 428/471 [01:19<00:08,  5.31it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.29it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.28it/s] 92%|█████████▏| 431/471 [01:20<00:07,  5.28it/s] 92%|█████████▏| 432/471 [01:20<00:07,  5.29it/s] 92%|█████████▏| 433/471 [01:20<00:07,  5.29it/s] 92%|█████████▏| 434/471 [01:21<00:06,  5.30it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.29it/s] 93%|█████████▎| 436/471 [01:21<00:06,  5.30it/s] 93%|█████████▎| 437/471 [01:21<00:06,  5.29it/s] 93%|█████████▎| 438/471 [01:21<00:06,  5.31it/s] 93%|█████████▎| 439/471 [01:21<00:06,  5.31it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.31it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.31it/s] 94%|█████████▍| 442/471 [01:22<00:05,  5.32it/s] 94%|█████████▍| 443/471 [01:22<00:05,  5.32it/s] 94%|█████████▍| 444/471 [01:22<00:05,  5.30it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.30it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.28it/s] 95%|█████████▍| 447/471 [01:23<00:04,  5.29it/s] 95%|█████████▌| 448/471 [01:23<00:04,  5.31it/s] 95%|█████████▌| 449/471 [01:23<00:04,  5.32it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.30it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.29it/s] 96%|█████████▌| 452/471 [01:24<00:03,  5.31it/s] 96%|█████████▌| 453/471 [01:24<00:03,  5.29it/s] 96%|█████████▋| 454/471 [01:24<00:03,  5.29it/s] 97%|█████████▋| 455/471 [01:24<00:03,  5.28it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.30it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.30it/s] 97%|█████████▋| 458/471 [01:25<00:02,  5.31it/s] 97%|█████████▋| 459/471 [01:25<00:02,  5.33it/s] 98%|█████████▊| 460/471 [01:25<00:02,  5.31it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.31it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.31it/s] 98%|█████████▊| 463/471 [01:26<00:01,  5.32it/s] 99%|█████████▊| 464/471 [01:26<00:01,  5.32it/s] 99%|█████████▊| 465/471 [01:26<00:01,  5.32it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.31it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.29it/s] 99%|█████████▉| 468/471 [01:27<00:00,  5.29it/s]100%|█████████▉| 469/471 [01:27<00:00,  5.30it/s]100%|█████████▉| 470/471 [01:27<00:00,  5.32it/s]100%|██████████| 471/471 [01:27<00:00,  5.68it/s]100%|██████████| 471/471 [01:27<00:00,  5.36it/s]
{'eval_loss': 4.089284896850586, 'eval_model_preparation_time': 0.0056, 'eval_acc': 0.15161975570897504, 'eval_runtime': 88.1166, 'eval_samples_per_second': 85.478, 'eval_steps_per_second': 5.345}
ROUND:2
CLIENT:75
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]                                              {'loss': 4.5908, 'grad_norm': 4.598965167999268, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]                                              {'loss': 3.7456, 'grad_norm': 4.363457679748535, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 3.2584, 'grad_norm': 4.154833793640137, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.0713, 'grad_norm': 5.8451828956604, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.8894, 'grad_norm': 5.685099124908447, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.0808, 'grad_norm': 6.78548526763916, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 1.8876, 'grad_norm': 6.278254508972168, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.4453, 'grad_norm': 16.808752059936523, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s]                                              {'loss': 1.0058, 'grad_norm': 4.786003112792969, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s]                                               {'loss': 0.4165, 'grad_norm': 4.254813194274902, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.4842, 'grad_norm': 5.1125593185424805, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.29it/s]                                               {'loss': 2.0011, 'grad_norm': 6.379988193511963, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.29it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s]                                               {'loss': 1.187, 'grad_norm': 4.835880756378174, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 1.3619, 'grad_norm': 5.400984287261963, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.2725, 'grad_norm': 5.866417407989502, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.7561, 'grad_norm': 20.835311889648438, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s]                                               {'loss': 0.1456, 'grad_norm': 1.3765828609466553, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.3467, 'grad_norm': 2.4678118228912354, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.4014, 'grad_norm': 3.1980624198913574, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.6938, 'grad_norm': 3.3393616676330566, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.667, 'grad_norm': 5.4292168617248535, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.3114, 'grad_norm': 4.819849014282227, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.3752, 'grad_norm': 6.78969669342041, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 2.3832, 'grad_norm': 46.37579345703125, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.4583, 'grad_norm': 5.397048473358154, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.0375, 'grad_norm': 0.676877498626709, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.09, 'grad_norm': 1.989953875541687, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.2098, 'grad_norm': 3.4201009273529053, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.4132, 'grad_norm': 1.0459388494491577, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.037, 'grad_norm': 0.6063578128814697, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.2684, 'grad_norm': 3.672724485397339, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0316, 'grad_norm': 1.7436583042144775, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s]                                               {'loss': 0.0339, 'grad_norm': 0.5757097005844116, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s]                                               {'loss': 0.3989, 'grad_norm': 3.5281617641448975, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0561, 'grad_norm': 1.131485939025879, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.0218, 'grad_norm': 0.5268239974975586, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.3641, 'grad_norm': 0.6632909774780273, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1041, 'grad_norm': 8.046113967895508, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0519, 'grad_norm': 1.331475019454956, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.2965, 'grad_norm': 16.141456604003906, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1449, 'train_samples_per_second': 46.522, 'train_steps_per_second': 3.294, 'train_loss': 0.9912948276847601, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.15it/s]                                              {'loss': 3.6366, 'grad_norm': 4.696237564086914, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.15it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 4.2379, 'grad_norm': 5.73801326751709, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.4636, 'grad_norm': 6.218109607696533, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.7846, 'grad_norm': 4.357229709625244, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 3.4843, 'grad_norm': 6.2708659172058105, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.6737, 'grad_norm': 6.675852298736572, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 3.4279, 'grad_norm': 7.5375895500183105, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 2.2672, 'grad_norm': 32.57071304321289, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.97it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.58it/s]                                              {'loss': 1.5534, 'grad_norm': 7.1592631340026855, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.58it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.40it/s]                                               {'loss': 1.8661, 'grad_norm': 6.924653053283691, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.40it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.30it/s]                                               {'loss': 1.7931, 'grad_norm': 6.4171247482299805, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.30it/s] 30%|███       | 12/40 [00:03<00:08,  3.21it/s]                                               {'loss': 0.8585, 'grad_norm': 6.7634196281433105, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.21it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.136, 'grad_norm': 6.167084693908691, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.8025, 'grad_norm': 6.426516532897949, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.2492, 'grad_norm': 7.67838191986084, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.2303, 'grad_norm': 7.557979106903076, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.4135, 'grad_norm': 2.5125465393066406, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s]                                               {'loss': 0.3893, 'grad_norm': 4.704623699188232, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.39, 'grad_norm': 3.703981399536133, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.728, 'grad_norm': 3.2328476905822754, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s]                                               {'loss': 0.5534, 'grad_norm': 3.1549530029296875, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.4939, 'grad_norm': 4.955244064331055, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.5263, 'grad_norm': 5.471122741699219, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.073, 'grad_norm': 3.4296138286590576, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s]                                               {'loss': 0.128, 'grad_norm': 2.7986228466033936, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.63it/s]                                               {'loss': 0.841, 'grad_norm': 1.964670181274414, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.63it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.45it/s]                                               {'loss': 0.1867, 'grad_norm': 3.8798656463623047, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.45it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.0639, 'grad_norm': 1.4131964445114136, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.0372, 'grad_norm': 1.1058481931686401, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.1584, 'grad_norm': 2.6671833992004395, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0956, 'grad_norm': 2.351423740386963, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0148, 'grad_norm': 0.8191962242126465, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.0197, 'grad_norm': 0.41358256340026855, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.0136, 'grad_norm': 0.28195181488990784, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.054, 'grad_norm': 1.5392478704452515, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.3704, 'grad_norm': 1.8411271572113037, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0887, 'grad_norm': 3.6749062538146973, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.4241, 'grad_norm': 0.8638366460800171, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0391, 'grad_norm': 0.6891055703163147, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0091, 'grad_norm': 0.5660634636878967, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1173, 'train_samples_per_second': 46.627, 'train_steps_per_second': 3.301, 'train_loss': 1.0394185308599844, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:46
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.16it/s]                                              {'loss': 3.7218, 'grad_norm': 4.433317184448242, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.16it/s]  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]                                              {'loss': 4.2365, 'grad_norm': 5.745333671569824, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 3.757, 'grad_norm': 5.075717926025391, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 3.2874, 'grad_norm': 4.585534572601318, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.1731, 'grad_norm': 6.7317681312561035, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.5561, 'grad_norm': 6.016291618347168, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 3.3354, 'grad_norm': 8.428309440612793, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 5.2717, 'grad_norm': 29.32322120666504, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 1.0365, 'grad_norm': 5.069332122802734, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 1.5439, 'grad_norm': 8.168330192565918, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 1.4602, 'grad_norm': 5.96307373046875, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.4649, 'grad_norm': 6.3176398277282715, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.3423, 'grad_norm': 4.634482383728027, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.309, 'grad_norm': 4.505270481109619, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 1.1597, 'grad_norm': 5.409724712371826, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 3.7344, 'grad_norm': 32.408226013183594, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s]                                               {'loss': 0.6549, 'grad_norm': 4.376087188720703, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 1.1333, 'grad_norm': 5.113670825958252, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s]                                               {'loss': 0.8342, 'grad_norm': 3.312004804611206, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.4021, 'grad_norm': 4.322207927703857, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.5475, 'grad_norm': 6.922961235046387, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s]                                               {'loss': 0.1146, 'grad_norm': 1.6300861835479736, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s]                                               {'loss': 0.7186, 'grad_norm': 6.420275688171387, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s]                                               {'loss': 0.1043, 'grad_norm': 5.659101963043213, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.02it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.70it/s]                                               {'loss': 0.0792, 'grad_norm': 2.194796323776245, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.70it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.48it/s]                                               {'loss': 0.1644, 'grad_norm': 4.769387722015381, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.48it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.1779, 'grad_norm': 5.991413116455078, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.31it/s] 70%|███████   | 28/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.5509, 'grad_norm': 1.7872908115386963, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.21it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s]                                               {'loss': 0.6428, 'grad_norm': 3.6356780529022217, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.1896, 'grad_norm': 3.5886356830596924, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.2719, 'grad_norm': 3.9035117626190186, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.0648, 'grad_norm': 3.2403907775878906, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.70it/s]                                               {'loss': 0.4065, 'grad_norm': 1.4066165685653687, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.70it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.46it/s]                                               {'loss': 0.186, 'grad_norm': 10.461322784423828, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.46it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s]                                               {'loss': 0.4593, 'grad_norm': 2.786677122116089, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.21it/s]                                               {'loss': 0.0828, 'grad_norm': 1.7549699544906616, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.21it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.2033, 'grad_norm': 5.3863396644592285, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0486, 'grad_norm': 0.8800793886184692, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.2002, 'grad_norm': 4.991193771362305, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 1.7083, 'grad_norm': 3.638261556625366, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]                                               {'train_runtime': 12.2931, 'train_samples_per_second': 45.961, 'train_steps_per_second': 3.254, 'train_loss': 1.3083994148299098, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
CLIENT:68
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 3.2709, 'grad_norm': 4.523273944854736, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 3.9752, 'grad_norm': 4.651933193206787, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 3.4947, 'grad_norm': 4.199632167816162, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 3.7297, 'grad_norm': 5.778169631958008, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 2.8295, 'grad_norm': 6.460909366607666, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:02<00:11,  3.00it/s]                                              {'loss': 3.0256, 'grad_norm': 6.879714488983154, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 2.5385, 'grad_norm': 7.721651554107666, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 0.9809, 'grad_norm': 22.677751541137695, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s]                                              {'loss': 0.9937, 'grad_norm': 6.349400043487549, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s]                                               {'loss': 1.289, 'grad_norm': 6.088437080383301, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 1.5217, 'grad_norm': 6.326113700866699, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 1.7665, 'grad_norm': 5.432167053222656, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.7324, 'grad_norm': 5.950098037719727, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 1.2103, 'grad_norm': 6.504226207733154, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.7281, 'grad_norm': 4.612929821014404, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.3538, 'grad_norm': 28.917858123779297, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.6968, 'grad_norm': 5.041503429412842, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.69, 'grad_norm': 5.216536045074463, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.3487, 'grad_norm': 3.8410215377807617, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.4513, 'grad_norm': 3.7765445709228516, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.3924, 'grad_norm': 4.408530235290527, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.8401, 'grad_norm': 5.833376407623291, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.4405, 'grad_norm': 6.129073143005371, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.9119, 'grad_norm': 27.435075759887695, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.0788, 'grad_norm': 1.1725349426269531, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.0813, 'grad_norm': 1.038804054260254, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.1158, 'grad_norm': 1.8344242572784424, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.4742, 'grad_norm': 1.4716497659683228, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.1017, 'grad_norm': 1.9996451139450073, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0592, 'grad_norm': 1.6639368534088135, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.2887, 'grad_norm': 6.378075122833252, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0502, 'grad_norm': 2.3598594665527344, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.88it/s]                                               {'loss': 0.1974, 'grad_norm': 4.901224136352539, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.88it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.0279, 'grad_norm': 0.6071358919143677, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.0924, 'grad_norm': 3.1128523349761963, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.0597, 'grad_norm': 1.579298973083496, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0347, 'grad_norm': 0.9233108162879944, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0417, 'grad_norm': 2.4110076427459717, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.4798, 'grad_norm': 3.1078476905822754, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0096, 'grad_norm': 0.41683390736579895, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.165, 'train_samples_per_second': 46.445, 'train_steps_per_second': 3.288, 'train_loss': 1.0101343801710754, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:3
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]                                              {'loss': 3.2497, 'grad_norm': 4.27190637588501, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]                                              {'loss': 2.9999, 'grad_norm': 4.106352806091309, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.8562, 'grad_norm': 3.788999080657959, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:12,  3.00it/s]                                              {'loss': 3.0481, 'grad_norm': 5.009311199188232, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 3.1609, 'grad_norm': 5.646756172180176, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.90it/s]                                              {'loss': 3.1026, 'grad_norm': 5.54048490524292, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.90it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 3.8345, 'grad_norm': 8.46491813659668, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 2.4387, 'grad_norm': 24.02939796447754, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.95it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.68it/s]                                              {'loss': 1.9234, 'grad_norm': 7.645185470581055, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.68it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.40it/s]                                               {'loss': 2.079, 'grad_norm': 11.697415351867676, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.40it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.27it/s]                                               {'loss': 2.455, 'grad_norm': 10.1458101272583, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.27it/s] 30%|███       | 12/40 [00:03<00:08,  3.18it/s]                                               {'loss': 1.32, 'grad_norm': 6.486445903778076, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.18it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.3938, 'grad_norm': 4.501594066619873, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.12it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.0251, 'grad_norm': 6.556766510009766, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 1.1504, 'grad_norm': 5.140591621398926, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 2.0766, 'grad_norm': 41.96565628051758, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s]                                               {'loss': 0.8874, 'grad_norm': 3.635139226913452, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s]                                               {'loss': 0.3928, 'grad_norm': 3.138723611831665, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s]                                               {'loss': 0.9727, 'grad_norm': 4.073339462280273, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s] 50%|█████     | 20/40 [00:06<00:06,  3.23it/s]                                               {'loss': 0.79, 'grad_norm': 4.792733192443848, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.23it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.13it/s]                                               {'loss': 0.2298, 'grad_norm': 2.8919920921325684, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.13it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.03it/s]                                               {'loss': 0.5517, 'grad_norm': 9.730159759521484, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.03it/s] 57%|█████▊    | 23/40 [00:07<00:05,  2.98it/s]                                               {'loss': 0.6702, 'grad_norm': 5.765382766723633, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  2.98it/s]                                               {'loss': 0.0389, 'grad_norm': 2.0313758850097656, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  2.98it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.65it/s]                                               {'loss': 0.115, 'grad_norm': 2.2058143615722656, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.65it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.45it/s]                                               {'loss': 0.0654, 'grad_norm': 1.5936022996902466, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.45it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.32it/s]                                               {'loss': 0.0514, 'grad_norm': 2.109194040298462, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.32it/s] 70%|███████   | 28/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.2476, 'grad_norm': 2.607090950012207, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.22it/s] 72%|███████▎  | 29/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0881, 'grad_norm': 1.381400227546692, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:09<00:03,  3.13it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.2991, 'grad_norm': 4.900343418121338, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.6335, 'grad_norm': 4.823022365570068, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0134, 'grad_norm': 0.8075236082077026, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.79it/s]                                               {'loss': 0.4633, 'grad_norm': 0.7673289179801941, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0285, 'grad_norm': 0.5474350452423096, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s]                                               {'loss': 0.0692, 'grad_norm': 1.5021641254425049, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.18it/s]                                               {'loss': 0.0607, 'grad_norm': 1.8891736268997192, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.18it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1478, 'grad_norm': 0.7236509919166565, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.1576, 'grad_norm': 0.5583407282829285, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.05it/s]                                               {'loss': 0.024, 'grad_norm': 1.112410306930542, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.05it/s]                                               {'loss': 0.0288, 'grad_norm': 2.5260651111602783, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]                                               {'train_runtime': 12.3806, 'train_samples_per_second': 45.636, 'train_steps_per_second': 3.231, 'train_loss': 1.1535131639102474, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]100%|██████████| 40/40 [00:12<00:00,  3.23it/s]
CLIENT:39
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]                                              {'loss': 4.7289, 'grad_norm': 5.569986343383789, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 3.6026, 'grad_norm': 4.761326789855957, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:01<00:12,  3.01it/s]                                              {'loss': 3.9826, 'grad_norm': 4.4819512367248535, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.0271, 'grad_norm': 4.777061939239502, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.6517, 'grad_norm': 5.719221591949463, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.8132, 'grad_norm': 7.558746814727783, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 2.6121, 'grad_norm': 5.499409198760986, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.7274, 'grad_norm': 17.58648681640625, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 2.292, 'grad_norm': 7.388679504394531, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 1.5874, 'grad_norm': 7.056763648986816, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 2.0216, 'grad_norm': 8.819220542907715, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 2.1733, 'grad_norm': 5.435306072235107, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s]                                               {'loss': 1.3807, 'grad_norm': 4.462538242340088, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.8795, 'grad_norm': 4.105214595794678, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 1.3234, 'grad_norm': 4.1807451248168945, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 1.8443, 'grad_norm': 31.31613540649414, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.14it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s]                                               {'loss': 1.171, 'grad_norm': 4.108613967895508, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s]                                               {'loss': 0.681, 'grad_norm': 3.336134195327759, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s]                                               {'loss': 0.9804, 'grad_norm': 5.335590362548828, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.648, 'grad_norm': 3.529812812805176, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s]                                               {'loss': 0.5822, 'grad_norm': 4.251758098602295, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.5973, 'grad_norm': 4.471911907196045, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.18it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.4818, 'grad_norm': 3.370582342147827, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.1753, 'grad_norm': 8.846511840820312, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.13it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.1022, 'grad_norm': 2.180769920349121, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s]                                               {'loss': 0.6221, 'grad_norm': 4.35640811920166, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s]                                               {'loss': 0.1636, 'grad_norm': 3.319467067718506, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.3661, 'grad_norm': 4.493676662445068, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1571, 'grad_norm': 3.735644578933716, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s]                                               {'loss': 0.1492, 'grad_norm': 2.7258353233337402, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.2211, 'grad_norm': 2.0610692501068115, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0583, 'grad_norm': 1.6801837682724, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.7434, 'grad_norm': 2.461857795715332, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s]                                               {'loss': 0.1637, 'grad_norm': 1.2273186445236206, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.45it/s]                                               {'loss': 0.0444, 'grad_norm': 0.9291870594024658, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.45it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s]                                               {'loss': 0.0589, 'grad_norm': 0.9777728319168091, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.0595, 'grad_norm': 1.7287439107894897, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0783, 'grad_norm': 2.1181907653808594, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1195, 'grad_norm': 4.323695659637451, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0375, 'grad_norm': 1.5252816677093506, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.1664, 'train_samples_per_second': 46.439, 'train_steps_per_second': 3.288, 'train_loss': 1.1527476749382912, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:23
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.00it/s]                                              {'loss': 3.6757, 'grad_norm': 3.7738850116729736, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 3.3142, 'grad_norm': 3.914600133895874, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 5.2552, 'grad_norm': 4.32063102722168, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.6081, 'grad_norm': 4.3420891761779785, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.1894, 'grad_norm': 6.478490829467773, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.8709, 'grad_norm': 6.603949069976807, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 2.3256, 'grad_norm': 8.38040828704834, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.3237, 'grad_norm': 9.892054557800293, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 1.7127, 'grad_norm': 6.971911430358887, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 2.1574, 'grad_norm': 5.263123035430908, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.6991, 'grad_norm': 6.2018818855285645, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.1824, 'grad_norm': 6.224777698516846, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.1174, 'grad_norm': 6.414285659790039, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.9736, 'grad_norm': 4.26736307144165, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.0961, 'grad_norm': 5.125978469848633, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 3.2439, 'grad_norm': 29.210424423217773, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s]                                               {'loss': 0.5987, 'grad_norm': 3.7507073879241943, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.2954, 'grad_norm': 2.6593523025512695, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.9408, 'grad_norm': 4.961137771606445, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.7151, 'grad_norm': 6.20033597946167, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s]                                               {'loss': 0.1991, 'grad_norm': 2.4440789222717285, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.8177, 'grad_norm': 5.423079490661621, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.3245, 'grad_norm': 3.86527681350708, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 3.7556, 'grad_norm': 51.88225173950195, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.5189, 'grad_norm': 1.9766132831573486, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.2637, 'grad_norm': 2.9893290996551514, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.3078, 'grad_norm': 5.0413994789123535, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.0948, 'grad_norm': 3.4924144744873047, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1145, 'grad_norm': 1.8170379400253296, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.1765, 'grad_norm': 1.2232913970947266, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.5781, 'grad_norm': 4.355576038360596, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0394, 'grad_norm': 2.473522663116455, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0488, 'grad_norm': 1.0445911884307861, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.049, 'grad_norm': 1.1703027486801147, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.5838, 'grad_norm': 1.7511509656906128, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0522, 'grad_norm': 1.3685216903686523, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0493, 'grad_norm': 1.127297043800354, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.1383, 'grad_norm': 2.763381242752075, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.5439, 'grad_norm': 0.6532866358757019, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0318, 'grad_norm': 2.0608410835266113, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.129, 'train_samples_per_second': 46.582, 'train_steps_per_second': 3.298, 'train_loss': 1.199577396735549, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:20
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 3.4249, 'grad_norm': 4.747334003448486, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.785, 'grad_norm': 4.783246994018555, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 3.9946, 'grad_norm': 6.110980033874512, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.08it/s]                                              {'loss': 3.6587, 'grad_norm': 5.303973197937012, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.08it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 3.2339, 'grad_norm': 6.967758655548096, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.0495, 'grad_norm': 8.308976173400879, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 2.185, 'grad_norm': 7.042391300201416, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 4.0094, 'grad_norm': 38.474918365478516, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 1.9521, 'grad_norm': 12.201498985290527, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 1.8634, 'grad_norm': 8.670244216918945, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 1.5445, 'grad_norm': 8.855952262878418, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 2.4937, 'grad_norm': 8.726612091064453, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.498, 'grad_norm': 5.036780834197998, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 1.7191, 'grad_norm': 5.460379123687744, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.8757, 'grad_norm': 5.462569713592529, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 2.991, 'grad_norm': 39.90457534790039, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s]                                               {'loss': 1.6201, 'grad_norm': 3.4059391021728516, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.6638, 'grad_norm': 2.5315067768096924, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 1.4705, 'grad_norm': 7.689818382263184, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.5573, 'grad_norm': 6.649745941162109, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.4057, 'grad_norm': 3.466742992401123, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.7212, 'grad_norm': 4.424696445465088, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.4603, 'grad_norm': 7.879836559295654, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.0099, 'grad_norm': 0.5261226892471313, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.70it/s]                                               {'loss': 0.196, 'grad_norm': 5.18254280090332, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.70it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.50it/s]                                               {'loss': 0.554, 'grad_norm': 6.161739349365234, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.50it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.4947, 'grad_norm': 2.683037281036377, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.8012, 'grad_norm': 2.7082839012145996, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.6443, 'grad_norm': 3.505608081817627, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.6748, 'grad_norm': 8.39622974395752, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.2682, 'grad_norm': 3.964348793029785, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.012, 'grad_norm': 0.596546471118927, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s]                                               {'loss': 0.4288, 'grad_norm': 1.2839603424072266, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s]                                               {'loss': 0.0699, 'grad_norm': 1.3608030080795288, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.3879, 'grad_norm': 0.8167660236358643, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.3052, 'grad_norm': 1.259318232536316, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.4177, 'grad_norm': 1.1175618171691895, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.7026, 'grad_norm': 2.3885202407836914, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.166, 'grad_norm': 4.402243137359619, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0171, 'grad_norm': 0.8484035134315491, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1871, 'train_samples_per_second': 46.361, 'train_steps_per_second': 3.282, 'train_loss': 1.3581918230745942, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:70
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 5.0919, 'grad_norm': 4.278078556060791, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 4.2176, 'grad_norm': 3.921665906906128, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  2.96it/s]                                              {'loss': 2.8224, 'grad_norm': 3.9307565689086914, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.96it/s] 10%|█         | 4/40 [00:01<00:12,  2.98it/s]                                              {'loss': 3.9561, 'grad_norm': 4.285918712615967, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.98it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s]                                              {'loss': 2.6156, 'grad_norm': 4.360752105712891, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s]                                              {'loss': 2.2197, 'grad_norm': 4.426026821136475, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.96it/s]                                              {'loss': 2.4397, 'grad_norm': 5.77546501159668, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.96it/s]                                              {'loss': 0.8497, 'grad_norm': 17.81185531616211, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.96it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 1.2304, 'grad_norm': 4.810622692108154, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 1.0688, 'grad_norm': 5.3525543212890625, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s]                                               {'loss': 1.3954, 'grad_norm': 5.652294158935547, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s] 30%|███       | 12/40 [00:03<00:08,  3.21it/s]                                               {'loss': 1.3954, 'grad_norm': 8.224632263183594, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.21it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s]                                               {'loss': 2.011, 'grad_norm': 6.288396835327148, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.8155, 'grad_norm': 5.571752548217773, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s]                                               {'loss': 1.7211, 'grad_norm': 9.01666259765625, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s]                                               {'loss': 0.2159, 'grad_norm': 10.60460090637207, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.03it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.3306, 'grad_norm': 3.6871914863586426, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.5172, 'grad_norm': 4.702805519104004, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s]                                               {'loss': 0.6861, 'grad_norm': 3.034754753112793, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s] 50%|█████     | 20/40 [00:06<00:06,  3.23it/s]                                               {'loss': 0.4004, 'grad_norm': 7.338958740234375, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.23it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.13it/s]                                               {'loss': 0.2942, 'grad_norm': 3.7061052322387695, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.13it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s]                                               {'loss': 0.59, 'grad_norm': 4.720744609832764, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s]                                               {'loss': 0.486, 'grad_norm': 7.38851261138916, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s]                                               {'loss': 0.164, 'grad_norm': 9.13369083404541, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.02it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.69it/s]                                               {'loss': 0.0871, 'grad_norm': 1.2409958839416504, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.69it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.45it/s]                                               {'loss': 0.0976, 'grad_norm': 1.7155592441558838, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.45it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.0861, 'grad_norm': 1.2651557922363281, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.30it/s] 70%|███████   | 28/40 [00:08<00:03,  3.15it/s]                                               {'loss': 0.5811, 'grad_norm': 2.6207776069641113, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.15it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.08it/s]                                               {'loss': 0.1307, 'grad_norm': 7.085379123687744, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.08it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.01it/s]                                               {'loss': 0.1339, 'grad_norm': 5.76761531829834, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.01it/s] 78%|███████▊  | 31/40 [00:09<00:03,  2.98it/s]                                               {'loss': 0.1211, 'grad_norm': 2.658247709274292, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:03,  2.98it/s]                                               {'loss': 0.0532, 'grad_norm': 5.564182281494141, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  2.98it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.75it/s]                                               {'loss': 0.4662, 'grad_norm': 0.7235230803489685, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.75it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.49it/s]                                               {'loss': 0.0388, 'grad_norm': 0.7087377309799194, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.49it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.32it/s]                                               {'loss': 0.0178, 'grad_norm': 0.4732835292816162, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.32it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.20it/s]                                               {'loss': 0.0219, 'grad_norm': 0.5594825148582458, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.20it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.2357, 'grad_norm': 10.424931526184082, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0474, 'grad_norm': 1.0148060321807861, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.06it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.02it/s]                                               {'loss': 0.0663, 'grad_norm': 2.7407546043395996, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.02it/s]                                               {'loss': 0.1971, 'grad_norm': 11.021657943725586, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.02it/s]                                               {'train_runtime': 12.4486, 'train_samples_per_second': 45.387, 'train_steps_per_second': 3.213, 'train_loss': 0.9979149491526187, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.02it/s]100%|██████████| 40/40 [00:12<00:00,  3.21it/s]
CLIENT:73
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.93it/s]                                              {'loss': 5.0486, 'grad_norm': 4.448971271514893, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.93it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 3.8947, 'grad_norm': 4.3765549659729, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  3.00it/s]                                              {'loss': 3.2501, 'grad_norm': 4.083184242248535, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  3.00it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.0811, 'grad_norm': 5.325883388519287, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.2227, 'grad_norm': 6.679911136627197, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.0994, 'grad_norm': 5.762972354888916, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.4209, 'grad_norm': 7.284677982330322, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.9618, 'grad_norm': 27.419466018676758, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 1.7534, 'grad_norm': 7.780856132507324, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 0.7045, 'grad_norm': 5.567626953125, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 0.9669, 'grad_norm': 5.540674686431885, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.7708, 'grad_norm': 7.648612976074219, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.8388, 'grad_norm': 6.673650741577148, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.2052, 'grad_norm': 5.818518161773682, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.2055, 'grad_norm': 5.281649589538574, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.0315, 'grad_norm': 1.3493635654449463, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.3095, 'grad_norm': 4.83577823638916, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.3832, 'grad_norm': 2.899575710296631, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s]                                               {'loss': 0.4394, 'grad_norm': 3.3823604583740234, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.7956, 'grad_norm': 8.165914535522461, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.5014, 'grad_norm': 4.059670925140381, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.3897, 'grad_norm': 5.026113033294678, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.3872, 'grad_norm': 5.616112232208252, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.0079, 'grad_norm': 0.3225562274456024, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.1017, 'grad_norm': 1.9192298650741577, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.0807, 'grad_norm': 1.2258085012435913, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s]                                               {'loss': 0.2277, 'grad_norm': 5.699549674987793, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.1127, 'grad_norm': 3.0135087966918945, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.1385, 'grad_norm': 2.517871141433716, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.1916, 'grad_norm': 2.6880369186401367, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0724, 'grad_norm': 1.5829684734344482, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.3439, 'grad_norm': 14.256264686584473, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.0285, 'grad_norm': 0.6960389018058777, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.0303, 'grad_norm': 0.7910438179969788, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0608, 'grad_norm': 1.6049435138702393, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s]                                               {'loss': 0.013, 'grad_norm': 0.33023950457572937, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0326, 'grad_norm': 1.058951735496521, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.14it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0893, 'grad_norm': 3.5229172706604004, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.02it/s]                                               {'loss': 0.0246, 'grad_norm': 0.6259491443634033, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.02it/s]                                               {'loss': 0.0097, 'grad_norm': 0.4519200325012207, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.02it/s]                                               {'train_runtime': 12.2561, 'train_samples_per_second': 46.099, 'train_steps_per_second': 3.264, 'train_loss': 0.9556887965882197, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.02it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:43, 10.86it/s]  1%|          | 4/471 [00:00<01:08,  6.82it/s]  1%|          | 5/471 [00:00<01:14,  6.27it/s]  1%|▏         | 6/471 [00:00<01:18,  5.96it/s]  1%|▏         | 7/471 [00:01<01:20,  5.75it/s]  2%|▏         | 8/471 [00:01<01:21,  5.66it/s]  2%|▏         | 9/471 [00:01<01:22,  5.57it/s]  2%|▏         | 10/471 [00:01<01:23,  5.52it/s]  2%|▏         | 11/471 [00:01<01:24,  5.46it/s]  3%|▎         | 12/471 [00:02<01:24,  5.42it/s]  3%|▎         | 13/471 [00:02<01:24,  5.40it/s]  3%|▎         | 14/471 [00:02<01:24,  5.39it/s]  3%|▎         | 15/471 [00:02<01:24,  5.40it/s]  3%|▎         | 16/471 [00:02<01:24,  5.38it/s]  4%|▎         | 17/471 [00:02<01:24,  5.37it/s]  4%|▍         | 18/471 [00:03<01:24,  5.37it/s]  4%|▍         | 19/471 [00:03<01:24,  5.36it/s]  4%|▍         | 20/471 [00:03<01:24,  5.35it/s]  4%|▍         | 21/471 [00:03<01:24,  5.36it/s]  5%|▍         | 22/471 [00:03<01:24,  5.34it/s]  5%|▍         | 23/471 [00:04<01:23,  5.35it/s]  5%|▌         | 24/471 [00:04<01:23,  5.34it/s]  5%|▌         | 25/471 [00:04<01:23,  5.33it/s]  6%|▌         | 26/471 [00:04<01:23,  5.35it/s]  6%|▌         | 27/471 [00:04<01:22,  5.35it/s]  6%|▌         | 28/471 [00:05<01:23,  5.34it/s]  6%|▌         | 29/471 [00:05<01:22,  5.33it/s]  6%|▋         | 30/471 [00:05<01:22,  5.32it/s]  7%|▋         | 31/471 [00:05<01:22,  5.33it/s]  7%|▋         | 32/471 [00:05<01:21,  5.35it/s]  7%|▋         | 33/471 [00:05<01:21,  5.38it/s]  7%|▋         | 34/471 [00:06<01:21,  5.38it/s]  7%|▋         | 35/471 [00:06<01:21,  5.35it/s]  8%|▊         | 36/471 [00:06<01:21,  5.36it/s]  8%|▊         | 37/471 [00:06<01:21,  5.35it/s]  8%|▊         | 38/471 [00:06<01:21,  5.33it/s]  8%|▊         | 39/471 [00:07<01:21,  5.33it/s]  8%|▊         | 40/471 [00:07<01:20,  5.33it/s]  9%|▊         | 41/471 [00:07<01:20,  5.33it/s]  9%|▉         | 42/471 [00:07<01:20,  5.33it/s]  9%|▉         | 43/471 [00:07<01:20,  5.33it/s]  9%|▉         | 44/471 [00:08<01:19,  5.34it/s] 10%|▉         | 45/471 [00:08<01:19,  5.34it/s] 10%|▉         | 46/471 [00:08<01:19,  5.33it/s] 10%|▉         | 47/471 [00:08<01:19,  5.34it/s] 10%|█         | 48/471 [00:08<01:19,  5.35it/s] 10%|█         | 49/471 [00:08<01:19,  5.33it/s] 11%|█         | 50/471 [00:09<01:18,  5.33it/s] 11%|█         | 51/471 [00:09<01:18,  5.32it/s] 11%|█         | 52/471 [00:09<01:18,  5.32it/s] 11%|█▏        | 53/471 [00:09<01:18,  5.33it/s] 11%|█▏        | 54/471 [00:09<01:18,  5.33it/s] 12%|█▏        | 55/471 [00:10<01:18,  5.31it/s] 12%|█▏        | 56/471 [00:10<01:18,  5.30it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.31it/s] 12%|█▏        | 58/471 [00:10<01:17,  5.32it/s] 13%|█▎        | 59/471 [00:10<01:17,  5.33it/s] 13%|█▎        | 60/471 [00:11<01:17,  5.33it/s] 13%|█▎        | 61/471 [00:11<01:17,  5.32it/s] 13%|█▎        | 62/471 [00:11<01:17,  5.31it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.31it/s] 14%|█▎        | 64/471 [00:11<01:16,  5.32it/s] 14%|█▍        | 65/471 [00:11<01:16,  5.33it/s] 14%|█▍        | 66/471 [00:12<01:16,  5.33it/s] 14%|█▍        | 67/471 [00:12<01:16,  5.31it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.31it/s] 15%|█▍        | 69/471 [00:12<01:15,  5.31it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.31it/s] 15%|█▌        | 71/471 [00:13<01:15,  5.31it/s] 15%|█▌        | 72/471 [00:13<01:15,  5.31it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.31it/s] 16%|█▌        | 74/471 [00:13<01:14,  5.32it/s] 16%|█▌        | 75/471 [00:13<01:14,  5.31it/s] 16%|█▌        | 76/471 [00:14<01:14,  5.33it/s] 16%|█▋        | 77/471 [00:14<01:14,  5.32it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.31it/s] 17%|█▋        | 79/471 [00:14<01:14,  5.30it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.30it/s] 17%|█▋        | 81/471 [00:14<01:13,  5.32it/s] 17%|█▋        | 82/471 [00:15<01:13,  5.33it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.32it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.32it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.31it/s] 18%|█▊        | 86/471 [00:15<01:12,  5.30it/s] 18%|█▊        | 87/471 [00:16<01:12,  5.33it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.34it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.33it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.31it/s] 19%|█▉        | 91/471 [00:16<01:11,  5.31it/s] 20%|█▉        | 92/471 [00:17<01:11,  5.34it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.34it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.34it/s] 20%|██        | 95/471 [00:17<01:10,  5.34it/s] 20%|██        | 96/471 [00:17<01:10,  5.32it/s] 21%|██        | 97/471 [00:18<01:10,  5.31it/s] 21%|██        | 98/471 [00:18<01:10,  5.32it/s] 21%|██        | 99/471 [00:18<01:09,  5.33it/s] 21%|██        | 100/471 [00:18<01:09,  5.35it/s] 21%|██▏       | 101/471 [00:18<01:09,  5.35it/s] 22%|██▏       | 102/471 [00:18<01:09,  5.33it/s] 22%|██▏       | 103/471 [00:19<01:09,  5.31it/s] 22%|██▏       | 104/471 [00:19<01:09,  5.29it/s] 22%|██▏       | 105/471 [00:19<01:09,  5.29it/s] 23%|██▎       | 106/471 [00:19<01:08,  5.33it/s] 23%|██▎       | 107/471 [00:19<01:08,  5.33it/s] 23%|██▎       | 108/471 [00:20<01:08,  5.32it/s] 23%|██▎       | 109/471 [00:20<01:08,  5.32it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.34it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.33it/s] 24%|██▍       | 112/471 [00:20<01:07,  5.32it/s] 24%|██▍       | 113/471 [00:21<01:06,  5.35it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.33it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.33it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.31it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.31it/s] 25%|██▌       | 118/471 [00:21<01:06,  5.29it/s] 25%|██▌       | 119/471 [00:22<01:06,  5.29it/s] 25%|██▌       | 120/471 [00:22<01:06,  5.30it/s] 26%|██▌       | 121/471 [00:22<01:06,  5.29it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.31it/s] 26%|██▌       | 123/471 [00:22<01:05,  5.31it/s] 26%|██▋       | 124/471 [00:23<01:05,  5.30it/s] 27%|██▋       | 125/471 [00:23<01:05,  5.30it/s] 27%|██▋       | 126/471 [00:23<01:05,  5.30it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.30it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.30it/s] 27%|██▋       | 129/471 [00:24<01:04,  5.30it/s] 28%|██▊       | 130/471 [00:24<01:04,  5.31it/s] 28%|██▊       | 131/471 [00:24<01:04,  5.30it/s] 28%|██▊       | 132/471 [00:24<01:04,  5.29it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.29it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.28it/s] 29%|██▊       | 135/471 [00:25<01:03,  5.29it/s] 29%|██▉       | 136/471 [00:25<01:03,  5.29it/s] 29%|██▉       | 137/471 [00:25<01:03,  5.28it/s] 29%|██▉       | 138/471 [00:25<01:03,  5.27it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.29it/s] 30%|██▉       | 140/471 [00:26<01:02,  5.29it/s] 30%|██▉       | 141/471 [00:26<01:02,  5.31it/s] 30%|███       | 142/471 [00:26<01:01,  5.32it/s] 30%|███       | 143/471 [00:26<01:01,  5.31it/s] 31%|███       | 144/471 [00:26<01:01,  5.28it/s] 31%|███       | 145/471 [00:27<01:01,  5.31it/s] 31%|███       | 146/471 [00:27<01:01,  5.30it/s] 31%|███       | 147/471 [00:27<01:01,  5.29it/s] 31%|███▏      | 148/471 [00:27<01:01,  5.29it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.29it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.27it/s] 32%|███▏      | 151/471 [00:28<01:00,  5.26it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.26it/s] 32%|███▏      | 153/471 [00:28<01:00,  5.27it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.31it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.30it/s] 33%|███▎      | 156/471 [00:29<00:59,  5.31it/s] 33%|███▎      | 157/471 [00:29<00:59,  5.30it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.31it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.33it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.31it/s] 34%|███▍      | 161/471 [00:30<00:58,  5.31it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.29it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.27it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.30it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.29it/s] 35%|███▌      | 166/471 [00:31<00:57,  5.28it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.28it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.26it/s] 36%|███▌      | 169/471 [00:31<00:57,  5.26it/s] 36%|███▌      | 170/471 [00:31<00:57,  5.28it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.28it/s] 37%|███▋      | 172/471 [00:32<00:56,  5.29it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.28it/s] 37%|███▋      | 174/471 [00:32<00:56,  5.27it/s] 37%|███▋      | 175/471 [00:32<00:56,  5.27it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.28it/s] 38%|███▊      | 177/471 [00:33<00:55,  5.28it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.29it/s] 38%|███▊      | 179/471 [00:33<00:55,  5.30it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.30it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.29it/s] 39%|███▊      | 182/471 [00:34<00:54,  5.29it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.29it/s] 39%|███▉      | 184/471 [00:34<00:54,  5.30it/s] 39%|███▉      | 185/471 [00:34<00:54,  5.29it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.29it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.28it/s] 40%|███▉      | 188/471 [00:35<00:53,  5.27it/s] 40%|████      | 189/471 [00:35<00:53,  5.28it/s] 40%|████      | 190/471 [00:35<00:53,  5.29it/s] 41%|████      | 191/471 [00:35<00:52,  5.29it/s] 41%|████      | 192/471 [00:35<00:52,  5.30it/s] 41%|████      | 193/471 [00:36<00:52,  5.32it/s] 41%|████      | 194/471 [00:36<00:52,  5.30it/s] 41%|████▏     | 195/471 [00:36<00:52,  5.30it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.29it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 198/471 [00:37<00:51,  5.32it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.31it/s] 42%|████▏     | 200/471 [00:37<00:51,  5.30it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 203/471 [00:38<00:50,  5.31it/s] 43%|████▎     | 204/471 [00:38<00:50,  5.30it/s] 44%|████▎     | 205/471 [00:38<00:50,  5.31it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.31it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.30it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.33it/s] 44%|████▍     | 209/471 [00:39<00:49,  5.33it/s] 45%|████▍     | 210/471 [00:39<00:49,  5.33it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.31it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.32it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.31it/s] 45%|████▌     | 214/471 [00:40<00:48,  5.31it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.31it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.28it/s] 46%|████▌     | 217/471 [00:40<00:48,  5.28it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.29it/s] 46%|████▋     | 219/471 [00:41<00:47,  5.29it/s] 47%|████▋     | 220/471 [00:41<00:47,  5.29it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.26it/s] 47%|████▋     | 222/471 [00:41<00:47,  5.28it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.30it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.29it/s] 48%|████▊     | 225/471 [00:42<00:46,  5.29it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.28it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.28it/s] 48%|████▊     | 228/471 [00:42<00:46,  5.27it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.27it/s] 49%|████▉     | 230/471 [00:43<00:45,  5.27it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.28it/s] 49%|████▉     | 232/471 [00:43<00:45,  5.31it/s] 49%|████▉     | 233/471 [00:43<00:45,  5.29it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.28it/s] 50%|████▉     | 235/471 [00:44<00:44,  5.28it/s] 50%|█████     | 236/471 [00:44<00:44,  5.29it/s] 50%|█████     | 237/471 [00:44<00:44,  5.29it/s] 51%|█████     | 238/471 [00:44<00:44,  5.28it/s] 51%|█████     | 239/471 [00:44<00:43,  5.28it/s] 51%|█████     | 240/471 [00:44<00:43,  5.29it/s] 51%|█████     | 241/471 [00:45<00:43,  5.28it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.30it/s] 52%|█████▏    | 243/471 [00:45<00:43,  5.29it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.29it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.28it/s] 52%|█████▏    | 246/471 [00:46<00:42,  5.29it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.33it/s] 53%|█████▎    | 248/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 249/471 [00:46<00:41,  5.30it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.30it/s] 53%|█████▎    | 251/471 [00:47<00:41,  5.29it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.29it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.29it/s] 54%|█████▍    | 254/471 [00:47<00:41,  5.28it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.29it/s] 54%|█████▍    | 256/471 [00:48<00:40,  5.29it/s] 55%|█████▍    | 257/471 [00:48<00:40,  5.28it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.29it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.29it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.29it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.29it/s] 56%|█████▌    | 262/471 [00:49<00:39,  5.30it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.30it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.30it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.29it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.28it/s] 57%|█████▋    | 267/471 [00:50<00:38,  5.29it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.29it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.29it/s] 57%|█████▋    | 270/471 [00:50<00:38,  5.28it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.30it/s] 58%|█████▊    | 272/471 [00:51<00:37,  5.31it/s] 58%|█████▊    | 273/471 [00:51<00:37,  5.31it/s] 58%|█████▊    | 274/471 [00:51<00:36,  5.33it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.33it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.31it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.31it/s] 59%|█████▉    | 278/471 [00:52<00:36,  5.29it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.30it/s] 59%|█████▉    | 280/471 [00:52<00:36,  5.30it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.29it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.30it/s] 60%|██████    | 283/471 [00:53<00:35,  5.30it/s] 60%|██████    | 284/471 [00:53<00:35,  5.30it/s] 61%|██████    | 285/471 [00:53<00:35,  5.29it/s] 61%|██████    | 286/471 [00:53<00:34,  5.29it/s] 61%|██████    | 287/471 [00:53<00:34,  5.29it/s] 61%|██████    | 288/471 [00:54<00:34,  5.29it/s] 61%|██████▏   | 289/471 [00:54<00:34,  5.30it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.29it/s] 62%|██████▏   | 291/471 [00:54<00:34,  5.29it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.29it/s] 62%|██████▏   | 293/471 [00:55<00:33,  5.31it/s] 62%|██████▏   | 294/471 [00:55<00:33,  5.31it/s] 63%|██████▎   | 295/471 [00:55<00:33,  5.32it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.32it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.32it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.30it/s] 63%|██████▎   | 299/471 [00:56<00:32,  5.31it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.30it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.29it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.29it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.30it/s] 65%|██████▍   | 304/471 [00:57<00:31,  5.31it/s] 65%|██████▍   | 305/471 [00:57<00:31,  5.30it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.29it/s] 65%|██████▌   | 307/471 [00:57<00:31,  5.28it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.28it/s] 66%|██████▌   | 309/471 [00:58<00:30,  5.28it/s] 66%|██████▌   | 310/471 [00:58<00:30,  5.30it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.29it/s] 66%|██████▌   | 312/471 [00:58<00:30,  5.29it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.30it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.31it/s] 67%|██████▋   | 315/471 [00:59<00:29,  5.32it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.33it/s] 67%|██████▋   | 317/471 [00:59<00:29,  5.31it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.30it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.29it/s] 68%|██████▊   | 320/471 [01:00<00:28,  5.30it/s] 68%|██████▊   | 321/471 [01:00<00:28,  5.29it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.28it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.26it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.26it/s] 69%|██████▉   | 325/471 [01:01<00:27,  5.28it/s] 69%|██████▉   | 326/471 [01:01<00:27,  5.30it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.31it/s] 70%|██████▉   | 328/471 [01:01<00:27,  5.29it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.28it/s] 70%|███████   | 330/471 [01:01<00:26,  5.30it/s] 70%|███████   | 331/471 [01:02<00:26,  5.31it/s] 70%|███████   | 332/471 [01:02<00:26,  5.30it/s] 71%|███████   | 333/471 [01:02<00:26,  5.30it/s] 71%|███████   | 334/471 [01:02<00:25,  5.29it/s] 71%|███████   | 335/471 [01:02<00:25,  5.29it/s] 71%|███████▏  | 336/471 [01:03<00:25,  5.30it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.31it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.31it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.30it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.30it/s] 72%|███████▏  | 341/471 [01:04<00:24,  5.29it/s] 73%|███████▎  | 342/471 [01:04<00:24,  5.30it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.30it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.32it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.30it/s] 73%|███████▎  | 346/471 [01:05<00:23,  5.29it/s] 74%|███████▎  | 347/471 [01:05<00:23,  5.30it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.30it/s] 74%|███████▍  | 349/471 [01:05<00:22,  5.31it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.30it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.32it/s] 75%|███████▍  | 352/471 [01:06<00:22,  5.30it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.28it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.29it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.28it/s] 76%|███████▌  | 357/471 [01:07<00:21,  5.28it/s] 76%|███████▌  | 358/471 [01:07<00:21,  5.29it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.28it/s] 76%|███████▋  | 360/471 [01:07<00:20,  5.30it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 362/471 [01:08<00:20,  5.31it/s] 77%|███████▋  | 363/471 [01:08<00:20,  5.31it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.30it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.30it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.29it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.29it/s] 78%|███████▊  | 368/471 [01:09<00:19,  5.29it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.30it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.29it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.29it/s] 79%|███████▉  | 373/471 [01:10<00:18,  5.28it/s] 79%|███████▉  | 374/471 [01:10<00:18,  5.30it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.31it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.30it/s] 80%|████████  | 377/471 [01:10<00:17,  5.32it/s] 80%|████████  | 378/471 [01:11<00:17,  5.33it/s] 80%|████████  | 379/471 [01:11<00:17,  5.31it/s] 81%|████████  | 380/471 [01:11<00:17,  5.29it/s] 81%|████████  | 381/471 [01:11<00:17,  5.29it/s] 81%|████████  | 382/471 [01:11<00:16,  5.29it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.29it/s] 82%|████████▏ | 384/471 [01:12<00:16,  5.27it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.27it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.26it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.27it/s] 83%|████████▎ | 389/471 [01:13<00:15,  5.30it/s] 83%|████████▎ | 390/471 [01:13<00:15,  5.29it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.28it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.29it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.30it/s] 84%|████████▎ | 394/471 [01:14<00:14,  5.27it/s] 84%|████████▍ | 395/471 [01:14<00:14,  5.28it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.27it/s] 84%|████████▍ | 397/471 [01:14<00:14,  5.28it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.27it/s] 85%|████████▍ | 399/471 [01:15<00:13,  5.26it/s] 85%|████████▍ | 400/471 [01:15<00:13,  5.26it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.28it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.26it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.27it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.27it/s] 86%|████████▌ | 405/471 [01:16<00:12,  5.27it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.29it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.30it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.30it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.28it/s] 87%|████████▋ | 410/471 [01:17<00:11,  5.30it/s] 87%|████████▋ | 411/471 [01:17<00:11,  5.31it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.29it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.29it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.28it/s] 88%|████████▊ | 415/471 [01:18<00:10,  5.29it/s] 88%|████████▊ | 416/471 [01:18<00:10,  5.27it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.28it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.27it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.28it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.30it/s] 89%|████████▉ | 421/471 [01:19<00:09,  5.30it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.32it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.31it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.30it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.30it/s] 90%|█████████ | 426/471 [01:20<00:08,  5.29it/s] 91%|█████████ | 427/471 [01:20<00:08,  5.30it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.30it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.29it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.28it/s] 92%|█████████▏| 431/471 [01:21<00:07,  5.27it/s] 92%|█████████▏| 432/471 [01:21<00:07,  5.28it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.29it/s] 92%|█████████▏| 434/471 [01:21<00:06,  5.30it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.28it/s] 93%|█████████▎| 436/471 [01:22<00:06,  5.29it/s] 93%|█████████▎| 437/471 [01:22<00:06,  5.29it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.28it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.30it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.30it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.31it/s] 94%|█████████▍| 442/471 [01:23<00:05,  5.32it/s] 94%|█████████▍| 443/471 [01:23<00:05,  5.30it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.29it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.28it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.28it/s] 95%|█████████▍| 447/471 [01:24<00:04,  5.29it/s] 95%|█████████▌| 448/471 [01:24<00:04,  5.31it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.31it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.30it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.30it/s] 96%|█████████▌| 452/471 [01:25<00:03,  5.30it/s] 96%|█████████▌| 453/471 [01:25<00:03,  5.29it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.27it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.27it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.28it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.28it/s] 97%|█████████▋| 458/471 [01:26<00:02,  5.28it/s] 97%|█████████▋| 459/471 [01:26<00:02,  5.31it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.32it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.30it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.29it/s] 98%|█████████▊| 463/471 [01:27<00:01,  5.29it/s] 99%|█████████▊| 464/471 [01:27<00:01,  5.30it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.32it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.31it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.30it/s] 99%|█████████▉| 468/471 [01:28<00:00,  5.28it/s]100%|█████████▉| 469/471 [01:28<00:00,  5.28it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.30it/s]100%|██████████| 471/471 [01:28<00:00,  5.67it/s]100%|██████████| 471/471 [01:28<00:00,  5.32it/s]
{'eval_loss': 4.064199447631836, 'eval_model_preparation_time': 0.0051, 'eval_acc': 0.1530801911842804, 'eval_runtime': 88.7567, 'eval_samples_per_second': 84.861, 'eval_steps_per_second': 5.307}
ROUND:3
CLIENT:17
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 4.2598, 'grad_norm': 4.557066440582275, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 3.6064, 'grad_norm': 4.170175075531006, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 2.3568, 'grad_norm': 3.558236837387085, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.3767, 'grad_norm': 5.730906009674072, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.642, 'grad_norm': 7.073764801025391, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:02<00:11,  3.01it/s]                                              {'loss': 3.3495, 'grad_norm': 7.370811462402344, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 2.3634, 'grad_norm': 7.1450700759887695, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 5.2544, 'grad_norm': 34.65114974975586, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 1.8745, 'grad_norm': 6.921697616577148, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.9179, 'grad_norm': 6.586381912231445, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.1775, 'grad_norm': 4.422696113586426, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 1.1077, 'grad_norm': 5.301702499389648, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.1491, 'grad_norm': 6.233464241027832, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.815, 'grad_norm': 4.381491661071777, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 1.2723, 'grad_norm': 6.942427635192871, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.043, 'grad_norm': 2.3253698348999023, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.05it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s]                                               {'loss': 0.7018, 'grad_norm': 2.4426429271698, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s]                                               {'loss': 0.263, 'grad_norm': 3.167536973953247, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s]                                               {'loss': 0.3778, 'grad_norm': 4.851568222045898, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.4997, 'grad_norm': 4.342982292175293, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s]                                               {'loss': 0.2253, 'grad_norm': 6.349090099334717, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.5556, 'grad_norm': 6.745846271514893, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.5077, 'grad_norm': 4.624478340148926, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.1175, 'grad_norm': 5.726053714752197, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.158, 'grad_norm': 2.1049675941467285, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.2414, 'grad_norm': 1.9570200443267822, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.2895, 'grad_norm': 5.71190071105957, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.5618, 'grad_norm': 6.316084861755371, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.1353, 'grad_norm': 2.0192487239837646, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.4275, 'grad_norm': 0.9482908248901367, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.3309, 'grad_norm': 6.194581031799316, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0444, 'grad_norm': 1.4906798601150513, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.0791, 'grad_norm': 1.7309826612472534, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.4257, 'grad_norm': 0.718278706073761, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0406, 'grad_norm': 0.9269800782203674, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.3156, 'grad_norm': 2.183415412902832, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.3037, 'grad_norm': 1.2096961736679077, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0503, 'grad_norm': 1.1849167346954346, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0375, 'grad_norm': 1.3714135885238647, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0831, 'grad_norm': 4.914971351623535, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1906, 'train_samples_per_second': 46.347, 'train_steps_per_second': 3.281, 'train_loss': 1.0584641637280583, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:33
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 4.7733, 'grad_norm': 5.76390266418457, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 4.4208, 'grad_norm': 4.891627311706543, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:01<00:12,  2.99it/s]                                              {'loss': 3.9182, 'grad_norm': 5.6008687019348145, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.99it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 3.1806, 'grad_norm': 5.628688812255859, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.5119, 'grad_norm': 7.157834053039551, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.6263, 'grad_norm': 5.795261859893799, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 3.1508, 'grad_norm': 7.834400177001953, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.0246, 'grad_norm': 1.1772851943969727, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s]                                              {'loss': 1.2169, 'grad_norm': 6.105933666229248, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s]                                               {'loss': 0.9561, 'grad_norm': 6.204843997955322, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s]                                               {'loss': 1.2795, 'grad_norm': 5.928656578063965, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.6718, 'grad_norm': 7.377464294433594, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s]                                               {'loss': 1.6286, 'grad_norm': 5.481778621673584, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 1.244, 'grad_norm': 5.260756015777588, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.1002, 'grad_norm': 6.102287769317627, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 2.0102, 'grad_norm': 24.000516891479492, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.1512, 'grad_norm': 2.3528549671173096, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.1971, 'grad_norm': 2.769796371459961, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.8189, 'grad_norm': 5.282523155212402, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:05,  3.34it/s]                                               {'loss': 0.3321, 'grad_norm': 3.855433225631714, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:05,  3.34it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.4265, 'grad_norm': 5.8944783210754395, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.625, 'grad_norm': 2.5613644123077393, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.4074, 'grad_norm': 4.85931396484375, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.2983, 'grad_norm': 10.748779296875, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.065, 'grad_norm': 1.6284964084625244, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.0587, 'grad_norm': 0.8817946910858154, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.1201, 'grad_norm': 2.0554988384246826, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.4531, 'grad_norm': 0.9426601529121399, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.0388, 'grad_norm': 1.003661870956421, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.4581, 'grad_norm': 2.351891279220581, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0904, 'grad_norm': 3.7637250423431396, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0074, 'grad_norm': 0.8176648020744324, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.0271, 'grad_norm': 0.6285473108291626, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.0249, 'grad_norm': 0.5944708585739136, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0681, 'grad_norm': 5.039193153381348, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.7348, 'grad_norm': 1.4001797437667847, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.0241, 'grad_norm': 0.8763940334320068, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0989, 'grad_norm': 5.010492324829102, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.091, 'grad_norm': 2.7279417514801025, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.009, 'grad_norm': 0.4761181175708771, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1186, 'train_samples_per_second': 46.622, 'train_steps_per_second': 3.301, 'train_loss': 1.0584952074335887, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:76
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.9367, 'grad_norm': 5.008791446685791, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 3.9927, 'grad_norm': 4.95054817199707, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 4.1231, 'grad_norm': 5.248538017272949, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.9844, 'grad_norm': 5.4325947761535645, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.4657, 'grad_norm': 6.040318012237549, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.3474, 'grad_norm': 5.748868942260742, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 2.6071, 'grad_norm': 6.98991060256958, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.2551, 'grad_norm': 8.83470630645752, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s]                                              {'loss': 1.619, 'grad_norm': 5.952160358428955, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s]                                               {'loss': 1.1111, 'grad_norm': 5.5472798347473145, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s]                                               {'loss': 0.9789, 'grad_norm': 4.385220527648926, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 1.3873, 'grad_norm': 5.23824405670166, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s]                                               {'loss': 1.006, 'grad_norm': 8.744544982910156, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.5489, 'grad_norm': 9.254894256591797, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.9822, 'grad_norm': 7.413837432861328, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.0188, 'grad_norm': 0.5453299880027771, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s]                                               {'loss': 0.3886, 'grad_norm': 3.238964080810547, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.66it/s]                                               {'loss': 0.2157, 'grad_norm': 2.6466615200042725, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.66it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s]                                               {'loss': 0.2558, 'grad_norm': 3.9447309970855713, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.661, 'grad_norm': 5.551966190338135, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.3804, 'grad_norm': 5.763885498046875, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.378, 'grad_norm': 5.257229804992676, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.14it/s]                                               {'loss': 0.785, 'grad_norm': 4.335256099700928, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.14it/s]                                               {'loss': 0.1895, 'grad_norm': 6.408865451812744, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.14it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s]                                               {'loss': 0.0979, 'grad_norm': 1.4742193222045898, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s]                                               {'loss': 0.1268, 'grad_norm': 1.7844042778015137, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.1198, 'grad_norm': 1.703464150428772, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.443, 'grad_norm': 3.4609222412109375, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.3334, 'grad_norm': 5.401555061340332, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.2444, 'grad_norm': 6.199432849884033, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.1917, 'grad_norm': 5.2257819175720215, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.3142, 'grad_norm': 15.44534969329834, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.08, 'grad_norm': 1.54679274559021, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s]                                               {'loss': 0.2802, 'grad_norm': 0.7016593813896179, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s]                                               {'loss': 0.071, 'grad_norm': 1.7532835006713867, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0619, 'grad_norm': 1.1707955598831177, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0729, 'grad_norm': 1.231438398361206, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.2097, 'grad_norm': 0.9293361902236938, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0289, 'grad_norm': 0.7835047245025635, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0181, 'grad_norm': 1.062398910522461, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.0324, 'train_samples_per_second': 46.957, 'train_steps_per_second': 3.324, 'train_loss': 0.9327954121865332, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:3
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.00it/s]                                              {'loss': 3.2234, 'grad_norm': 4.3613409996032715, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]                                              {'loss': 2.9533, 'grad_norm': 4.491147518157959, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 3.7661, 'grad_norm': 4.264553070068359, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:12,  3.00it/s]                                              {'loss': 2.8554, 'grad_norm': 5.48187255859375, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.9144, 'grad_norm': 6.212815284729004, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s]                                              {'loss': 3.0954, 'grad_norm': 6.519002437591553, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 3.6917, 'grad_norm': 9.500738143920898, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.2081, 'grad_norm': 25.80376434326172, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 1.8188, 'grad_norm': 7.52012825012207, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 1.9161, 'grad_norm': 11.437716484069824, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 2.2356, 'grad_norm': 8.662175178527832, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 1.2023, 'grad_norm': 6.073559284210205, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 1.3094, 'grad_norm': 4.387341499328613, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.906, 'grad_norm': 5.957957744598389, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 1.1311, 'grad_norm': 4.921329498291016, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 1.7984, 'grad_norm': 41.703529357910156, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.8166, 'grad_norm': 3.6086697578430176, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s]                                               {'loss': 0.355, 'grad_norm': 2.911949634552002, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s]                                               {'loss': 0.931, 'grad_norm': 3.9293603897094727, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.6792, 'grad_norm': 5.0141801834106445, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.1832, 'grad_norm': 3.2137818336486816, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.4547, 'grad_norm': 8.935766220092773, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.578, 'grad_norm': 5.728630065917969, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0202, 'grad_norm': 1.241310715675354, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.1115, 'grad_norm': 2.5734331607818604, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.0599, 'grad_norm': 1.513735294342041, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.0537, 'grad_norm': 1.249137282371521, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.2172, 'grad_norm': 1.948580265045166, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0838, 'grad_norm': 1.4027639627456665, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.2241, 'grad_norm': 3.252746343612671, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.6142, 'grad_norm': 4.378896236419678, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.0187, 'grad_norm': 1.0930516719818115, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.13it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.4645, 'grad_norm': 0.8952335715293884, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.0557, 'grad_norm': 3.646244764328003, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.0923, 'grad_norm': 2.0802154541015625, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0532, 'grad_norm': 1.6867033243179321, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.1442, 'grad_norm': 0.8242274522781372, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.1562, 'grad_norm': 0.7264127135276794, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1276, 'grad_norm': 17.551856994628906, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1036, 'grad_norm': 9.901480674743652, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.0967, 'train_samples_per_second': 46.707, 'train_steps_per_second': 3.307, 'train_loss': 1.0906009482219816, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:56
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]                                              {'loss': 4.6872, 'grad_norm': 4.523044109344482, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]  5%|▌         | 2/40 [00:00<00:12,  3.12it/s]                                              {'loss': 3.6952, 'grad_norm': 4.3596673011779785, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.12it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 3.1833, 'grad_norm': 5.283875465393066, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.5894, 'grad_norm': 5.380155086517334, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.9447, 'grad_norm': 6.669464111328125, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.9771, 'grad_norm': 10.304227828979492, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.9899, 'grad_norm': 7.874019145965576, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 5.4004, 'grad_norm': 34.927616119384766, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s]                                              {'loss': 1.9873, 'grad_norm': 8.822720527648926, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s]                                               {'loss': 1.9941, 'grad_norm': 12.30245304107666, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s]                                               {'loss': 1.1784, 'grad_norm': 8.325491905212402, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s] 30%|███       | 12/40 [00:03<00:08,  3.23it/s]                                               {'loss': 1.3837, 'grad_norm': 10.20140552520752, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.23it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 2.1552, 'grad_norm': 8.000774383544922, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 1.5966, 'grad_norm': 13.434127807617188, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 0.6113, 'grad_norm': 4.731376647949219, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 2.3876, 'grad_norm': 31.45880889892578, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.13it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.3624, 'grad_norm': 4.091582775115967, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.5173, 'grad_norm': 4.581608295440674, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s]                                               {'loss': 1.2315, 'grad_norm': 5.115511417388916, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.7222, 'grad_norm': 6.384336471557617, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 1.0134, 'grad_norm': 29.81221580505371, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 1.0188, 'grad_norm': 9.61937427520752, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 1.4144, 'grad_norm': 13.406634330749512, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.2116, 'grad_norm': 11.256068229675293, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s]                                               {'loss': 0.2976, 'grad_norm': 2.1950807571411133, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.316, 'grad_norm': 3.663278818130493, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 1.1759, 'grad_norm': 10.024995803833008, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.1589, 'grad_norm': 2.42822003364563, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.3622, 'grad_norm': 4.430646896362305, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.3524, 'grad_norm': 5.418117523193359, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.3529, 'grad_norm': 12.491779327392578, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.2222, 'grad_norm': 13.767115592956543, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s]                                               {'loss': 0.4499, 'grad_norm': 7.555199146270752, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s]                                               {'loss': 0.205, 'grad_norm': 8.456260681152344, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.2289, 'grad_norm': 5.02681827545166, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.6121, 'grad_norm': 7.48279333114624, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.167, 'grad_norm': 2.8462350368499756, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.1704, 'grad_norm': 4.084941387176514, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.1907, 'grad_norm': 3.723302125930786, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0527, 'grad_norm': 2.5439984798431396, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.08, 'train_samples_per_second': 46.771, 'train_steps_per_second': 3.311, 'train_loss': 1.364205051958561, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:0
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]                                              {'loss': 3.9891, 'grad_norm': 4.466833591461182, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 4.3904, 'grad_norm': 4.477149963378906, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:01<00:12,  2.99it/s]                                              {'loss': 3.3573, 'grad_norm': 5.070971488952637, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.99it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.4261, 'grad_norm': 6.856863498687744, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.6186, 'grad_norm': 6.7767438888549805, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.068, 'grad_norm': 7.657721042633057, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 1.8239, 'grad_norm': 6.603229522705078, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.1009, 'grad_norm': 4.550704002380371, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 1.7409, 'grad_norm': 7.700813293457031, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.48it/s]                                               {'loss': 1.4455, 'grad_norm': 9.476987838745117, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.48it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s]                                               {'loss': 1.6005, 'grad_norm': 9.871320724487305, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.1425, 'grad_norm': 6.665927410125732, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.2276, 'grad_norm': 6.574795246124268, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.5359, 'grad_norm': 6.189568519592285, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 1.3949, 'grad_norm': 5.080623626708984, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 2.0378, 'grad_norm': 80.19095611572266, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.13it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s]                                               {'loss': 0.5973, 'grad_norm': 2.5310003757476807, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.5704, 'grad_norm': 5.266474723815918, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.5229, 'grad_norm': 4.237446308135986, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.8388, 'grad_norm': 4.617643356323242, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.6969, 'grad_norm': 3.5038483142852783, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.5966, 'grad_norm': 3.2062489986419678, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.4944, 'grad_norm': 5.007075309753418, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s] 60%|██████    | 24/40 [00:07<00:04,  3.82it/s]                                               {'loss': 0.1555, 'grad_norm': 7.2889933586120605, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:04,  3.82it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.54it/s]                                               {'loss': 0.3121, 'grad_norm': 4.819201469421387, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.54it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.38it/s]                                               {'loss': 0.2987, 'grad_norm': 5.167250156402588, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.38it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.2353, 'grad_norm': 4.206244468688965, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.27it/s] 70%|███████   | 28/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.1089, 'grad_norm': 2.340797185897827, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.17it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.12it/s]                                               {'loss': 0.3511, 'grad_norm': 4.367232799530029, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.12it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.4696, 'grad_norm': 6.025113105773926, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.2997, 'grad_norm': 2.164548397064209, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0627, 'grad_norm': 3.868631601333618, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.0996, 'grad_norm': 2.7084827423095703, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.2778, 'grad_norm': 2.590980291366577, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.34, 'grad_norm': 1.0058060884475708, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s]                                               {'loss': 0.0341, 'grad_norm': 0.7415214776992798, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s]                                               {'loss': 0.098, 'grad_norm': 2.5039255619049072, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0649, 'grad_norm': 1.4234321117401123, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.1393, 'grad_norm': 3.6217904090881348, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0341, 'grad_norm': 1.6101032495498657, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.1653, 'train_samples_per_second': 46.444, 'train_steps_per_second': 3.288, 'train_loss': 1.064959416538477, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.593, 'grad_norm': 4.703197956085205, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 4.1231, 'grad_norm': 5.38276481628418, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 3.6461, 'grad_norm': 5.032171249389648, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.4126, 'grad_norm': 4.992436408996582, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 3.0236, 'grad_norm': 6.7581353187561035, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.9418, 'grad_norm': 8.434648513793945, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 3.0726, 'grad_norm': 8.891586303710938, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 0.4756, 'grad_norm': 16.792125701904297, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s]                                              {'loss': 1.6155, 'grad_norm': 7.606955051422119, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 0.8391, 'grad_norm': 4.325899600982666, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.8079, 'grad_norm': 5.977256774902344, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.6538, 'grad_norm': 7.017584800720215, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.8253, 'grad_norm': 6.032976150512695, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 1.2695, 'grad_norm': 5.819311141967773, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 1.0423, 'grad_norm': 4.440587997436523, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 2.5051, 'grad_norm': 39.051902770996094, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.5463, 'grad_norm': 2.4851725101470947, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s]                                               {'loss': 0.2691, 'grad_norm': 2.343113660812378, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.8482, 'grad_norm': 4.371077060699463, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.5137, 'grad_norm': 3.7664191722869873, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.5603, 'grad_norm': 6.033427715301514, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.5871, 'grad_norm': 3.8301405906677246, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.611, 'grad_norm': 6.124805450439453, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 2.0492, 'grad_norm': 119.87519073486328, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.502, 'grad_norm': 3.3012330532073975, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.1284, 'grad_norm': 4.047822952270508, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.5109, 'grad_norm': 4.518240928649902, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.1266, 'grad_norm': 2.7715976238250732, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.4379, 'grad_norm': 4.742258071899414, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.1253, 'grad_norm': 2.3551995754241943, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.1207, 'grad_norm': 2.294559955596924, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0145, 'grad_norm': 0.5859687328338623, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s]                                               {'loss': 0.0632, 'grad_norm': 1.0856009721755981, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.0379, 'grad_norm': 0.744377613067627, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s]                                               {'loss': 0.1527, 'grad_norm': 5.934499740600586, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0394, 'grad_norm': 0.9445669651031494, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0428, 'grad_norm': 1.120749592781067, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.2083, 'grad_norm': 3.213223695755005, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.7538, 'grad_norm': 1.9587565660476685, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0035, 'grad_norm': 0.17288801074028015, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.101, 'train_samples_per_second': 46.69, 'train_steps_per_second': 3.306, 'train_loss': 1.1274954648455604, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:8
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 3.7208, 'grad_norm': 4.706914901733398, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]                                              {'loss': 3.153, 'grad_norm': 4.55600643157959, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.8671, 'grad_norm': 4.146854877471924, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 4.094, 'grad_norm': 5.508816242218018, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.6249, 'grad_norm': 6.951143264770508, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.9771, 'grad_norm': 6.387350559234619, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 2.73, 'grad_norm': 7.733262538909912, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 1.0768, 'grad_norm': 21.56917381286621, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s]                                              {'loss': 0.8871, 'grad_norm': 5.158377647399902, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s]                                               {'loss': 0.8599, 'grad_norm': 4.905569076538086, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 1.0814, 'grad_norm': 5.431002140045166, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.7858, 'grad_norm': 6.583846092224121, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.7467, 'grad_norm': 7.093007564544678, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 1.8807, 'grad_norm': 6.235567569732666, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.3976, 'grad_norm': 5.926287651062012, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.234, 'grad_norm': 8.269949913024902, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.4306, 'grad_norm': 2.8465511798858643, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.50it/s]                                               {'loss': 0.5267, 'grad_norm': 4.334126949310303, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.50it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s]                                               {'loss': 0.3035, 'grad_norm': 2.704084634780884, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.2717, 'grad_norm': 3.984246015548706, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.4962, 'grad_norm': 6.120905876159668, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.4508, 'grad_norm': 7.7069993019104, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.9016, 'grad_norm': 6.700230121612549, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.2111, 'grad_norm': 13.30331802368164, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.71it/s]                                               {'loss': 0.2106, 'grad_norm': 9.67535400390625, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.71it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s]                                               {'loss': 0.1038, 'grad_norm': 2.322995185852051, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s]                                               {'loss': 0.1066, 'grad_norm': 1.8526983261108398, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.5171, 'grad_norm': 3.176388740539551, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.2657, 'grad_norm': 5.639638900756836, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.0593, 'grad_norm': 1.1426831483840942, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.1027, 'grad_norm': 1.7186145782470703, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0106, 'grad_norm': 0.6026355028152466, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.0328, 'grad_norm': 0.4536362588405609, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.3635, 'grad_norm': 1.0879589319229126, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.0623, 'grad_norm': 2.3240766525268555, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s]                                               {'loss': 0.0271, 'grad_norm': 0.535433828830719, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.1296, 'grad_norm': 2.541778087615967, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0799, 'grad_norm': 2.0696427822113037, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.1099, 'grad_norm': 2.279299259185791, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0271, 'grad_norm': 2.077319860458374, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]                                               {'train_runtime': 12.2258, 'train_samples_per_second': 46.214, 'train_steps_per_second': 3.272, 'train_loss': 0.9979428390972316, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.27it/s]
CLIENT:60
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 4.1878, 'grad_norm': 4.771231651306152, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 3.6975, 'grad_norm': 4.20427131652832, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.06it/s]                                              {'loss': 4.3062, 'grad_norm': 4.466928958892822, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.06it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.7137, 'grad_norm': 5.319380760192871, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.9461, 'grad_norm': 6.374787330627441, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.265, 'grad_norm': 4.613050937652588, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.7366, 'grad_norm': 6.005619049072266, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.8313, 'grad_norm': 20.194984436035156, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 1.2551, 'grad_norm': 4.781562328338623, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 2.2987, 'grad_norm': 9.1482515335083, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 0.8987, 'grad_norm': 5.780216693878174, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 2.1504, 'grad_norm': 7.513161659240723, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.2457, 'grad_norm': 5.78692102432251, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.6097, 'grad_norm': 4.155644416809082, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 1.419, 'grad_norm': 5.3356523513793945, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 2.658, 'grad_norm': 20.44308090209961, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.5241, 'grad_norm': 3.6936445236206055, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.5908, 'grad_norm': 4.050228595733643, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.4074, 'grad_norm': 3.4056692123413086, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.435, 'grad_norm': 3.7874813079833984, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.6852, 'grad_norm': 4.130687713623047, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.8137, 'grad_norm': 3.50215744972229, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.4466, 'grad_norm': 5.5806193351745605, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0261, 'grad_norm': 1.229022741317749, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.0566, 'grad_norm': 1.2858309745788574, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s]                                               {'loss': 0.1121, 'grad_norm': 3.049560070037842, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s]                                               {'loss': 0.1682, 'grad_norm': 1.2730034589767456, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.0845, 'grad_norm': 1.5595086812973022, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.0625, 'grad_norm': 1.3695124387741089, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.6796, 'grad_norm': 3.6153173446655273, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.1449, 'grad_norm': 2.1030688285827637, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0608, 'grad_norm': 2.5967495441436768, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.73it/s]                                               {'loss': 0.0526, 'grad_norm': 1.0339272022247314, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.73it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.0267, 'grad_norm': 0.474924772977829, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.5202, 'grad_norm': 0.8119629621505737, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0202, 'grad_norm': 0.3982405364513397, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.1366, 'grad_norm': 3.2126474380493164, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0658, 'grad_norm': 1.5961085557937622, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.205, 'grad_norm': 3.2468581199645996, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0406, 'grad_norm': 2.200026750564575, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.1812, 'train_samples_per_second': 46.383, 'train_steps_per_second': 3.284, 'train_loss': 1.0646287440788, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:67
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.88it/s]                                              {'loss': 3.9441, 'grad_norm': 4.066028594970703, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.88it/s]  5%|▌         | 2/40 [00:00<00:12,  2.96it/s]                                              {'loss': 3.5828, 'grad_norm': 5.25601053237915, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.96it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.9253, 'grad_norm': 4.900782585144043, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 4.0472, 'grad_norm': 8.11512279510498, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.4042, 'grad_norm': 7.155332088470459, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.7232, 'grad_norm': 8.048048973083496, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 2.1584, 'grad_norm': 7.202099800109863, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 6.4884, 'grad_norm': 38.23088836669922, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 1.2742, 'grad_norm': 6.403194904327393, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 1.3316, 'grad_norm': 5.696671962738037, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 0.9486, 'grad_norm': 6.526221752166748, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.8089, 'grad_norm': 5.2321600914001465, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s]                                               {'loss': 1.7083, 'grad_norm': 7.487923622131348, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.9424, 'grad_norm': 5.422151565551758, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 1.6893, 'grad_norm': 7.6569719314575195, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 1.2122, 'grad_norm': 27.958858489990234, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.7363, 'grad_norm': 3.8079967498779297, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s]                                               {'loss': 0.601, 'grad_norm': 4.135670185089111, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s]                                               {'loss': 0.4216, 'grad_norm': 3.6539483070373535, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.5055, 'grad_norm': 5.577959060668945, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.2354, 'grad_norm': 2.9213287830352783, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.2458, 'grad_norm': 3.644465446472168, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.2605, 'grad_norm': 3.2070953845977783, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.3489, 'grad_norm': 11.774063110351562, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.1466, 'grad_norm': 3.6716959476470947, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.4791, 'grad_norm': 7.439212799072266, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.0939, 'grad_norm': 1.6243293285369873, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.1149, 'grad_norm': 3.4823715686798096, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.2708, 'grad_norm': 3.7598049640655518, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.1972, 'grad_norm': 3.087675094604492, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.1293, 'grad_norm': 2.0177865028381348, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0354, 'grad_norm': 1.2276455163955688, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.0297, 'grad_norm': 0.42581239342689514, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.0856, 'grad_norm': 1.5431326627731323, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0927, 'grad_norm': 1.617987871170044, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0645, 'grad_norm': 1.2912917137145996, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0527, 'grad_norm': 1.301345705986023, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.1038, 'grad_norm': 2.2983455657958984, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.111, 'grad_norm': 3.070850372314453, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.117, 'grad_norm': 6.417296886444092, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.1258, 'train_samples_per_second': 46.595, 'train_steps_per_second': 3.299, 'train_loss': 1.0917105149012059, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:43, 10.87it/s]  1%|          | 4/471 [00:00<01:08,  6.82it/s]  1%|          | 5/471 [00:00<01:13,  6.33it/s]  1%|▏         | 6/471 [00:00<01:17,  5.98it/s]  1%|▏         | 7/471 [00:01<01:20,  5.77it/s]  2%|▏         | 8/471 [00:01<01:22,  5.64it/s]  2%|▏         | 9/471 [00:01<01:22,  5.58it/s]  2%|▏         | 10/471 [00:01<01:23,  5.52it/s]  2%|▏         | 11/471 [00:01<01:23,  5.48it/s]  3%|▎         | 12/471 [00:02<01:24,  5.44it/s]  3%|▎         | 13/471 [00:02<01:24,  5.40it/s]  3%|▎         | 14/471 [00:02<01:24,  5.39it/s]  3%|▎         | 15/471 [00:02<01:24,  5.39it/s]  3%|▎         | 16/471 [00:02<01:24,  5.38it/s]  4%|▎         | 17/471 [00:02<01:24,  5.38it/s]  4%|▍         | 18/471 [00:03<01:24,  5.36it/s]  4%|▍         | 19/471 [00:03<01:24,  5.35it/s]  4%|▍         | 20/471 [00:03<01:24,  5.35it/s]  4%|▍         | 21/471 [00:03<01:23,  5.36it/s]  5%|▍         | 22/471 [00:03<01:23,  5.35it/s]  5%|▍         | 23/471 [00:04<01:23,  5.36it/s]  5%|▌         | 24/471 [00:04<01:23,  5.34it/s]  5%|▌         | 25/471 [00:04<01:23,  5.36it/s]  6%|▌         | 26/471 [00:04<01:23,  5.36it/s]  6%|▌         | 27/471 [00:04<01:22,  5.36it/s]  6%|▌         | 28/471 [00:05<01:22,  5.36it/s]  6%|▌         | 29/471 [00:05<01:22,  5.35it/s]  6%|▋         | 30/471 [00:05<01:22,  5.35it/s]  7%|▋         | 31/471 [00:05<01:22,  5.35it/s]  7%|▋         | 32/471 [00:05<01:21,  5.36it/s]  7%|▋         | 33/471 [00:05<01:21,  5.40it/s]  7%|▋         | 34/471 [00:06<01:20,  5.40it/s]  7%|▋         | 35/471 [00:06<01:20,  5.39it/s]  8%|▊         | 36/471 [00:06<01:20,  5.38it/s]  8%|▊         | 37/471 [00:06<01:20,  5.37it/s]  8%|▊         | 38/471 [00:06<01:20,  5.37it/s]  8%|▊         | 39/471 [00:07<01:20,  5.36it/s]  8%|▊         | 40/471 [00:07<01:20,  5.37it/s]  9%|▊         | 41/471 [00:07<01:20,  5.36it/s]  9%|▉         | 42/471 [00:07<01:20,  5.35it/s]  9%|▉         | 43/471 [00:07<01:19,  5.36it/s]  9%|▉         | 44/471 [00:08<01:19,  5.37it/s] 10%|▉         | 45/471 [00:08<01:19,  5.37it/s] 10%|▉         | 46/471 [00:08<01:19,  5.37it/s] 10%|▉         | 47/471 [00:08<01:18,  5.38it/s] 10%|█         | 48/471 [00:08<01:18,  5.38it/s] 10%|█         | 49/471 [00:08<01:18,  5.37it/s] 11%|█         | 50/471 [00:09<01:18,  5.35it/s] 11%|█         | 51/471 [00:09<01:18,  5.35it/s] 11%|█         | 52/471 [00:09<01:18,  5.36it/s] 11%|█▏        | 53/471 [00:09<01:18,  5.34it/s] 11%|█▏        | 54/471 [00:09<01:18,  5.34it/s] 12%|█▏        | 55/471 [00:10<01:17,  5.34it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.33it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.34it/s] 12%|█▏        | 58/471 [00:10<01:17,  5.34it/s] 13%|█▎        | 59/471 [00:10<01:17,  5.33it/s] 13%|█▎        | 60/471 [00:11<01:16,  5.34it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.33it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.33it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.33it/s] 14%|█▎        | 64/471 [00:11<01:16,  5.33it/s] 14%|█▍        | 65/471 [00:11<01:15,  5.34it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.33it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.34it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.34it/s] 15%|█▍        | 69/471 [00:12<01:15,  5.33it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.32it/s] 15%|█▌        | 71/471 [00:13<01:15,  5.31it/s] 15%|█▌        | 72/471 [00:13<01:15,  5.32it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.33it/s] 16%|█▌        | 74/471 [00:13<01:14,  5.34it/s] 16%|█▌        | 75/471 [00:13<01:14,  5.33it/s] 16%|█▌        | 76/471 [00:14<01:13,  5.34it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.34it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.33it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.33it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.32it/s] 17%|█▋        | 81/471 [00:14<01:13,  5.34it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.34it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 86/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 87/471 [00:16<01:12,  5.33it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.34it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.34it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.32it/s] 19%|█▉        | 91/471 [00:16<01:11,  5.34it/s] 20%|█▉        | 92/471 [00:17<01:10,  5.35it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.35it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.35it/s] 20%|██        | 95/471 [00:17<01:10,  5.36it/s] 20%|██        | 96/471 [00:17<01:09,  5.36it/s] 21%|██        | 97/471 [00:17<01:10,  5.34it/s] 21%|██        | 98/471 [00:18<01:09,  5.35it/s] 21%|██        | 99/471 [00:18<01:09,  5.36it/s] 21%|██        | 100/471 [00:18<01:09,  5.38it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.39it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.36it/s] 22%|██▏       | 103/471 [00:19<01:08,  5.35it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.33it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.32it/s] 23%|██▎       | 106/471 [00:19<01:07,  5.37it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.38it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.38it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.37it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.38it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.36it/s] 24%|██▍       | 112/471 [00:20<01:07,  5.35it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.40it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.37it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.36it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.36it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.35it/s] 25%|██▌       | 118/471 [00:21<01:06,  5.35it/s] 25%|██▌       | 119/471 [00:22<01:05,  5.35it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.34it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.34it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.33it/s] 26%|██▌       | 123/471 [00:22<01:04,  5.36it/s] 26%|██▋       | 124/471 [00:22<01:04,  5.34it/s] 27%|██▋       | 125/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.34it/s] 27%|██▋       | 129/471 [00:23<01:03,  5.35it/s] 28%|██▊       | 130/471 [00:24<01:03,  5.35it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.34it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.34it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.32it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.32it/s] 29%|██▊       | 135/471 [00:25<01:03,  5.33it/s] 29%|██▉       | 136/471 [00:25<01:02,  5.33it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.32it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.31it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.33it/s] 30%|██▉       | 140/471 [00:25<01:01,  5.34it/s] 30%|██▉       | 141/471 [00:26<01:01,  5.35it/s] 30%|███       | 142/471 [00:26<01:01,  5.35it/s] 30%|███       | 143/471 [00:26<01:01,  5.35it/s] 31%|███       | 144/471 [00:26<01:01,  5.33it/s] 31%|███       | 145/471 [00:26<01:00,  5.35it/s] 31%|███       | 146/471 [00:27<01:00,  5.36it/s] 31%|███       | 147/471 [00:27<01:00,  5.35it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.34it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.33it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.32it/s] 32%|███▏      | 151/471 [00:28<01:00,  5.33it/s] 32%|███▏      | 152/471 [00:28<00:59,  5.32it/s] 32%|███▏      | 153/471 [00:28<00:59,  5.32it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.35it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.35it/s] 33%|███▎      | 156/471 [00:28<00:58,  5.36it/s] 33%|███▎      | 157/471 [00:29<00:58,  5.36it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.37it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.37it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.35it/s] 34%|███▍      | 161/471 [00:29<00:58,  5.33it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.32it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.30it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.32it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.33it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.33it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.32it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.31it/s] 36%|███▌      | 169/471 [00:31<00:56,  5.30it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.31it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.33it/s] 37%|███▋      | 172/471 [00:31<00:56,  5.34it/s] 37%|███▋      | 173/471 [00:32<00:55,  5.32it/s] 37%|███▋      | 174/471 [00:32<00:55,  5.31it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.30it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.32it/s] 38%|███▊      | 177/471 [00:32<00:55,  5.34it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.32it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.33it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.33it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.33it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.32it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.31it/s] 39%|███▉      | 184/471 [00:34<00:53,  5.33it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.33it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.32it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.32it/s] 40%|███▉      | 188/471 [00:34<00:53,  5.30it/s] 40%|████      | 189/471 [00:35<00:53,  5.31it/s] 40%|████      | 190/471 [00:35<00:52,  5.32it/s] 41%|████      | 191/471 [00:35<00:52,  5.32it/s] 41%|████      | 192/471 [00:35<00:52,  5.33it/s] 41%|████      | 193/471 [00:35<00:52,  5.35it/s] 41%|████      | 194/471 [00:36<00:51,  5.33it/s] 41%|████▏     | 195/471 [00:36<00:51,  5.33it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.35it/s] 42%|████▏     | 198/471 [00:36<00:50,  5.37it/s] 42%|████▏     | 199/471 [00:37<00:50,  5.35it/s] 42%|████▏     | 200/471 [00:37<00:50,  5.33it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.36it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.34it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.33it/s] 43%|████▎     | 204/471 [00:37<00:50,  5.32it/s] 44%|████▎     | 205/471 [00:38<00:49,  5.34it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.35it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.32it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.35it/s] 44%|████▍     | 209/471 [00:38<00:48,  5.37it/s] 45%|████▍     | 210/471 [00:39<00:48,  5.37it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.36it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.35it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.34it/s] 45%|████▌     | 214/471 [00:39<00:48,  5.33it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.33it/s] 46%|████▌     | 216/471 [00:40<00:47,  5.33it/s] 46%|████▌     | 217/471 [00:40<00:47,  5.32it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.31it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.31it/s] 47%|████▋     | 220/471 [00:40<00:47,  5.30it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.29it/s] 47%|████▋     | 222/471 [00:41<00:46,  5.31it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.34it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.32it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.31it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.30it/s] 48%|████▊     | 227/471 [00:42<00:45,  5.31it/s] 48%|████▊     | 228/471 [00:42<00:45,  5.32it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.32it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.30it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.30it/s] 49%|████▉     | 232/471 [00:43<00:44,  5.31it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.33it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.33it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.30it/s] 50%|█████     | 236/471 [00:43<00:44,  5.32it/s] 50%|█████     | 237/471 [00:44<00:44,  5.30it/s] 51%|█████     | 238/471 [00:44<00:43,  5.30it/s] 51%|█████     | 239/471 [00:44<00:43,  5.32it/s] 51%|█████     | 240/471 [00:44<00:43,  5.31it/s] 51%|█████     | 241/471 [00:44<00:43,  5.31it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.32it/s] 52%|█████▏    | 243/471 [00:45<00:42,  5.31it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.31it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.34it/s] 52%|█████▏    | 247/471 [00:46<00:41,  5.35it/s] 53%|█████▎    | 248/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 249/471 [00:46<00:41,  5.31it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.32it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.33it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.33it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.32it/s] 54%|█████▍    | 254/471 [00:47<00:40,  5.30it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.31it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.30it/s] 55%|█████▍    | 257/471 [00:47<00:40,  5.31it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.31it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.30it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.30it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.30it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.32it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.32it/s] 56%|█████▌    | 264/471 [00:49<00:38,  5.31it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.31it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.28it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.29it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.28it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.30it/s] 57%|█████▋    | 270/471 [00:50<00:37,  5.29it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.30it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.33it/s] 58%|█████▊    | 273/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 274/471 [00:51<00:36,  5.33it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.34it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 278/471 [00:51<00:36,  5.31it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.32it/s] 59%|█████▉    | 280/471 [00:52<00:35,  5.33it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.33it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.32it/s] 60%|██████    | 283/471 [00:52<00:35,  5.31it/s] 60%|██████    | 284/471 [00:53<00:35,  5.31it/s] 61%|██████    | 285/471 [00:53<00:34,  5.32it/s] 61%|██████    | 286/471 [00:53<00:34,  5.32it/s] 61%|██████    | 287/471 [00:53<00:34,  5.33it/s] 61%|██████    | 288/471 [00:53<00:34,  5.30it/s] 61%|██████▏   | 289/471 [00:53<00:34,  5.32it/s] 62%|██████▏   | 290/471 [00:54<00:33,  5.33it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.32it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.33it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.32it/s] 62%|██████▏   | 294/471 [00:54<00:33,  5.33it/s] 63%|██████▎   | 295/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.32it/s] 63%|██████▎   | 299/471 [00:55<00:32,  5.32it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.33it/s] 64%|██████▍   | 301/471 [00:56<00:31,  5.32it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.31it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.30it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.31it/s] 65%|██████▍   | 305/471 [00:56<00:31,  5.31it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.30it/s] 65%|██████▌   | 307/471 [00:57<00:30,  5.30it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.29it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.29it/s] 66%|██████▌   | 310/471 [00:57<00:30,  5.29it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.29it/s] 66%|██████▌   | 312/471 [00:58<00:29,  5.30it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.32it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.33it/s] 67%|██████▋   | 315/471 [00:58<00:29,  5.32it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.32it/s] 67%|██████▋   | 317/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.33it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 320/471 [00:59<00:28,  5.31it/s] 68%|██████▊   | 321/471 [00:59<00:28,  5.30it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.30it/s] 69%|██████▊   | 323/471 [01:00<00:27,  5.30it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.29it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.30it/s] 69%|██████▉   | 326/471 [01:00<00:27,  5.31it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.31it/s] 70%|██████▉   | 328/471 [01:01<00:26,  5.30it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.29it/s] 70%|███████   | 330/471 [01:01<00:26,  5.33it/s] 70%|███████   | 331/471 [01:01<00:26,  5.34it/s] 70%|███████   | 332/471 [01:02<00:26,  5.32it/s] 71%|███████   | 333/471 [01:02<00:25,  5.32it/s] 71%|███████   | 334/471 [01:02<00:25,  5.31it/s] 71%|███████   | 335/471 [01:02<00:25,  5.31it/s] 71%|███████▏  | 336/471 [01:02<00:25,  5.33it/s] 72%|███████▏  | 337/471 [01:02<00:25,  5.34it/s] 72%|███████▏  | 338/471 [01:03<00:24,  5.34it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.31it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.32it/s] 72%|███████▏  | 341/471 [01:03<00:24,  5.33it/s] 73%|███████▎  | 342/471 [01:03<00:24,  5.33it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.33it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.34it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.32it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.32it/s] 74%|███████▎  | 347/471 [01:04<00:23,  5.33it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.33it/s] 74%|███████▍  | 349/471 [01:05<00:22,  5.32it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.32it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.33it/s] 75%|███████▍  | 352/471 [01:05<00:22,  5.32it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.31it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.31it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.30it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.30it/s] 76%|███████▌  | 357/471 [01:06<00:21,  5.30it/s] 76%|███████▌  | 358/471 [01:06<00:21,  5.31it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.30it/s] 76%|███████▋  | 360/471 [01:07<00:20,  5.31it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.31it/s] 77%|███████▋  | 362/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 363/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.31it/s] 77%|███████▋  | 365/471 [01:08<00:19,  5.30it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.30it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.30it/s] 78%|███████▊  | 368/471 [01:08<00:19,  5.31it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.32it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.31it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 373/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 374/471 [01:09<00:18,  5.32it/s] 80%|███████▉  | 375/471 [01:10<00:17,  5.34it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.32it/s] 80%|████████  | 377/471 [01:10<00:17,  5.33it/s] 80%|████████  | 378/471 [01:10<00:17,  5.35it/s] 80%|████████  | 379/471 [01:10<00:17,  5.33it/s] 81%|████████  | 380/471 [01:11<00:17,  5.32it/s] 81%|████████  | 381/471 [01:11<00:16,  5.32it/s] 81%|████████  | 382/471 [01:11<00:16,  5.32it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.33it/s] 82%|████████▏ | 384/471 [01:11<00:16,  5.32it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.30it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.30it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.30it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.30it/s] 83%|████████▎ | 389/471 [01:12<00:15,  5.32it/s] 83%|████████▎ | 390/471 [01:12<00:15,  5.32it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.32it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.31it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.31it/s] 84%|████████▎ | 394/471 [01:13<00:14,  5.31it/s] 84%|████████▍ | 395/471 [01:13<00:14,  5.32it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.31it/s] 84%|████████▍ | 397/471 [01:14<00:13,  5.31it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.30it/s] 85%|████████▍ | 399/471 [01:14<00:13,  5.29it/s] 85%|████████▍ | 400/471 [01:14<00:13,  5.28it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.30it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.31it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.31it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.32it/s] 86%|████████▌ | 405/471 [01:15<00:12,  5.30it/s] 86%|████████▌ | 406/471 [01:15<00:12,  5.30it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.31it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.32it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.31it/s] 87%|████████▋ | 410/471 [01:16<00:11,  5.32it/s] 87%|████████▋ | 411/471 [01:16<00:11,  5.32it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.31it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.31it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.32it/s] 88%|████████▊ | 415/471 [01:17<00:10,  5.33it/s] 88%|████████▊ | 416/471 [01:17<00:10,  5.31it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.31it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.30it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.31it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.35it/s] 89%|████████▉ | 421/471 [01:18<00:09,  5.34it/s] 90%|████████▉ | 422/471 [01:18<00:09,  5.33it/s] 90%|████████▉ | 423/471 [01:19<00:08,  5.34it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.32it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.34it/s] 90%|█████████ | 426/471 [01:19<00:08,  5.32it/s] 91%|█████████ | 427/471 [01:19<00:08,  5.31it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.31it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.31it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.31it/s] 92%|█████████▏| 431/471 [01:20<00:07,  5.30it/s] 92%|█████████▏| 432/471 [01:20<00:07,  5.30it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.29it/s] 92%|█████████▏| 434/471 [01:21<00:06,  5.29it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.29it/s] 93%|█████████▎| 436/471 [01:21<00:06,  5.31it/s] 93%|█████████▎| 437/471 [01:21<00:06,  5.31it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.32it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.30it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.31it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.31it/s] 94%|█████████▍| 442/471 [01:22<00:05,  5.33it/s] 94%|█████████▍| 443/471 [01:22<00:05,  5.33it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.30it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.30it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.29it/s] 95%|█████████▍| 447/471 [01:23<00:04,  5.31it/s] 95%|█████████▌| 448/471 [01:23<00:04,  5.32it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.32it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.31it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.30it/s] 96%|█████████▌| 452/471 [01:24<00:03,  5.31it/s] 96%|█████████▌| 453/471 [01:24<00:03,  5.29it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.28it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.29it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.30it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.29it/s] 97%|█████████▋| 458/471 [01:25<00:02,  5.31it/s] 97%|█████████▋| 459/471 [01:25<00:02,  5.34it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.32it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.30it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.30it/s] 98%|█████████▊| 463/471 [01:26<00:01,  5.32it/s] 99%|█████████▊| 464/471 [01:26<00:01,  5.34it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.33it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.31it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.30it/s] 99%|█████████▉| 468/471 [01:27<00:00,  5.29it/s]100%|█████████▉| 469/471 [01:27<00:00,  5.31it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.33it/s]100%|██████████| 471/471 [01:28<00:00,  5.70it/s]100%|██████████| 471/471 [01:28<00:00,  5.34it/s]
{'eval_loss': 4.004890441894531, 'eval_model_preparation_time': 0.005, 'eval_acc': 0.1575942644715879, 'eval_runtime': 88.3496, 'eval_samples_per_second': 85.252, 'eval_steps_per_second': 5.331}
ROUND:4
CLIENT:88
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]                                              {'loss': 4.0027, 'grad_norm': 6.732585430145264, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 4.3336, 'grad_norm': 4.97165060043335, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  2.98it/s]                                              {'loss': 2.8828, 'grad_norm': 5.862645149230957, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.98it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 3.4552, 'grad_norm': 6.505381107330322, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s]                                              {'loss': 2.8155, 'grad_norm': 6.659036636352539, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s]                                              {'loss': 1.9435, 'grad_norm': 7.400217056274414, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 3.0465, 'grad_norm': 10.76464557647705, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 0.9838, 'grad_norm': 27.961776733398438, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.97it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s]                                              {'loss': 1.4278, 'grad_norm': 7.579203128814697, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s]                                               {'loss': 0.9442, 'grad_norm': 6.189276218414307, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s]                                               {'loss': 0.5985, 'grad_norm': 5.755124568939209, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s] 30%|███       | 12/40 [00:03<00:08,  3.20it/s]                                               {'loss': 2.1498, 'grad_norm': 6.331264019012451, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.20it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.7991, 'grad_norm': 5.881893634796143, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.09it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.8291, 'grad_norm': 3.8693370819091797, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.04it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.02it/s]                                               {'loss': 0.9226, 'grad_norm': 6.1342973709106445, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.02it/s]                                               {'loss': 0.0329, 'grad_norm': 1.6604303121566772, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.02it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s]                                               {'loss': 0.3845, 'grad_norm': 14.654838562011719, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 1.0747, 'grad_norm': 6.033997058868408, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.4281, 'grad_norm': 3.676318645477295, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.4739, 'grad_norm': 4.579666614532471, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s]                                               {'loss': 0.3839, 'grad_norm': 7.674556732177734, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.3909, 'grad_norm': 4.310147762298584, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.705, 'grad_norm': 6.131307601928711, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.1026, 'grad_norm': 4.951506614685059, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.5557, 'grad_norm': 3.0905845165252686, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.0926, 'grad_norm': 1.2142411470413208, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.2592, 'grad_norm': 2.386420488357544, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.1296, 'grad_norm': 4.075408458709717, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.0447, 'grad_norm': 0.7975214123725891, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.3617, 'grad_norm': 1.445209264755249, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.1216, 'grad_norm': 2.234867811203003, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0006, 'grad_norm': 0.02901402674615383, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0214, 'grad_norm': 0.7189600467681885, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.0991, 'grad_norm': 1.820966362953186, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.0286, 'grad_norm': 0.7406564354896545, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.3286, 'grad_norm': 0.946304976940155, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.5314, 'grad_norm': 0.3702574372291565, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.027, 'grad_norm': 0.5738428235054016, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0239, 'grad_norm': 0.8473243713378906, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0216, 'grad_norm': 0.8345852494239807, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]                                               {'train_runtime': 12.2137, 'train_samples_per_second': 46.26, 'train_steps_per_second': 3.275, 'train_loss': 0.9439612179165124, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:4
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.1653, 'grad_norm': 4.746005535125732, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 5.1382, 'grad_norm': 5.130014896392822, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 3.7787, 'grad_norm': 7.107089519500732, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 3.7308, 'grad_norm': 7.081564426422119, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.7878, 'grad_norm': 8.162381172180176, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.07it/s]                                              {'loss': 2.3204, 'grad_norm': 6.76870584487915, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.07it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.07it/s]                                              {'loss': 2.8171, 'grad_norm': 11.312419891357422, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.07it/s]                                              {'loss': 0.4796, 'grad_norm': 15.99081802368164, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.07it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s]                                              {'loss': 1.9377, 'grad_norm': 12.310657501220703, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.60it/s]                                               {'loss': 2.5216, 'grad_norm': 13.62171459197998, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.60it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s]                                               {'loss': 1.2896, 'grad_norm': 10.159868240356445, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 1.3019, 'grad_norm': 7.843394756317139, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.23it/s]                                               {'loss': 1.0695, 'grad_norm': 4.5787811279296875, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.23it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.3768, 'grad_norm': 7.2897796630859375, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.15it/s]                                               {'loss': 1.5869, 'grad_norm': 4.293911457061768, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.15it/s]                                               {'loss': 2.1263, 'grad_norm': 34.1400032043457, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.15it/s] 42%|████▎     | 17/40 [00:04<00:05,  3.91it/s]                                               {'loss': 0.2919, 'grad_norm': 3.605592727661133, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:04<00:05,  3.91it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.65it/s]                                               {'loss': 0.463, 'grad_norm': 4.424058437347412, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.65it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.46it/s]                                               {'loss': 1.1307, 'grad_norm': 6.626012325286865, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.46it/s] 50%|█████     | 20/40 [00:05<00:05,  3.34it/s]                                               {'loss': 1.1417, 'grad_norm': 7.748827934265137, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:05<00:05,  3.34it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.26it/s]                                               {'loss': 1.1265, 'grad_norm': 4.701780319213867, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.26it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.2835, 'grad_norm': 3.4011733531951904, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.19it/s] 57%|█████▊    | 23/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.8619, 'grad_norm': 4.731170654296875, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:06<00:05,  3.16it/s]                                               {'loss': 1.0486, 'grad_norm': 0.7441949844360352, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.16it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.90it/s]                                               {'loss': 0.387, 'grad_norm': 3.9501760005950928, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.90it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.66it/s]                                               {'loss': 0.1887, 'grad_norm': 3.6356074810028076, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.66it/s] 68%|██████▊   | 27/40 [00:07<00:03,  3.49it/s]                                               {'loss': 0.4736, 'grad_norm': 2.2418742179870605, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:07<00:03,  3.49it/s] 70%|███████   | 28/40 [00:08<00:03,  3.35it/s]                                               {'loss': 0.5072, 'grad_norm': 1.8778579235076904, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.35it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.1697, 'grad_norm': 2.5102784633636475, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s] 75%|███████▌  | 30/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.6582, 'grad_norm': 3.1745336055755615, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:08<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1554, 'grad_norm': 3.1197001934051514, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.01, 'grad_norm': 0.4251371920108795, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.70it/s]                                               {'loss': 0.3677, 'grad_norm': 0.5689952969551086, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.70it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.1857, 'grad_norm': 1.2908785343170166, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.4599, 'grad_norm': 1.383744478225708, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.1205, 'grad_norm': 1.285251259803772, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.2208, 'grad_norm': 2.3768563270568848, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.5886, 'grad_norm': 3.8243727684020996, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0433, 'grad_norm': 0.862078070640564, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0358, 'grad_norm': 1.6231951713562012, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]                                               {'train_runtime': 11.9754, 'train_samples_per_second': 47.18, 'train_steps_per_second': 3.34, 'train_loss': 1.208701320225373, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]100%|██████████| 40/40 [00:11<00:00,  3.34it/s]
CLIENT:79
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.91, 'grad_norm': 4.87074089050293, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.6487, 'grad_norm': 5.03335428237915, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.1111, 'grad_norm': 5.9447197914123535, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.7137, 'grad_norm': 7.462125301361084, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.1865, 'grad_norm': 5.962546348571777, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.588, 'grad_norm': 9.211581230163574, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 3.1262, 'grad_norm': 11.684694290161133, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 5.0546, 'grad_norm': 47.2043342590332, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 2.0888, 'grad_norm': 9.374773979187012, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 0.8852, 'grad_norm': 5.385263919830322, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s]                                               {'loss': 0.8582, 'grad_norm': 5.389823913574219, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.2367, 'grad_norm': 5.481597423553467, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 1.1112, 'grad_norm': 5.728106498718262, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 1.1267, 'grad_norm': 4.862181186676025, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.5066, 'grad_norm': 6.247300624847412, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.5171, 'grad_norm': 13.703853607177734, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s]                                               {'loss': 0.6511, 'grad_norm': 4.398788928985596, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.4682, 'grad_norm': 4.788579940795898, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s]                                               {'loss': 1.031, 'grad_norm': 4.143218994140625, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.3056, 'grad_norm': 4.602211952209473, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.4271, 'grad_norm': 6.917749881744385, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.3753, 'grad_norm': 6.007516384124756, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.3916, 'grad_norm': 5.5445942878723145, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0177, 'grad_norm': 1.0690189599990845, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.2768, 'grad_norm': 1.9718101024627686, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.0791, 'grad_norm': 1.6291184425354004, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.0883, 'grad_norm': 2.727937698364258, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.7339, 'grad_norm': 1.884198546409607, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0648, 'grad_norm': 1.6928168535232544, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.1162, 'grad_norm': 2.4225194454193115, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1277, 'grad_norm': 3.8383278846740723, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.5005, 'grad_norm': 33.145538330078125, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.0362, 'grad_norm': 0.6346703767776489, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0536, 'grad_norm': 1.3975495100021362, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.2081, 'grad_norm': 1.2222093343734741, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.4914, 'grad_norm': 3.0744621753692627, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.064, 'grad_norm': 1.7375437021255493, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.254, 'grad_norm': 2.4312188625335693, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0279, 'grad_norm': 0.6188291907310486, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.005, 'grad_norm': 0.2382991909980774, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.0858, 'train_samples_per_second': 46.749, 'train_steps_per_second': 3.31, 'train_loss': 1.1116087532485834, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:14
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.7897, 'grad_norm': 5.000177383422852, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.441, 'grad_norm': 6.829881191253662, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 3.7747, 'grad_norm': 5.716183185577393, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 3.5774, 'grad_norm': 6.985567092895508, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.3663, 'grad_norm': 6.690028667449951, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.8991, 'grad_norm': 7.32010555267334, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 3.3902, 'grad_norm': 10.939743995666504, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 2.6895, 'grad_norm': 61.27824783325195, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.05it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s]                                              {'loss': 2.1435, 'grad_norm': 8.375773429870605, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s]                                               {'loss': 1.4259, 'grad_norm': 6.191615104675293, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 1.0836, 'grad_norm': 7.237650394439697, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 1.1855, 'grad_norm': 4.7554240226745605, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.23it/s]                                               {'loss': 2.1793, 'grad_norm': 9.842976570129395, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.23it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.0759, 'grad_norm': 7.326758861541748, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.9858, 'grad_norm': 6.310728549957275, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 2.8146, 'grad_norm': 91.21918487548828, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s]                                               {'loss': 0.3297, 'grad_norm': 2.2223117351531982, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.395, 'grad_norm': 3.471181869506836, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.371, 'grad_norm': 4.737828254699707, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.356, 'grad_norm': 5.494706153869629, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.5583, 'grad_norm': 6.138301849365234, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.8482, 'grad_norm': 6.737742900848389, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 1.2783, 'grad_norm': 8.565361022949219, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.033, 'grad_norm': 1.9446465969085693, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.13it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s]                                               {'loss': 0.1073, 'grad_norm': 1.498141884803772, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s]                                               {'loss': 0.1053, 'grad_norm': 2.8013765811920166, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.1931, 'grad_norm': 3.9646975994110107, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.0484, 'grad_norm': 1.2021981477737427, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.9094, 'grad_norm': 8.678131103515625, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.1775, 'grad_norm': 2.73008131980896, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.1119, 'grad_norm': 2.132972002029419, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0319, 'grad_norm': 1.5838260650634766, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.0459, 'grad_norm': 0.9158006906509399, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.0396, 'grad_norm': 1.382175326347351, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.0602, 'grad_norm': 1.3814805746078491, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0718, 'grad_norm': 2.620485544204712, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.496, 'grad_norm': 1.1213783025741577, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.3214, 'grad_norm': 4.721199035644531, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0187, 'grad_norm': 0.4235186278820038, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0092, 'grad_norm': 0.48956623673439026, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0965, 'train_samples_per_second': 46.708, 'train_steps_per_second': 3.307, 'train_loss': 1.1684793750755489, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:55
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 4.2133, 'grad_norm': 5.33856201171875, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 4.6295, 'grad_norm': 5.43591833114624, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  3.06it/s]                                              {'loss': 2.9103, 'grad_norm': 6.029854774475098, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.06it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.6598, 'grad_norm': 6.080344200134277, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.4192, 'grad_norm': 9.655461311340332, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.8501, 'grad_norm': 6.5161027908325195, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.7017, 'grad_norm': 7.674441337585449, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 2.826, 'grad_norm': 39.83100891113281, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s]                                              {'loss': 1.3844, 'grad_norm': 9.393179893493652, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 0.903, 'grad_norm': 5.939903259277344, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 1.1239, 'grad_norm': 7.9648942947387695, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.29it/s]                                               {'loss': 1.0165, 'grad_norm': 6.437344074249268, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.29it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 1.0879, 'grad_norm': 5.879846572875977, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.8587, 'grad_norm': 3.8762898445129395, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.647, 'grad_norm': 4.003444194793701, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.39, 'grad_norm': 13.196134567260742, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.2456, 'grad_norm': 2.2835867404937744, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.3783, 'grad_norm': 2.0278234481811523, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.5501, 'grad_norm': 4.459235191345215, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.296, 'grad_norm': 2.7764875888824463, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.2601, 'grad_norm': 3.590703248977661, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.1407, 'grad_norm': 2.5295512676239014, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.3625, 'grad_norm': 6.210832595825195, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.006, 'grad_norm': 0.6197879910469055, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.1175, 'grad_norm': 4.063899040222168, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.0606, 'grad_norm': 1.7075625658035278, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.1047, 'grad_norm': 3.0254569053649902, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.0769, 'grad_norm': 1.554996371269226, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.3781, 'grad_norm': 375.629150390625, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.0677, 'grad_norm': 1.4218963384628296, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.1626, 'grad_norm': 3.989557981491089, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0024, 'grad_norm': 0.1358053833246231, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.73it/s]                                               {'loss': 0.3434, 'grad_norm': 6.46314811706543, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.73it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s]                                               {'loss': 0.0272, 'grad_norm': 0.4886084198951721, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.3952, 'grad_norm': 11.832468032836914, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0252, 'grad_norm': 0.5140466094017029, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.1692, 'grad_norm': 3.4647676944732666, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0527, 'grad_norm': 1.5133830308914185, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0213, 'grad_norm': 0.5729578137397766, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0009, 'grad_norm': 0.05037279799580574, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.1876, 'train_samples_per_second': 46.359, 'train_steps_per_second': 3.282, 'train_loss': 0.896648976985307, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:3
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.1603, 'grad_norm': 4.5892534255981445, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.865, 'grad_norm': 5.228445053100586, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 3.6224, 'grad_norm': 5.077647686004639, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.08it/s]                                              {'loss': 2.5886, 'grad_norm': 6.286626815795898, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.08it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.6076, 'grad_norm': 6.989906311035156, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.06it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.1382, 'grad_norm': 8.526494979858398, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 3.4822, 'grad_norm': 11.016922950744629, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 1.8726, 'grad_norm': 27.93260955810547, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s]                                              {'loss': 1.7413, 'grad_norm': 8.571224212646484, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s]                                               {'loss': 1.8358, 'grad_norm': 12.316596031188965, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 2.0616, 'grad_norm': 8.054471015930176, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.23it/s]                                               {'loss': 1.0563, 'grad_norm': 5.859002113342285, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.23it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.2213, 'grad_norm': 4.594823837280273, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.7775, 'grad_norm': 5.6316118240356445, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.0856, 'grad_norm': 5.040008544921875, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.5273, 'grad_norm': 41.438419342041016, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.7445, 'grad_norm': 3.6331660747528076, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.3284, 'grad_norm': 3.0523295402526855, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.8771, 'grad_norm': 3.6098155975341797, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.6005, 'grad_norm': 5.0795416831970215, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.1637, 'grad_norm': 3.599120616912842, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.4274, 'grad_norm': 9.110567092895508, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.5439, 'grad_norm': 6.409060955047607, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.0116, 'grad_norm': 0.8782564401626587, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.1425, 'grad_norm': 3.7979795932769775, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.0651, 'grad_norm': 1.6661940813064575, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.0704, 'grad_norm': 1.7585508823394775, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.1941, 'grad_norm': 1.4263254404067993, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.074, 'grad_norm': 1.3097337484359741, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s]                                               {'loss': 0.2256, 'grad_norm': 3.078659772872925, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.593, 'grad_norm': 2.7208030223846436, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.0187, 'grad_norm': 1.0801310539245605, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.14it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s]                                               {'loss': 0.4639, 'grad_norm': 0.9038248658180237, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s]                                               {'loss': 0.0454, 'grad_norm': 1.5551462173461914, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.0906, 'grad_norm': 2.0728564262390137, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.049, 'grad_norm': 1.3049569129943848, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.1355, 'grad_norm': 1.2652941942214966, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.166, 'grad_norm': 1.0110875368118286, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0566, 'grad_norm': 6.931102275848389, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0531, 'grad_norm': 5.121537685394287, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.1193, 'train_samples_per_second': 46.62, 'train_steps_per_second': 3.301, 'train_loss': 1.0196076857391745, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:19
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.07it/s]                                              {'loss': 3.548, 'grad_norm': 5.209415435791016, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.07it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 4.0891, 'grad_norm': 5.998985767364502, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 4.2299, 'grad_norm': 5.986383438110352, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.777, 'grad_norm': 5.3124518394470215, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.5318, 'grad_norm': 5.850521087646484, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.5005, 'grad_norm': 9.61463451385498, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 3.3931, 'grad_norm': 10.127434730529785, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.9507, 'grad_norm': 39.82455825805664, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 1.8732, 'grad_norm': 7.243251323699951, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 1.0371, 'grad_norm': 5.417501449584961, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.7192, 'grad_norm': 12.677566528320312, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 1.3196, 'grad_norm': 7.169410705566406, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.0698, 'grad_norm': 5.984479904174805, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.7019, 'grad_norm': 8.522497177124023, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 1.4241, 'grad_norm': 5.512105941772461, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.078, 'grad_norm': 3.0659117698669434, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s]                                               {'loss': 0.6092, 'grad_norm': 4.802809238433838, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.9218, 'grad_norm': 5.0347089767456055, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 1.3149, 'grad_norm': 6.970118045806885, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.5456, 'grad_norm': 5.6142258644104, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.6799, 'grad_norm': 7.315273761749268, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.6607, 'grad_norm': 4.395834445953369, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.4075, 'grad_norm': 5.481470584869385, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0512, 'grad_norm': 4.357794284820557, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s]                                               {'loss': 0.1589, 'grad_norm': 2.7349698543548584, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s]                                               {'loss': 0.1695, 'grad_norm': 2.258901357650757, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.7213, 'grad_norm': 24.39383888244629, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.4117, 'grad_norm': 2.630183458328247, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.3791, 'grad_norm': 7.0929975509643555, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.1195, 'grad_norm': 1.8744784593582153, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.5463, 'grad_norm': 7.901198387145996, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0488, 'grad_norm': 3.0547564029693604, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.0686, 'grad_norm': 2.2388501167297363, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.2966, 'grad_norm': 2.4832773208618164, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0391, 'grad_norm': 1.2001873254776, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.2431, 'grad_norm': 2.984610080718994, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0945, 'grad_norm': 1.96161687374115, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.4552, 'grad_norm': 2.564648151397705, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.3505, 'grad_norm': 14.184806823730469, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0022, 'grad_norm': 0.34950339794158936, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1451, 'train_samples_per_second': 46.521, 'train_steps_per_second': 3.294, 'train_loss': 1.1384649695362896, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:28
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 3.7155, 'grad_norm': 4.891965389251709, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 3.4903, 'grad_norm': 4.843712329864502, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 4.5432, 'grad_norm': 6.150400638580322, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.7271, 'grad_norm': 6.708207130432129, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 3.4954, 'grad_norm': 8.182943344116211, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.619, 'grad_norm': 9.22488784790039, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.4295, 'grad_norm': 7.95695686340332, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 3.3238, 'grad_norm': 3.0818512439727783, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s]                                              {'loss': 1.533, 'grad_norm': 7.358898162841797, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s]                                               {'loss': 1.0309, 'grad_norm': 7.1112494468688965, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s]                                               {'loss': 1.0356, 'grad_norm': 10.608634948730469, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 1.6216, 'grad_norm': 12.73624324798584, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s]                                               {'loss': 1.1906, 'grad_norm': 8.784515380859375, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.824, 'grad_norm': 5.515405654907227, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.6831, 'grad_norm': 5.023185729980469, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.4898, 'grad_norm': 27.27031135559082, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.12it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.4057, 'grad_norm': 2.3737523555755615, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.3235, 'grad_norm': 3.1036477088928223, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.6156, 'grad_norm': 5.579061031341553, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.4587, 'grad_norm': 4.6193084716796875, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.3691, 'grad_norm': 6.1946210861206055, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.3254, 'grad_norm': 6.302884101867676, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.18it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.3204, 'grad_norm': 3.6699485778808594, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.8898, 'grad_norm': 54.709373474121094, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s]                                               {'loss': 0.2146, 'grad_norm': 1.8400261402130127, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.1645, 'grad_norm': 4.482029914855957, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.1683, 'grad_norm': 5.178247928619385, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.1827, 'grad_norm': 7.7628326416015625, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.1433, 'grad_norm': 3.8590309619903564, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.0692, 'grad_norm': 1.5086188316345215, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.1266, 'grad_norm': 2.409230947494507, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.318, 'grad_norm': 73.18990325927734, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.0601, 'grad_norm': 1.0420864820480347, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.0596, 'grad_norm': 0.9085105061531067, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.0372, 'grad_norm': 1.0855929851531982, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.1727, 'grad_norm': 0.9222135543823242, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0481, 'grad_norm': 1.3277336359024048, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0774, 'grad_norm': 2.6434481143951416, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1028, 'grad_norm': 11.030364990234375, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0227, 'grad_norm': 2.8918323516845703, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.0595, 'train_samples_per_second': 46.851, 'train_steps_per_second': 3.317, 'train_loss': 1.0357033202890307, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:94
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]                                              {'loss': 3.7676, 'grad_norm': 3.998234272003174, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]                                              {'loss': 3.8147, 'grad_norm': 5.816473007202148, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 5.1225, 'grad_norm': 7.1366424560546875, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 2.7955, 'grad_norm': 5.650475025177002, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s]                                              {'loss': 3.5123, 'grad_norm': 8.445444107055664, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.9453, 'grad_norm': 10.932764053344727, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 3.3024, 'grad_norm': 10.791325569152832, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 2.8466, 'grad_norm': 36.63066101074219, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 2.3438, 'grad_norm': 8.129138946533203, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 1.7301, 'grad_norm': 9.026487350463867, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.3995, 'grad_norm': 6.320940017700195, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.7551, 'grad_norm': 4.9718451499938965, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.7916, 'grad_norm': 4.534303665161133, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 1.6432, 'grad_norm': 6.454336166381836, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.877, 'grad_norm': 6.414247989654541, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 3.6822, 'grad_norm': 27.64189910888672, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 0.8128, 'grad_norm': 3.217153787612915, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.5425, 'grad_norm': 3.4451143741607666, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.4955, 'grad_norm': 3.7588179111480713, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.8055, 'grad_norm': 5.729547500610352, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.343, 'grad_norm': 4.149987697601318, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.6728, 'grad_norm': 7.784394264221191, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.4846, 'grad_norm': 5.295403480529785, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0136, 'grad_norm': 0.7479630708694458, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.4996, 'grad_norm': 1.244208574295044, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.321, 'grad_norm': 7.045604705810547, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.2906, 'grad_norm': 3.837496757507324, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.1841, 'grad_norm': 2.9813058376312256, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.2157, 'grad_norm': 2.9733808040618896, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.5903, 'grad_norm': 2.919748067855835, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.1972, 'grad_norm': 4.247272968292236, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 1.6722, 'grad_norm': 62.59843444824219, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s]                                               {'loss': 0.2157, 'grad_norm': 10.048420906066895, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.2063, 'grad_norm': 5.808104515075684, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.536, 'grad_norm': 6.145671367645264, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.2269, 'grad_norm': 4.099241733551025, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0648, 'grad_norm': 0.9904964566230774, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0556, 'grad_norm': 1.0291544198989868, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.6304, 'grad_norm': 4.063595771789551, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.1195, 'grad_norm': 5.3300065994262695, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.1425, 'train_samples_per_second': 46.531, 'train_steps_per_second': 3.294, 'train_loss': 1.3131363349733873, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:25
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 4.7843, 'grad_norm': 5.616247177124023, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.8065, 'grad_norm': 5.679586887359619, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.2863, 'grad_norm': 5.26406717300415, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.1441, 'grad_norm': 7.317808628082275, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.6532, 'grad_norm': 7.212827205657959, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.6793, 'grad_norm': 9.25291919708252, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.8399, 'grad_norm': 9.429835319519043, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.2165, 'grad_norm': 22.205732345581055, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 1.9385, 'grad_norm': 7.9524970054626465, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 1.1072, 'grad_norm': 5.498237133026123, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 1.2938, 'grad_norm': 7.674735069274902, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.633, 'grad_norm': 4.479630470275879, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.6678, 'grad_norm': 4.867094039916992, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.12it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.04it/s]                                               {'loss': 1.4016, 'grad_norm': 5.360795974731445, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.04it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 1.685, 'grad_norm': 5.844255447387695, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.3416, 'grad_norm': 15.225167274475098, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.9788, 'grad_norm': 6.27182149887085, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.5753, 'grad_norm': 3.0981600284576416, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.303, 'grad_norm': 3.705681085586548, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.7572, 'grad_norm': 6.912500858306885, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.4614, 'grad_norm': 6.832316875457764, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.3977, 'grad_norm': 7.7345709800720215, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.3158, 'grad_norm': 4.516730308532715, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.2273, 'grad_norm': 10.714865684509277, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.5348, 'grad_norm': 2.40336012840271, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.1661, 'grad_norm': 5.140651702880859, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.1242, 'grad_norm': 2.140597105026245, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.4763, 'grad_norm': 9.802404403686523, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.0852, 'grad_norm': 1.69149649143219, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.1102, 'grad_norm': 2.8210673332214355, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.3252, 'grad_norm': 12.459759712219238, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.044, 'grad_norm': 2.407829523086548, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.13it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.0987, 'grad_norm': 3.772846221923828, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.0527, 'grad_norm': 1.2149662971496582, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.1017, 'grad_norm': 2.8877177238464355, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.401, 'grad_norm': 4.6835198402404785, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.1601, 'grad_norm': 2.84387469291687, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.073, 'grad_norm': 1.2739959955215454, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.5343, 'grad_norm': 7.277079105377197, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.1349, 'grad_norm': 5.5947771072387695, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.1716, 'train_samples_per_second': 46.42, 'train_steps_per_second': 3.286, 'train_loss': 1.0229385358281433, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:43, 10.74it/s]  1%|          | 4/471 [00:00<01:08,  6.77it/s]  1%|          | 5/471 [00:00<01:14,  6.25it/s]  1%|▏         | 6/471 [00:00<01:18,  5.95it/s]  1%|▏         | 7/471 [00:01<01:20,  5.74it/s]  2%|▏         | 8/471 [00:01<01:22,  5.61it/s]  2%|▏         | 9/471 [00:01<01:23,  5.54it/s]  2%|▏         | 10/471 [00:01<01:24,  5.48it/s]  2%|▏         | 11/471 [00:01<01:24,  5.43it/s]  3%|▎         | 12/471 [00:02<01:25,  5.39it/s]  3%|▎         | 13/471 [00:02<01:25,  5.36it/s]  3%|▎         | 14/471 [00:02<01:25,  5.35it/s]  3%|▎         | 15/471 [00:02<01:25,  5.35it/s]  3%|▎         | 16/471 [00:02<01:25,  5.33it/s]  4%|▎         | 17/471 [00:03<01:25,  5.33it/s]  4%|▍         | 18/471 [00:03<01:25,  5.33it/s]  4%|▍         | 19/471 [00:03<01:24,  5.33it/s]  4%|▍         | 20/471 [00:03<01:24,  5.32it/s]  4%|▍         | 21/471 [00:03<01:24,  5.31it/s]  5%|▍         | 22/471 [00:03<01:24,  5.30it/s]  5%|▍         | 23/471 [00:04<01:24,  5.31it/s]  5%|▌         | 24/471 [00:04<01:24,  5.31it/s]  5%|▌         | 25/471 [00:04<01:23,  5.32it/s]  6%|▌         | 26/471 [00:04<01:23,  5.31it/s]  6%|▌         | 27/471 [00:04<01:23,  5.30it/s]  6%|▌         | 28/471 [00:05<01:23,  5.30it/s]  6%|▌         | 29/471 [00:05<01:23,  5.30it/s]  6%|▋         | 30/471 [00:05<01:23,  5.30it/s]  7%|▋         | 31/471 [00:05<01:22,  5.31it/s]  7%|▋         | 32/471 [00:05<01:22,  5.33it/s]  7%|▋         | 33/471 [00:06<01:21,  5.35it/s]  7%|▋         | 34/471 [00:06<01:21,  5.36it/s]  7%|▋         | 35/471 [00:06<01:21,  5.34it/s]  8%|▊         | 36/471 [00:06<01:21,  5.34it/s]  8%|▊         | 37/471 [00:06<01:21,  5.32it/s]  8%|▊         | 38/471 [00:06<01:21,  5.30it/s]  8%|▊         | 39/471 [00:07<01:21,  5.31it/s]  8%|▊         | 40/471 [00:07<01:21,  5.32it/s]  9%|▊         | 41/471 [00:07<01:20,  5.31it/s]  9%|▉         | 42/471 [00:07<01:20,  5.30it/s]  9%|▉         | 43/471 [00:07<01:20,  5.30it/s]  9%|▉         | 44/471 [00:08<01:20,  5.32it/s] 10%|▉         | 45/471 [00:08<01:20,  5.32it/s] 10%|▉         | 46/471 [00:08<01:19,  5.31it/s] 10%|▉         | 47/471 [00:08<01:19,  5.33it/s] 10%|█         | 48/471 [00:08<01:19,  5.32it/s] 10%|█         | 49/471 [00:09<01:19,  5.31it/s] 11%|█         | 50/471 [00:09<01:19,  5.30it/s] 11%|█         | 51/471 [00:09<01:19,  5.30it/s] 11%|█         | 52/471 [00:09<01:18,  5.31it/s] 11%|█▏        | 53/471 [00:09<01:18,  5.29it/s] 11%|█▏        | 54/471 [00:09<01:18,  5.29it/s] 12%|█▏        | 55/471 [00:10<01:18,  5.28it/s] 12%|█▏        | 56/471 [00:10<01:18,  5.27it/s] 12%|█▏        | 57/471 [00:10<01:18,  5.30it/s] 12%|█▏        | 58/471 [00:10<01:18,  5.29it/s] 13%|█▎        | 59/471 [00:10<01:18,  5.28it/s] 13%|█▎        | 60/471 [00:11<01:17,  5.28it/s] 13%|█▎        | 61/471 [00:11<01:17,  5.27it/s] 13%|█▎        | 62/471 [00:11<01:17,  5.28it/s] 13%|█▎        | 63/471 [00:11<01:17,  5.28it/s] 14%|█▎        | 64/471 [00:11<01:17,  5.27it/s] 14%|█▍        | 65/471 [00:12<01:17,  5.26it/s] 14%|█▍        | 66/471 [00:12<01:16,  5.26it/s] 14%|█▍        | 67/471 [00:12<01:16,  5.26it/s] 14%|█▍        | 68/471 [00:12<01:16,  5.27it/s] 15%|█▍        | 69/471 [00:12<01:16,  5.28it/s] 15%|█▍        | 70/471 [00:13<01:16,  5.26it/s] 15%|█▌        | 71/471 [00:13<01:16,  5.26it/s] 15%|█▌        | 72/471 [00:13<01:15,  5.26it/s] 15%|█▌        | 73/471 [00:13<01:15,  5.26it/s] 16%|█▌        | 74/471 [00:13<01:15,  5.27it/s] 16%|█▌        | 75/471 [00:13<01:15,  5.27it/s] 16%|█▌        | 76/471 [00:14<01:14,  5.28it/s] 16%|█▋        | 77/471 [00:14<01:14,  5.27it/s] 17%|█▋        | 78/471 [00:14<01:14,  5.26it/s] 17%|█▋        | 79/471 [00:14<01:14,  5.25it/s] 17%|█▋        | 80/471 [00:14<01:14,  5.25it/s] 17%|█▋        | 81/471 [00:15<01:13,  5.28it/s] 17%|█▋        | 82/471 [00:15<01:13,  5.29it/s] 18%|█▊        | 83/471 [00:15<01:13,  5.29it/s] 18%|█▊        | 84/471 [00:15<01:13,  5.29it/s] 18%|█▊        | 85/471 [00:15<01:13,  5.27it/s] 18%|█▊        | 86/471 [00:16<01:13,  5.27it/s] 18%|█▊        | 87/471 [00:16<01:12,  5.28it/s] 19%|█▊        | 88/471 [00:16<01:12,  5.31it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.31it/s] 19%|█▉        | 90/471 [00:16<01:12,  5.28it/s] 19%|█▉        | 91/471 [00:16<01:11,  5.30it/s] 20%|█▉        | 92/471 [00:17<01:11,  5.28it/s] 20%|█▉        | 93/471 [00:17<01:11,  5.27it/s] 20%|█▉        | 94/471 [00:17<01:11,  5.28it/s] 20%|██        | 95/471 [00:17<01:10,  5.30it/s] 20%|██        | 96/471 [00:17<01:10,  5.31it/s] 21%|██        | 97/471 [00:18<01:10,  5.29it/s] 21%|██        | 98/471 [00:18<01:10,  5.28it/s] 21%|██        | 99/471 [00:18<01:10,  5.29it/s] 21%|██        | 100/471 [00:18<01:09,  5.31it/s] 21%|██▏       | 101/471 [00:18<01:09,  5.32it/s] 22%|██▏       | 102/471 [00:19<01:09,  5.30it/s] 22%|██▏       | 103/471 [00:19<01:09,  5.28it/s] 22%|██▏       | 104/471 [00:19<01:09,  5.27it/s] 22%|██▏       | 105/471 [00:19<01:09,  5.26it/s] 23%|██▎       | 106/471 [00:19<01:08,  5.30it/s] 23%|██▎       | 107/471 [00:20<01:08,  5.32it/s] 23%|██▎       | 108/471 [00:20<01:08,  5.31it/s] 23%|██▎       | 109/471 [00:20<01:08,  5.31it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.31it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.30it/s] 24%|██▍       | 112/471 [00:20<01:07,  5.29it/s] 24%|██▍       | 113/471 [00:21<01:07,  5.33it/s] 24%|██▍       | 114/471 [00:21<01:07,  5.31it/s] 24%|██▍       | 115/471 [00:21<01:07,  5.30it/s] 25%|██▍       | 116/471 [00:21<01:07,  5.29it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.29it/s] 25%|██▌       | 118/471 [00:22<01:06,  5.28it/s] 25%|██▌       | 119/471 [00:22<01:06,  5.28it/s] 25%|██▌       | 120/471 [00:22<01:06,  5.27it/s] 26%|██▌       | 121/471 [00:22<01:06,  5.27it/s] 26%|██▌       | 122/471 [00:22<01:06,  5.27it/s] 26%|██▌       | 123/471 [00:23<01:06,  5.27it/s] 26%|██▋       | 124/471 [00:23<01:05,  5.26it/s] 27%|██▋       | 125/471 [00:23<01:05,  5.27it/s] 27%|██▋       | 126/471 [00:23<01:05,  5.28it/s] 27%|██▋       | 127/471 [00:23<01:05,  5.28it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.28it/s] 27%|██▋       | 129/471 [00:24<01:04,  5.28it/s] 28%|██▊       | 130/471 [00:24<01:04,  5.28it/s] 28%|██▊       | 131/471 [00:24<01:04,  5.28it/s] 28%|██▊       | 132/471 [00:24<01:04,  5.27it/s] 28%|██▊       | 133/471 [00:24<01:04,  5.26it/s] 28%|██▊       | 134/471 [00:25<01:04,  5.24it/s] 29%|██▊       | 135/471 [00:25<01:03,  5.25it/s] 29%|██▉       | 136/471 [00:25<01:03,  5.26it/s] 29%|██▉       | 137/471 [00:25<01:03,  5.25it/s] 29%|██▉       | 138/471 [00:25<01:03,  5.25it/s] 30%|██▉       | 139/471 [00:26<01:03,  5.27it/s] 30%|██▉       | 140/471 [00:26<01:02,  5.26it/s] 30%|██▉       | 141/471 [00:26<01:02,  5.27it/s] 30%|███       | 142/471 [00:26<01:02,  5.27it/s] 30%|███       | 143/471 [00:26<01:02,  5.27it/s] 31%|███       | 144/471 [00:27<01:02,  5.27it/s] 31%|███       | 145/471 [00:27<01:01,  5.28it/s] 31%|███       | 146/471 [00:27<01:01,  5.27it/s] 31%|███       | 147/471 [00:27<01:01,  5.26it/s] 31%|███▏      | 148/471 [00:27<01:01,  5.26it/s] 32%|███▏      | 149/471 [00:27<01:01,  5.24it/s] 32%|███▏      | 150/471 [00:28<01:01,  5.23it/s] 32%|███▏      | 151/471 [00:28<01:01,  5.24it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.25it/s] 32%|███▏      | 153/471 [00:28<01:00,  5.26it/s] 33%|███▎      | 154/471 [00:28<01:00,  5.27it/s] 33%|███▎      | 155/471 [00:29<01:00,  5.26it/s] 33%|███▎      | 156/471 [00:29<00:59,  5.27it/s] 33%|███▎      | 157/471 [00:29<00:59,  5.27it/s] 34%|███▎      | 158/471 [00:29<00:59,  5.29it/s] 34%|███▍      | 159/471 [00:29<00:59,  5.29it/s] 34%|███▍      | 160/471 [00:30<00:58,  5.28it/s] 34%|███▍      | 161/471 [00:30<00:58,  5.26it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.25it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.25it/s] 35%|███▍      | 164/471 [00:30<00:58,  5.26it/s] 35%|███▌      | 165/471 [00:31<00:58,  5.25it/s] 35%|███▌      | 166/471 [00:31<00:58,  5.24it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.25it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.25it/s] 36%|███▌      | 169/471 [00:31<00:57,  5.25it/s] 36%|███▌      | 170/471 [00:31<00:57,  5.26it/s] 36%|███▋      | 171/471 [00:32<00:57,  5.25it/s] 37%|███▋      | 172/471 [00:32<00:56,  5.25it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.25it/s] 37%|███▋      | 174/471 [00:32<00:56,  5.25it/s] 37%|███▋      | 175/471 [00:32<00:56,  5.25it/s] 37%|███▋      | 176/471 [00:33<00:56,  5.25it/s] 38%|███▊      | 177/471 [00:33<00:56,  5.24it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.24it/s] 38%|███▊      | 179/471 [00:33<00:55,  5.25it/s] 38%|███▊      | 180/471 [00:33<00:55,  5.25it/s] 38%|███▊      | 181/471 [00:34<00:55,  5.25it/s] 39%|███▊      | 182/471 [00:34<00:55,  5.25it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.25it/s] 39%|███▉      | 184/471 [00:34<00:54,  5.26it/s] 39%|███▉      | 185/471 [00:34<00:54,  5.25it/s] 39%|███▉      | 186/471 [00:35<00:54,  5.24it/s] 40%|███▉      | 187/471 [00:35<00:54,  5.23it/s] 40%|███▉      | 188/471 [00:35<00:54,  5.23it/s] 40%|████      | 189/471 [00:35<00:53,  5.24it/s] 40%|████      | 190/471 [00:35<00:53,  5.25it/s] 41%|████      | 191/471 [00:35<00:53,  5.23it/s] 41%|████      | 192/471 [00:36<00:53,  5.23it/s] 41%|████      | 193/471 [00:36<00:52,  5.27it/s] 41%|████      | 194/471 [00:36<00:52,  5.26it/s] 41%|████▏     | 195/471 [00:36<00:52,  5.25it/s] 42%|████▏     | 196/471 [00:36<00:52,  5.24it/s] 42%|████▏     | 197/471 [00:37<00:51,  5.28it/s] 42%|████▏     | 198/471 [00:37<00:51,  5.26it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.25it/s] 42%|████▏     | 200/471 [00:37<00:51,  5.25it/s] 43%|████▎     | 201/471 [00:37<00:51,  5.28it/s] 43%|████▎     | 202/471 [00:38<00:51,  5.26it/s] 43%|████▎     | 203/471 [00:38<00:51,  5.25it/s] 43%|████▎     | 204/471 [00:38<00:50,  5.26it/s] 44%|████▎     | 205/471 [00:38<00:50,  5.28it/s] 44%|████▎     | 206/471 [00:38<00:50,  5.27it/s] 44%|████▍     | 207/471 [00:39<00:50,  5.26it/s] 44%|████▍     | 208/471 [00:39<00:49,  5.28it/s] 44%|████▍     | 209/471 [00:39<00:49,  5.29it/s] 45%|████▍     | 210/471 [00:39<00:49,  5.29it/s] 45%|████▍     | 211/471 [00:39<00:49,  5.27it/s] 45%|████▌     | 212/471 [00:39<00:49,  5.27it/s] 45%|████▌     | 213/471 [00:40<00:49,  5.26it/s] 45%|████▌     | 214/471 [00:40<00:48,  5.25it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.25it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.26it/s] 46%|████▌     | 217/471 [00:40<00:48,  5.25it/s] 46%|████▋     | 218/471 [00:41<00:48,  5.24it/s] 46%|████▋     | 219/471 [00:41<00:48,  5.24it/s] 47%|████▋     | 220/471 [00:41<00:47,  5.24it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.24it/s] 47%|████▋     | 222/471 [00:41<00:47,  5.26it/s] 47%|████▋     | 223/471 [00:42<00:47,  5.26it/s] 48%|████▊     | 224/471 [00:42<00:47,  5.25it/s] 48%|████▊     | 225/471 [00:42<00:46,  5.25it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.24it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.24it/s] 48%|████▊     | 228/471 [00:43<00:46,  5.24it/s] 49%|████▊     | 229/471 [00:43<00:46,  5.23it/s] 49%|████▉     | 230/471 [00:43<00:45,  5.24it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.24it/s] 49%|████▉     | 232/471 [00:43<00:45,  5.27it/s] 49%|████▉     | 233/471 [00:43<00:45,  5.26it/s] 50%|████▉     | 234/471 [00:44<00:45,  5.26it/s] 50%|████▉     | 235/471 [00:44<00:44,  5.25it/s] 50%|█████     | 236/471 [00:44<00:44,  5.27it/s] 50%|█████     | 237/471 [00:44<00:44,  5.25it/s] 51%|█████     | 238/471 [00:44<00:44,  5.25it/s] 51%|█████     | 239/471 [00:45<00:44,  5.26it/s] 51%|█████     | 240/471 [00:45<00:43,  5.26it/s] 51%|█████     | 241/471 [00:45<00:43,  5.25it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.26it/s] 52%|█████▏    | 243/471 [00:45<00:43,  5.25it/s] 52%|█████▏    | 244/471 [00:46<00:43,  5.25it/s] 52%|█████▏    | 245/471 [00:46<00:43,  5.24it/s] 52%|█████▏    | 246/471 [00:46<00:42,  5.25it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.27it/s] 53%|█████▎    | 248/471 [00:46<00:42,  5.28it/s] 53%|█████▎    | 249/471 [00:46<00:42,  5.26it/s] 53%|█████▎    | 250/471 [00:47<00:42,  5.26it/s] 53%|█████▎    | 251/471 [00:47<00:41,  5.24it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.24it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.24it/s] 54%|█████▍    | 254/471 [00:47<00:41,  5.24it/s] 54%|█████▍    | 255/471 [00:48<00:41,  5.25it/s] 54%|█████▍    | 256/471 [00:48<00:41,  5.24it/s] 55%|█████▍    | 257/471 [00:48<00:40,  5.24it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.25it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.25it/s] 55%|█████▌    | 260/471 [00:49<00:40,  5.24it/s] 55%|█████▌    | 261/471 [00:49<00:40,  5.24it/s] 56%|█████▌    | 262/471 [00:49<00:39,  5.24it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.24it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.25it/s] 56%|█████▋    | 265/471 [00:50<00:39,  5.25it/s] 56%|█████▋    | 266/471 [00:50<00:39,  5.23it/s] 57%|█████▋    | 267/471 [00:50<00:39,  5.23it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.24it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.25it/s] 57%|█████▋    | 270/471 [00:51<00:38,  5.26it/s] 58%|█████▊    | 271/471 [00:51<00:38,  5.25it/s] 58%|█████▊    | 272/471 [00:51<00:37,  5.25it/s] 58%|█████▊    | 273/471 [00:51<00:37,  5.26it/s] 58%|█████▊    | 274/471 [00:51<00:37,  5.29it/s] 58%|█████▊    | 275/471 [00:51<00:37,  5.29it/s] 59%|█████▊    | 276/471 [00:52<00:36,  5.27it/s] 59%|█████▉    | 277/471 [00:52<00:36,  5.27it/s] 59%|█████▉    | 278/471 [00:52<00:36,  5.25it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.26it/s] 59%|█████▉    | 280/471 [00:52<00:36,  5.27it/s] 60%|█████▉    | 281/471 [00:53<00:36,  5.24it/s] 60%|█████▉    | 282/471 [00:53<00:35,  5.25it/s] 60%|██████    | 283/471 [00:53<00:35,  5.25it/s] 60%|██████    | 284/471 [00:53<00:35,  5.26it/s] 61%|██████    | 285/471 [00:53<00:35,  5.26it/s] 61%|██████    | 286/471 [00:54<00:35,  5.24it/s] 61%|██████    | 287/471 [00:54<00:35,  5.25it/s] 61%|██████    | 288/471 [00:54<00:34,  5.24it/s] 61%|██████▏   | 289/471 [00:54<00:34,  5.26it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.27it/s] 62%|██████▏   | 291/471 [00:54<00:34,  5.26it/s] 62%|██████▏   | 292/471 [00:55<00:34,  5.26it/s] 62%|██████▏   | 293/471 [00:55<00:33,  5.27it/s] 62%|██████▏   | 294/471 [00:55<00:33,  5.28it/s] 63%|██████▎   | 295/471 [00:55<00:33,  5.29it/s] 63%|██████▎   | 296/471 [00:55<00:33,  5.29it/s] 63%|██████▎   | 297/471 [00:56<00:32,  5.28it/s] 63%|██████▎   | 298/471 [00:56<00:32,  5.26it/s] 63%|██████▎   | 299/471 [00:56<00:32,  5.27it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.26it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.26it/s] 64%|██████▍   | 302/471 [00:57<00:32,  5.27it/s] 64%|██████▍   | 303/471 [00:57<00:31,  5.26it/s] 65%|██████▍   | 304/471 [00:57<00:31,  5.28it/s] 65%|██████▍   | 305/471 [00:57<00:31,  5.27it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.26it/s] 65%|██████▌   | 307/471 [00:58<00:31,  5.26it/s] 65%|██████▌   | 308/471 [00:58<00:31,  5.25it/s] 66%|██████▌   | 309/471 [00:58<00:30,  5.25it/s] 66%|██████▌   | 310/471 [00:58<00:30,  5.26it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.26it/s] 66%|██████▌   | 312/471 [00:58<00:30,  5.27it/s] 66%|██████▋   | 313/471 [00:59<00:29,  5.27it/s] 67%|██████▋   | 314/471 [00:59<00:29,  5.27it/s] 67%|██████▋   | 315/471 [00:59<00:29,  5.28it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.29it/s] 67%|██████▋   | 317/471 [00:59<00:29,  5.28it/s] 68%|██████▊   | 318/471 [01:00<00:29,  5.27it/s] 68%|██████▊   | 319/471 [01:00<00:28,  5.26it/s] 68%|██████▊   | 320/471 [01:00<00:28,  5.26it/s] 68%|██████▊   | 321/471 [01:00<00:28,  5.26it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.26it/s] 69%|██████▊   | 323/471 [01:01<00:28,  5.24it/s] 69%|██████▉   | 324/471 [01:01<00:28,  5.23it/s] 69%|██████▉   | 325/471 [01:01<00:27,  5.24it/s] 69%|██████▉   | 326/471 [01:01<00:27,  5.25it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.27it/s] 70%|██████▉   | 328/471 [01:02<00:27,  5.26it/s] 70%|██████▉   | 329/471 [01:02<00:27,  5.25it/s] 70%|███████   | 330/471 [01:02<00:26,  5.27it/s] 70%|███████   | 331/471 [01:02<00:26,  5.26it/s] 70%|███████   | 332/471 [01:02<00:26,  5.25it/s] 71%|███████   | 333/471 [01:02<00:26,  5.26it/s] 71%|███████   | 334/471 [01:03<00:26,  5.26it/s] 71%|███████   | 335/471 [01:03<00:25,  5.25it/s] 71%|███████▏  | 336/471 [01:03<00:25,  5.25it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.27it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.29it/s] 72%|███████▏  | 339/471 [01:04<00:25,  5.28it/s] 72%|███████▏  | 340/471 [01:04<00:24,  5.28it/s] 72%|███████▏  | 341/471 [01:04<00:24,  5.28it/s] 73%|███████▎  | 342/471 [01:04<00:24,  5.28it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.28it/s] 73%|███████▎  | 344/471 [01:05<00:23,  5.29it/s] 73%|███████▎  | 345/471 [01:05<00:23,  5.28it/s] 73%|███████▎  | 346/471 [01:05<00:23,  5.27it/s] 74%|███████▎  | 347/471 [01:05<00:23,  5.28it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.28it/s] 74%|███████▍  | 349/471 [01:06<00:23,  5.28it/s] 74%|███████▍  | 350/471 [01:06<00:23,  5.24it/s] 75%|███████▍  | 351/471 [01:06<00:22,  5.27it/s] 75%|███████▍  | 352/471 [01:06<00:22,  5.27it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.27it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.27it/s] 75%|███████▌  | 355/471 [01:07<00:22,  5.26it/s] 76%|███████▌  | 356/471 [01:07<00:21,  5.26it/s] 76%|███████▌  | 357/471 [01:07<00:21,  5.25it/s] 76%|███████▌  | 358/471 [01:07<00:21,  5.27it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.26it/s] 76%|███████▋  | 360/471 [01:08<00:21,  5.26it/s] 77%|███████▋  | 361/471 [01:08<00:20,  5.26it/s] 77%|███████▋  | 362/471 [01:08<00:20,  5.26it/s] 77%|███████▋  | 363/471 [01:08<00:20,  5.26it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.29it/s] 77%|███████▋  | 365/471 [01:09<00:20,  5.27it/s] 78%|███████▊  | 366/471 [01:09<00:19,  5.25it/s] 78%|███████▊  | 367/471 [01:09<00:19,  5.25it/s] 78%|███████▊  | 368/471 [01:09<00:19,  5.26it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.27it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.27it/s] 79%|███████▉  | 371/471 [01:10<00:19,  5.26it/s] 79%|███████▉  | 372/471 [01:10<00:18,  5.25it/s] 79%|███████▉  | 373/471 [01:10<00:18,  5.25it/s] 79%|███████▉  | 374/471 [01:10<00:18,  5.26it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.27it/s] 80%|███████▉  | 376/471 [01:11<00:18,  5.27it/s] 80%|████████  | 377/471 [01:11<00:17,  5.27it/s] 80%|████████  | 378/471 [01:11<00:17,  5.29it/s] 80%|████████  | 379/471 [01:11<00:17,  5.26it/s] 81%|████████  | 380/471 [01:11<00:17,  5.26it/s] 81%|████████  | 381/471 [01:12<00:17,  5.27it/s] 81%|████████  | 382/471 [01:12<00:16,  5.26it/s] 81%|████████▏ | 383/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 384/471 [01:12<00:16,  5.25it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.24it/s] 82%|████████▏ | 386/471 [01:13<00:16,  5.25it/s] 82%|████████▏ | 387/471 [01:13<00:15,  5.26it/s] 82%|████████▏ | 388/471 [01:13<00:15,  5.25it/s] 83%|████████▎ | 389/471 [01:13<00:15,  5.27it/s] 83%|████████▎ | 390/471 [01:13<00:15,  5.26it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.25it/s] 83%|████████▎ | 392/471 [01:14<00:15,  5.26it/s] 83%|████████▎ | 393/471 [01:14<00:14,  5.27it/s] 84%|████████▎ | 394/471 [01:14<00:14,  5.26it/s] 84%|████████▍ | 395/471 [01:14<00:14,  5.25it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.25it/s] 84%|████████▍ | 397/471 [01:15<00:14,  5.25it/s] 85%|████████▍ | 398/471 [01:15<00:13,  5.26it/s] 85%|████████▍ | 399/471 [01:15<00:13,  5.25it/s] 85%|████████▍ | 400/471 [01:15<00:13,  5.25it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.25it/s] 85%|████████▌ | 402/471 [01:16<00:13,  5.24it/s] 86%|████████▌ | 403/471 [01:16<00:12,  5.26it/s] 86%|████████▌ | 404/471 [01:16<00:12,  5.26it/s] 86%|████████▌ | 405/471 [01:16<00:12,  5.25it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.26it/s] 86%|████████▋ | 407/471 [01:17<00:12,  5.26it/s] 87%|████████▋ | 408/471 [01:17<00:11,  5.25it/s] 87%|████████▋ | 409/471 [01:17<00:11,  5.25it/s] 87%|████████▋ | 410/471 [01:17<00:11,  5.27it/s] 87%|████████▋ | 411/471 [01:17<00:11,  5.29it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.26it/s] 88%|████████▊ | 413/471 [01:18<00:11,  5.27it/s] 88%|████████▊ | 414/471 [01:18<00:10,  5.26it/s] 88%|████████▊ | 415/471 [01:18<00:10,  5.27it/s] 88%|████████▊ | 416/471 [01:18<00:10,  5.25it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.26it/s] 89%|████████▊ | 418/471 [01:19<00:10,  5.25it/s] 89%|████████▉ | 419/471 [01:19<00:09,  5.28it/s] 89%|████████▉ | 420/471 [01:19<00:09,  5.29it/s] 89%|████████▉ | 421/471 [01:19<00:09,  5.28it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.28it/s] 90%|████████▉ | 423/471 [01:20<00:09,  5.28it/s] 90%|█████████ | 424/471 [01:20<00:08,  5.28it/s] 90%|█████████ | 425/471 [01:20<00:08,  5.30it/s] 90%|█████████ | 426/471 [01:20<00:08,  5.29it/s] 91%|█████████ | 427/471 [01:20<00:08,  5.27it/s] 91%|█████████ | 428/471 [01:21<00:08,  5.26it/s] 91%|█████████ | 429/471 [01:21<00:07,  5.26it/s] 91%|█████████▏| 430/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 431/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 432/471 [01:21<00:07,  5.27it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 434/471 [01:22<00:07,  5.26it/s] 92%|█████████▏| 435/471 [01:22<00:06,  5.25it/s] 93%|█████████▎| 436/471 [01:22<00:06,  5.26it/s] 93%|█████████▎| 437/471 [01:22<00:06,  5.26it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.26it/s] 93%|█████████▎| 439/471 [01:23<00:06,  5.25it/s] 93%|█████████▎| 440/471 [01:23<00:05,  5.26it/s] 94%|█████████▎| 441/471 [01:23<00:05,  5.27it/s] 94%|█████████▍| 442/471 [01:23<00:05,  5.29it/s] 94%|█████████▍| 443/471 [01:23<00:05,  5.27it/s] 94%|█████████▍| 444/471 [01:24<00:05,  5.27it/s] 94%|█████████▍| 445/471 [01:24<00:04,  5.26it/s] 95%|█████████▍| 446/471 [01:24<00:04,  5.26it/s] 95%|█████████▍| 447/471 [01:24<00:04,  5.26it/s] 95%|█████████▌| 448/471 [01:24<00:04,  5.27it/s] 95%|█████████▌| 449/471 [01:25<00:04,  5.28it/s] 96%|█████████▌| 450/471 [01:25<00:03,  5.27it/s] 96%|█████████▌| 451/471 [01:25<00:03,  5.27it/s] 96%|█████████▌| 452/471 [01:25<00:03,  5.28it/s] 96%|█████████▌| 453/471 [01:25<00:03,  5.26it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.26it/s] 97%|█████████▋| 455/471 [01:26<00:03,  5.26it/s] 97%|█████████▋| 456/471 [01:26<00:02,  5.26it/s] 97%|█████████▋| 457/471 [01:26<00:02,  5.26it/s] 97%|█████████▋| 458/471 [01:26<00:02,  5.27it/s] 97%|█████████▋| 459/471 [01:26<00:02,  5.30it/s] 98%|█████████▊| 460/471 [01:27<00:02,  5.30it/s] 98%|█████████▊| 461/471 [01:27<00:01,  5.28it/s] 98%|█████████▊| 462/471 [01:27<00:01,  5.27it/s] 98%|█████████▊| 463/471 [01:27<00:01,  5.29it/s] 99%|█████████▊| 464/471 [01:27<00:01,  5.28it/s] 99%|█████████▊| 465/471 [01:28<00:01,  5.29it/s] 99%|█████████▉| 466/471 [01:28<00:00,  5.26it/s] 99%|█████████▉| 467/471 [01:28<00:00,  5.25it/s] 99%|█████████▉| 468/471 [01:28<00:00,  5.26it/s]100%|█████████▉| 469/471 [01:28<00:00,  5.27it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.26it/s]100%|██████████| 471/471 [01:29<00:00,  5.64it/s]100%|██████████| 471/471 [01:29<00:00,  5.28it/s]
{'eval_loss': 3.8947482109069824, 'eval_model_preparation_time': 0.0049, 'eval_acc': 0.16648964418481146, 'eval_runtime': 89.3135, 'eval_samples_per_second': 84.332, 'eval_steps_per_second': 5.274}
ROUND:5
CLIENT:79
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.17it/s]                                              {'loss': 3.7575, 'grad_norm': 5.263138294219971, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.17it/s]  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]                                              {'loss': 3.4667, 'grad_norm': 5.885226726531982, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.9128, 'grad_norm': 6.879411220550537, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 3.3771, 'grad_norm': 9.166790962219238, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.9298, 'grad_norm': 6.876222133636475, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.4251, 'grad_norm': 10.918776512145996, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 3.012, 'grad_norm': 13.998650550842285, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 4.9904, 'grad_norm': 55.564353942871094, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.98it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s]                                              {'loss': 1.9098, 'grad_norm': 10.324389457702637, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 0.7422, 'grad_norm': 5.986673831939697, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s]                                               {'loss': 0.7438, 'grad_norm': 5.8665995597839355, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s] 30%|███       | 12/40 [00:03<00:08,  3.22it/s]                                               {'loss': 1.0626, 'grad_norm': 6.03345251083374, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.22it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.0806, 'grad_norm': 6.108838081359863, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.0031, 'grad_norm': 5.477603435516357, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 1.298, 'grad_norm': 7.033034801483154, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.4634, 'grad_norm': 12.750587463378906, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.05it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.6392, 'grad_norm': 5.783577919006348, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.4043, 'grad_norm': 5.17915153503418, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.98, 'grad_norm': 4.141463279724121, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.369, 'grad_norm': 6.016828536987305, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.3404, 'grad_norm': 7.263729095458984, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.2566, 'grad_norm': 3.999483823776245, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.4014, 'grad_norm': 6.847292900085449, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0108, 'grad_norm': 0.6278862953186035, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.2924, 'grad_norm': 3.794778823852539, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.0926, 'grad_norm': 1.8174279928207397, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.0745, 'grad_norm': 1.6386176347732544, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.763, 'grad_norm': 2.92419171333313, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.0473, 'grad_norm': 1.7029801607131958, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.1765, 'grad_norm': 4.18294095993042, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.1284, 'grad_norm': 3.301666021347046, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.2122, 'grad_norm': 11.821688652038574, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s]                                               {'loss': 0.0349, 'grad_norm': 0.7014454007148743, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s]                                               {'loss': 0.0753, 'grad_norm': 2.5230374336242676, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.2043, 'grad_norm': 0.7595576643943787, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.4602, 'grad_norm': 0.8283584117889404, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0991, 'grad_norm': 2.559467315673828, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.2301, 'grad_norm': 1.8017628192901611, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0695, 'grad_norm': 2.0188651084899902, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0132, 'grad_norm': 0.9578108191490173, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.1988, 'train_samples_per_second': 46.316, 'train_steps_per_second': 3.279, 'train_loss': 1.038750087027438, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:75
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 4.3547, 'grad_norm': 5.605999946594238, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.267, 'grad_norm': 6.01336669921875, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  2.99it/s]                                              {'loss': 2.8636, 'grad_norm': 6.553573131561279, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  2.99it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.0324, 'grad_norm': 7.326902866363525, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.6243, 'grad_norm': 9.293539047241211, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s]                                              {'loss': 1.9534, 'grad_norm': 10.682503700256348, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 1.8107, 'grad_norm': 10.016936302185059, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.5047, 'grad_norm': 24.836395263671875, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s]                                              {'loss': 0.8139, 'grad_norm': 5.168661117553711, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s]                                               {'loss': 0.1861, 'grad_norm': 2.1961843967437744, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.28it/s]                                               {'loss': 1.2018, 'grad_norm': 5.642205238342285, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.28it/s] 30%|███       | 12/40 [00:03<00:08,  3.21it/s]                                               {'loss': 1.5163, 'grad_norm': 5.6268744468688965, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.21it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.0739, 'grad_norm': 5.493383884429932, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.0951, 'grad_norm': 5.4750142097473145, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.954, 'grad_norm': 6.011960983276367, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.2937, 'grad_norm': 10.7754545211792, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.73it/s]                                               {'loss': 0.149, 'grad_norm': 1.849724531173706, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.73it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.49it/s]                                               {'loss': 0.332, 'grad_norm': 3.2795071601867676, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.49it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s]                                               {'loss': 0.2754, 'grad_norm': 3.00563907623291, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.6048, 'grad_norm': 2.7909414768218994, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.6231, 'grad_norm': 5.711788177490234, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.2425, 'grad_norm': 3.8120944499969482, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.3215, 'grad_norm': 5.020110130310059, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 2.0007, 'grad_norm': 40.3643684387207, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s]                                               {'loss': 0.3685, 'grad_norm': 3.130509853363037, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s]                                               {'loss': 0.0427, 'grad_norm': 0.7611455917358398, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.1159, 'grad_norm': 2.3916540145874023, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.1664, 'grad_norm': 3.2144010066986084, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.396, 'grad_norm': 0.9522034525871277, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0399, 'grad_norm': 1.0511345863342285, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.2146, 'grad_norm': 5.39446496963501, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0509, 'grad_norm': 3.0342905521392822, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s]                                               {'loss': 0.0443, 'grad_norm': 0.9149009585380554, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.3709, 'grad_norm': 3.3507657051086426, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0499, 'grad_norm': 1.0988954305648804, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.0224, 'grad_norm': 0.5606464147567749, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.3521, 'grad_norm': 0.8877161741256714, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0493, 'grad_norm': 1.1736654043197632, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.053, 'grad_norm': 1.27459716796875, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0353, 'grad_norm': 2.5192949771881104, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.169, 'train_samples_per_second': 46.429, 'train_steps_per_second': 3.287, 'train_loss': 0.8366671519353985, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 4.0967, 'grad_norm': 5.561666488647461, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.0444, 'grad_norm': 5.169528961181641, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.6218, 'grad_norm': 6.773483753204346, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.8618, 'grad_norm': 7.200897693634033, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.6903, 'grad_norm': 10.382418632507324, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 3.3221, 'grad_norm': 11.30184268951416, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.5963, 'grad_norm': 14.02007007598877, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 7.6318, 'grad_norm': 48.569271087646484, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 1.2359, 'grad_norm': 9.462248802185059, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 1.4737, 'grad_norm': 9.148959159851074, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.4111, 'grad_norm': 9.280108451843262, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.0086, 'grad_norm': 8.69533634185791, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s]                                               {'loss': 0.8804, 'grad_norm': 5.612003326416016, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.5521, 'grad_norm': 7.47402811050415, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.15it/s]                                               {'loss': 1.3517, 'grad_norm': 7.2887983322143555, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.15it/s]                                               {'loss': 2.2668, 'grad_norm': 36.009151458740234, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.15it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 0.6035, 'grad_norm': 4.129009246826172, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.3833, 'grad_norm': 4.349663734436035, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.2992, 'grad_norm': 2.715365171432495, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.1517, 'grad_norm': 2.6868820190429688, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.5393, 'grad_norm': 8.875473022460938, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.7037, 'grad_norm': 9.029765129089355, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.2882, 'grad_norm': 5.101628303527832, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.4012, 'grad_norm': 20.165098190307617, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.1547, 'grad_norm': 2.1700682640075684, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.2614, 'grad_norm': 2.6084489822387695, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.1955, 'grad_norm': 3.1603755950927734, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.3668, 'grad_norm': 4.125909328460693, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.084, 'grad_norm': 1.5160526037216187, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.0778, 'grad_norm': 1.76761794090271, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.1575, 'grad_norm': 3.523434638977051, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0764, 'grad_norm': 7.455287933349609, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s]                                               {'loss': 0.0338, 'grad_norm': 0.869359016418457, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s]                                               {'loss': 0.0239, 'grad_norm': 0.6569429636001587, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.1434, 'grad_norm': 0.7809052467346191, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.0367, 'grad_norm': 0.9919061660766602, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.0469, 'grad_norm': 0.8968901038169861, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0603, 'grad_norm': 1.7129122018814087, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0913, 'grad_norm': 4.6426920890808105, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0261, 'grad_norm': 1.9017529487609863, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.0477, 'train_samples_per_second': 46.897, 'train_steps_per_second': 3.32, 'train_loss': 1.131304746400565, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:15
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 3.9644, 'grad_norm': 5.688267707824707, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.6982, 'grad_norm': 5.1161017417907715, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:11,  3.09it/s]                                              {'loss': 3.4959, 'grad_norm': 7.230370044708252, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.09it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.5967, 'grad_norm': 7.353598594665527, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.7181, 'grad_norm': 9.078736305236816, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.003, 'grad_norm': 11.693684577941895, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 2.6979, 'grad_norm': 11.339588165283203, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.7614, 'grad_norm': 24.292566299438477, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 1.4716, 'grad_norm': 8.16895580291748, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 1.2612, 'grad_norm': 8.246309280395508, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.6808, 'grad_norm': 7.95052433013916, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 1.215, 'grad_norm': 7.073549747467041, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 1.4315, 'grad_norm': 9.526174545288086, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.7264, 'grad_norm': 6.855140209197998, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.9616, 'grad_norm': 6.769958019256592, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.0772, 'grad_norm': 2.7457003593444824, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.12it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.7676, 'grad_norm': 3.6768510341644287, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.6015, 'grad_norm': 2.7005903720855713, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s]                                               {'loss': 0.4547, 'grad_norm': 5.550766468048096, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 1.0313, 'grad_norm': 4.90712833404541, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s]                                               {'loss': 0.3774, 'grad_norm': 3.8334734439849854, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.5581, 'grad_norm': 6.211009502410889, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.614, 'grad_norm': 8.226088523864746, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.5746, 'grad_norm': 18.384105682373047, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.2027, 'grad_norm': 3.848921775817871, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.7227, 'grad_norm': 2.002072334289551, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.0912, 'grad_norm': 1.6997097730636597, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.116, 'grad_norm': 3.1873507499694824, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.2636, 'grad_norm': 4.429340839385986, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0524, 'grad_norm': 2.796799659729004, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.4472, 'grad_norm': 3.2092926502227783, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.006, 'grad_norm': 0.3187101483345032, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.4316, 'grad_norm': 0.9734467267990112, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.3919, 'grad_norm': 0.8354405164718628, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0829, 'grad_norm': 1.8085224628448486, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.2345, 'grad_norm': 0.8803978562355042, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.0444, 'grad_norm': 1.26974618434906, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1085, 'grad_norm': 5.751467227935791, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.1939, 'grad_norm': 2.903434991836548, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0311, 'grad_norm': 3.0505149364471436, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1322, 'train_samples_per_second': 46.57, 'train_steps_per_second': 3.297, 'train_loss': 0.9790188104845583, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:38
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.07it/s]                                              {'loss': 3.8754, 'grad_norm': 5.991659641265869, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.07it/s]  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]                                              {'loss': 4.3831, 'grad_norm': 6.145843982696533, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 2.86, 'grad_norm': 7.386871814727783, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.072, 'grad_norm': 8.269169807434082, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 3.0792, 'grad_norm': 11.664056777954102, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.6896, 'grad_norm': 7.93368673324585, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 2.9105, 'grad_norm': 10.381387710571289, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.0599, 'grad_norm': 4.162520408630371, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 1.4035, 'grad_norm': 7.939202785491943, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 1.2012, 'grad_norm': 10.773611068725586, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.5355, 'grad_norm': 10.228002548217773, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 1.3302, 'grad_norm': 10.330265998840332, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s]                                               {'loss': 1.6124, 'grad_norm': 8.327838897705078, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.6968, 'grad_norm': 4.520569324493408, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 1.2372, 'grad_norm': 10.060965538024902, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.0662, 'grad_norm': 2.4730029106140137, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s]                                               {'loss': 0.9741, 'grad_norm': 3.9707813262939453, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.7579, 'grad_norm': 4.9375691413879395, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.4889, 'grad_norm': 5.098742485046387, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.6027, 'grad_norm': 4.361347675323486, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.4346, 'grad_norm': 3.87088680267334, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.7406, 'grad_norm': 4.789798736572266, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.3987, 'grad_norm': 4.162804126739502, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0017, 'grad_norm': 0.10995227098464966, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s]                                               {'loss': 0.205, 'grad_norm': 2.354238748550415, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.1031, 'grad_norm': 3.2684876918792725, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.1364, 'grad_norm': 3.407592296600342, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.0857, 'grad_norm': 2.163057804107666, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.3467, 'grad_norm': 4.3654351234436035, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.6653, 'grad_norm': 3.9530036449432373, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.1784, 'grad_norm': 2.535688877105713, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.2443, 'grad_norm': 10.018214225769043, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.1354, 'grad_norm': 6.2064385414123535, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.039, 'grad_norm': 0.7650965452194214, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.0943, 'grad_norm': 1.927076816558838, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.2301, 'grad_norm': 2.3111917972564697, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s]                                               {'loss': 0.0673, 'grad_norm': 1.056869626045227, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0448, 'grad_norm': 0.7673095464706421, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.4309, 'grad_norm': 0.5008310675621033, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.2233, 'grad_norm': 18.63030242919922, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.0605, 'train_samples_per_second': 46.847, 'train_steps_per_second': 3.317, 'train_loss': 0.9410414300247794, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:11
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 3.2046, 'grad_norm': 5.394166469573975, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]                                              {'loss': 3.3575, 'grad_norm': 6.122246265411377, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 4.1799, 'grad_norm': 8.065940856933594, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.2667, 'grad_norm': 7.003408908843994, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.1843, 'grad_norm': 9.679108619689941, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.2035, 'grad_norm': 11.608558654785156, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 3.7363, 'grad_norm': 11.50952434539795, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.2301, 'grad_norm': 11.850502014160156, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 1.1963, 'grad_norm': 7.028246879577637, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 1.0631, 'grad_norm': 7.1087822914123535, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.3789, 'grad_norm': 8.368449211120605, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.0521, 'grad_norm': 4.853035926818848, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.9125, 'grad_norm': 4.332677841186523, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.5167, 'grad_norm': 4.004626750946045, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.9194, 'grad_norm': 5.987842559814453, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.0612, 'grad_norm': 1.8905047178268433, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s]                                               {'loss': 0.6724, 'grad_norm': 2.715604066848755, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.3529, 'grad_norm': 3.4623610973358154, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.4828, 'grad_norm': 6.060720920562744, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.9648, 'grad_norm': 7.370912551879883, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.4791, 'grad_norm': 10.070045471191406, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.237, 'grad_norm': 4.224938869476318, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.2645, 'grad_norm': 2.538931369781494, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0039, 'grad_norm': 0.23031464219093323, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.8871, 'grad_norm': 1.6797889471054077, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s]                                               {'loss': 0.1391, 'grad_norm': 2.3644378185272217, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s]                                               {'loss': 0.1389, 'grad_norm': 2.577951192855835, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s] 70%|███████   | 28/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.057, 'grad_norm': 0.9411636590957642, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.23it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s]                                               {'loss': 0.0675, 'grad_norm': 1.1380239725112915, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.1023, 'grad_norm': 2.25014591217041, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.132, 'grad_norm': 4.7428436279296875, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.5837, 'grad_norm': 22.0423641204834, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s]                                               {'loss': 0.0666, 'grad_norm': 1.484144687652588, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.0252, 'grad_norm': 0.4793185889720917, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.1379, 'grad_norm': 0.5037608742713928, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.0661, 'grad_norm': 6.940622329711914, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.3176, 'grad_norm': 0.6183981895446777, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.422, 'grad_norm': 1.934956669807434, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0196, 'grad_norm': 0.38548216223716736, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0039, 'grad_norm': 0.16898126900196075, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.151, 'train_samples_per_second': 46.498, 'train_steps_per_second': 3.292, 'train_loss': 0.9271855859551579, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:40
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.7173, 'grad_norm': 5.576552867889404, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]                                              {'loss': 3.5679, 'grad_norm': 5.999777317047119, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]  8%|▊         | 3/40 [00:00<00:11,  3.12it/s]                                              {'loss': 3.2074, 'grad_norm': 5.957620620727539, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.12it/s] 10%|█         | 4/40 [00:01<00:11,  3.08it/s]                                              {'loss': 3.7141, 'grad_norm': 7.379587650299072, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.08it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.7879, 'grad_norm': 7.70576810836792, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.4064, 'grad_norm': 10.323196411132812, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.8917, 'grad_norm': 12.003030776977539, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 5.8715, 'grad_norm': 49.0395622253418, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s]                                              {'loss': 1.1596, 'grad_norm': 6.965737342834473, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 1.9801, 'grad_norm': 8.351807594299316, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.556, 'grad_norm': 11.882974624633789, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.6078, 'grad_norm': 11.73409366607666, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.5619, 'grad_norm': 9.170072555541992, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.988, 'grad_norm': 9.407784461975098, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.1127, 'grad_norm': 6.442448616027832, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.6689, 'grad_norm': 30.157203674316406, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 1.1223, 'grad_norm': 5.467564105987549, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.5385, 'grad_norm': 4.582578659057617, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.7391, 'grad_norm': 6.108700752258301, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.9854, 'grad_norm': 6.487416744232178, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.4484, 'grad_norm': 4.3880839347839355, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.5631, 'grad_norm': 4.169338226318359, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 1.1366, 'grad_norm': 6.701014518737793, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.256, 'grad_norm': 14.570963859558105, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.0822, 'grad_norm': 1.6299779415130615, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.6638, 'grad_norm': 8.872554779052734, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.5227, 'grad_norm': 4.0970845222473145, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.1717, 'grad_norm': 3.858283519744873, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.4003, 'grad_norm': 3.881351947784424, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0885, 'grad_norm': 1.6585144996643066, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.5546, 'grad_norm': 3.8549392223358154, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0074, 'grad_norm': 0.36226892471313477, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.1298, 'grad_norm': 2.823878288269043, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.2587, 'grad_norm': 7.300690650939941, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.45it/s]                                               {'loss': 0.7933, 'grad_norm': 2.459643602371216, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.45it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0711, 'grad_norm': 1.6677457094192505, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0788, 'grad_norm': 1.8926945924758911, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.2275, 'grad_norm': 1.9246017932891846, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0787, 'grad_norm': 2.9916281700134277, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.021, 'grad_norm': 1.0563514232635498, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0659, 'train_samples_per_second': 46.826, 'train_steps_per_second': 3.315, 'train_loss': 1.2184617243008689, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:45
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.7324, 'grad_norm': 5.67629861831665, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 3.5975, 'grad_norm': 5.809628963470459, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 3.0753, 'grad_norm': 7.972142696380615, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.5615, 'grad_norm': 9.29430103302002, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.7523, 'grad_norm': 9.659747123718262, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.5386, 'grad_norm': 9.774782180786133, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 3.3329, 'grad_norm': 10.551244735717773, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 0.5729, 'grad_norm': 20.871091842651367, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.05it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 1.2893, 'grad_norm': 6.9147186279296875, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 1.3672, 'grad_norm': 5.3680925369262695, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.8158, 'grad_norm': 4.519627571105957, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 2.0512, 'grad_norm': 6.973912715911865, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 1.0198, 'grad_norm': 4.590330600738525, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 1.7384, 'grad_norm': 4.923930644989014, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.0617, 'grad_norm': 4.88455867767334, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.9712, 'grad_norm': 16.15637969970703, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s]                                               {'loss': 0.3696, 'grad_norm': 2.8877737522125244, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s]                                               {'loss': 0.679, 'grad_norm': 2.7165262699127197, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.3754, 'grad_norm': 5.477653980255127, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.3388, 'grad_norm': 5.001194477081299, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.7462, 'grad_norm': 4.712126731872559, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.1867, 'grad_norm': 2.8399338722229004, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.7768, 'grad_norm': 6.369588851928711, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 1.1827, 'grad_norm': 28.203365325927734, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s]                                               {'loss': 0.0856, 'grad_norm': 1.1579627990722656, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.5553, 'grad_norm': 1.6093829870224, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.0678, 'grad_norm': 1.5731643438339233, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.0534, 'grad_norm': 1.2832632064819336, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1838, 'grad_norm': 4.173584938049316, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s]                                               {'loss': 0.5392, 'grad_norm': 2.7626707553863525, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.1802, 'grad_norm': 1.0026271343231201, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0005, 'grad_norm': 0.03765501081943512, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.1461, 'grad_norm': 0.45330435037612915, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.5076, 'grad_norm': 1.3576908111572266, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0209, 'grad_norm': 0.4659121632575989, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0336, 'grad_norm': 0.7332779765129089, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.4612, 'grad_norm': 2.41196870803833, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0281, 'grad_norm': 0.6919252276420593, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0249, 'grad_norm': 0.629277229309082, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0279, 'grad_norm': 1.4580345153808594, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.1021, 'train_samples_per_second': 46.686, 'train_steps_per_second': 3.305, 'train_loss': 1.0012364414709736, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:39
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 4.5146, 'grad_norm': 6.465250015258789, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.3505, 'grad_norm': 6.599939823150635, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:11,  3.10it/s]                                              {'loss': 3.3661, 'grad_norm': 6.419712543487549, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.10it/s] 10%|█         | 4/40 [00:01<00:11,  3.09it/s]                                              {'loss': 2.649, 'grad_norm': 6.837128162384033, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.09it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.08it/s]                                              {'loss': 1.9356, 'grad_norm': 7.782005786895752, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.08it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.4256, 'grad_norm': 10.463170051574707, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.1767, 'grad_norm': 6.934728622436523, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.3576, 'grad_norm': 48.662452697753906, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 2.1177, 'grad_norm': 8.46672534942627, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 1.2412, 'grad_norm': 7.748917579650879, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.5326, 'grad_norm': 8.33347225189209, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.8693, 'grad_norm': 4.912439346313477, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s]                                               {'loss': 1.1932, 'grad_norm': 3.830495595932007, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.7372, 'grad_norm': 3.631082773208618, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 1.0681, 'grad_norm': 3.5316736698150635, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 1.4745, 'grad_norm': 32.54815673828125, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.13it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.9535, 'grad_norm': 3.5162370204925537, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.62it/s]                                               {'loss': 0.5344, 'grad_norm': 4.11797571182251, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.62it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s]                                               {'loss': 0.4609, 'grad_norm': 3.6827309131622314, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.6478, 'grad_norm': 5.170609474182129, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.3807, 'grad_norm': 4.869510650634766, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.4317, 'grad_norm': 5.117537021636963, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.3457, 'grad_norm': 3.551548480987549, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0511, 'grad_norm': 3.505314826965332, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.70it/s]                                               {'loss': 0.2016, 'grad_norm': 4.329930782318115, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.70it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.50it/s]                                               {'loss': 0.5653, 'grad_norm': 2.493821382522583, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.50it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s]                                               {'loss': 0.0964, 'grad_norm': 2.066981792449951, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.2606, 'grad_norm': 2.076754570007324, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s]                                               {'loss': 0.126, 'grad_norm': 2.2076592445373535, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.1972, 'grad_norm': 3.3850018978118896, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.2913, 'grad_norm': 2.3176259994506836, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.1602, 'grad_norm': 4.358541965484619, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.679, 'grad_norm': 1.5362175703048706, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s]                                               {'loss': 0.181, 'grad_norm': 1.47780442237854, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.46it/s]                                               {'loss': 0.0962, 'grad_norm': 3.1855363845825195, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.46it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s]                                               {'loss': 0.0931, 'grad_norm': 5.441867828369141, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.0574, 'grad_norm': 1.1699508428573608, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.1174, 'grad_norm': 3.277165651321411, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0578, 'grad_norm': 2.975210189819336, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0384, 'grad_norm': 1.6271506547927856, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0673, 'train_samples_per_second': 46.821, 'train_steps_per_second': 3.315, 'train_loss': 1.0258609445765614, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:62
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 4.2698, 'grad_norm': 6.001679420471191, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.0787, 'grad_norm': 5.841487884521484, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  3.08it/s]                                              {'loss': 2.1214, 'grad_norm': 5.177845478057861, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.08it/s] 10%|█         | 4/40 [00:01<00:11,  3.07it/s]                                              {'loss': 2.8203, 'grad_norm': 8.875767707824707, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.07it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.5911, 'grad_norm': 10.288683891296387, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.07it/s]                                              {'loss': 2.3977, 'grad_norm': 8.381403923034668, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.07it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.7528, 'grad_norm': 9.658342361450195, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 3.8941, 'grad_norm': 36.38289260864258, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 0.9414, 'grad_norm': 7.127484321594238, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 1.2546, 'grad_norm': 8.000826835632324, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.1501, 'grad_norm': 6.73412561416626, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.29it/s]                                               {'loss': 1.5354, 'grad_norm': 9.057632446289062, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.29it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 1.0713, 'grad_norm': 5.612524509429932, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.7442, 'grad_norm': 4.588265895843506, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.7753, 'grad_norm': 7.633934497833252, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.4777, 'grad_norm': 1.0587186813354492, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.3276, 'grad_norm': 3.2809884548187256, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.7973, 'grad_norm': 8.11185359954834, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.2235, 'grad_norm': 2.565671443939209, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.3344, 'grad_norm': 3.9826910495758057, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.23, 'grad_norm': 2.5931899547576904, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.2644, 'grad_norm': 3.9147369861602783, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.3859, 'grad_norm': 6.049797534942627, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0939, 'grad_norm': 4.010810852050781, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.0862, 'grad_norm': 1.9397271871566772, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.0784, 'grad_norm': 1.3666783571243286, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.1519, 'grad_norm': 3.0462422370910645, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.0512, 'grad_norm': 1.145555019378662, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.0657, 'grad_norm': 1.1173810958862305, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.2312, 'grad_norm': 3.131847858428955, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.072, 'grad_norm': 1.2826569080352783, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.1726, 'grad_norm': 8.16973876953125, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.72it/s]                                               {'loss': 0.03, 'grad_norm': 0.7190142273902893, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.72it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s]                                               {'loss': 0.0339, 'grad_norm': 1.35740327835083, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s]                                               {'loss': 0.0364, 'grad_norm': 0.8152759075164795, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.20it/s]                                               {'loss': 0.0528, 'grad_norm': 1.5704272985458374, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.20it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0444, 'grad_norm': 1.5180665254592896, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0428, 'grad_norm': 1.166784644126892, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.07it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.1144, 'grad_norm': 1.3855046033859253, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0005, 'grad_norm': 0.031729936599731445, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.1641, 'train_samples_per_second': 46.448, 'train_steps_per_second': 3.288, 'train_loss': 0.8949353236908791, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:42, 10.91it/s]  1%|          | 4/471 [00:00<01:08,  6.85it/s]  1%|          | 5/471 [00:00<01:13,  6.33it/s]  1%|▏         | 6/471 [00:00<01:17,  6.01it/s]  1%|▏         | 7/471 [00:01<01:19,  5.82it/s]  2%|▏         | 8/471 [00:01<01:21,  5.68it/s]  2%|▏         | 9/471 [00:01<01:22,  5.60it/s]  2%|▏         | 10/471 [00:01<01:23,  5.55it/s]  2%|▏         | 11/471 [00:01<01:23,  5.50it/s]  3%|▎         | 12/471 [00:02<01:23,  5.46it/s]  3%|▎         | 13/471 [00:02<01:24,  5.43it/s]  3%|▎         | 14/471 [00:02<01:24,  5.43it/s]  3%|▎         | 15/471 [00:02<01:23,  5.43it/s]  3%|▎         | 16/471 [00:02<01:24,  5.41it/s]  4%|▎         | 17/471 [00:02<01:24,  5.40it/s]  4%|▍         | 18/471 [00:03<01:23,  5.41it/s]  4%|▍         | 19/471 [00:03<01:23,  5.40it/s]  4%|▍         | 20/471 [00:03<01:23,  5.39it/s]  4%|▍         | 21/471 [00:03<01:23,  5.39it/s]  5%|▍         | 22/471 [00:03<01:23,  5.38it/s]  5%|▍         | 23/471 [00:04<01:23,  5.39it/s]  5%|▌         | 24/471 [00:04<01:23,  5.37it/s]  5%|▌         | 25/471 [00:04<01:22,  5.38it/s]  6%|▌         | 26/471 [00:04<01:22,  5.38it/s]  6%|▌         | 27/471 [00:04<01:22,  5.37it/s]  6%|▌         | 28/471 [00:05<01:22,  5.38it/s]  6%|▌         | 29/471 [00:05<01:22,  5.37it/s]  6%|▋         | 30/471 [00:05<01:22,  5.36it/s]  7%|▋         | 31/471 [00:05<01:21,  5.38it/s]  7%|▋         | 32/471 [00:05<01:21,  5.39it/s]  7%|▋         | 33/471 [00:05<01:20,  5.42it/s]  7%|▋         | 34/471 [00:06<01:20,  5.43it/s]  7%|▋         | 35/471 [00:06<01:20,  5.39it/s]  8%|▊         | 36/471 [00:06<01:20,  5.40it/s]  8%|▊         | 37/471 [00:06<01:20,  5.38it/s]  8%|▊         | 38/471 [00:06<01:20,  5.37it/s]  8%|▊         | 39/471 [00:07<01:20,  5.37it/s]  8%|▊         | 40/471 [00:07<01:20,  5.37it/s]  9%|▊         | 41/471 [00:07<01:20,  5.37it/s]  9%|▉         | 42/471 [00:07<01:20,  5.36it/s]  9%|▉         | 43/471 [00:07<01:19,  5.36it/s]  9%|▉         | 44/471 [00:07<01:19,  5.37it/s] 10%|▉         | 45/471 [00:08<01:19,  5.37it/s] 10%|▉         | 46/471 [00:08<01:19,  5.36it/s] 10%|▉         | 47/471 [00:08<01:18,  5.37it/s] 10%|█         | 48/471 [00:08<01:18,  5.39it/s] 10%|█         | 49/471 [00:08<01:18,  5.37it/s] 11%|█         | 50/471 [00:09<01:18,  5.37it/s] 11%|█         | 51/471 [00:09<01:18,  5.36it/s] 11%|█         | 52/471 [00:09<01:18,  5.36it/s] 11%|█▏        | 53/471 [00:09<01:18,  5.35it/s] 11%|█▏        | 54/471 [00:09<01:17,  5.35it/s] 12%|█▏        | 55/471 [00:10<01:17,  5.35it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.33it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.34it/s] 12%|█▏        | 58/471 [00:10<01:17,  5.35it/s] 13%|█▎        | 59/471 [00:10<01:17,  5.34it/s] 13%|█▎        | 60/471 [00:10<01:16,  5.35it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.35it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.35it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.34it/s] 14%|█▎        | 64/471 [00:11<01:16,  5.33it/s] 14%|█▍        | 65/471 [00:11<01:16,  5.34it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.35it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.33it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.33it/s] 15%|█▍        | 69/471 [00:12<01:15,  5.34it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.33it/s] 15%|█▌        | 71/471 [00:13<01:15,  5.33it/s] 15%|█▌        | 72/471 [00:13<01:14,  5.32it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.33it/s] 16%|█▌        | 74/471 [00:13<01:14,  5.35it/s] 16%|█▌        | 75/471 [00:13<01:14,  5.33it/s] 16%|█▌        | 76/471 [00:13<01:13,  5.34it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.34it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.34it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.31it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.31it/s] 17%|█▋        | 81/471 [00:14<01:12,  5.35it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.35it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.35it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.34it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 86/471 [00:15<01:12,  5.34it/s] 18%|█▊        | 87/471 [00:16<01:11,  5.35it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.37it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.36it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.35it/s] 19%|█▉        | 91/471 [00:16<01:10,  5.37it/s] 20%|█▉        | 92/471 [00:16<01:10,  5.36it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.34it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.36it/s] 20%|██        | 95/471 [00:17<01:10,  5.37it/s] 20%|██        | 96/471 [00:17<01:09,  5.37it/s] 21%|██        | 97/471 [00:17<01:09,  5.34it/s] 21%|██        | 98/471 [00:18<01:09,  5.35it/s] 21%|██        | 99/471 [00:18<01:09,  5.35it/s] 21%|██        | 100/471 [00:18<01:09,  5.37it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.38it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.36it/s] 22%|██▏       | 103/471 [00:19<01:08,  5.35it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.34it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.32it/s] 23%|██▎       | 106/471 [00:19<01:08,  5.35it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.36it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.36it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.36it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.37it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.35it/s] 24%|██▍       | 112/471 [00:20<01:07,  5.34it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.36it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.36it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.35it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.33it/s] 25%|██▌       | 118/471 [00:21<01:06,  5.33it/s] 25%|██▌       | 119/471 [00:22<01:06,  5.32it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.33it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.33it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.32it/s] 26%|██▌       | 123/471 [00:22<01:05,  5.32it/s] 26%|██▋       | 124/471 [00:22<01:05,  5.32it/s] 27%|██▋       | 125/471 [00:23<01:05,  5.32it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.32it/s] 27%|██▋       | 129/471 [00:23<01:04,  5.32it/s] 28%|██▊       | 130/471 [00:24<01:03,  5.34it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.31it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.32it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.32it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.31it/s] 29%|██▊       | 135/471 [00:25<01:03,  5.32it/s] 29%|██▉       | 136/471 [00:25<01:02,  5.32it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.32it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.30it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.32it/s] 30%|██▉       | 140/471 [00:25<01:02,  5.33it/s] 30%|██▉       | 141/471 [00:26<01:01,  5.34it/s] 30%|███       | 142/471 [00:26<01:01,  5.32it/s] 30%|███       | 143/471 [00:26<01:01,  5.32it/s] 31%|███       | 144/471 [00:26<01:01,  5.32it/s] 31%|███       | 145/471 [00:26<01:00,  5.35it/s] 31%|███       | 146/471 [00:27<01:00,  5.33it/s] 31%|███       | 147/471 [00:27<01:00,  5.32it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.32it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.31it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.31it/s] 32%|███▏      | 151/471 [00:28<01:00,  5.30it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.30it/s] 32%|███▏      | 153/471 [00:28<01:00,  5.29it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.33it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.34it/s] 33%|███▎      | 156/471 [00:28<00:59,  5.34it/s] 33%|███▎      | 157/471 [00:29<00:58,  5.33it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.33it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.34it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.34it/s] 34%|███▍      | 161/471 [00:29<00:58,  5.33it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.30it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.28it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.30it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.31it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.31it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.30it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.29it/s] 36%|███▌      | 169/471 [00:31<00:57,  5.28it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.31it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.31it/s] 37%|███▋      | 172/471 [00:31<00:56,  5.31it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.31it/s] 37%|███▋      | 174/471 [00:32<00:55,  5.33it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.31it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.31it/s] 38%|███▊      | 177/471 [00:32<00:55,  5.31it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.30it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.31it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.30it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.30it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.30it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.30it/s] 39%|███▉      | 184/471 [00:34<00:54,  5.31it/s] 39%|███▉      | 185/471 [00:34<00:54,  5.29it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.29it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.29it/s] 40%|███▉      | 188/471 [00:34<00:53,  5.29it/s] 40%|████      | 189/471 [00:35<00:53,  5.30it/s] 40%|████      | 190/471 [00:35<00:53,  5.30it/s] 41%|████      | 191/471 [00:35<00:53,  5.28it/s] 41%|████      | 192/471 [00:35<00:52,  5.29it/s] 41%|████      | 193/471 [00:35<00:52,  5.32it/s] 41%|████      | 194/471 [00:36<00:52,  5.31it/s] 41%|████▏     | 195/471 [00:36<00:52,  5.28it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.29it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 198/471 [00:36<00:51,  5.31it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.30it/s] 42%|████▏     | 200/471 [00:37<00:51,  5.29it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.30it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.29it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.29it/s] 43%|████▎     | 204/471 [00:38<00:50,  5.28it/s] 44%|████▎     | 205/471 [00:38<00:50,  5.29it/s] 44%|████▎     | 206/471 [00:38<00:50,  5.29it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.29it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.32it/s] 44%|████▍     | 209/471 [00:38<00:49,  5.32it/s] 45%|████▍     | 210/471 [00:39<00:49,  5.31it/s] 45%|████▍     | 211/471 [00:39<00:49,  5.31it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.31it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.30it/s] 45%|████▌     | 214/471 [00:39<00:48,  5.30it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.30it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.29it/s] 46%|████▌     | 217/471 [00:40<00:48,  5.27it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.28it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.28it/s] 47%|████▋     | 220/471 [00:41<00:47,  5.27it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.27it/s] 47%|████▋     | 222/471 [00:41<00:47,  5.29it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.30it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.29it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.29it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.28it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.28it/s] 48%|████▊     | 228/471 [00:42<00:46,  5.27it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.27it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.27it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.27it/s] 49%|████▉     | 232/471 [00:43<00:45,  5.30it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.30it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.29it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.27it/s] 50%|█████     | 236/471 [00:44<00:44,  5.29it/s] 50%|█████     | 237/471 [00:44<00:44,  5.28it/s] 51%|█████     | 238/471 [00:44<00:44,  5.28it/s] 51%|█████     | 239/471 [00:44<00:43,  5.29it/s] 51%|█████     | 240/471 [00:44<00:43,  5.29it/s] 51%|█████     | 241/471 [00:45<00:43,  5.27it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.27it/s] 52%|█████▏    | 243/471 [00:45<00:43,  5.26it/s] 52%|█████▏    | 244/471 [00:45<00:43,  5.26it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.26it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.28it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.30it/s] 53%|█████▎    | 248/471 [00:46<00:42,  5.29it/s] 53%|█████▎    | 249/471 [00:46<00:42,  5.28it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.28it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.28it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.29it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.28it/s] 54%|█████▍    | 254/471 [00:47<00:41,  5.27it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.28it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.28it/s] 55%|█████▍    | 257/471 [00:48<00:40,  5.26it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.29it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.27it/s] 55%|█████▌    | 260/471 [00:48<00:40,  5.26it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.26it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.28it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.27it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.27it/s] 56%|█████▋    | 265/471 [00:49<00:39,  5.26it/s] 56%|█████▋    | 266/471 [00:49<00:39,  5.25it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.26it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.26it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.26it/s] 57%|█████▋    | 270/471 [00:50<00:38,  5.26it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.27it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.28it/s] 58%|█████▊    | 273/471 [00:51<00:37,  5.28it/s] 58%|█████▊    | 274/471 [00:51<00:37,  5.29it/s] 58%|█████▊    | 275/471 [00:51<00:37,  5.30it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.28it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.27it/s] 59%|█████▉    | 278/471 [00:52<00:36,  5.25it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.28it/s] 59%|█████▉    | 280/471 [00:52<00:36,  5.27it/s] 60%|█████▉    | 281/471 [00:52<00:36,  5.27it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.27it/s] 60%|██████    | 283/471 [00:52<00:35,  5.26it/s] 60%|██████    | 284/471 [00:53<00:35,  5.26it/s] 61%|██████    | 285/471 [00:53<00:35,  5.24it/s] 61%|██████    | 286/471 [00:53<00:35,  5.25it/s] 61%|██████    | 287/471 [00:53<00:35,  5.26it/s] 61%|██████    | 288/471 [00:53<00:34,  5.25it/s] 61%|██████▏   | 289/471 [00:54<00:34,  5.27it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.26it/s] 62%|██████▏   | 291/471 [00:54<00:34,  5.27it/s] 62%|██████▏   | 292/471 [00:54<00:34,  5.26it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.28it/s] 62%|██████▏   | 294/471 [00:55<00:33,  5.27it/s] 63%|██████▎   | 295/471 [00:55<00:33,  5.27it/s] 63%|██████▎   | 296/471 [00:55<00:33,  5.27it/s] 63%|██████▎   | 297/471 [00:55<00:33,  5.27it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.27it/s] 63%|██████▎   | 299/471 [00:56<00:32,  5.26it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.26it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.24it/s] 64%|██████▍   | 302/471 [00:56<00:32,  5.26it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.27it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.28it/s] 65%|██████▍   | 305/471 [00:57<00:31,  5.26it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.26it/s] 65%|██████▌   | 307/471 [00:57<00:31,  5.25it/s] 65%|██████▌   | 308/471 [00:57<00:31,  5.25it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.25it/s] 66%|██████▌   | 310/471 [00:58<00:30,  5.26it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.26it/s] 66%|██████▌   | 312/471 [00:58<00:30,  5.26it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.28it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.28it/s] 67%|██████▋   | 315/471 [00:59<00:29,  5.27it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.28it/s] 67%|██████▋   | 317/471 [00:59<00:29,  5.28it/s] 68%|██████▊   | 318/471 [00:59<00:29,  5.27it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.26it/s] 68%|██████▊   | 320/471 [01:00<00:28,  5.26it/s] 68%|██████▊   | 321/471 [01:00<00:28,  5.25it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.26it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.24it/s] 69%|██████▉   | 324/471 [01:00<00:28,  5.24it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.25it/s] 69%|██████▉   | 326/471 [01:01<00:27,  5.25it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.27it/s] 70%|██████▉   | 328/471 [01:01<00:27,  5.26it/s] 70%|██████▉   | 329/471 [01:01<00:27,  5.25it/s] 70%|███████   | 330/471 [01:01<00:26,  5.28it/s] 70%|███████   | 331/471 [01:02<00:26,  5.28it/s] 70%|███████   | 332/471 [01:02<00:26,  5.27it/s] 71%|███████   | 333/471 [01:02<00:26,  5.28it/s] 71%|███████   | 334/471 [01:02<00:26,  5.26it/s] 71%|███████   | 335/471 [01:02<00:25,  5.26it/s] 71%|███████▏  | 336/471 [01:03<00:25,  5.27it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.29it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.28it/s] 72%|███████▏  | 339/471 [01:03<00:25,  5.26it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.27it/s] 72%|███████▏  | 341/471 [01:04<00:24,  5.26it/s] 73%|███████▎  | 342/471 [01:04<00:24,  5.27it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.26it/s] 73%|███████▎  | 344/471 [01:04<00:24,  5.27it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.26it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.25it/s] 74%|███████▎  | 347/471 [01:05<00:23,  5.26it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.27it/s] 74%|███████▍  | 349/471 [01:05<00:23,  5.26it/s] 74%|███████▍  | 350/471 [01:05<00:23,  5.26it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.29it/s] 75%|███████▍  | 352/471 [01:06<00:22,  5.27it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.25it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.26it/s] 75%|███████▌  | 355/471 [01:06<00:22,  5.25it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.27it/s] 76%|███████▌  | 357/471 [01:07<00:21,  5.26it/s] 76%|███████▌  | 358/471 [01:07<00:21,  5.28it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.26it/s] 76%|███████▋  | 360/471 [01:07<00:21,  5.26it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.27it/s] 77%|███████▋  | 362/471 [01:07<00:20,  5.27it/s] 77%|███████▋  | 363/471 [01:08<00:20,  5.27it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.27it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.26it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.25it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.26it/s] 78%|███████▊  | 368/471 [01:09<00:19,  5.26it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.26it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.25it/s] 79%|███████▉  | 371/471 [01:09<00:19,  5.25it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.25it/s] 79%|███████▉  | 373/471 [01:10<00:18,  5.25it/s] 79%|███████▉  | 374/471 [01:10<00:18,  5.27it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.27it/s] 80%|███████▉  | 376/471 [01:10<00:18,  5.26it/s] 80%|████████  | 377/471 [01:10<00:17,  5.27it/s] 80%|████████  | 378/471 [01:11<00:17,  5.29it/s] 80%|████████  | 379/471 [01:11<00:17,  5.28it/s] 81%|████████  | 380/471 [01:11<00:17,  5.26it/s] 81%|████████  | 381/471 [01:11<00:17,  5.26it/s] 81%|████████  | 382/471 [01:11<00:16,  5.26it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.27it/s] 82%|████████▏ | 384/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.24it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.24it/s] 82%|████████▏ | 387/471 [01:12<00:16,  5.23it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.24it/s] 83%|████████▎ | 389/471 [01:13<00:15,  5.26it/s] 83%|████████▎ | 390/471 [01:13<00:15,  5.25it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.24it/s] 83%|████████▎ | 392/471 [01:13<00:15,  5.24it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.26it/s] 84%|████████▎ | 394/471 [01:14<00:14,  5.25it/s] 84%|████████▍ | 395/471 [01:14<00:14,  5.25it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.24it/s] 84%|████████▍ | 397/471 [01:14<00:14,  5.26it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.25it/s] 85%|████████▍ | 399/471 [01:15<00:13,  5.25it/s] 85%|████████▍ | 400/471 [01:15<00:13,  5.25it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.25it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.25it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.25it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.26it/s] 86%|████████▌ | 405/471 [01:16<00:12,  5.25it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.25it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.27it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.26it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.26it/s] 87%|████████▋ | 410/471 [01:17<00:11,  5.28it/s] 87%|████████▋ | 411/471 [01:17<00:11,  5.29it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.28it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.28it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.28it/s] 88%|████████▊ | 415/471 [01:18<00:10,  5.27it/s] 88%|████████▊ | 416/471 [01:18<00:10,  5.25it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.28it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.25it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.28it/s] 89%|████████▉ | 420/471 [01:19<00:09,  5.29it/s] 89%|████████▉ | 421/471 [01:19<00:09,  5.28it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.29it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.29it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.28it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.29it/s] 90%|█████████ | 426/471 [01:20<00:08,  5.28it/s] 91%|█████████ | 427/471 [01:20<00:08,  5.27it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.27it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.26it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.26it/s] 92%|█████████▏| 431/471 [01:21<00:07,  5.25it/s] 92%|█████████▏| 432/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 434/471 [01:21<00:07,  5.25it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.25it/s] 93%|█████████▎| 436/471 [01:22<00:06,  5.26it/s] 93%|█████████▎| 437/471 [01:22<00:06,  5.25it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.25it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.26it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.27it/s] 94%|█████████▎| 441/471 [01:23<00:05,  5.28it/s] 94%|█████████▍| 442/471 [01:23<00:05,  5.28it/s] 94%|█████████▍| 443/471 [01:23<00:05,  5.27it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.25it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.25it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.24it/s] 95%|█████████▍| 447/471 [01:24<00:04,  5.26it/s] 95%|█████████▌| 448/471 [01:24<00:04,  5.26it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.26it/s] 96%|█████████▌| 450/471 [01:24<00:04,  5.24it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.24it/s] 96%|█████████▌| 452/471 [01:25<00:03,  5.25it/s] 96%|█████████▌| 453/471 [01:25<00:03,  5.25it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.25it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.23it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.23it/s] 97%|█████████▋| 457/471 [01:26<00:02,  5.23it/s] 97%|█████████▋| 458/471 [01:26<00:02,  5.25it/s] 97%|█████████▋| 459/471 [01:26<00:02,  5.27it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.26it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.24it/s] 98%|█████████▊| 462/471 [01:27<00:01,  5.24it/s] 98%|█████████▊| 463/471 [01:27<00:01,  5.26it/s] 99%|█████████▊| 464/471 [01:27<00:01,  5.27it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.27it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.25it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.25it/s] 99%|█████████▉| 468/471 [01:28<00:00,  5.24it/s]100%|█████████▉| 469/471 [01:28<00:00,  5.24it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.26it/s]100%|██████████| 471/471 [01:28<00:00,  5.62it/s]100%|██████████| 471/471 [01:28<00:00,  5.31it/s]
{'eval_loss': 3.740525007247925, 'eval_model_preparation_time': 0.005, 'eval_acc': 0.17671269251194902, 'eval_runtime': 88.8515, 'eval_samples_per_second': 84.771, 'eval_steps_per_second': 5.301}
ROUND:6
CLIENT:69
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]                                              {'loss': 3.7715, 'grad_norm': 5.356387138366699, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 2.9748, 'grad_norm': 7.123004913330078, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 2.9492, 'grad_norm': 7.814269065856934, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:12,  2.98it/s]                                              {'loss': 2.4579, 'grad_norm': 9.016593933105469, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.98it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.95it/s]                                              {'loss': 1.3453, 'grad_norm': 9.0920991897583, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.95it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.95it/s]                                              {'loss': 2.3596, 'grad_norm': 10.083910942077637, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.95it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 1.8742, 'grad_norm': 11.821511268615723, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 0.5682, 'grad_norm': 32.063323974609375, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.95it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.70it/s]                                              {'loss': 1.0283, 'grad_norm': 7.50971794128418, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.70it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.48it/s]                                               {'loss': 1.3137, 'grad_norm': 10.237957000732422, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.48it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s]                                               {'loss': 1.9327, 'grad_norm': 15.329349517822266, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s] 30%|███       | 12/40 [00:03<00:08,  3.21it/s]                                               {'loss': 0.9206, 'grad_norm': 6.556292533874512, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.21it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.6497, 'grad_norm': 5.05934476852417, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.12it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.3612, 'grad_norm': 3.4481778144836426, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.07it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.9729, 'grad_norm': 5.0954084396362305, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.4961, 'grad_norm': 10.446702003479004, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.75it/s]                                               {'loss': 0.7838, 'grad_norm': 3.974822998046875, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.75it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.1642, 'grad_norm': 1.9998064041137695, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s]                                               {'loss': 0.7456, 'grad_norm': 4.645287036895752, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.2148, 'grad_norm': 2.5092320442199707, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.3293, 'grad_norm': 5.1263909339904785, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.398, 'grad_norm': 4.435671329498291, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.606, 'grad_norm': 6.41874885559082, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.0434, 'grad_norm': 2.171588897705078, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.04it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s]                                               {'loss': 0.1461, 'grad_norm': 4.478200435638428, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s]                                               {'loss': 0.0763, 'grad_norm': 1.8068797588348389, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.3032, 'grad_norm': 2.9140737056732178, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.0468, 'grad_norm': 0.9068077206611633, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.21it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.14it/s]                                               {'loss': 0.1131, 'grad_norm': 2.7878260612487793, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.14it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.1803, 'grad_norm': 3.4893851280212402, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.152, 'grad_norm': 2.6123862266540527, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.0145, 'grad_norm': 0.9124771356582642, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.74it/s]                                               {'loss': 0.0385, 'grad_norm': 0.832982063293457, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.74it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s]                                               {'loss': 0.0298, 'grad_norm': 0.6402987837791443, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0356, 'grad_norm': 0.8756753206253052, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.21it/s]                                               {'loss': 0.0669, 'grad_norm': 1.8330997228622437, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.21it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0327, 'grad_norm': 0.8479134440422058, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.2221, 'grad_norm': 1.3869922161102295, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.06it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.02it/s]                                               {'loss': 0.1352, 'grad_norm': 4.107711315155029, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.02it/s]                                               {'loss': 0.0042, 'grad_norm': 0.2744690477848053, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.02it/s]                                               {'train_runtime': 12.3806, 'train_samples_per_second': 45.636, 'train_steps_per_second': 3.231, 'train_loss': 0.7714521638816223, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.02it/s]100%|██████████| 40/40 [00:12<00:00,  3.23it/s]
CLIENT:74
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.21it/s]                                              {'loss': 5.0781, 'grad_norm': 6.273964881896973, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.21it/s]  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]                                              {'loss': 2.985, 'grad_norm': 6.161732196807861, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 2.9357, 'grad_norm': 7.774724960327148, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.4388, 'grad_norm': 7.0861592292785645, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.0017, 'grad_norm': 9.156550407409668, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.2126, 'grad_norm': 12.735173225402832, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 2.5213, 'grad_norm': 9.608230590820312, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 2.4557, 'grad_norm': 34.92242431640625, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 1.8344, 'grad_norm': 11.83662223815918, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 1.0351, 'grad_norm': 6.259662628173828, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.2119, 'grad_norm': 8.851268768310547, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 1.2641, 'grad_norm': 6.129505634307861, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 0.913, 'grad_norm': 6.052964210510254, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.4036, 'grad_norm': 6.590782165527344, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.17it/s]                                               {'loss': 1.9806, 'grad_norm': 6.970828533172607, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.17it/s]                                               {'loss': 2.4239, 'grad_norm': 21.685558319091797, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.17it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.92it/s]                                               {'loss': 0.4918, 'grad_norm': 5.9386796951293945, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.92it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.66it/s]                                               {'loss': 0.4968, 'grad_norm': 2.641172170639038, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.66it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.46it/s]                                               {'loss': 0.4867, 'grad_norm': 3.5187504291534424, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.46it/s] 50%|█████     | 20/40 [00:06<00:06,  3.33it/s]                                               {'loss': 0.6532, 'grad_norm': 5.6084418296813965, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.33it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s]                                               {'loss': 0.8427, 'grad_norm': 5.4772162437438965, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.5608, 'grad_norm': 3.8599302768707275, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.7522, 'grad_norm': 3.6924853324890137, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.0432, 'grad_norm': 2.1060032844543457, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.13it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s]                                               {'loss': 0.1182, 'grad_norm': 2.402949094772339, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s]                                               {'loss': 0.2223, 'grad_norm': 1.7113182544708252, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s]                                               {'loss': 0.1073, 'grad_norm': 1.600698709487915, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.2274, 'grad_norm': 3.9351816177368164, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.4937, 'grad_norm': 1.0320733785629272, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s]                                               {'loss': 0.7649, 'grad_norm': 4.598209857940674, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.46, 'grad_norm': 2.7670798301696777, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.039, 'grad_norm': 1.6516344547271729, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.89it/s]                                               {'loss': 0.371, 'grad_norm': 0.9660630226135254, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.89it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.63it/s]                                               {'loss': 0.2446, 'grad_norm': 2.3752496242523193, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.63it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.46it/s]                                               {'loss': 0.2747, 'grad_norm': 2.5728588104248047, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.46it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0989, 'grad_norm': 7.100279808044434, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.4579, 'grad_norm': 0.9254640340805054, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.4543, 'grad_norm': 0.8365070223808289, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.1341, 'grad_norm': 8.958367347717285, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0178, 'grad_norm': 0.9464184045791626, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0909, 'train_samples_per_second': 46.729, 'train_steps_per_second': 3.308, 'train_loss': 1.13773452793248, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:34
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]                                              {'loss': 3.8721, 'grad_norm': 6.889714241027832, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]                                              {'loss': 2.8495, 'grad_norm': 7.139438152313232, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.2689, 'grad_norm': 9.326409339904785, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.1086, 'grad_norm': 11.308222770690918, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.7679, 'grad_norm': 13.495476722717285, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s]                                              {'loss': 1.6262, 'grad_norm': 8.607338905334473, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 1.5736, 'grad_norm': 8.583558082580566, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 2.4423, 'grad_norm': 64.2287826538086, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.98it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s]                                              {'loss': 0.71, 'grad_norm': 4.539533615112305, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 0.7259, 'grad_norm': 7.563445568084717, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 0.8425, 'grad_norm': 5.3968658447265625, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.1382, 'grad_norm': 11.448753356933594, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.1695, 'grad_norm': 7.652695655822754, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.6888, 'grad_norm': 7.4708333015441895, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.4163, 'grad_norm': 3.928605079650879, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 2.3328, 'grad_norm': 44.59527587890625, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 0.0679, 'grad_norm': 1.0824154615402222, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.4087, 'grad_norm': 3.184609889984131, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.3808, 'grad_norm': 3.4676778316497803, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.2371, 'grad_norm': 3.0529606342315674, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.5122, 'grad_norm': 6.455113887786865, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.1173, 'grad_norm': 3.2093615531921387, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.3278, 'grad_norm': 5.037970542907715, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0944, 'grad_norm': 4.868386268615723, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.04, 'grad_norm': 0.7985233068466187, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.0606, 'grad_norm': 1.1140424013137817, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.1963, 'grad_norm': 3.488508462905884, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.0893, 'grad_norm': 2.258099317550659, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.3954, 'grad_norm': 5.298990249633789, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.0487, 'grad_norm': 1.078729271888733, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0825, 'grad_norm': 1.6074779033660889, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0999, 'grad_norm': 5.525561332702637, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0248, 'grad_norm': 0.5855017900466919, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.0213, 'grad_norm': 0.4320400059223175, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.1442, 'grad_norm': 0.4959941804409027, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.1047, 'grad_norm': 3.138037919998169, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0625, 'grad_norm': 1.387543797492981, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1661, 'grad_norm': 5.405984401702881, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0355, 'grad_norm': 1.3182501792907715, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0227, 'grad_norm': 1.562538743019104, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.2009, 'train_samples_per_second': 46.308, 'train_steps_per_second': 3.278, 'train_loss': 0.806849388545379, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:68
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 2.8358, 'grad_norm': 5.856238842010498, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 3.2022, 'grad_norm': 6.1260666847229, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:01<00:12,  3.00it/s]                                              {'loss': 2.4759, 'grad_norm': 8.005118370056152, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  3.00it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.0453, 'grad_norm': 9.974964141845703, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.1815, 'grad_norm': 12.114542961120605, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.0593, 'grad_norm': 14.26968765258789, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 2.0382, 'grad_norm': 14.184226989746094, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 0.602, 'grad_norm': 26.75530433654785, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.06it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 0.8569, 'grad_norm': 10.01052188873291, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 0.7427, 'grad_norm': 6.792372703552246, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 1.0204, 'grad_norm': 8.204391479492188, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 1.4573, 'grad_norm': 8.567355155944824, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.26it/s]                                               {'loss': 0.76, 'grad_norm': 7.8461079597473145, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.26it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.8566, 'grad_norm': 6.7689642906188965, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.5103, 'grad_norm': 4.466859340667725, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 1.3924, 'grad_norm': 33.421905517578125, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s]                                               {'loss': 0.3868, 'grad_norm': 3.506124258041382, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.7336, 'grad_norm': 7.623107433319092, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.334, 'grad_norm': 4.999567985534668, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.3568, 'grad_norm': 3.872168779373169, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.3825, 'grad_norm': 5.049539566040039, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.7658, 'grad_norm': 6.24457311630249, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.4374, 'grad_norm': 9.206591606140137, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 1.1652, 'grad_norm': 49.24481964111328, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.1118, 'grad_norm': 5.4079437255859375, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s]                                               {'loss': 0.0883, 'grad_norm': 1.4926306009292603, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.18, 'grad_norm': 3.02093505859375, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.5047, 'grad_norm': 2.2163312435150146, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.1222, 'grad_norm': 1.8595772981643677, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.1263, 'grad_norm': 2.6483967304229736, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.2566, 'grad_norm': 6.8174285888671875, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.023, 'grad_norm': 1.5954116582870483, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.1033, 'grad_norm': 2.589512348175049, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.0568, 'grad_norm': 1.4072563648223877, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.0991, 'grad_norm': 2.7997853755950928, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.0776, 'grad_norm': 1.8125616312026978, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0975, 'grad_norm': 1.9722881317138672, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.185, 'grad_norm': 4.351302146911621, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.5545, 'grad_norm': 2.8668577671051025, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0321, 'grad_norm': 1.5521835088729858, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.1257, 'train_samples_per_second': 46.595, 'train_steps_per_second': 3.299, 'train_loss': 0.8554389400873333, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 3.2845, 'grad_norm': 6.251343727111816, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.79, 'grad_norm': 8.165360450744629, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.5829, 'grad_norm': 7.913745880126953, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.3731, 'grad_norm': 7.708411693572998, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.3201, 'grad_norm': 9.363017082214355, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.0258, 'grad_norm': 10.333805084228516, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 2.3575, 'grad_norm': 11.202512741088867, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.0169, 'grad_norm': 31.820466995239258, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s]                                              {'loss': 1.7164, 'grad_norm': 17.43842315673828, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.63it/s]                                               {'loss': 1.8155, 'grad_norm': 13.486336708068848, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.63it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.47it/s]                                               {'loss': 1.5082, 'grad_norm': 6.6574015617370605, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.47it/s] 30%|███       | 12/40 [00:03<00:08,  3.32it/s]                                               {'loss': 0.4439, 'grad_norm': 4.913727283477783, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.32it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s]                                               {'loss': 0.9781, 'grad_norm': 6.210158824920654, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.7596, 'grad_norm': 6.591904163360596, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 1.0381, 'grad_norm': 6.512787342071533, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 0.2387, 'grad_norm': 7.62532377243042, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.13it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s]                                               {'loss': 0.4456, 'grad_norm': 3.1246891021728516, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s]                                               {'loss': 0.2927, 'grad_norm': 3.6358814239501953, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.46it/s]                                               {'loss': 0.2203, 'grad_norm': 2.3641297817230225, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.46it/s] 50%|█████     | 20/40 [00:06<00:06,  3.33it/s]                                               {'loss': 0.7215, 'grad_norm': 3.728635787963867, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.33it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s]                                               {'loss': 0.4963, 'grad_norm': 2.981055736541748, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.6712, 'grad_norm': 6.645719051361084, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.568, 'grad_norm': 7.2274065017700195, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0705, 'grad_norm': 3.498520612716675, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.1923, 'grad_norm': 4.6086931228637695, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s]                                               {'loss': 0.7804, 'grad_norm': 1.4610521793365479, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s]                                               {'loss': 0.205, 'grad_norm': 3.619108200073242, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.0779, 'grad_norm': 1.6290401220321655, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.0265, 'grad_norm': 0.7695087194442749, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.1815, 'grad_norm': 2.732621908187866, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.1671, 'grad_norm': 5.75944185256958, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.035, 'grad_norm': 1.9052821397781372, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.70it/s]                                               {'loss': 0.0254, 'grad_norm': 0.5083003640174866, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.70it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s]                                               {'loss': 0.0099, 'grad_norm': 0.2579217553138733, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0725, 'grad_norm': 1.9502978324890137, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.3577, 'grad_norm': 1.828032374382019, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.1003, 'grad_norm': 2.793294906616211, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.4429, 'grad_norm': 1.7186827659606934, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.1173, 'grad_norm': 2.273951768875122, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.002, 'grad_norm': 0.1293783187866211, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.0598, 'train_samples_per_second': 46.85, 'train_steps_per_second': 3.317, 'train_loss': 0.8632334232563152, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:0
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]                                              {'loss': 3.7223, 'grad_norm': 5.8214945793151855, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]                                              {'loss': 3.8402, 'grad_norm': 6.7938055992126465, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]  8%|▊         | 3/40 [00:00<00:11,  3.14it/s]                                              {'loss': 2.7441, 'grad_norm': 8.811376571655273, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.14it/s] 10%|█         | 4/40 [00:01<00:11,  3.10it/s]                                              {'loss': 2.6923, 'grad_norm': 8.742860794067383, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.10it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.08it/s]                                              {'loss': 1.9387, 'grad_norm': 8.690550804138184, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.08it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.3653, 'grad_norm': 12.091741561889648, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 1.4694, 'grad_norm': 8.667635917663574, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 0.0137, 'grad_norm': 0.8304513096809387, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.06it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s]                                              {'loss': 1.3125, 'grad_norm': 7.9431538581848145, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.58it/s]                                               {'loss': 1.1494, 'grad_norm': 11.257359504699707, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.58it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s]                                               {'loss': 0.9954, 'grad_norm': 9.902976989746094, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s] 30%|███       | 12/40 [00:03<00:08,  3.36it/s]                                               {'loss': 0.7519, 'grad_norm': 8.512613296508789, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.36it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.7152, 'grad_norm': 4.741279602050781, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.25it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.8611, 'grad_norm': 6.156717777252197, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 1.2469, 'grad_norm': 6.220470428466797, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 1.21, 'grad_norm': 45.708736419677734, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.14it/s] 42%|████▎     | 17/40 [00:04<00:05,  3.93it/s]                                               {'loss': 0.5095, 'grad_norm': 4.093968391418457, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:04<00:05,  3.93it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.66it/s]                                               {'loss': 0.388, 'grad_norm': 4.116247653961182, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.66it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.48it/s]                                               {'loss': 0.3257, 'grad_norm': 3.782667636871338, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.48it/s] 50%|█████     | 20/40 [00:05<00:05,  3.35it/s]                                               {'loss': 0.5711, 'grad_norm': 5.531864643096924, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:05<00:05,  3.35it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.26it/s]                                               {'loss': 0.4446, 'grad_norm': 3.471315622329712, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.26it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.5089, 'grad_norm': 3.283396005630493, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.20it/s] 57%|█████▊    | 23/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.2589, 'grad_norm': 6.14848518371582, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.5511, 'grad_norm': 31.456195831298828, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:06<00:05,  3.14it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s]                                               {'loss': 0.4291, 'grad_norm': 5.355702877044678, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.64it/s]                                               {'loss': 0.1536, 'grad_norm': 3.1958932876586914, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.64it/s] 68%|██████▊   | 27/40 [00:07<00:03,  3.47it/s]                                               {'loss': 0.2333, 'grad_norm': 6.478063583374023, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:07<00:03,  3.47it/s] 70%|███████   | 28/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.0402, 'grad_norm': 0.8532726764678955, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.33it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.2253, 'grad_norm': 1.0909826755523682, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.25it/s] 75%|███████▌  | 30/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.3875, 'grad_norm': 5.117154121398926, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:08<00:03,  3.19it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.2452, 'grad_norm': 1.3045897483825684, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.0746, 'grad_norm': 4.363383769989014, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.13it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s]                                               {'loss': 0.039, 'grad_norm': 1.1469502449035645, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s]                                               {'loss': 0.2186, 'grad_norm': 1.8483641147613525, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s]                                               {'loss': 0.3249, 'grad_norm': 1.3273165225982666, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.33it/s]                                               {'loss': 0.0172, 'grad_norm': 0.4723600745201111, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.33it/s] 92%|█████████▎| 37/40 [00:10<00:00,  3.25it/s]                                               {'loss': 0.3229, 'grad_norm': 12.389800071716309, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:10<00:00,  3.25it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.1917, 'grad_norm': 12.816240310668945, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.19it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0956, 'grad_norm': 3.0852203369140625, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0228, 'grad_norm': 1.6114206314086914, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]                                               {'train_runtime': 11.9042, 'train_samples_per_second': 47.462, 'train_steps_per_second': 3.36, 'train_loss': 0.8401885173283518, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]100%|██████████| 40/40 [00:11<00:00,  3.36it/s]
CLIENT:32
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.06it/s]                                              {'loss': 3.9468, 'grad_norm': 6.931708812713623, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.06it/s]  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]                                              {'loss': 3.8468, 'grad_norm': 7.400902271270752, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 3.7861, 'grad_norm': 9.071172714233398, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.563, 'grad_norm': 9.191115379333496, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.2476, 'grad_norm': 10.530997276306152, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.051, 'grad_norm': 11.420764923095703, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 2.7145, 'grad_norm': 11.820944786071777, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 2.8616, 'grad_norm': 45.438575744628906, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s]                                              {'loss': 2.0142, 'grad_norm': 8.388481140136719, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s]                                               {'loss': 1.1054, 'grad_norm': 8.5004243850708, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s]                                               {'loss': 1.303, 'grad_norm': 6.835598945617676, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s] 30%|███       | 12/40 [00:03<00:08,  3.29it/s]                                               {'loss': 1.6303, 'grad_norm': 8.29727840423584, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.29it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 1.2895, 'grad_norm': 8.195075035095215, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 1.0381, 'grad_norm': 4.819419860839844, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.8978, 'grad_norm': 5.40984582901001, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 3.3305, 'grad_norm': 25.022369384765625, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.83it/s]                                               {'loss': 1.103, 'grad_norm': 6.4600090980529785, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.7232, 'grad_norm': 3.968942165374756, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.3792, 'grad_norm': 3.791365385055542, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 1.0786, 'grad_norm': 7.456124305725098, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.4366, 'grad_norm': 9.026321411132812, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.3333, 'grad_norm': 7.858715057373047, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.3995, 'grad_norm': 5.970264434814453, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.1932, 'grad_norm': 9.592813491821289, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.266, 'grad_norm': 5.602845668792725, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.2811, 'grad_norm': 4.165832996368408, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.0736, 'grad_norm': 1.4196484088897705, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.2122, 'grad_norm': 1.547234296798706, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.722, 'grad_norm': 3.0840718746185303, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.2069, 'grad_norm': 3.4266016483306885, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.1612, 'grad_norm': 2.1231436729431152, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0089, 'grad_norm': 0.5669993758201599, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.1116, 'grad_norm': 2.574876546859741, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.4676, 'grad_norm': 1.3684327602386475, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0546, 'grad_norm': 1.7352397441864014, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.2134, 'grad_norm': 5.797763347625732, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0467, 'grad_norm': 0.9329087138175964, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.1086, 'grad_norm': 7.5511698722839355, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.1098, 'grad_norm': 3.4279744625091553, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0959, 'grad_norm': 4.629385471343994, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0672, 'train_samples_per_second': 46.821, 'train_steps_per_second': 3.315, 'train_loss': 1.135321622295305, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:88
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 3.724, 'grad_norm': 7.788293838500977, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.13it/s]                                              {'loss': 3.8731, 'grad_norm': 6.673690319061279, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.13it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 2.1878, 'grad_norm': 7.882785797119141, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 3.0137, 'grad_norm': 9.936586380004883, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.1823, 'grad_norm': 9.413965225219727, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.4894, 'grad_norm': 11.077596664428711, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.8088, 'grad_norm': 16.77297019958496, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 3.4388, 'grad_norm': 63.78945541381836, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s]                                              {'loss': 1.2479, 'grad_norm': 9.117280006408691, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 0.6263, 'grad_norm': 5.639315128326416, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 0.4291, 'grad_norm': 5.535545349121094, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 1.9845, 'grad_norm': 7.196880340576172, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.5847, 'grad_norm': 5.471048831939697, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.8153, 'grad_norm': 4.803669452667236, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.8725, 'grad_norm': 5.837621688842773, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.0325, 'grad_norm': 1.4137845039367676, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.12it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.88it/s]                                               {'loss': 0.2306, 'grad_norm': 4.040531158447266, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.88it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.64it/s]                                               {'loss': 1.1025, 'grad_norm': 6.181056976318359, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.64it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.46it/s]                                               {'loss': 0.3501, 'grad_norm': 3.4226157665252686, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.46it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.267, 'grad_norm': 4.462085723876953, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.3025, 'grad_norm': 4.91128396987915, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.4163, 'grad_norm': 5.46328592300415, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.6688, 'grad_norm': 8.232776641845703, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.0507, 'grad_norm': 2.976154327392578, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.13it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s]                                               {'loss': 0.621, 'grad_norm': 4.66724157333374, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s]                                               {'loss': 0.1026, 'grad_norm': 2.9892706871032715, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s]                                               {'loss': 0.5768, 'grad_norm': 11.61085319519043, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.1209, 'grad_norm': 3.2006754875183105, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1139, 'grad_norm': 5.153395652770996, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s]                                               {'loss': 0.3449, 'grad_norm': 1.2878714799880981, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.1977, 'grad_norm': 3.7087574005126953, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.0023, 'grad_norm': 0.10000906139612198, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.14it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.90it/s]                                               {'loss': 0.0375, 'grad_norm': 0.6315536499023438, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.90it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.63it/s]                                               {'loss': 0.1329, 'grad_norm': 3.0108721256256104, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.63it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s]                                               {'loss': 0.0624, 'grad_norm': 1.0583171844482422, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.3673, 'grad_norm': 1.66975736618042, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.24it/s]                                               {'loss': 0.5526, 'grad_norm': 0.7755202651023865, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.24it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0844, 'grad_norm': 1.958573818206787, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1642, 'grad_norm': 3.526179790496826, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0163, 'grad_norm': 0.7676496505737305, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]                                               {'train_runtime': 11.9909, 'train_samples_per_second': 47.119, 'train_steps_per_second': 3.336, 'train_loss': 0.9049257261620369, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]100%|██████████| 40/40 [00:11<00:00,  3.34it/s]
CLIENT:8
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 3.4144, 'grad_norm': 5.853975296020508, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.5926, 'grad_norm': 6.419469833374023, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:11,  3.08it/s]                                              {'loss': 2.1954, 'grad_norm': 6.169212818145752, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.08it/s] 10%|█         | 4/40 [00:01<00:11,  3.08it/s]                                              {'loss': 3.7083, 'grad_norm': 9.698423385620117, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.08it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.7231, 'grad_norm': 10.620140075683594, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.06it/s] 15%|█▌        | 6/40 [00:01<00:10,  3.10it/s]                                              {'loss': 2.6901, 'grad_norm': 11.124615669250488, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:10,  3.10it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 1.9725, 'grad_norm': 12.227947235107422, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 0.4899, 'grad_norm': 17.247838973999023, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.05it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 0.6627, 'grad_norm': 7.033682346343994, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 0.6137, 'grad_norm': 6.647748947143555, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 0.997, 'grad_norm': 8.45483112335205, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.681, 'grad_norm': 7.4271087646484375, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 1.4007, 'grad_norm': 6.793242454528809, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.3331, 'grad_norm': 6.61444616317749, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.1, 'grad_norm': 7.276289939880371, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.1325, 'grad_norm': 5.391158103942871, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s]                                               {'loss': 0.4337, 'grad_norm': 3.5414483547210693, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s]                                               {'loss': 0.3633, 'grad_norm': 3.9715616703033447, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.2323, 'grad_norm': 2.5786852836608887, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.1882, 'grad_norm': 3.4136569499969482, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.2491, 'grad_norm': 3.2877252101898193, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.2926, 'grad_norm': 4.2225213050842285, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.6107, 'grad_norm': 4.405582904815674, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0213, 'grad_norm': 1.237004041671753, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.1088, 'grad_norm': 4.030176639556885, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.0391, 'grad_norm': 1.0094977617263794, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.1434, 'grad_norm': 3.1864771842956543, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.4296, 'grad_norm': 2.6394994258880615, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.1065, 'grad_norm': 2.2506182193756104, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.0439, 'grad_norm': 0.9808168411254883, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0693, 'grad_norm': 1.498077154159546, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0043, 'grad_norm': 0.2713890075683594, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0264, 'grad_norm': 0.433590292930603, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.3253, 'grad_norm': 0.8371148705482483, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0573, 'grad_norm': 3.2691895961761475, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.0449, 'grad_norm': 1.7455720901489258, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0678, 'grad_norm': 1.689038634300232, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0487, 'grad_norm': 1.8884961605072021, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1062, 'grad_norm': 2.914836883544922, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1892, 'grad_norm': 14.858536720275879, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.0826, 'train_samples_per_second': 46.761, 'train_steps_per_second': 3.311, 'train_loss': 0.7977228985284455, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:3
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.9046, 'grad_norm': 5.117267608642578, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.4804, 'grad_norm': 6.960484504699707, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 3.1795, 'grad_norm': 7.273608207702637, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.9844, 'grad_norm': 8.42561149597168, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.1152, 'grad_norm': 8.319591522216797, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 3.0576, 'grad_norm': 12.294964790344238, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 2.9717, 'grad_norm': 12.85811996459961, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.0354, 'grad_norm': 33.230472564697266, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 1.5518, 'grad_norm': 10.789449691772461, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 1.7868, 'grad_norm': 14.366311073303223, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 1.9379, 'grad_norm': 9.269551277160645, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 0.6257, 'grad_norm': 5.112868309020996, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s]                                               {'loss': 1.0713, 'grad_norm': 6.090141296386719, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.5319, 'grad_norm': 4.679358959197998, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 0.8029, 'grad_norm': 5.313071250915527, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 0.4415, 'grad_norm': 23.224599838256836, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.14it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.92it/s]                                               {'loss': 0.566, 'grad_norm': 3.4491562843322754, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.92it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.66it/s]                                               {'loss': 0.1814, 'grad_norm': 2.709428310394287, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.66it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.49it/s]                                               {'loss': 0.7684, 'grad_norm': 3.6780524253845215, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.49it/s] 50%|█████     | 20/40 [00:06<00:05,  3.35it/s]                                               {'loss': 0.3412, 'grad_norm': 5.139020919799805, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:05,  3.35it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.28it/s]                                               {'loss': 0.1733, 'grad_norm': 3.595337390899658, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.28it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.3382, 'grad_norm': 8.948007583618164, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.20it/s] 57%|█████▊    | 23/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.7141, 'grad_norm': 10.377643585205078, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.0263, 'grad_norm': 2.4915695190429688, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.14it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.1403, 'grad_norm': 3.634030342102051, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.0491, 'grad_norm': 1.1650804281234741, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.129, 'grad_norm': 3.0490357875823975, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.1747, 'grad_norm': 0.9131516814231873, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.0687, 'grad_norm': 1.2596473693847656, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.18it/s]                                               {'loss': 0.1956, 'grad_norm': 2.2938270568847656, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.18it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.5291, 'grad_norm': 1.8553634881973267, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.0103, 'grad_norm': 0.696821391582489, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.13it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s]                                               {'loss': 0.4576, 'grad_norm': 0.8069278001785278, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.0153, 'grad_norm': 0.34344950318336487, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.0326, 'grad_norm': 0.7282520532608032, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0624, 'grad_norm': 2.6300864219665527, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.1266, 'grad_norm': 0.6387460231781006, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.1854, 'grad_norm': 2.613070249557495, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.019, 'grad_norm': 0.5878214836120605, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0121, 'grad_norm': 0.9604148864746094, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.0253, 'train_samples_per_second': 46.984, 'train_steps_per_second': 3.326, 'train_loss': 0.8448812919668853, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.33it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:42, 10.92it/s]  1%|          | 4/471 [00:00<01:08,  6.86it/s]  1%|          | 5/471 [00:00<01:13,  6.35it/s]  1%|▏         | 6/471 [00:00<01:17,  6.03it/s]  1%|▏         | 7/471 [00:01<01:19,  5.82it/s]  2%|▏         | 8/471 [00:01<01:21,  5.71it/s]  2%|▏         | 9/471 [00:01<01:21,  5.64it/s]  2%|▏         | 10/471 [00:01<01:22,  5.57it/s]  2%|▏         | 11/471 [00:01<01:23,  5.51it/s]  3%|▎         | 12/471 [00:02<01:23,  5.47it/s]  3%|▎         | 13/471 [00:02<01:23,  5.45it/s]  3%|▎         | 14/471 [00:02<01:23,  5.44it/s]  3%|▎         | 15/471 [00:02<01:23,  5.45it/s]  3%|▎         | 16/471 [00:02<01:23,  5.42it/s]  4%|▎         | 17/471 [00:02<01:23,  5.42it/s]  4%|▍         | 18/471 [00:03<01:23,  5.41it/s]  4%|▍         | 19/471 [00:03<01:23,  5.42it/s]  4%|▍         | 20/471 [00:03<01:23,  5.41it/s]  4%|▍         | 21/471 [00:03<01:23,  5.40it/s]  5%|▍         | 22/471 [00:03<01:23,  5.38it/s]  5%|▍         | 23/471 [00:04<01:23,  5.39it/s]  5%|▌         | 24/471 [00:04<01:22,  5.41it/s]  5%|▌         | 25/471 [00:04<01:22,  5.42it/s]  6%|▌         | 26/471 [00:04<01:22,  5.41it/s]  6%|▌         | 27/471 [00:04<01:22,  5.40it/s]  6%|▌         | 28/471 [00:04<01:22,  5.40it/s]  6%|▌         | 29/471 [00:05<01:21,  5.40it/s]  6%|▋         | 30/471 [00:05<01:21,  5.39it/s]  7%|▋         | 31/471 [00:05<01:21,  5.39it/s]  7%|▋         | 32/471 [00:05<01:21,  5.42it/s]  7%|▋         | 33/471 [00:05<01:20,  5.44it/s]  7%|▋         | 34/471 [00:06<01:20,  5.43it/s]  7%|▋         | 35/471 [00:06<01:20,  5.42it/s]  8%|▊         | 36/471 [00:06<01:20,  5.42it/s]  8%|▊         | 37/471 [00:06<01:20,  5.42it/s]  8%|▊         | 38/471 [00:06<01:20,  5.40it/s]  8%|▊         | 39/471 [00:07<01:19,  5.40it/s]  8%|▊         | 40/471 [00:07<01:19,  5.39it/s]  9%|▊         | 41/471 [00:07<01:19,  5.39it/s]  9%|▉         | 42/471 [00:07<01:19,  5.39it/s]  9%|▉         | 43/471 [00:07<01:19,  5.39it/s]  9%|▉         | 44/471 [00:07<01:18,  5.41it/s] 10%|▉         | 45/471 [00:08<01:18,  5.40it/s] 10%|▉         | 46/471 [00:08<01:18,  5.41it/s] 10%|▉         | 47/471 [00:08<01:18,  5.41it/s] 10%|█         | 48/471 [00:08<01:18,  5.42it/s] 10%|█         | 49/471 [00:08<01:17,  5.41it/s] 11%|█         | 50/471 [00:09<01:17,  5.40it/s] 11%|█         | 51/471 [00:09<01:17,  5.39it/s] 11%|█         | 52/471 [00:09<01:17,  5.40it/s] 11%|█▏        | 53/471 [00:09<01:17,  5.39it/s] 11%|█▏        | 54/471 [00:09<01:17,  5.39it/s] 12%|█▏        | 55/471 [00:09<01:17,  5.38it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.37it/s] 12%|█▏        | 57/471 [00:10<01:16,  5.38it/s] 12%|█▏        | 58/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 59/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 60/471 [00:10<01:16,  5.39it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.38it/s] 13%|█▎        | 62/471 [00:11<01:15,  5.39it/s] 13%|█▎        | 63/471 [00:11<01:15,  5.37it/s] 14%|█▎        | 64/471 [00:11<01:15,  5.37it/s] 14%|█▍        | 65/471 [00:11<01:15,  5.37it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.38it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.38it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.37it/s] 15%|█▍        | 69/471 [00:12<01:14,  5.36it/s] 15%|█▍        | 70/471 [00:12<01:14,  5.37it/s] 15%|█▌        | 71/471 [00:12<01:14,  5.36it/s] 15%|█▌        | 72/471 [00:13<01:14,  5.36it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.37it/s] 16%|█▌        | 74/471 [00:13<01:13,  5.39it/s] 16%|█▌        | 75/471 [00:13<01:13,  5.39it/s] 16%|█▌        | 76/471 [00:13<01:13,  5.39it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.39it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.38it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.37it/s] 17%|█▋        | 80/471 [00:14<01:12,  5.38it/s] 17%|█▋        | 81/471 [00:14<01:12,  5.38it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.40it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.38it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.37it/s] 18%|█▊        | 85/471 [00:15<01:11,  5.37it/s] 18%|█▊        | 86/471 [00:15<01:11,  5.36it/s] 18%|█▊        | 87/471 [00:15<01:11,  5.37it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.39it/s] 19%|█▉        | 89/471 [00:16<01:10,  5.40it/s] 19%|█▉        | 90/471 [00:16<01:10,  5.38it/s] 19%|█▉        | 91/471 [00:16<01:10,  5.39it/s] 20%|█▉        | 92/471 [00:16<01:10,  5.39it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.37it/s] 20%|█▉        | 94/471 [00:17<01:09,  5.39it/s] 20%|██        | 95/471 [00:17<01:09,  5.40it/s] 20%|██        | 96/471 [00:17<01:09,  5.41it/s] 21%|██        | 97/471 [00:17<01:09,  5.38it/s] 21%|██        | 98/471 [00:17<01:09,  5.38it/s] 21%|██        | 99/471 [00:18<01:08,  5.40it/s] 21%|██        | 100/471 [00:18<01:08,  5.42it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.42it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.40it/s] 22%|██▏       | 103/471 [00:18<01:08,  5.39it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.37it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.37it/s] 23%|██▎       | 106/471 [00:19<01:07,  5.40it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.42it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.39it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.39it/s] 23%|██▎       | 110/471 [00:20<01:06,  5.40it/s] 24%|██▎       | 111/471 [00:20<01:06,  5.40it/s] 24%|██▍       | 112/471 [00:20<01:06,  5.39it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.42it/s] 24%|██▍       | 114/471 [00:20<01:06,  5.39it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.39it/s] 25%|██▍       | 116/471 [00:21<01:05,  5.39it/s] 25%|██▍       | 117/471 [00:21<01:05,  5.38it/s] 25%|██▌       | 118/471 [00:21<01:05,  5.38it/s] 25%|██▌       | 119/471 [00:21<01:05,  5.38it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.36it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.37it/s] 26%|██▌       | 122/471 [00:22<01:04,  5.37it/s] 26%|██▌       | 123/471 [00:22<01:04,  5.38it/s] 26%|██▋       | 124/471 [00:22<01:04,  5.37it/s] 27%|██▋       | 125/471 [00:22<01:04,  5.36it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.37it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.37it/s] 27%|██▋       | 128/471 [00:23<01:03,  5.36it/s] 27%|██▋       | 129/471 [00:23<01:03,  5.37it/s] 28%|██▊       | 130/471 [00:23<01:03,  5.38it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.36it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.36it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.36it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.33it/s] 29%|██▊       | 135/471 [00:24<01:02,  5.34it/s] 29%|██▉       | 136/471 [00:25<01:02,  5.36it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.36it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.35it/s] 30%|██▉       | 139/471 [00:25<01:01,  5.36it/s] 30%|██▉       | 140/471 [00:25<01:01,  5.34it/s] 30%|██▉       | 141/471 [00:25<01:01,  5.36it/s] 30%|███       | 142/471 [00:26<01:01,  5.38it/s] 30%|███       | 143/471 [00:26<01:01,  5.37it/s] 31%|███       | 144/471 [00:26<01:01,  5.36it/s] 31%|███       | 145/471 [00:26<01:00,  5.38it/s] 31%|███       | 146/471 [00:26<01:00,  5.36it/s] 31%|███       | 147/471 [00:27<01:00,  5.37it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.36it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.34it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.32it/s] 32%|███▏      | 151/471 [00:27<01:00,  5.33it/s] 32%|███▏      | 152/471 [00:28<00:59,  5.34it/s] 32%|███▏      | 153/471 [00:28<00:59,  5.33it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.35it/s] 33%|███▎      | 155/471 [00:28<00:58,  5.36it/s] 33%|███▎      | 156/471 [00:28<00:58,  5.36it/s] 33%|███▎      | 157/471 [00:28<00:58,  5.36it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.38it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.37it/s] 34%|███▍      | 160/471 [00:29<00:57,  5.37it/s] 34%|███▍      | 161/471 [00:29<00:57,  5.35it/s] 34%|███▍      | 162/471 [00:29<00:57,  5.34it/s] 35%|███▍      | 163/471 [00:30<00:57,  5.32it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.34it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.34it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.33it/s] 35%|███▌      | 167/471 [00:30<00:57,  5.32it/s] 36%|███▌      | 168/471 [00:31<00:56,  5.32it/s] 36%|███▌      | 169/471 [00:31<00:56,  5.32it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.33it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.34it/s] 37%|███▋      | 172/471 [00:31<00:55,  5.35it/s] 37%|███▋      | 173/471 [00:31<00:55,  5.34it/s] 37%|███▋      | 174/471 [00:32<00:55,  5.33it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.32it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.34it/s] 38%|███▊      | 177/471 [00:32<00:54,  5.36it/s] 38%|███▊      | 178/471 [00:32<00:54,  5.35it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.36it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.34it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.33it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.33it/s] 39%|███▉      | 183/471 [00:33<00:54,  5.33it/s] 39%|███▉      | 184/471 [00:34<00:53,  5.35it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.34it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.31it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.31it/s] 40%|███▉      | 188/471 [00:34<00:53,  5.31it/s] 40%|████      | 189/471 [00:34<00:52,  5.34it/s] 40%|████      | 190/471 [00:35<00:52,  5.34it/s] 41%|████      | 191/471 [00:35<00:52,  5.33it/s] 41%|████      | 192/471 [00:35<00:52,  5.33it/s] 41%|████      | 193/471 [00:35<00:51,  5.36it/s] 41%|████      | 194/471 [00:35<00:51,  5.36it/s] 41%|████▏     | 195/471 [00:36<00:51,  5.37it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.35it/s] 42%|████▏     | 197/471 [00:36<00:50,  5.37it/s] 42%|████▏     | 198/471 [00:36<00:50,  5.38it/s] 42%|████▏     | 199/471 [00:36<00:50,  5.36it/s] 42%|████▏     | 200/471 [00:37<00:50,  5.34it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.37it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.35it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.34it/s] 43%|████▎     | 204/471 [00:37<00:50,  5.33it/s] 44%|████▎     | 205/471 [00:37<00:49,  5.36it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.36it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.35it/s] 44%|████▍     | 208/471 [00:38<00:48,  5.37it/s] 44%|████▍     | 209/471 [00:38<00:48,  5.37it/s] 45%|████▍     | 210/471 [00:38<00:48,  5.38it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.36it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.35it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.34it/s] 45%|████▌     | 214/471 [00:39<00:48,  5.35it/s] 46%|████▌     | 215/471 [00:39<00:47,  5.34it/s] 46%|████▌     | 216/471 [00:40<00:47,  5.33it/s] 46%|████▌     | 217/471 [00:40<00:47,  5.31it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.31it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.32it/s] 47%|████▋     | 220/471 [00:40<00:47,  5.32it/s] 47%|████▋     | 221/471 [00:40<00:47,  5.30it/s] 47%|████▋     | 222/471 [00:41<00:46,  5.32it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.34it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.33it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.32it/s] 48%|████▊     | 226/471 [00:41<00:46,  5.31it/s] 48%|████▊     | 227/471 [00:42<00:45,  5.31it/s] 48%|████▊     | 228/471 [00:42<00:45,  5.32it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.32it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.31it/s] 49%|████▉     | 231/471 [00:42<00:45,  5.31it/s] 49%|████▉     | 232/471 [00:43<00:44,  5.32it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.32it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.32it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.32it/s] 50%|█████     | 236/471 [00:43<00:44,  5.33it/s] 50%|█████     | 237/471 [00:43<00:43,  5.32it/s] 51%|█████     | 238/471 [00:44<00:43,  5.32it/s] 51%|█████     | 239/471 [00:44<00:43,  5.34it/s] 51%|█████     | 240/471 [00:44<00:43,  5.32it/s] 51%|█████     | 241/471 [00:44<00:43,  5.32it/s] 51%|█████▏    | 242/471 [00:44<00:43,  5.32it/s] 52%|█████▏    | 243/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 247/471 [00:45<00:41,  5.33it/s] 53%|█████▎    | 248/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 249/471 [00:46<00:41,  5.32it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.32it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.32it/s] 54%|█████▎    | 252/471 [00:46<00:41,  5.31it/s] 54%|█████▎    | 253/471 [00:46<00:41,  5.31it/s] 54%|█████▍    | 254/471 [00:47<00:40,  5.31it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.32it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.31it/s] 55%|█████▍    | 257/471 [00:47<00:40,  5.30it/s] 55%|█████▍    | 258/471 [00:47<00:40,  5.29it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.29it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.29it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.29it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.31it/s] 56%|█████▌    | 263/471 [00:48<00:39,  5.31it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.30it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.29it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.27it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.28it/s] 57%|█████▋    | 268/471 [00:49<00:38,  5.28it/s] 57%|█████▋    | 269/471 [00:49<00:38,  5.29it/s] 57%|█████▋    | 270/471 [00:50<00:37,  5.29it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.30it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.30it/s] 58%|█████▊    | 273/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 274/471 [00:50<00:36,  5.33it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.31it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.32it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.32it/s] 59%|█████▉    | 278/471 [00:51<00:36,  5.31it/s] 59%|█████▉    | 279/471 [00:51<00:36,  5.32it/s] 59%|█████▉    | 280/471 [00:52<00:36,  5.31it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.30it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.30it/s] 60%|██████    | 283/471 [00:52<00:35,  5.31it/s] 60%|██████    | 284/471 [00:52<00:35,  5.32it/s] 61%|██████    | 285/471 [00:52<00:35,  5.30it/s] 61%|██████    | 286/471 [00:53<00:34,  5.30it/s] 61%|██████    | 287/471 [00:53<00:34,  5.29it/s] 61%|██████    | 288/471 [00:53<00:34,  5.29it/s] 61%|██████▏   | 289/471 [00:53<00:34,  5.31it/s] 62%|██████▏   | 290/471 [00:53<00:34,  5.31it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.32it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.31it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.32it/s] 62%|██████▏   | 294/471 [00:54<00:33,  5.32it/s] 63%|██████▎   | 295/471 [00:54<00:33,  5.33it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.35it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.33it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.31it/s] 63%|██████▎   | 299/471 [00:55<00:32,  5.30it/s] 64%|██████▎   | 300/471 [00:55<00:32,  5.30it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.30it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.30it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.30it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.31it/s] 65%|██████▍   | 305/471 [00:56<00:31,  5.32it/s] 65%|██████▍   | 306/471 [00:56<00:31,  5.31it/s] 65%|██████▌   | 307/471 [00:57<00:30,  5.30it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.28it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.28it/s] 66%|██████▌   | 310/471 [00:57<00:30,  5.30it/s] 66%|██████▌   | 311/471 [00:57<00:30,  5.30it/s] 66%|██████▌   | 312/471 [00:58<00:30,  5.29it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.30it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.29it/s] 67%|██████▋   | 315/471 [00:58<00:29,  5.30it/s] 67%|██████▋   | 316/471 [00:58<00:29,  5.31it/s] 67%|██████▋   | 317/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.30it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.28it/s] 68%|██████▊   | 320/471 [00:59<00:28,  5.28it/s] 68%|██████▊   | 321/471 [00:59<00:28,  5.28it/s] 68%|██████▊   | 322/471 [00:59<00:28,  5.28it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.26it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.26it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.28it/s] 69%|██████▉   | 326/471 [01:00<00:27,  5.27it/s] 69%|██████▉   | 327/471 [01:00<00:27,  5.29it/s] 70%|██████▉   | 328/471 [01:01<00:27,  5.28it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.27it/s] 70%|███████   | 330/471 [01:01<00:26,  5.30it/s] 70%|███████   | 331/471 [01:01<00:26,  5.30it/s] 70%|███████   | 332/471 [01:01<00:26,  5.29it/s] 71%|███████   | 333/471 [01:02<00:26,  5.30it/s] 71%|███████   | 334/471 [01:02<00:25,  5.29it/s] 71%|███████   | 335/471 [01:02<00:25,  5.28it/s] 71%|███████▏  | 336/471 [01:02<00:25,  5.30it/s] 72%|███████▏  | 337/471 [01:02<00:25,  5.31it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.31it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.29it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.30it/s] 72%|███████▏  | 341/471 [01:03<00:24,  5.30it/s] 73%|███████▎  | 342/471 [01:03<00:24,  5.32it/s] 73%|███████▎  | 343/471 [01:03<00:24,  5.30it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.30it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.30it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.29it/s] 74%|███████▎  | 347/471 [01:04<00:23,  5.30it/s] 74%|███████▍  | 348/471 [01:04<00:23,  5.30it/s] 74%|███████▍  | 349/471 [01:05<00:23,  5.29it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.29it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.31it/s] 75%|███████▍  | 352/471 [01:05<00:22,  5.29it/s] 75%|███████▍  | 353/471 [01:05<00:22,  5.27it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.27it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.28it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.27it/s] 76%|███████▌  | 357/471 [01:06<00:21,  5.27it/s] 76%|███████▌  | 358/471 [01:06<00:21,  5.28it/s] 76%|███████▌  | 359/471 [01:06<00:21,  5.27it/s] 76%|███████▋  | 360/471 [01:07<00:21,  5.27it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.28it/s] 77%|███████▋  | 362/471 [01:07<00:20,  5.28it/s] 77%|███████▋  | 363/471 [01:07<00:20,  5.28it/s] 77%|███████▋  | 364/471 [01:07<00:20,  5.29it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.28it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.26it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.26it/s] 78%|███████▊  | 368/471 [01:08<00:19,  5.26it/s] 78%|███████▊  | 369/471 [01:08<00:19,  5.28it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.27it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.27it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.27it/s] 79%|███████▉  | 373/471 [01:09<00:18,  5.25it/s] 79%|███████▉  | 374/471 [01:09<00:18,  5.27it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.28it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.29it/s] 80%|████████  | 377/471 [01:10<00:17,  5.30it/s] 80%|████████  | 378/471 [01:10<00:17,  5.32it/s] 80%|████████  | 379/471 [01:10<00:17,  5.30it/s] 81%|████████  | 380/471 [01:10<00:17,  5.28it/s] 81%|████████  | 381/471 [01:11<00:17,  5.29it/s] 81%|████████  | 382/471 [01:11<00:16,  5.28it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.29it/s] 82%|████████▏ | 384/471 [01:11<00:16,  5.27it/s] 82%|████████▏ | 385/471 [01:11<00:16,  5.27it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.25it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.26it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.25it/s] 83%|████████▎ | 389/471 [01:12<00:15,  5.28it/s] 83%|████████▎ | 390/471 [01:12<00:15,  5.27it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.27it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.28it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.29it/s] 84%|████████▎ | 394/471 [01:13<00:14,  5.27it/s] 84%|████████▍ | 395/471 [01:13<00:14,  5.27it/s] 84%|████████▍ | 396/471 [01:13<00:14,  5.26it/s] 84%|████████▍ | 397/471 [01:14<00:14,  5.27it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.27it/s] 85%|████████▍ | 399/471 [01:14<00:13,  5.26it/s] 85%|████████▍ | 400/471 [01:14<00:13,  5.26it/s] 85%|████████▌ | 401/471 [01:14<00:13,  5.26it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.25it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.27it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.27it/s] 86%|████████▌ | 405/471 [01:15<00:12,  5.26it/s] 86%|████████▌ | 406/471 [01:15<00:12,  5.27it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.28it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.27it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.26it/s] 87%|████████▋ | 410/471 [01:16<00:11,  5.26it/s] 87%|████████▋ | 411/471 [01:16<00:11,  5.29it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.28it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.27it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.26it/s] 88%|████████▊ | 415/471 [01:17<00:10,  5.27it/s] 88%|████████▊ | 416/471 [01:17<00:10,  5.26it/s] 89%|████████▊ | 417/471 [01:17<00:10,  5.27it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.26it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.26it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.28it/s] 89%|████████▉ | 421/471 [01:18<00:09,  5.27it/s] 90%|████████▉ | 422/471 [01:18<00:09,  5.29it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.30it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.28it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.28it/s] 90%|█████████ | 426/471 [01:19<00:08,  5.26it/s] 91%|█████████ | 427/471 [01:19<00:08,  5.27it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.26it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.26it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.25it/s] 92%|█████████▏| 431/471 [01:20<00:07,  5.25it/s] 92%|█████████▏| 432/471 [01:20<00:07,  5.26it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 434/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.25it/s] 93%|█████████▎| 436/471 [01:21<00:06,  5.27it/s] 93%|█████████▎| 437/471 [01:21<00:06,  5.26it/s] 93%|█████████▎| 438/471 [01:21<00:06,  5.26it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.26it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.27it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.27it/s] 94%|█████████▍| 442/471 [01:22<00:05,  5.28it/s] 94%|█████████▍| 443/471 [01:22<00:05,  5.27it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.26it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.26it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.26it/s] 95%|█████████▍| 447/471 [01:23<00:04,  5.27it/s] 95%|█████████▌| 448/471 [01:23<00:04,  5.27it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.27it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.26it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.26it/s] 96%|█████████▌| 452/471 [01:24<00:03,  5.28it/s] 96%|█████████▌| 453/471 [01:24<00:03,  5.26it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.25it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.25it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.25it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.25it/s] 97%|█████████▋| 458/471 [01:25<00:02,  5.25it/s] 97%|█████████▋| 459/471 [01:25<00:02,  5.28it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.28it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.26it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.25it/s] 98%|█████████▊| 463/471 [01:26<00:01,  5.27it/s] 99%|█████████▊| 464/471 [01:26<00:01,  5.26it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.28it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.27it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.25it/s] 99%|█████████▉| 468/471 [01:27<00:00,  5.24it/s]100%|█████████▉| 469/471 [01:27<00:00,  5.24it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.24it/s]100%|██████████| 471/471 [01:28<00:00,  5.61it/s]100%|██████████| 471/471 [01:28<00:00,  5.34it/s]
{'eval_loss': 3.5489625930786133, 'eval_model_preparation_time': 0.005, 'eval_acc': 0.1976898566117897, 'eval_runtime': 88.367, 'eval_samples_per_second': 85.235, 'eval_steps_per_second': 5.33}
ROUND:7
CLIENT:71
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.93it/s]                                              {'loss': 3.0351, 'grad_norm': 6.863789081573486, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.93it/s]  5%|▌         | 2/40 [00:00<00:13,  2.91it/s]                                              {'loss': 3.752, 'grad_norm': 7.078118324279785, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:13,  2.91it/s]  8%|▊         | 3/40 [00:01<00:12,  2.93it/s]                                              {'loss': 3.273, 'grad_norm': 9.449475288391113, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.93it/s] 10%|█         | 4/40 [00:01<00:12,  2.94it/s]                                              {'loss': 2.4381, 'grad_norm': 10.58635139465332, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.94it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.93it/s]                                              {'loss': 2.415, 'grad_norm': 10.94413948059082, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.93it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.90it/s]                                              {'loss': 1.5771, 'grad_norm': 8.66636848449707, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.90it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.88it/s]                                              {'loss': 1.9014, 'grad_norm': 11.597733497619629, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.88it/s]                                              {'loss': 1.5125, 'grad_norm': 73.83576202392578, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:11,  2.88it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.59it/s]                                              {'loss': 1.2589, 'grad_norm': 11.182626724243164, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.59it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.37it/s]                                               {'loss': 1.1146, 'grad_norm': 13.014604568481445, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.37it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.0597, 'grad_norm': 9.17129898071289, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.27it/s] 30%|███       | 12/40 [00:03<00:08,  3.17it/s]                                               {'loss': 0.786, 'grad_norm': 9.71080207824707, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.17it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.8005, 'grad_norm': 9.94884204864502, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.10it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.5428, 'grad_norm': 8.131311416625977, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.05it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.01it/s]                                               {'loss': 0.7507, 'grad_norm': 6.9443182945251465, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.01it/s]                                               {'loss': 0.849, 'grad_norm': 23.426809310913086, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.01it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.72it/s]                                               {'loss': 0.2314, 'grad_norm': 2.8761610984802246, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.72it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.49it/s]                                               {'loss': 0.6174, 'grad_norm': 3.192408323287964, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.49it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.32it/s]                                               {'loss': 0.2864, 'grad_norm': 3.525289297103882, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.32it/s] 50%|█████     | 20/40 [00:06<00:06,  3.22it/s]                                               {'loss': 1.0388, 'grad_norm': 7.602935314178467, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.22it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.4661, 'grad_norm': 4.6326799392700195, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.2656, 'grad_norm': 3.591459035873413, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.3244, 'grad_norm': 4.536135196685791, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.0021, 'grad_norm': 0.11158809810876846, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s]                                               {'loss': 0.0654, 'grad_norm': 1.3152700662612915, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s] 65%|██████▌   | 26/40 [00:08<00:03,  3.51it/s]                                               {'loss': 0.1217, 'grad_norm': 2.9066050052642822, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:08<00:03,  3.51it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.0894, 'grad_norm': 1.9128977060317993, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s] 70%|███████   | 28/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.2776, 'grad_norm': 4.929303169250488, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.22it/s] 72%|███████▎  | 29/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.3739, 'grad_norm': 5.417402267456055, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:09<00:03,  3.15it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.2142, 'grad_norm': 4.685964584350586, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.4562, 'grad_norm': 1.249590516090393, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.1915, 'grad_norm': 8.163113594055176, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.76it/s]                                               {'loss': 0.0637, 'grad_norm': 1.1445701122283936, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.76it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.4244, 'grad_norm': 1.8139207363128662, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.255, 'grad_norm': 7.540664196014404, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.24it/s]                                               {'loss': 0.0512, 'grad_norm': 2.932839870452881, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0562, 'grad_norm': 1.255859136581421, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.14it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.1086, 'grad_norm': 2.3684792518615723, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.03it/s]                                               {'loss': 0.0367, 'grad_norm': 0.7485285997390747, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.03it/s]                                               {'loss': 0.0054, 'grad_norm': 0.17701035737991333, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.03it/s]                                               {'train_runtime': 12.5259, 'train_samples_per_second': 45.107, 'train_steps_per_second': 3.193, 'train_loss': 0.827248356549535, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.03it/s]100%|██████████| 40/40 [00:12<00:00,  3.19it/s]
CLIENT:33
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 4.2518, 'grad_norm': 7.694558143615723, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 3.1007, 'grad_norm': 7.942783355712891, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 2.7555, 'grad_norm': 9.435236930847168, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:12,  2.97it/s]                                              {'loss': 2.0039, 'grad_norm': 9.326498985290527, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.97it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.96it/s]                                              {'loss': 3.027, 'grad_norm': 15.027640342712402, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.96it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.94it/s]                                              {'loss': 2.5756, 'grad_norm': 13.145874977111816, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.94it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 2.8051, 'grad_norm': 14.360891342163086, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 0.045, 'grad_norm': 3.2794971466064453, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.95it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.63it/s]                                              {'loss': 1.2581, 'grad_norm': 10.657146453857422, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.63it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.42it/s]                                               {'loss': 1.0917, 'grad_norm': 9.339760780334473, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.42it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.9433, 'grad_norm': 8.209737777709961, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.28it/s] 30%|███       | 12/40 [00:03<00:08,  3.19it/s]                                               {'loss': 1.2683, 'grad_norm': 10.525713920593262, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.19it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.393, 'grad_norm': 6.367240905761719, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.0728, 'grad_norm': 6.568173885345459, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.7283, 'grad_norm': 6.680492877960205, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 1.4404, 'grad_norm': 29.789033889770508, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.05it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 0.1376, 'grad_norm': 2.111736536026001, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.2799, 'grad_norm': 3.127418279647827, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.683, 'grad_norm': 3.3022923469543457, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.2442, 'grad_norm': 2.6690611839294434, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.3894, 'grad_norm': 6.117616653442383, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.6751, 'grad_norm': 4.864656448364258, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.3934, 'grad_norm': 4.865966796875, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.3104, 'grad_norm': 13.862669944763184, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.06it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.75it/s]                                               {'loss': 0.1017, 'grad_norm': 3.0023465156555176, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.75it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.0962, 'grad_norm': 2.5432283878326416, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.1556, 'grad_norm': 3.1429531574249268, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.4664, 'grad_norm': 1.0818654298782349, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.0555, 'grad_norm': 1.1822668313980103, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.4584, 'grad_norm': 1.4215452671051025, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0815, 'grad_norm': 1.4723443984985352, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.006, 'grad_norm': 0.6162773370742798, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.0308, 'grad_norm': 0.709416389465332, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s]                                               {'loss': 0.0221, 'grad_norm': 0.7983914017677307, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0235, 'grad_norm': 0.8308231234550476, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.7852, 'grad_norm': 1.8998931646347046, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0712, 'grad_norm': 2.1834776401519775, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.122, 'grad_norm': 10.91484546661377, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.06it/s]                                               {'loss': 0.0559, 'grad_norm': 1.662072777748108, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.06it/s]                                               {'loss': 0.0239, 'grad_norm': 1.4094464778900146, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]                                               {'train_runtime': 12.3245, 'train_samples_per_second': 45.844, 'train_steps_per_second': 3.246, 'train_loss': 0.8857323055271991, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.10it/s]                                              {'loss': 3.035, 'grad_norm': 6.385856628417969, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.10it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 3.1373, 'grad_norm': 8.725473403930664, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  2.99it/s]                                              {'loss': 2.4169, 'grad_norm': 7.303277492523193, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.99it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.0253, 'grad_norm': 10.723921775817871, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.1503, 'grad_norm': 13.380898475646973, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.7806, 'grad_norm': 19.995439529418945, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 2.3939, 'grad_norm': 15.14357852935791, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.2532, 'grad_norm': 24.190778732299805, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.61it/s]                                              {'loss': 1.3533, 'grad_norm': 13.183173179626465, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.61it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.44it/s]                                               {'loss': 1.1891, 'grad_norm': 14.741243362426758, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.44it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.31it/s]                                               {'loss': 1.1131, 'grad_norm': 10.229302406311035, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.31it/s] 30%|███       | 12/40 [00:03<00:08,  3.19it/s]                                               {'loss': 1.1932, 'grad_norm': 13.246386528015137, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.19it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.13it/s]                                               {'loss': 1.0283, 'grad_norm': 8.744522094726562, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.13it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.7065, 'grad_norm': 8.08747673034668, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.5832, 'grad_norm': 3.6074206829071045, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.6782, 'grad_norm': 54.07737731933594, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.4527, 'grad_norm': 3.422680377960205, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.2247, 'grad_norm': 3.1206283569335938, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.6216, 'grad_norm': 6.774810791015625, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.3749, 'grad_norm': 3.9273924827575684, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.4874, 'grad_norm': 6.507584095001221, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.5326, 'grad_norm': 12.73245906829834, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.5112, 'grad_norm': 8.763496398925781, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.7352, 'grad_norm': 63.17574691772461, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.4241, 'grad_norm': 1.9528954029083252, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.1267, 'grad_norm': 3.7554917335510254, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s]                                               {'loss': 0.4957, 'grad_norm': 6.047593116760254, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s] 70%|███████   | 28/40 [00:08<00:03,  3.32it/s]                                               {'loss': 0.1312, 'grad_norm': 3.4366273880004883, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.32it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.2444, 'grad_norm': 5.648324489593506, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.1641, 'grad_norm': 3.6681790351867676, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0969, 'grad_norm': 1.7678595781326294, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.1624, 'grad_norm': 8.366424560546875, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0604, 'grad_norm': 2.560032367706299, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.0222, 'grad_norm': 0.5720540285110474, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.1098, 'grad_norm': 1.0105302333831787, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.0918, 'grad_norm': 2.438626766204834, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.0269, 'grad_norm': 0.6604795455932617, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0418, 'grad_norm': 1.4734195470809937, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.6741, 'grad_norm': 1.2469391822814941, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.003, 'grad_norm': 0.19856776297092438, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.1736, 'train_samples_per_second': 46.412, 'train_steps_per_second': 3.286, 'train_loss': 0.8463313225540332, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:10
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.24it/s]                                              {'loss': 3.4762, 'grad_norm': 6.140448093414307, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.24it/s]  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]                                              {'loss': 3.0118, 'grad_norm': 8.046737670898438, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]  8%|▊         | 3/40 [00:00<00:12,  3.08it/s]                                              {'loss': 2.8588, 'grad_norm': 10.551353454589844, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.08it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.9206, 'grad_norm': 12.054729461669922, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.8727, 'grad_norm': 20.992300033569336, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.3277, 'grad_norm': 14.907502174377441, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 2.4007, 'grad_norm': 9.517396926879883, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 0.7213, 'grad_norm': 24.606340408325195, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 1.4906, 'grad_norm': 6.6140971183776855, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s]                                               {'loss': 0.998, 'grad_norm': 7.6417365074157715, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s]                                               {'loss': 0.9523, 'grad_norm': 9.45947265625, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 1.1122, 'grad_norm': 9.562889099121094, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.7899, 'grad_norm': 5.700435638427734, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.13it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.0943, 'grad_norm': 8.618398666381836, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.6855, 'grad_norm': 7.338960647583008, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.2494, 'grad_norm': 12.025824546813965, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s]                                               {'loss': 0.1065, 'grad_norm': 2.1276566982269287, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.1496, 'grad_norm': 3.127331495285034, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s]                                               {'loss': 0.1302, 'grad_norm': 3.439870834350586, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s] 50%|█████     | 20/40 [00:06<00:06,  3.23it/s]                                               {'loss': 0.6507, 'grad_norm': 11.26485538482666, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.23it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s]                                               {'loss': 0.5843, 'grad_norm': 7.262104034423828, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.4924, 'grad_norm': 3.8316214084625244, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.4501, 'grad_norm': 6.444035053253174, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.4042, 'grad_norm': 15.80517864227295, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s]                                               {'loss': 0.4633, 'grad_norm': 1.7090171575546265, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s]                                               {'loss': 0.2033, 'grad_norm': 2.8228962421417236, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.0823, 'grad_norm': 2.1314644813537598, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.0743, 'grad_norm': 1.4294904470443726, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.0851, 'grad_norm': 2.1212236881256104, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.4349, 'grad_norm': 1.8356927633285522, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1266, 'grad_norm': 2.3990020751953125, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1277, 'grad_norm': 9.79625415802002, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0393, 'grad_norm': 0.941504955291748, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.1688, 'grad_norm': 9.2933988571167, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.3924, 'grad_norm': 7.090287208557129, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.0592, 'grad_norm': 2.04488468170166, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0689, 'grad_norm': 3.7256457805633545, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1262, 'grad_norm': 3.651071071624756, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.4886, 'grad_norm': 3.529325246810913, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.001, 'grad_norm': 0.06064770370721817, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.1908, 'train_samples_per_second': 46.346, 'train_steps_per_second': 3.281, 'train_loss': 0.8217912800930207, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:44
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]                                              {'loss': 3.5476, 'grad_norm': 6.943655014038086, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]                                              {'loss': 2.9908, 'grad_norm': 7.62611722946167, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.3233, 'grad_norm': 8.359025001525879, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.3504, 'grad_norm': 14.661493301391602, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.7739, 'grad_norm': 14.825074195861816, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.5077, 'grad_norm': 12.577640533447266, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 2.2123, 'grad_norm': 12.092273712158203, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 5.1094, 'grad_norm': 69.80803680419922, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.98it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 0.7657, 'grad_norm': 6.982532024383545, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 0.8266, 'grad_norm': 11.255135536193848, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 0.8928, 'grad_norm': 6.693371295928955, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.8888, 'grad_norm': 6.582508087158203, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.3819, 'grad_norm': 7.527342319488525, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.2167, 'grad_norm': 9.843938827514648, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.9447, 'grad_norm': 6.319941520690918, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.5824, 'grad_norm': 19.255504608154297, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.62it/s]                                               {'loss': 0.5965, 'grad_norm': 5.553625583648682, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.62it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.617, 'grad_norm': 5.40627908706665, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.43it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.29it/s]                                               {'loss': 0.2761, 'grad_norm': 2.5551135540008545, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.29it/s] 50%|█████     | 20/40 [00:06<00:06,  3.20it/s]                                               {'loss': 0.8071, 'grad_norm': 4.754610538482666, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.20it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.3043, 'grad_norm': 4.9117865562438965, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.2648, 'grad_norm': 5.057566165924072, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.3288, 'grad_norm': 4.860037803649902, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.2467, 'grad_norm': 8.88500690460205, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.2616, 'grad_norm': 3.252936601638794, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.1347, 'grad_norm': 2.5942983627319336, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s]                                               {'loss': 0.1266, 'grad_norm': 3.0827713012695312, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.0862, 'grad_norm': 1.4532867670059204, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.4168, 'grad_norm': 2.4578423500061035, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.0754, 'grad_norm': 1.1659419536590576, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0624, 'grad_norm': 1.3263969421386719, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.3324, 'grad_norm': 23.25010871887207, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s]                                               {'loss': 0.0255, 'grad_norm': 0.6477334499359131, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s]                                               {'loss': 0.0377, 'grad_norm': 1.1501766443252563, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0325, 'grad_norm': 0.6046943664550781, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s]                                               {'loss': 0.1047, 'grad_norm': 1.938361406326294, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0844, 'grad_norm': 2.2984836101531982, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.3767, 'grad_norm': 1.8693252801895142, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.06it/s]                                               {'loss': 0.052, 'grad_norm': 1.3767398595809937, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.06it/s]                                               {'loss': 0.0044, 'grad_norm': 0.4038735330104828, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]                                               {'train_runtime': 12.2837, 'train_samples_per_second': 45.996, 'train_steps_per_second': 3.256, 'train_loss': 0.9242546337773092, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
CLIENT:34
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 3.6121, 'grad_norm': 7.302474021911621, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]                                              {'loss': 2.4516, 'grad_norm': 7.894191741943359, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.0144, 'grad_norm': 10.4570894241333, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.0428, 'grad_norm': 17.956817626953125, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.7506, 'grad_norm': 15.31879711151123, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.457, 'grad_norm': 9.770657539367676, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.3711, 'grad_norm': 9.199027061462402, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.5497, 'grad_norm': 67.67300415039062, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s]                                              {'loss': 0.5994, 'grad_norm': 4.71892786026001, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 0.618, 'grad_norm': 7.299557209014893, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 0.6809, 'grad_norm': 4.7725725173950195, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.8952, 'grad_norm': 10.906671524047852, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.1384, 'grad_norm': 7.983303070068359, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.5353, 'grad_norm': 6.363982677459717, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.3806, 'grad_norm': 4.107051372528076, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.3471, 'grad_norm': 43.752986907958984, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.0634, 'grad_norm': 1.0819321870803833, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.3258, 'grad_norm': 2.592092514038086, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.3203, 'grad_norm': 4.3903985023498535, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.1679, 'grad_norm': 2.6521568298339844, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.17it/s]                                               {'loss': 0.2921, 'grad_norm': 4.660731315612793, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.1224, 'grad_norm': 4.383456230163574, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.1834, 'grad_norm': 3.4941282272338867, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0991, 'grad_norm': 5.325135231018066, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.0339, 'grad_norm': 0.8212976455688477, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s]                                               {'loss': 0.0548, 'grad_norm': 1.1536445617675781, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s]                                               {'loss': 0.162, 'grad_norm': 3.6627790927886963, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.0644, 'grad_norm': 1.7182425260543823, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.2738, 'grad_norm': 3.1856467723846436, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.0355, 'grad_norm': 0.7939502000808716, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0467, 'grad_norm': 0.9953787326812744, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0383, 'grad_norm': 2.3553988933563232, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.69it/s]                                               {'loss': 0.0584, 'grad_norm': 2.0115740299224854, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.69it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.0266, 'grad_norm': 0.6610975861549377, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.1571, 'grad_norm': 0.7061185836791992, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.1104, 'grad_norm': 3.5964341163635254, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.073, 'grad_norm': 1.6993911266326904, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1786, 'grad_norm': 3.4518260955810547, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0309, 'grad_norm': 0.8943946361541748, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0177, 'grad_norm': 1.4437986612319946, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.2004, 'train_samples_per_second': 46.31, 'train_steps_per_second': 3.279, 'train_loss': 0.6845095600467175, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:24
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]                                              {'loss': 3.3531, 'grad_norm': 6.181798458099365, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]                                              {'loss': 3.2394, 'grad_norm': 6.644155025482178, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 2.9067, 'grad_norm': 10.282415390014648, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.8343, 'grad_norm': 8.689141273498535, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.4073, 'grad_norm': 9.593330383300781, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.5606, 'grad_norm': 11.232138633728027, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.4206, 'grad_norm': 7.492640495300293, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.0527, 'grad_norm': 2.5704712867736816, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s]                                              {'loss': 1.1416, 'grad_norm': 11.052032470703125, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s]                                               {'loss': 0.8496, 'grad_norm': 8.332499504089355, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.5739, 'grad_norm': 7.751620769500732, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.0137, 'grad_norm': 11.348784446716309, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.3529, 'grad_norm': 9.696748733520508, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 1.1263, 'grad_norm': 5.903160095214844, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.2393, 'grad_norm': 8.723793983459473, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.0108, 'grad_norm': 0.36784884333610535, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.2703, 'grad_norm': 3.4796559810638428, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.7694, 'grad_norm': 6.498593807220459, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.4375, 'grad_norm': 4.775937080383301, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.563, 'grad_norm': 8.199633598327637, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.7866, 'grad_norm': 8.43689250946045, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 1.1598, 'grad_norm': 9.781716346740723, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.4898, 'grad_norm': 6.394683361053467, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.5776, 'grad_norm': 33.683807373046875, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.06it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.73it/s]                                               {'loss': 0.5106, 'grad_norm': 3.1812541484832764, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.73it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.4672, 'grad_norm': 2.5086169242858887, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.5404, 'grad_norm': 5.523245811462402, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.1029, 'grad_norm': 3.378331184387207, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.1793, 'grad_norm': 5.385737895965576, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.1583, 'grad_norm': 7.594523906707764, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.2284, 'grad_norm': 2.900218963623047, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.026, 'grad_norm': 1.1888282299041748, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.4271, 'grad_norm': 1.3171377182006836, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.1735, 'grad_norm': 2.9695069789886475, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.5284, 'grad_norm': 4.838501930236816, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.042, 'grad_norm': 0.7509402632713318, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.086, 'grad_norm': 1.7437820434570312, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0897, 'grad_norm': 1.7484616041183472, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.4283, 'grad_norm': 1.798667073249817, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.016, 'grad_norm': 1.2556489706039429, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1494, 'train_samples_per_second': 46.504, 'train_steps_per_second': 3.292, 'train_loss': 0.8785233358852566, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:98
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.06it/s]                                              {'loss': 3.5088, 'grad_norm': 5.852649211883545, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.06it/s]  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]                                              {'loss': 3.0086, 'grad_norm': 7.543722629547119, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]  8%|▊         | 3/40 [00:00<00:12,  3.06it/s]                                              {'loss': 3.8579, 'grad_norm': 10.626867294311523, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.06it/s] 10%|█         | 4/40 [00:01<00:11,  3.11it/s]                                              {'loss': 2.8487, 'grad_norm': 9.742525100708008, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.11it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s]                                              {'loss': 1.9495, 'grad_norm': 11.412333488464355, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.452, 'grad_norm': 10.680567741394043, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.7545, 'grad_norm': 10.492618560791016, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.606, 'grad_norm': 33.91154098510742, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s]                                              {'loss': 1.1619, 'grad_norm': 7.52811336517334, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s]                                               {'loss': 1.4376, 'grad_norm': 9.373416900634766, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 0.6551, 'grad_norm': 5.646066188812256, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.29it/s]                                               {'loss': 1.6601, 'grad_norm': 7.959925651550293, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.29it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.21it/s]                                               {'loss': 1.313, 'grad_norm': 8.663763046264648, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.6648, 'grad_norm': 6.558125972747803, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.3342, 'grad_norm': 3.889946460723877, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 2.5045, 'grad_norm': 57.78668975830078, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.2463, 'grad_norm': 3.0444605350494385, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.344, 'grad_norm': 3.5532896518707275, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s]                                               {'loss': 0.2836, 'grad_norm': 4.892727375030518, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.2168, 'grad_norm': 6.0729522705078125, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.3732, 'grad_norm': 6.263156890869141, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.5549, 'grad_norm': 8.400155067443848, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.581, 'grad_norm': 6.42656946182251, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.03, 'grad_norm': 1.01520574092865, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.0517, 'grad_norm': 1.2205698490142822, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.1714, 'grad_norm': 3.2448201179504395, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.347, 'grad_norm': 1.6752893924713135, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.1068, 'grad_norm': 2.417091131210327, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.2492, 'grad_norm': 7.730029106140137, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.0358, 'grad_norm': 1.042630672454834, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.1827, 'grad_norm': 6.490752220153809, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0034, 'grad_norm': 0.23733407258987427, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.3127, 'grad_norm': 0.8253035545349121, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s]                                               {'loss': 0.07, 'grad_norm': 1.9331644773483276, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.0954, 'grad_norm': 2.8900039196014404, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0636, 'grad_norm': 1.3578813076019287, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0478, 'grad_norm': 1.1693142652511597, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0484, 'grad_norm': 1.9320261478424072, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0509, 'grad_norm': 2.5444772243499756, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0013, 'grad_norm': 0.10386714339256287, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.0658, 'train_samples_per_second': 46.827, 'train_steps_per_second': 3.315, 'train_loss': 0.8796294813451823, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:73
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]                                              {'loss': 4.5234, 'grad_norm': 6.273439407348633, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]                                              {'loss': 3.2094, 'grad_norm': 7.212462425231934, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.4944, 'grad_norm': 9.271651268005371, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.6842, 'grad_norm': 11.1338472366333, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.7822, 'grad_norm': 9.916849136352539, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.3837, 'grad_norm': 11.000784873962402, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.4334, 'grad_norm': 9.273881912231445, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.1831, 'grad_norm': 34.26679992675781, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 1.2593, 'grad_norm': 11.268380165100098, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 0.2824, 'grad_norm': 4.1627984046936035, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.9423, 'grad_norm': 8.149312019348145, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.25, 'grad_norm': 8.061864852905273, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.2776, 'grad_norm': 4.054211139678955, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.709, 'grad_norm': 6.0954155921936035, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.6848, 'grad_norm': 5.440184593200684, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.3433, 'grad_norm': 17.46068000793457, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.1688, 'grad_norm': 2.943103551864624, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.1253, 'grad_norm': 1.783220887184143, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.2392, 'grad_norm': 3.9480769634246826, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.2702, 'grad_norm': 3.716702699661255, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s]                                               {'loss': 0.2766, 'grad_norm': 2.8858821392059326, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.1413, 'grad_norm': 1.9000548124313354, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.1075, 'grad_norm': 2.4896135330200195, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0049, 'grad_norm': 0.27405840158462524, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.0401, 'grad_norm': 1.3851138353347778, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.1123, 'grad_norm': 5.968720436096191, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.0273, 'grad_norm': 1.739013671875, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.0209, 'grad_norm': 0.4003140926361084, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0341, 'grad_norm': 1.0806516408920288, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.0283, 'grad_norm': 0.6293784976005554, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0218, 'grad_norm': 0.6125618815422058, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.061, 'grad_norm': 3.2285525798797607, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0112, 'grad_norm': 0.3417353630065918, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.1945, 'grad_norm': 7.790746212005615, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.0637, 'grad_norm': 1.962886095046997, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0333, 'grad_norm': 0.9658505916595459, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.062, 'grad_norm': 2.0172011852264404, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0692, 'grad_norm': 1.4600841999053955, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0458, 'grad_norm': 1.298183798789978, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.048, 'grad_norm': 2.324921131134033, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1106, 'train_samples_per_second': 46.653, 'train_steps_per_second': 3.303, 'train_loss': 0.641235125681851, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:95
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 4.0118, 'grad_norm': 6.922454357147217, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.5703, 'grad_norm': 9.865274429321289, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:11,  3.10it/s]                                              {'loss': 2.6948, 'grad_norm': 8.580183029174805, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.10it/s] 10%|█         | 4/40 [00:01<00:11,  3.08it/s]                                              {'loss': 3.2459, 'grad_norm': 10.926332473754883, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.08it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s]                                              {'loss': 2.0105, 'grad_norm': 9.550667762756348, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.544, 'grad_norm': 12.640873908996582, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 1.2381, 'grad_norm': 8.499062538146973, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 5.6395, 'grad_norm': 59.087650299072266, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.05it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s]                                              {'loss': 1.2226, 'grad_norm': 7.754591464996338, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 1.0371, 'grad_norm': 8.7781343460083, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 0.6213, 'grad_norm': 6.604936122894287, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.5927, 'grad_norm': 3.5779471397399902, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s]                                               {'loss': 1.636, 'grad_norm': 7.661794662475586, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.0203, 'grad_norm': 7.489333629608154, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.433, 'grad_norm': 4.748290538787842, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 3.0851, 'grad_norm': 40.46255874633789, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 0.1289, 'grad_norm': 2.0038068294525146, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.3425, 'grad_norm': 9.491425514221191, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 1.0574, 'grad_norm': 4.836698532104492, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.2562, 'grad_norm': 6.406849384307861, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.4659, 'grad_norm': 3.7890427112579346, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.0978, 'grad_norm': 3.359990119934082, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0934, 'grad_norm': 1.8904896974563599, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0291, 'grad_norm': 1.9791898727416992, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.72it/s]                                               {'loss': 0.0677, 'grad_norm': 2.2892863750457764, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.72it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s]                                               {'loss': 0.0862, 'grad_norm': 2.6460094451904297, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.5467, 'grad_norm': 7.357356548309326, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.5937, 'grad_norm': 4.680837154388428, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.3984, 'grad_norm': 5.5218987464904785, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.0837, 'grad_norm': 1.8626346588134766, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.633, 'grad_norm': 3.811147928237915, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.1276, 'grad_norm': 7.486210823059082, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.4366, 'grad_norm': 1.3439031839370728, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.0607, 'grad_norm': 1.838980793952942, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.191, 'grad_norm': 5.28627347946167, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.718, 'grad_norm': 3.181361436843872, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.34it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.24it/s]                                               {'loss': 0.0391, 'grad_norm': 1.399477243423462, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.24it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.047, 'grad_norm': 0.939633846282959, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0656, 'grad_norm': 2.9253926277160645, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0835, 'grad_norm': 7.3025922775268555, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.0602, 'train_samples_per_second': 46.848, 'train_steps_per_second': 3.317, 'train_loss': 1.0063098018523307, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:42, 10.95it/s]  1%|          | 4/471 [00:00<01:07,  6.90it/s]  1%|          | 5/471 [00:00<01:12,  6.39it/s]  1%|▏         | 6/471 [00:00<01:17,  6.02it/s]  1%|▏         | 7/471 [00:01<01:19,  5.84it/s]  2%|▏         | 8/471 [00:01<01:20,  5.72it/s]  2%|▏         | 9/471 [00:01<01:22,  5.62it/s]  2%|▏         | 10/471 [00:01<01:22,  5.59it/s]  2%|▏         | 11/471 [00:01<01:23,  5.51it/s]  3%|▎         | 12/471 [00:02<01:23,  5.48it/s]  3%|▎         | 13/471 [00:02<01:24,  5.45it/s]  3%|▎         | 14/471 [00:02<01:23,  5.45it/s]  3%|▎         | 15/471 [00:02<01:23,  5.44it/s]  3%|▎         | 16/471 [00:02<01:23,  5.43it/s]  4%|▎         | 17/471 [00:02<01:23,  5.42it/s]  4%|▍         | 18/471 [00:03<01:23,  5.41it/s]  4%|▍         | 19/471 [00:03<01:23,  5.40it/s]  4%|▍         | 20/471 [00:03<01:23,  5.41it/s]  4%|▍         | 21/471 [00:03<01:23,  5.40it/s]  5%|▍         | 22/471 [00:03<01:23,  5.40it/s]  5%|▍         | 23/471 [00:04<01:23,  5.40it/s]  5%|▌         | 24/471 [00:04<01:22,  5.39it/s]  5%|▌         | 25/471 [00:04<01:22,  5.40it/s]  6%|▌         | 26/471 [00:04<01:22,  5.40it/s]  6%|▌         | 27/471 [00:04<01:22,  5.40it/s]  6%|▌         | 28/471 [00:04<01:22,  5.40it/s]  6%|▌         | 29/471 [00:05<01:21,  5.39it/s]  6%|▋         | 30/471 [00:05<01:21,  5.38it/s]  7%|▋         | 31/471 [00:05<01:21,  5.40it/s]  7%|▋         | 32/471 [00:05<01:21,  5.40it/s]  7%|▋         | 33/471 [00:05<01:20,  5.44it/s]  7%|▋         | 34/471 [00:06<01:20,  5.45it/s]  7%|▋         | 35/471 [00:06<01:20,  5.41it/s]  8%|▊         | 36/471 [00:06<01:20,  5.42it/s]  8%|▊         | 37/471 [00:06<01:20,  5.40it/s]  8%|▊         | 38/471 [00:06<01:20,  5.39it/s]  8%|▊         | 39/471 [00:07<01:19,  5.40it/s]  8%|▊         | 40/471 [00:07<01:19,  5.40it/s]  9%|▊         | 41/471 [00:07<01:19,  5.39it/s]  9%|▉         | 42/471 [00:07<01:19,  5.37it/s]  9%|▉         | 43/471 [00:07<01:19,  5.39it/s]  9%|▉         | 44/471 [00:07<01:19,  5.40it/s] 10%|▉         | 45/471 [00:08<01:18,  5.41it/s] 10%|▉         | 46/471 [00:08<01:18,  5.39it/s] 10%|▉         | 47/471 [00:08<01:18,  5.41it/s] 10%|█         | 48/471 [00:08<01:18,  5.40it/s] 10%|█         | 49/471 [00:08<01:18,  5.39it/s] 11%|█         | 50/471 [00:09<01:17,  5.40it/s] 11%|█         | 51/471 [00:09<01:17,  5.39it/s] 11%|█         | 52/471 [00:09<01:17,  5.38it/s] 11%|█▏        | 53/471 [00:09<01:17,  5.37it/s] 11%|█▏        | 54/471 [00:09<01:17,  5.38it/s] 12%|█▏        | 55/471 [00:09<01:17,  5.38it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.36it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.37it/s] 12%|█▏        | 58/471 [00:10<01:16,  5.38it/s] 13%|█▎        | 59/471 [00:10<01:16,  5.38it/s] 13%|█▎        | 60/471 [00:10<01:16,  5.39it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.39it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.38it/s] 13%|█▎        | 63/471 [00:11<01:15,  5.38it/s] 14%|█▎        | 64/471 [00:11<01:15,  5.39it/s] 14%|█▍        | 65/471 [00:11<01:15,  5.38it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.39it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.38it/s] 14%|█▍        | 68/471 [00:12<01:14,  5.38it/s] 15%|█▍        | 69/471 [00:12<01:14,  5.39it/s] 15%|█▍        | 70/471 [00:12<01:14,  5.36it/s] 15%|█▌        | 71/471 [00:12<01:14,  5.36it/s] 15%|█▌        | 72/471 [00:13<01:14,  5.38it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.37it/s] 16%|█▌        | 74/471 [00:13<01:13,  5.38it/s] 16%|█▌        | 75/471 [00:13<01:13,  5.37it/s] 16%|█▌        | 76/471 [00:13<01:13,  5.39it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.39it/s] 17%|█▋        | 78/471 [00:14<01:12,  5.39it/s] 17%|█▋        | 79/471 [00:14<01:12,  5.38it/s] 17%|█▋        | 80/471 [00:14<01:12,  5.37it/s] 17%|█▋        | 81/471 [00:14<01:12,  5.38it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.39it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.38it/s] 18%|█▊        | 84/471 [00:15<01:11,  5.38it/s] 18%|█▊        | 85/471 [00:15<01:11,  5.37it/s] 18%|█▊        | 86/471 [00:15<01:11,  5.36it/s] 18%|█▊        | 87/471 [00:15<01:11,  5.39it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.39it/s] 19%|█▉        | 89/471 [00:16<01:10,  5.39it/s] 19%|█▉        | 90/471 [00:16<01:10,  5.37it/s] 19%|█▉        | 91/471 [00:16<01:10,  5.36it/s] 20%|█▉        | 92/471 [00:16<01:10,  5.38it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.37it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.38it/s] 20%|██        | 95/471 [00:17<01:09,  5.38it/s] 20%|██        | 96/471 [00:17<01:09,  5.38it/s] 21%|██        | 97/471 [00:17<01:09,  5.37it/s] 21%|██        | 98/471 [00:17<01:09,  5.37it/s] 21%|██        | 99/471 [00:18<01:09,  5.38it/s] 21%|██        | 100/471 [00:18<01:08,  5.40it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.41it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.38it/s] 22%|██▏       | 103/471 [00:18<01:08,  5.35it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.36it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.35it/s] 23%|██▎       | 106/471 [00:19<01:07,  5.38it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.40it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.38it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.39it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.39it/s] 24%|██▎       | 111/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 112/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.40it/s] 24%|██▍       | 114/471 [00:20<01:06,  5.39it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.37it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.37it/s] 25%|██▍       | 117/471 [00:21<01:05,  5.37it/s] 25%|██▌       | 118/471 [00:21<01:05,  5.36it/s] 25%|██▌       | 119/471 [00:21<01:05,  5.37it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.36it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.36it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.36it/s] 26%|██▌       | 123/471 [00:22<01:04,  5.37it/s] 26%|██▋       | 124/471 [00:22<01:04,  5.36it/s] 27%|██▋       | 125/471 [00:23<01:04,  5.36it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.36it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.35it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.36it/s] 27%|██▋       | 129/471 [00:23<01:03,  5.37it/s] 28%|██▊       | 130/471 [00:23<01:03,  5.36it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.35it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.34it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.35it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.34it/s] 29%|██▊       | 135/471 [00:24<01:02,  5.36it/s] 29%|██▉       | 136/471 [00:25<01:02,  5.35it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.34it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.35it/s] 30%|██▉       | 139/471 [00:25<01:01,  5.36it/s] 30%|██▉       | 140/471 [00:25<01:01,  5.35it/s] 30%|██▉       | 141/471 [00:26<01:01,  5.36it/s] 30%|███       | 142/471 [00:26<01:01,  5.36it/s] 30%|███       | 143/471 [00:26<01:01,  5.35it/s] 31%|███       | 144/471 [00:26<01:01,  5.36it/s] 31%|███       | 145/471 [00:26<01:00,  5.38it/s] 31%|███       | 146/471 [00:26<01:00,  5.35it/s] 31%|███       | 147/471 [00:27<01:00,  5.34it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.35it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.33it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.33it/s] 32%|███▏      | 151/471 [00:27<01:00,  5.33it/s] 32%|███▏      | 152/471 [00:28<00:59,  5.33it/s] 32%|███▏      | 153/471 [00:28<00:59,  5.34it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.35it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.35it/s] 33%|███▎      | 156/471 [00:28<00:58,  5.35it/s] 33%|███▎      | 157/471 [00:28<00:58,  5.35it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.37it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.37it/s] 34%|███▍      | 160/471 [00:29<00:57,  5.36it/s] 34%|███▍      | 161/471 [00:29<00:57,  5.37it/s] 34%|███▍      | 162/471 [00:29<00:57,  5.34it/s] 35%|███▍      | 163/471 [00:30<00:57,  5.33it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.36it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.36it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.34it/s] 35%|███▌      | 167/471 [00:30<00:56,  5.33it/s] 36%|███▌      | 168/471 [00:31<00:56,  5.33it/s] 36%|███▌      | 169/471 [00:31<00:56,  5.33it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.34it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.34it/s] 37%|███▋      | 172/471 [00:31<00:55,  5.36it/s] 37%|███▋      | 173/471 [00:31<00:55,  5.34it/s] 37%|███▋      | 174/471 [00:32<00:55,  5.33it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.32it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.35it/s] 38%|███▊      | 177/471 [00:32<00:54,  5.35it/s] 38%|███▊      | 178/471 [00:32<00:54,  5.35it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.36it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.35it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.34it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.34it/s] 39%|███▉      | 183/471 [00:33<00:53,  5.35it/s] 39%|███▉      | 184/471 [00:34<00:53,  5.35it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.35it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.34it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.33it/s] 40%|███▉      | 188/471 [00:34<00:53,  5.32it/s] 40%|████      | 189/471 [00:34<00:52,  5.33it/s] 40%|████      | 190/471 [00:35<00:52,  5.37it/s] 41%|████      | 191/471 [00:35<00:52,  5.34it/s] 41%|████      | 192/471 [00:35<00:52,  5.35it/s] 41%|████      | 193/471 [00:35<00:51,  5.38it/s] 41%|████      | 194/471 [00:35<00:51,  5.35it/s] 41%|████▏     | 195/471 [00:36<00:51,  5.35it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.35it/s] 42%|████▏     | 197/471 [00:36<00:50,  5.38it/s] 42%|████▏     | 198/471 [00:36<00:50,  5.38it/s] 42%|████▏     | 199/471 [00:36<00:50,  5.35it/s] 42%|████▏     | 200/471 [00:37<00:50,  5.34it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.37it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.36it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.34it/s] 43%|████▎     | 204/471 [00:37<00:50,  5.34it/s] 44%|████▎     | 205/471 [00:37<00:49,  5.35it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.35it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.35it/s] 44%|████▍     | 208/471 [00:38<00:48,  5.37it/s] 44%|████▍     | 209/471 [00:38<00:48,  5.38it/s] 45%|████▍     | 210/471 [00:38<00:48,  5.38it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.36it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.35it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.33it/s] 45%|████▌     | 214/471 [00:39<00:48,  5.33it/s] 46%|████▌     | 215/471 [00:39<00:47,  5.35it/s] 46%|████▌     | 216/471 [00:40<00:47,  5.34it/s] 46%|████▌     | 217/471 [00:40<00:47,  5.33it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.32it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.31it/s] 47%|████▋     | 220/471 [00:40<00:47,  5.32it/s] 47%|████▋     | 221/471 [00:40<00:47,  5.31it/s] 47%|████▋     | 222/471 [00:41<00:46,  5.32it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.33it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.32it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.33it/s] 48%|████▊     | 226/471 [00:41<00:46,  5.33it/s] 48%|████▊     | 227/471 [00:42<00:45,  5.31it/s] 48%|████▊     | 228/471 [00:42<00:45,  5.30it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.30it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.31it/s] 49%|████▉     | 231/471 [00:42<00:45,  5.33it/s] 49%|████▉     | 232/471 [00:43<00:44,  5.34it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.32it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.32it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.31it/s] 50%|█████     | 236/471 [00:43<00:44,  5.34it/s] 50%|█████     | 237/471 [00:43<00:43,  5.33it/s] 51%|█████     | 238/471 [00:44<00:43,  5.33it/s] 51%|█████     | 239/471 [00:44<00:43,  5.33it/s] 51%|█████     | 240/471 [00:44<00:43,  5.32it/s] 51%|█████     | 241/471 [00:44<00:43,  5.31it/s] 51%|█████▏    | 242/471 [00:44<00:43,  5.32it/s] 52%|█████▏    | 243/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.33it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.33it/s] 52%|█████▏    | 247/471 [00:45<00:41,  5.34it/s] 53%|█████▎    | 248/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 249/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.32it/s] 54%|█████▎    | 252/471 [00:46<00:41,  5.31it/s] 54%|█████▎    | 253/471 [00:46<00:41,  5.31it/s] 54%|█████▍    | 254/471 [00:47<00:40,  5.31it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.32it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.31it/s] 55%|█████▍    | 257/471 [00:47<00:40,  5.30it/s] 55%|█████▍    | 258/471 [00:47<00:40,  5.29it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.29it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.30it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.31it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.33it/s] 56%|█████▌    | 263/471 [00:48<00:39,  5.32it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.30it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.30it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.29it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.30it/s] 57%|█████▋    | 268/471 [00:49<00:38,  5.30it/s] 57%|█████▋    | 269/471 [00:49<00:38,  5.31it/s] 57%|█████▋    | 270/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.30it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 273/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 274/471 [00:50<00:36,  5.35it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.35it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.34it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.34it/s] 59%|█████▉    | 278/471 [00:51<00:36,  5.32it/s] 59%|█████▉    | 279/471 [00:51<00:35,  5.33it/s] 59%|█████▉    | 280/471 [00:52<00:35,  5.34it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.33it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.32it/s] 60%|██████    | 283/471 [00:52<00:35,  5.32it/s] 60%|██████    | 284/471 [00:52<00:35,  5.31it/s] 61%|██████    | 285/471 [00:52<00:34,  5.32it/s] 61%|██████    | 286/471 [00:53<00:34,  5.32it/s] 61%|██████    | 287/471 [00:53<00:34,  5.33it/s] 61%|██████    | 288/471 [00:53<00:34,  5.32it/s] 61%|██████▏   | 289/471 [00:53<00:34,  5.32it/s] 62%|██████▏   | 290/471 [00:53<00:33,  5.33it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.33it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.33it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.34it/s] 62%|██████▏   | 294/471 [00:54<00:33,  5.34it/s] 63%|██████▎   | 295/471 [00:54<00:32,  5.34it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 299/471 [00:55<00:32,  5.35it/s] 64%|██████▎   | 300/471 [00:55<00:32,  5.33it/s] 64%|██████▍   | 301/471 [00:55<00:31,  5.33it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.32it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.33it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.34it/s] 65%|██████▍   | 305/471 [00:56<00:31,  5.33it/s] 65%|██████▍   | 306/471 [00:56<00:30,  5.33it/s] 65%|██████▌   | 307/471 [00:57<00:30,  5.33it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.32it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.32it/s] 66%|██████▌   | 310/471 [00:57<00:30,  5.31it/s] 66%|██████▌   | 311/471 [00:57<00:30,  5.31it/s] 66%|██████▌   | 312/471 [00:58<00:29,  5.33it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.33it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.33it/s] 67%|██████▋   | 315/471 [00:58<00:29,  5.33it/s] 67%|██████▋   | 316/471 [00:58<00:28,  5.35it/s] 67%|██████▋   | 317/471 [00:58<00:28,  5.34it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 320/471 [00:59<00:28,  5.31it/s] 68%|██████▊   | 321/471 [00:59<00:28,  5.31it/s] 68%|██████▊   | 322/471 [00:59<00:28,  5.32it/s] 69%|██████▊   | 323/471 [01:00<00:27,  5.31it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.29it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.30it/s] 69%|██████▉   | 326/471 [01:00<00:27,  5.32it/s] 69%|██████▉   | 327/471 [01:00<00:26,  5.34it/s] 70%|██████▉   | 328/471 [01:01<00:26,  5.32it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.31it/s] 70%|███████   | 330/471 [01:01<00:26,  5.32it/s] 70%|███████   | 331/471 [01:01<00:26,  5.32it/s] 70%|███████   | 332/471 [01:01<00:26,  5.32it/s] 71%|███████   | 333/471 [01:02<00:25,  5.33it/s] 71%|███████   | 334/471 [01:02<00:25,  5.32it/s] 71%|███████   | 335/471 [01:02<00:25,  5.30it/s] 71%|███████▏  | 336/471 [01:02<00:25,  5.31it/s] 72%|███████▏  | 337/471 [01:02<00:25,  5.33it/s] 72%|███████▏  | 338/471 [01:02<00:24,  5.34it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.32it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.32it/s] 72%|███████▏  | 341/471 [01:03<00:24,  5.31it/s] 73%|███████▎  | 342/471 [01:03<00:24,  5.31it/s] 73%|███████▎  | 343/471 [01:03<00:24,  5.32it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.34it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.32it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.31it/s] 74%|███████▎  | 347/471 [01:04<00:23,  5.31it/s] 74%|███████▍  | 348/471 [01:04<00:23,  5.32it/s] 74%|███████▍  | 349/471 [01:05<00:22,  5.32it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.31it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.32it/s] 75%|███████▍  | 352/471 [01:05<00:22,  5.31it/s] 75%|███████▍  | 353/471 [01:05<00:22,  5.31it/s] 75%|███████▌  | 354/471 [01:05<00:21,  5.33it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.31it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 357/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 358/471 [01:06<00:21,  5.30it/s] 76%|███████▌  | 359/471 [01:06<00:21,  5.30it/s] 76%|███████▋  | 360/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.33it/s] 77%|███████▋  | 362/471 [01:07<00:20,  5.31it/s] 77%|███████▋  | 363/471 [01:07<00:20,  5.30it/s] 77%|███████▋  | 364/471 [01:07<00:20,  5.31it/s] 77%|███████▋  | 365/471 [01:08<00:19,  5.30it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.29it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.30it/s] 78%|███████▊  | 368/471 [01:08<00:19,  5.31it/s] 78%|███████▊  | 369/471 [01:08<00:19,  5.30it/s] 79%|███████▊  | 370/471 [01:08<00:19,  5.30it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.31it/s] 79%|███████▉  | 373/471 [01:09<00:18,  5.31it/s] 79%|███████▉  | 374/471 [01:09<00:18,  5.33it/s] 80%|███████▉  | 375/471 [01:09<00:18,  5.32it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.29it/s] 80%|████████  | 377/471 [01:10<00:17,  5.31it/s] 80%|████████  | 378/471 [01:10<00:17,  5.34it/s] 80%|████████  | 379/471 [01:10<00:17,  5.33it/s] 81%|████████  | 380/471 [01:10<00:17,  5.31it/s] 81%|████████  | 381/471 [01:11<00:16,  5.31it/s] 81%|████████  | 382/471 [01:11<00:16,  5.30it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.31it/s] 82%|████████▏ | 384/471 [01:11<00:16,  5.31it/s] 82%|████████▏ | 385/471 [01:11<00:16,  5.31it/s] 82%|████████▏ | 386/471 [01:11<00:16,  5.31it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.30it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.30it/s] 83%|████████▎ | 389/471 [01:12<00:15,  5.31it/s] 83%|████████▎ | 390/471 [01:12<00:15,  5.30it/s] 83%|████████▎ | 391/471 [01:12<00:15,  5.31it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.32it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.32it/s] 84%|████████▎ | 394/471 [01:13<00:14,  5.31it/s] 84%|████████▍ | 395/471 [01:13<00:14,  5.30it/s] 84%|████████▍ | 396/471 [01:13<00:14,  5.31it/s] 84%|████████▍ | 397/471 [01:14<00:13,  5.32it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.32it/s] 85%|████████▍ | 399/471 [01:14<00:13,  5.30it/s] 85%|████████▍ | 400/471 [01:14<00:13,  5.29it/s] 85%|████████▌ | 401/471 [01:14<00:13,  5.30it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.30it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.31it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.32it/s] 86%|████████▌ | 405/471 [01:15<00:12,  5.31it/s] 86%|████████▌ | 406/471 [01:15<00:12,  5.32it/s] 86%|████████▋ | 407/471 [01:15<00:12,  5.32it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.31it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.31it/s] 87%|████████▋ | 410/471 [01:16<00:11,  5.32it/s] 87%|████████▋ | 411/471 [01:16<00:11,  5.34it/s] 87%|████████▋ | 412/471 [01:16<00:11,  5.32it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.31it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.29it/s] 88%|████████▊ | 415/471 [01:17<00:10,  5.30it/s] 88%|████████▊ | 416/471 [01:17<00:10,  5.30it/s] 89%|████████▊ | 417/471 [01:17<00:10,  5.31it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.29it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.30it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.32it/s] 89%|████████▉ | 421/471 [01:18<00:09,  5.31it/s] 90%|████████▉ | 422/471 [01:18<00:09,  5.33it/s] 90%|████████▉ | 423/471 [01:18<00:09,  5.33it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.31it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.32it/s] 90%|█████████ | 426/471 [01:19<00:08,  5.30it/s] 91%|█████████ | 427/471 [01:19<00:08,  5.30it/s] 91%|█████████ | 428/471 [01:19<00:08,  5.30it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.30it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.29it/s] 92%|█████████▏| 431/471 [01:20<00:07,  5.28it/s] 92%|█████████▏| 432/471 [01:20<00:07,  5.29it/s] 92%|█████████▏| 433/471 [01:20<00:07,  5.29it/s] 92%|█████████▏| 434/471 [01:21<00:07,  5.28it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.28it/s] 93%|█████████▎| 436/471 [01:21<00:06,  5.30it/s] 93%|█████████▎| 437/471 [01:21<00:06,  5.28it/s] 93%|█████████▎| 438/471 [01:21<00:06,  5.28it/s] 93%|█████████▎| 439/471 [01:21<00:06,  5.28it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.30it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.32it/s] 94%|█████████▍| 442/471 [01:22<00:05,  5.30it/s] 94%|█████████▍| 443/471 [01:22<00:05,  5.29it/s] 94%|█████████▍| 444/471 [01:22<00:05,  5.28it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.27it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.26it/s] 95%|█████████▍| 447/471 [01:23<00:04,  5.27it/s] 95%|█████████▌| 448/471 [01:23<00:04,  5.28it/s] 95%|█████████▌| 449/471 [01:23<00:04,  5.28it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.26it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.27it/s] 96%|█████████▌| 452/471 [01:24<00:03,  5.29it/s] 96%|█████████▌| 453/471 [01:24<00:03,  5.27it/s] 96%|█████████▋| 454/471 [01:24<00:03,  5.26it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.24it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.26it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.26it/s] 97%|█████████▋| 458/471 [01:25<00:02,  5.27it/s] 97%|█████████▋| 459/471 [01:25<00:02,  5.29it/s] 98%|█████████▊| 460/471 [01:25<00:02,  5.27it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.27it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.26it/s] 98%|█████████▊| 463/471 [01:26<00:01,  5.27it/s] 99%|█████████▊| 464/471 [01:26<00:01,  5.27it/s] 99%|█████████▊| 465/471 [01:26<00:01,  5.27it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.26it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.26it/s] 99%|█████████▉| 468/471 [01:27<00:00,  5.25it/s]100%|█████████▉| 469/471 [01:27<00:00,  5.26it/s]100%|█████████▉| 470/471 [01:27<00:00,  5.27it/s]100%|██████████| 471/471 [01:28<00:00,  5.63it/s]100%|██████████| 471/471 [01:28<00:00,  5.35it/s]
{'eval_loss': 3.3320400714874268, 'eval_model_preparation_time': 0.005, 'eval_acc': 0.22318109399893787, 'eval_runtime': 88.1612, 'eval_samples_per_second': 85.434, 'eval_steps_per_second': 5.342}
ROUND:8
CLIENT:2
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.93it/s]                                              {'loss': 3.2664, 'grad_norm': 6.2309136390686035, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.93it/s]  5%|▌         | 2/40 [00:00<00:13,  2.92it/s]                                              {'loss': 2.7935, 'grad_norm': 7.683542728424072, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:13,  2.92it/s]  8%|▊         | 3/40 [00:01<00:12,  2.91it/s]                                              {'loss': 2.335, 'grad_norm': 10.293375015258789, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.91it/s] 10%|█         | 4/40 [00:01<00:12,  2.92it/s]                                              {'loss': 2.7422, 'grad_norm': 12.22283935546875, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.92it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.93it/s]                                              {'loss': 2.1036, 'grad_norm': 10.526212692260742, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.93it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.94it/s]                                              {'loss': 2.178, 'grad_norm': 11.787162780761719, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.94it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.93it/s]                                              {'loss': 1.4577, 'grad_norm': 11.544219017028809, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.93it/s]                                              {'loss': 0.3611, 'grad_norm': 18.262102127075195, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.93it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s]                                              {'loss': 0.8221, 'grad_norm': 6.768990993499756, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.46it/s]                                               {'loss': 0.9324, 'grad_norm': 8.82391357421875, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.46it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.7585, 'grad_norm': 8.716352462768555, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.30it/s] 30%|███       | 12/40 [00:03<00:08,  3.20it/s]                                               {'loss': 1.1388, 'grad_norm': 8.64728832244873, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.20it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.376, 'grad_norm': 5.08419132232666, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.12it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.7553, 'grad_norm': 10.013642311096191, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.05it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.02it/s]                                               {'loss': 0.9595, 'grad_norm': 6.609038352966309, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.02it/s]                                               {'loss': 0.0657, 'grad_norm': 3.1274728775024414, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.02it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s]                                               {'loss': 0.3105, 'grad_norm': 5.023008823394775, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s]                                               {'loss': 0.2908, 'grad_norm': 3.1282694339752197, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.34it/s]                                               {'loss': 0.1722, 'grad_norm': 2.4183754920959473, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.34it/s] 50%|█████     | 20/40 [00:06<00:06,  3.21it/s]                                               {'loss': 0.3089, 'grad_norm': 3.3280415534973145, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.21it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.6856, 'grad_norm': 7.155399799346924, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.4278, 'grad_norm': 8.210536003112793, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.03it/s]                                               {'loss': 0.2884, 'grad_norm': 7.592557430267334, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.03it/s]                                               {'loss': 0.5996, 'grad_norm': 32.25825881958008, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.03it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s]                                               {'loss': 0.1244, 'grad_norm': 3.197178363800049, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s]                                               {'loss': 0.078, 'grad_norm': 1.7128851413726807, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.1768, 'grad_norm': 4.343005657196045, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s] 70%|███████   | 28/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.1414, 'grad_norm': 2.399651050567627, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.21it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s]                                               {'loss': 0.1083, 'grad_norm': 1.627578616142273, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s]                                               {'loss': 0.1793, 'grad_norm': 2.774864435195923, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.01it/s]                                               {'loss': 0.1931, 'grad_norm': 3.722141742706299, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.01it/s]                                               {'loss': 0.0136, 'grad_norm': 0.544756293296814, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.01it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.68it/s]                                               {'loss': 0.2103, 'grad_norm': 4.976401329040527, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.68it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.46it/s]                                               {'loss': 0.4869, 'grad_norm': 5.6666460037231445, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.46it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0438, 'grad_norm': 1.1078124046325684, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.29it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.18it/s]                                               {'loss': 0.2286, 'grad_norm': 5.5011396408081055, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.18it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.028, 'grad_norm': 0.6454510688781738, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.1353, 'grad_norm': 5.100063800811768, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.04it/s] 98%|█████████▊| 39/40 [00:12<00:00,  2.98it/s]                                               {'loss': 0.0688, 'grad_norm': 2.2152366638183594, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  2.98it/s]                                               {'loss': 0.0486, 'grad_norm': 4.074695110321045, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  2.98it/s]                                               {'train_runtime': 12.4772, 'train_samples_per_second': 45.283, 'train_steps_per_second': 3.206, 'train_loss': 0.7098668470280245, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  2.98it/s]100%|██████████| 40/40 [00:12<00:00,  3.21it/s]
CLIENT:49
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 3.4052, 'grad_norm': 6.621648788452148, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 2.5623, 'grad_norm': 9.193731307983398, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 2.8052, 'grad_norm': 10.487375259399414, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:12,  2.96it/s]                                              {'loss': 1.4527, 'grad_norm': 9.96311092376709, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.96it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.95it/s]                                              {'loss': 2.033, 'grad_norm': 15.054399490356445, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.95it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.93it/s]                                              {'loss': 3.3544, 'grad_norm': 20.828298568725586, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.93it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.93it/s]                                              {'loss': 1.7034, 'grad_norm': 13.23984432220459, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.93it/s]                                              {'loss': 0.6242, 'grad_norm': 28.50800132751465, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.93it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s]                                              {'loss': 1.2073, 'grad_norm': 11.550253868103027, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s]                                               {'loss': 0.8649, 'grad_norm': 11.022051811218262, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s]                                               {'loss': 1.2588, 'grad_norm': 12.312061309814453, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s] 30%|███       | 12/40 [00:03<00:08,  3.21it/s]                                               {'loss': 1.079, 'grad_norm': 10.915987014770508, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.21it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.3225, 'grad_norm': 7.393515586853027, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.7455, 'grad_norm': 6.887824535369873, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.7365, 'grad_norm': 7.724135875701904, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.3803, 'grad_norm': 12.967344284057617, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.05it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.1377, 'grad_norm': 2.579745054244995, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s]                                               {'loss': 0.6917, 'grad_norm': 4.026645183563232, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.6837, 'grad_norm': 4.65135383605957, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.3721, 'grad_norm': 9.309009552001953, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.5653, 'grad_norm': 4.507137298583984, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.3131, 'grad_norm': 9.06882095336914, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.4733, 'grad_norm': 7.0985541343688965, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.0515, 'grad_norm': 2.845611810684204, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.4753, 'grad_norm': 3.0043277740478516, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.1006, 'grad_norm': 2.9795730113983154, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s]                                               {'loss': 0.6946, 'grad_norm': 6.355456352233887, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s] 70%|███████   | 28/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.1089, 'grad_norm': 1.8589322566986084, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.24it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.3922, 'grad_norm': 1.5563687086105347, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.08it/s]                                               {'loss': 0.1738, 'grad_norm': 8.967973709106445, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.08it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.03it/s]                                               {'loss': 0.0911, 'grad_norm': 1.7355091571807861, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.03it/s]                                               {'loss': 0.0016, 'grad_norm': 0.09817370772361755, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.03it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.75it/s]                                               {'loss': 0.0937, 'grad_norm': 1.6009725332260132, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.75it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s]                                               {'loss': 0.3536, 'grad_norm': 1.0668894052505493, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.1353, 'grad_norm': 3.115652322769165, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.21it/s]                                               {'loss': 0.0995, 'grad_norm': 3.5273444652557373, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.21it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.2963, 'grad_norm': 1.3690634965896606, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.3023, 'grad_norm': 21.250654220581055, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.04it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.00it/s]                                               {'loss': 0.4509, 'grad_norm': 4.052197456359863, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.00it/s]                                               {'loss': 0.2673, 'grad_norm': 10.637743949890137, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.00it/s]                                               {'train_runtime': 12.4703, 'train_samples_per_second': 45.308, 'train_steps_per_second': 3.208, 'train_loss': 0.8215009557752637, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.00it/s]100%|██████████| 40/40 [00:12<00:00,  3.21it/s]
CLIENT:82
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]                                              {'loss': 4.618, 'grad_norm': 8.560615539550781, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.2561, 'grad_norm': 6.634433746337891, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 1.8524, 'grad_norm': 8.12234878540039, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.1642, 'grad_norm': 12.791964530944824, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 1.643, 'grad_norm': 9.197822570800781, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.397, 'grad_norm': 10.247278213500977, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 1.8468, 'grad_norm': 13.63154125213623, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 0.1122, 'grad_norm': 4.573973178863525, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 1.4161, 'grad_norm': 9.422966957092285, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.5346, 'grad_norm': 6.077037334442139, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 0.7026, 'grad_norm': 6.620560169219971, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.23it/s]                                               {'loss': 0.5951, 'grad_norm': 9.891701698303223, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.23it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.2192, 'grad_norm': 8.320956230163574, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.7777, 'grad_norm': 7.153837203979492, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.5859, 'grad_norm': 5.411489963531494, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.761, 'grad_norm': 1.9340873956680298, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s]                                               {'loss': 0.1674, 'grad_norm': 2.7004945278167725, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.3881, 'grad_norm': 5.48188591003418, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.1727, 'grad_norm': 2.578615665435791, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.4894, 'grad_norm': 4.338630199432373, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.4418, 'grad_norm': 3.8806443214416504, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.2875, 'grad_norm': 5.821682929992676, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.6293, 'grad_norm': 8.270319938659668, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.1339, 'grad_norm': 15.084936141967773, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.3854, 'grad_norm': 1.1670459508895874, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.0536, 'grad_norm': 2.2126989364624023, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.0386, 'grad_norm': 1.4523411989212036, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.0426, 'grad_norm': 1.6621323823928833, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s]                                               {'loss': 0.3697, 'grad_norm': 3.349717378616333, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.5306, 'grad_norm': 1.607898235321045, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1904, 'grad_norm': 5.5598578453063965, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.2349, 'grad_norm': 11.506308555603027, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s]                                               {'loss': 0.035, 'grad_norm': 0.9469668865203857, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.0357, 'grad_norm': 0.9231333136558533, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.115, 'grad_norm': 0.737852156162262, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0268, 'grad_norm': 0.9953347444534302, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.3699, 'grad_norm': 1.9752917289733887, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.3192, 'grad_norm': 2.30299973487854, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.5454, 'grad_norm': 0.6989319324493408, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0356, 'grad_norm': 1.8203140497207642, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.188, 'train_samples_per_second': 46.357, 'train_steps_per_second': 3.282, 'train_loss': 0.7630081260576844, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]                                              {'loss': 3.1381, 'grad_norm': 6.457444667816162, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]  5%|▌         | 2/40 [00:00<00:12,  2.95it/s]                                              {'loss': 2.9526, 'grad_norm': 8.907440185546875, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.95it/s]  8%|▊         | 3/40 [00:01<00:12,  2.95it/s]                                              {'loss': 1.9791, 'grad_norm': 9.571415901184082, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.95it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.662, 'grad_norm': 10.23196792602539, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.8552, 'grad_norm': 17.483301162719727, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.3244, 'grad_norm': 14.372147560119629, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 2.4808, 'grad_norm': 14.427733421325684, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.5185, 'grad_norm': 25.071847915649414, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 0.9893, 'grad_norm': 7.2240309715271, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.48it/s]                                               {'loss': 0.7093, 'grad_norm': 7.266376495361328, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.48it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s]                                               {'loss': 1.3223, 'grad_norm': 10.686541557312012, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s] 30%|███       | 12/40 [00:03<00:08,  3.22it/s]                                               {'loss': 1.8628, 'grad_norm': 12.387150764465332, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.22it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.13it/s]                                               {'loss': 1.172, 'grad_norm': 10.435935974121094, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.13it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.7147, 'grad_norm': 6.225147724151611, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.6665, 'grad_norm': 6.196089267730713, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.2155, 'grad_norm': 9.569622993469238, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.265, 'grad_norm': 3.459904909133911, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.4178, 'grad_norm': 4.813481330871582, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s]                                               {'loss': 0.2696, 'grad_norm': 4.1966776847839355, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.2561, 'grad_norm': 3.591536283493042, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.3444, 'grad_norm': 6.299337387084961, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.5257, 'grad_norm': 6.942023754119873, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.5064, 'grad_norm': 2.32954740524292, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.9932, 'grad_norm': 27.583484649658203, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.06it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s]                                               {'loss': 0.1442, 'grad_norm': 3.0278282165527344, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.1483, 'grad_norm': 5.198055744171143, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.0413, 'grad_norm': 0.6686834096908569, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.4705, 'grad_norm': 2.756781578063965, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.1029, 'grad_norm': 1.8538436889648438, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.0867, 'grad_norm': 1.4447190761566162, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.0573, 'grad_norm': 1.0308964252471924, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.4087, 'grad_norm': 24.723602294921875, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s]                                               {'loss': 0.0481, 'grad_norm': 2.0143706798553467, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.4134, 'grad_norm': 7.477204322814941, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.0433, 'grad_norm': 2.0304760932922363, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s]                                               {'loss': 0.066, 'grad_norm': 1.5563387870788574, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0488, 'grad_norm': 1.7088407278060913, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.063, 'grad_norm': 1.868811845779419, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.03it/s]                                               {'loss': 0.077, 'grad_norm': 2.245421886444092, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.03it/s]                                               {'loss': 0.4236, 'grad_norm': 17.32574462890625, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.03it/s]                                               {'train_runtime': 12.2918, 'train_samples_per_second': 45.966, 'train_steps_per_second': 3.254, 'train_loss': 0.7946059790439903, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.03it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.17it/s]                                              {'loss': 2.7614, 'grad_norm': 7.073061943054199, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.17it/s]  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]                                              {'loss': 2.7747, 'grad_norm': 8.440276145935059, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.039, 'grad_norm': 7.912003993988037, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.9675, 'grad_norm': 14.135026931762695, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.8088, 'grad_norm': 14.313337326049805, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.6379, 'grad_norm': 21.943986892700195, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.1402, 'grad_norm': 16.478010177612305, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.2886, 'grad_norm': 24.715391159057617, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 1.0814, 'grad_norm': 11.982034683227539, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.7614, 'grad_norm': 17.799211502075195, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 0.8734, 'grad_norm': 11.575166702270508, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.6199, 'grad_norm': 9.664501190185547, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 0.9819, 'grad_norm': 10.504878997802734, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.5131, 'grad_norm': 7.062454700469971, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.5669, 'grad_norm': 4.805613040924072, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.9305, 'grad_norm': 62.19385528564453, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.12it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s]                                               {'loss': 0.4106, 'grad_norm': 3.356060266494751, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.62it/s]                                               {'loss': 0.1198, 'grad_norm': 1.9973080158233643, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.62it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s]                                               {'loss': 0.5597, 'grad_norm': 8.012646675109863, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.2587, 'grad_norm': 3.7879068851470947, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.318, 'grad_norm': 4.038224220275879, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.2707, 'grad_norm': 6.496278285980225, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.3539, 'grad_norm': 6.336098670959473, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.1098, 'grad_norm': 13.740736961364746, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.4038, 'grad_norm': 1.533084511756897, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.041, 'grad_norm': 1.0784341096878052, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.47it/s]                                               {'loss': 0.4191, 'grad_norm': 3.4233791828155518, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.47it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.146, 'grad_norm': 3.230677843093872, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.0874, 'grad_norm': 4.775308132171631, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.2266, 'grad_norm': 4.695120334625244, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.121, 'grad_norm': 2.7335431575775146, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.8477, 'grad_norm': 51.72428894042969, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0825, 'grad_norm': 9.16402530670166, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.0223, 'grad_norm': 0.975907027721405, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0963, 'grad_norm': 1.0507161617279053, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0185, 'grad_norm': 0.4218076169490814, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.0227, 'grad_norm': 0.5414026975631714, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.3068, 'grad_norm': 4.326726913452148, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.768, 'grad_norm': 2.4606242179870605, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0019, 'grad_norm': 0.11958172172307968, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.064, 'train_samples_per_second': 46.834, 'train_steps_per_second': 3.316, 'train_loss': 0.7439845753018745, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:12
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.88it/s]                                              {'loss': 3.2243, 'grad_norm': 6.772474765777588, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.88it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 3.0092, 'grad_norm': 8.36902141571045, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  2.99it/s]                                              {'loss': 2.3648, 'grad_norm': 9.961919784545898, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.99it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 3.1235, 'grad_norm': 16.43565559387207, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.7338, 'grad_norm': 11.46251392364502, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:02<00:11,  3.00it/s]                                              {'loss': 1.9186, 'grad_norm': 15.597396850585938, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 2.4825, 'grad_norm': 13.732714653015137, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 2.3288, 'grad_norm': 55.78517532348633, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 0.8893, 'grad_norm': 11.835073471069336, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 1.2718, 'grad_norm': 9.561915397644043, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.45it/s]                                               {'loss': 0.4514, 'grad_norm': 5.183451175689697, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.45it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 0.8415, 'grad_norm': 7.369534969329834, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s]                                               {'loss': 1.044, 'grad_norm': 7.853484153747559, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.6455, 'grad_norm': 5.464286804199219, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.6225, 'grad_norm': 6.711005687713623, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.3066, 'grad_norm': 12.074654579162598, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.289, 'grad_norm': 4.212128639221191, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.3314, 'grad_norm': 5.99291467666626, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 1.0927, 'grad_norm': 6.017096996307373, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.2547, 'grad_norm': 5.404672145843506, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.2261, 'grad_norm': 3.6779322624206543, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.296, 'grad_norm': 4.67302942276001, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.2508, 'grad_norm': 3.3248777389526367, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0467, 'grad_norm': 2.3275351524353027, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.0873, 'grad_norm': 1.8494737148284912, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.1462, 'grad_norm': 2.8283567428588867, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.1629, 'grad_norm': 2.6121134757995605, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.5094, 'grad_norm': 1.7792667150497437, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.6494, 'grad_norm': 5.8264031410217285, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s]                                               {'loss': 0.1317, 'grad_norm': 2.9990756511688232, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0561, 'grad_norm': 1.1793818473815918, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0063, 'grad_norm': 0.2959105372428894, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.4682, 'grad_norm': 2.552405595779419, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.0465, 'grad_norm': 1.2822288274765015, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0401, 'grad_norm': 1.0641435384750366, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.0471, 'grad_norm': 1.083484411239624, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.4826, 'grad_norm': 0.8764906525611877, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.032, 'grad_norm': 0.6490309238433838, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.045, 'grad_norm': 1.2742340564727783, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0037, 'grad_norm': 0.30316486954689026, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0747, 'train_samples_per_second': 46.792, 'train_steps_per_second': 3.313, 'train_loss': 0.7990004096413031, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:87
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]                                              {'loss': 2.9847, 'grad_norm': 6.2186479568481445, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 2.318, 'grad_norm': 8.568305969238281, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  2.95it/s]                                              {'loss': 1.7943, 'grad_norm': 9.476033210754395, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.95it/s] 10%|█         | 4/40 [00:01<00:12,  3.00it/s]                                              {'loss': 1.6517, 'grad_norm': 14.019680976867676, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.6873, 'grad_norm': 13.151549339294434, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.6616, 'grad_norm': 19.96063995361328, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 2.9487, 'grad_norm': 22.474063873291016, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 2.4174, 'grad_norm': 75.80663299560547, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 0.6548, 'grad_norm': 9.403300285339355, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 0.9756, 'grad_norm': 12.394308090209961, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 1.5271, 'grad_norm': 11.78964614868164, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.878, 'grad_norm': 6.974084854125977, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 1.0071, 'grad_norm': 8.49836540222168, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.6324, 'grad_norm': 7.270816802978516, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.0625, 'grad_norm': 9.571307182312012, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.0565, 'grad_norm': 2.1362009048461914, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.5744, 'grad_norm': 6.065121173858643, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.5203, 'grad_norm': 4.991507530212402, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.709, 'grad_norm': 3.288217067718506, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.3235, 'grad_norm': 3.9725940227508545, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.2676, 'grad_norm': 3.2895267009735107, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.6133, 'grad_norm': 9.384672164916992, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.1085, 'grad_norm': 2.539994716644287, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 2.1892, 'grad_norm': 48.69155502319336, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.0925, 'grad_norm': 4.199275970458984, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.3215, 'grad_norm': 11.082771301269531, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.1514, 'grad_norm': 3.647357225418091, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.0572, 'grad_norm': 2.451685667037964, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.1022, 'grad_norm': 8.590249061584473, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.2273, 'grad_norm': 6.568620204925537, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.667, 'grad_norm': 4.288873672485352, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0648, 'grad_norm': 3.402677297592163, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.5453, 'grad_norm': 2.0844600200653076, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.0378, 'grad_norm': 0.8550774455070496, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.1004, 'grad_norm': 3.093473196029663, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.0585, 'grad_norm': 1.1474851369857788, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0462, 'grad_norm': 0.9669519066810608, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0754, 'grad_norm': 1.7321679592132568, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0457, 'grad_norm': 0.9584165215492249, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0055, 'grad_norm': 0.3132319152355194, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1604, 'train_samples_per_second': 46.462, 'train_steps_per_second': 3.289, 'train_loss': 0.829055534512736, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]                                              {'loss': 2.7971, 'grad_norm': 7.103287220001221, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 3.358, 'grad_norm': 9.573416709899902, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:00<00:12,  3.06it/s]                                              {'loss': 1.9115, 'grad_norm': 8.726365089416504, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.06it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.1294, 'grad_norm': 12.259156227111816, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 1.6608, 'grad_norm': 10.10744857788086, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s]                                              {'loss': 1.8384, 'grad_norm': 12.140546798706055, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 1.9618, 'grad_norm': 13.86115550994873, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 1.0175, 'grad_norm': 34.31438064575195, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.95it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 1.4407, 'grad_norm': 14.383647918701172, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 1.2873, 'grad_norm': 12.22626781463623, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 1.2996, 'grad_norm': 6.571141719818115, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 0.3884, 'grad_norm': 5.529952049255371, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.738, 'grad_norm': 6.1037678718566895, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.5262, 'grad_norm': 5.714874744415283, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.7938, 'grad_norm': 6.649053573608398, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.0764, 'grad_norm': 3.3563406467437744, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.3001, 'grad_norm': 3.007438898086548, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.2645, 'grad_norm': 3.621638536453247, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.2062, 'grad_norm': 2.950122356414795, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.5953, 'grad_norm': 3.112860679626465, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.4593, 'grad_norm': 3.0029327869415283, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.4857, 'grad_norm': 8.531197547912598, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.3341, 'grad_norm': 5.449514865875244, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.0459, 'grad_norm': 2.4475975036621094, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.0917, 'grad_norm': 2.447732925415039, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.7699, 'grad_norm': 2.9721813201904297, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.1539, 'grad_norm': 7.191500663757324, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.1022, 'grad_norm': 2.3993351459503174, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.0701, 'grad_norm': 2.8741567134857178, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.213, 'grad_norm': 3.1351776123046875, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.1513, 'grad_norm': 9.591239929199219, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0573, 'grad_norm': 2.9463539123535156, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s]                                               {'loss': 0.0895, 'grad_norm': 2.38602876663208, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0209, 'grad_norm': 0.4721101224422455, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.0519, 'grad_norm': 1.4860600233078003, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.3558, 'grad_norm': 2.7575838565826416, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.1834, 'grad_norm': 5.2661566734313965, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.4632, 'grad_norm': 2.9337430000305176, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0598, 'grad_norm': 1.5275973081588745, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0146, 'grad_norm': 1.7896193265914917, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.1775, 'train_samples_per_second': 46.397, 'train_steps_per_second': 3.285, 'train_loss': 0.7191158031579107, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:99
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 3.9681, 'grad_norm': 8.033126831054688, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 2.4561, 'grad_norm': 9.780166625976562, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.3647, 'grad_norm': 9.336701393127441, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.0058, 'grad_norm': 15.8822021484375, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.473, 'grad_norm': 18.55014991760254, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.8567, 'grad_norm': 20.031414031982422, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.956, 'grad_norm': 11.218286514282227, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s] 20%|██        | 8/40 [00:02<00:10,  3.08it/s]                                              {'loss': 2.226, 'grad_norm': 16.843717575073242, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.08it/s] 22%|██▎       | 9/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.8558, 'grad_norm': 12.965012550354004, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:10,  3.04it/s] 25%|██▌       | 10/40 [00:03<00:09,  3.00it/s]                                               {'loss': 0.7578, 'grad_norm': 8.003643989562988, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:09,  3.00it/s] 28%|██▊       | 11/40 [00:03<00:09,  2.97it/s]                                               {'loss': 0.7234, 'grad_norm': 8.45969295501709, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:09,  2.97it/s] 30%|███       | 12/40 [00:03<00:09,  2.97it/s]                                               {'loss': 0.7948, 'grad_norm': 11.167431831359863, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:09,  2.97it/s] 32%|███▎      | 13/40 [00:04<00:09,  2.98it/s]                                               {'loss': 0.935, 'grad_norm': 12.421991348266602, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:09,  2.98it/s] 35%|███▌      | 14/40 [00:04<00:08,  2.98it/s]                                               {'loss': 0.3863, 'grad_norm': 5.967860221862793, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  2.98it/s] 38%|███▊      | 15/40 [00:04<00:08,  2.99it/s]                                               {'loss': 0.9506, 'grad_norm': 7.306535720825195, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  2.99it/s] 40%|████      | 16/40 [00:05<00:07,  3.05it/s]                                               {'loss': 0.5887, 'grad_norm': 5.635308265686035, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:05<00:07,  3.05it/s] 42%|████▎     | 17/40 [00:05<00:07,  3.05it/s]                                               {'loss': 0.494, 'grad_norm': 4.479493141174316, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:07,  3.05it/s] 45%|████▌     | 18/40 [00:05<00:07,  3.02it/s]                                               {'loss': 0.1766, 'grad_norm': 2.7133755683898926, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:07,  3.02it/s] 48%|████▊     | 19/40 [00:06<00:06,  3.01it/s]                                               {'loss': 0.1786, 'grad_norm': 3.3022871017456055, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:06<00:06,  3.01it/s] 50%|█████     | 20/40 [00:06<00:06,  3.01it/s]                                               {'loss': 0.2533, 'grad_norm': 4.054466724395752, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.01it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.00it/s]                                               {'loss': 0.486, 'grad_norm': 6.6401591300964355, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.00it/s] 55%|█████▌    | 22/40 [00:07<00:05,  3.00it/s]                                               {'loss': 0.7101, 'grad_norm': 6.084471702575684, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:07<00:05,  3.00it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.00it/s]                                               {'loss': 0.395, 'grad_norm': 6.511544704437256, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.00it/s] 60%|██████    | 24/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.2439, 'grad_norm': 2.715120792388916, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:08<00:04,  3.04it/s]                                               {'loss': 0.145, 'grad_norm': 2.4801340103149414, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:08<00:04,  3.04it/s] 65%|██████▌   | 26/40 [00:08<00:04,  3.02it/s]                                               {'loss': 0.2492, 'grad_norm': 2.315661668777466, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:08<00:04,  3.02it/s] 68%|██████▊   | 27/40 [00:08<00:04,  3.02it/s]                                               {'loss': 0.5853, 'grad_norm': 2.4076285362243652, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:04,  3.02it/s] 70%|███████   | 28/40 [00:09<00:03,  3.01it/s]                                               {'loss': 0.1659, 'grad_norm': 4.079166889190674, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:09<00:03,  3.01it/s] 72%|███████▎  | 29/40 [00:09<00:03,  3.00it/s]                                               {'loss': 0.1151, 'grad_norm': 2.467432737350464, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:09<00:03,  3.00it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.00it/s]                                               {'loss': 0.1456, 'grad_norm': 3.774001359939575, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.00it/s] 78%|███████▊  | 31/40 [00:10<00:02,  3.00it/s]                                               {'loss': 0.0892, 'grad_norm': 2.082692861557007, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:10<00:02,  3.00it/s] 80%|████████  | 32/40 [00:10<00:02,  3.06it/s]                                               {'loss': 0.0893, 'grad_norm': 2.012263298034668, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:10<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:10<00:02,  3.03it/s]                                               {'loss': 0.0839, 'grad_norm': 2.733961820602417, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:02,  3.03it/s] 85%|████████▌ | 34/40 [00:11<00:01,  3.02it/s]                                               {'loss': 0.1123, 'grad_norm': 8.296697616577148, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:11<00:01,  3.02it/s] 88%|████████▊ | 35/40 [00:11<00:01,  3.00it/s]                                               {'loss': 0.0873, 'grad_norm': 3.4116671085357666, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:11<00:01,  3.00it/s] 90%|█████████ | 36/40 [00:11<00:01,  2.98it/s]                                               {'loss': 0.0483, 'grad_norm': 1.3045397996902466, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  2.98it/s] 92%|█████████▎| 37/40 [00:12<00:01,  2.99it/s]                                               {'loss': 0.3695, 'grad_norm': 6.444279193878174, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:12<00:01,  2.99it/s] 95%|█████████▌| 38/40 [00:12<00:00,  2.99it/s]                                               {'loss': 0.0364, 'grad_norm': 0.7699384689331055, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:12<00:00,  2.99it/s] 98%|█████████▊| 39/40 [00:12<00:00,  2.99it/s]                                               {'loss': 0.5869, 'grad_norm': 2.941364049911499, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  2.99it/s]100%|██████████| 40/40 [00:13<00:00,  3.06it/s]                                               {'loss': 0.0759, 'grad_norm': 1.6015653610229492, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:13<00:00,  3.06it/s]                                               {'train_runtime': 13.4704, 'train_samples_per_second': 47.14, 'train_steps_per_second': 2.969, 'train_loss': 0.8055311529897153, 'epoch': 5.0}
100%|██████████| 40/40 [00:13<00:00,  3.06it/s]100%|██████████| 40/40 [00:13<00:00,  2.97it/s]
CLIENT:85
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.08it/s]                                              {'loss': 0.2194, 'grad_norm': 2.131486654281616, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.08it/s]  5%|▌         | 2/40 [00:00<00:11,  3.19it/s]                                              {'loss': 0.0215, 'grad_norm': 0.48325011134147644, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:11,  3.19it/s]  8%|▊         | 3/40 [00:00<00:11,  3.10it/s]                                              {'loss': 0.0787, 'grad_norm': 3.9690375328063965, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.10it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 0.3268, 'grad_norm': 0.35717692971229553, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 0.0973, 'grad_norm': 0.9177937507629395, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 0.007, 'grad_norm': 0.09847326576709747, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.3192, 'grad_norm': 0.39968448877334595, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.0013, 'grad_norm': 0.03313343971967697, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 0.005, 'grad_norm': 0.05665210261940956, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 0.0072, 'grad_norm': 0.07452193647623062, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s]                                               {'loss': 0.0118, 'grad_norm': 0.16162404417991638, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.4463, 'grad_norm': 0.29977357387542725, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.0066, 'grad_norm': 0.07534637302160263, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.177, 'grad_norm': 0.3207423985004425, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.1656, 'grad_norm': 0.2951785922050476, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.0001, 'grad_norm': 0.001142421504482627, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 0.0035, 'grad_norm': 0.04430346190929413, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.0014, 'grad_norm': 0.019037464633584023, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.0029, 'grad_norm': 0.03316304832696915, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.153, 'grad_norm': 0.3050432801246643, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.0767, 'grad_norm': 0.21663127839565277, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.2629, 'grad_norm': 0.32154208421707153, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.2797, 'grad_norm': 0.43434861302375793, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.0018, 'grad_norm': 0.09860093146562576, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.12it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.0016, 'grad_norm': 0.015035168267786503, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.0022, 'grad_norm': 0.02711765468120575, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.1454, 'grad_norm': 0.3162091076374054, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.2692, 'grad_norm': 0.4493122100830078, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1706, 'grad_norm': 0.4683714807033539, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.0053, 'grad_norm': 0.09701324254274368, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.1931, 'grad_norm': 0.4824371933937073, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0, 'grad_norm': 0.00023079008678905666, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.0771, 'grad_norm': 0.18042036890983582, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.1142, 'grad_norm': 0.0985458642244339, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.2541, 'grad_norm': 0.26172664761543274, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.0023, 'grad_norm': 0.032990310341119766, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.1458, 'grad_norm': 0.26096901297569275, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0022, 'grad_norm': 0.024848517030477524, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.1877, 'grad_norm': 0.29075273871421814, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0025, 'grad_norm': 0.06697157025337219, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.1249, 'train_samples_per_second': 46.598, 'train_steps_per_second': 3.299, 'train_loss': 0.10614787638163534, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:43, 10.87it/s]  1%|          | 4/471 [00:00<01:08,  6.82it/s]  1%|          | 5/471 [00:00<01:14,  6.29it/s]  1%|▏         | 6/471 [00:00<01:17,  5.98it/s]  1%|▏         | 7/471 [00:01<01:20,  5.79it/s]  2%|▏         | 8/471 [00:01<01:21,  5.65it/s]  2%|▏         | 9/471 [00:01<01:22,  5.59it/s]  2%|▏         | 10/471 [00:01<01:23,  5.53it/s]  2%|▏         | 11/471 [00:01<01:23,  5.50it/s]  3%|▎         | 12/471 [00:02<01:24,  5.45it/s]  3%|▎         | 13/471 [00:02<01:24,  5.41it/s]  3%|▎         | 14/471 [00:02<01:24,  5.39it/s]  3%|▎         | 15/471 [00:02<01:24,  5.39it/s]  3%|▎         | 16/471 [00:02<01:24,  5.39it/s]  4%|▎         | 17/471 [00:02<01:24,  5.38it/s]  4%|▍         | 18/471 [00:03<01:24,  5.38it/s]  4%|▍         | 19/471 [00:03<01:24,  5.37it/s]  4%|▍         | 20/471 [00:03<01:23,  5.37it/s]  4%|▍         | 21/471 [00:03<01:23,  5.36it/s]  5%|▍         | 22/471 [00:03<01:23,  5.36it/s]  5%|▍         | 23/471 [00:04<01:23,  5.36it/s]  5%|▌         | 24/471 [00:04<01:23,  5.36it/s]  5%|▌         | 25/471 [00:04<01:22,  5.38it/s]  6%|▌         | 26/471 [00:04<01:22,  5.36it/s]  6%|▌         | 27/471 [00:04<01:22,  5.36it/s]  6%|▌         | 28/471 [00:05<01:22,  5.36it/s]  6%|▌         | 29/471 [00:05<01:22,  5.36it/s]  6%|▋         | 30/471 [00:05<01:22,  5.34it/s]  7%|▋         | 31/471 [00:05<01:22,  5.33it/s]  7%|▋         | 32/471 [00:05<01:21,  5.36it/s]  7%|▋         | 33/471 [00:05<01:21,  5.38it/s]  7%|▋         | 34/471 [00:06<01:21,  5.38it/s]  7%|▋         | 35/471 [00:06<01:21,  5.36it/s]  8%|▊         | 36/471 [00:06<01:21,  5.36it/s]  8%|▊         | 37/471 [00:06<01:21,  5.34it/s]  8%|▊         | 38/471 [00:06<01:20,  5.35it/s]  8%|▊         | 39/471 [00:07<01:20,  5.34it/s]  8%|▊         | 40/471 [00:07<01:20,  5.34it/s]  9%|▊         | 41/471 [00:07<01:20,  5.34it/s]  9%|▉         | 42/471 [00:07<01:20,  5.31it/s]  9%|▉         | 43/471 [00:07<01:20,  5.35it/s]  9%|▉         | 44/471 [00:08<01:19,  5.36it/s] 10%|▉         | 45/471 [00:08<01:19,  5.36it/s] 10%|▉         | 46/471 [00:08<01:19,  5.35it/s] 10%|▉         | 47/471 [00:08<01:19,  5.35it/s] 10%|█         | 48/471 [00:08<01:18,  5.37it/s] 10%|█         | 49/471 [00:08<01:18,  5.35it/s] 11%|█         | 50/471 [00:09<01:18,  5.34it/s] 11%|█         | 51/471 [00:09<01:18,  5.34it/s] 11%|█         | 52/471 [00:09<01:18,  5.34it/s] 11%|█▏        | 53/471 [00:09<01:18,  5.32it/s] 11%|█▏        | 54/471 [00:09<01:18,  5.32it/s] 12%|█▏        | 55/471 [00:10<01:18,  5.32it/s] 12%|█▏        | 56/471 [00:10<01:18,  5.31it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.33it/s] 12%|█▏        | 58/471 [00:10<01:17,  5.32it/s] 13%|█▎        | 59/471 [00:10<01:17,  5.32it/s] 13%|█▎        | 60/471 [00:11<01:17,  5.33it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.34it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.33it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.32it/s] 14%|█▎        | 64/471 [00:11<01:16,  5.31it/s] 14%|█▍        | 65/471 [00:11<01:16,  5.31it/s] 14%|█▍        | 66/471 [00:12<01:16,  5.32it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.32it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.31it/s] 15%|█▍        | 69/471 [00:12<01:15,  5.31it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.30it/s] 15%|█▌        | 71/471 [00:13<01:15,  5.31it/s] 15%|█▌        | 72/471 [00:13<01:15,  5.32it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.33it/s] 16%|█▌        | 74/471 [00:13<01:14,  5.33it/s] 16%|█▌        | 75/471 [00:13<01:14,  5.31it/s] 16%|█▌        | 76/471 [00:14<01:14,  5.32it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.33it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.33it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.31it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.30it/s] 17%|█▋        | 81/471 [00:14<01:13,  5.32it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.34it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.32it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.32it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.31it/s] 18%|█▊        | 86/471 [00:15<01:12,  5.32it/s] 18%|█▊        | 87/471 [00:16<01:11,  5.34it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.33it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.32it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.31it/s] 19%|█▉        | 91/471 [00:16<01:11,  5.33it/s] 20%|█▉        | 92/471 [00:17<01:11,  5.33it/s] 20%|█▉        | 93/471 [00:17<01:11,  5.31it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.32it/s] 20%|██        | 95/471 [00:17<01:10,  5.33it/s] 20%|██        | 96/471 [00:17<01:10,  5.34it/s] 21%|██        | 97/471 [00:17<01:10,  5.32it/s] 21%|██        | 98/471 [00:18<01:10,  5.32it/s] 21%|██        | 99/471 [00:18<01:09,  5.32it/s] 21%|██        | 100/471 [00:18<01:09,  5.35it/s] 21%|██▏       | 101/471 [00:18<01:09,  5.35it/s] 22%|██▏       | 102/471 [00:18<01:09,  5.33it/s] 22%|██▏       | 103/471 [00:19<01:09,  5.32it/s] 22%|██▏       | 104/471 [00:19<01:09,  5.31it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.30it/s] 23%|██▎       | 106/471 [00:19<01:08,  5.34it/s] 23%|██▎       | 107/471 [00:19<01:08,  5.35it/s] 23%|██▎       | 108/471 [00:20<01:07,  5.34it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.35it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.35it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.34it/s] 24%|██▍       | 112/471 [00:20<01:07,  5.33it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.36it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.34it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.33it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.33it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.32it/s] 25%|██▌       | 118/471 [00:21<01:06,  5.31it/s] 25%|██▌       | 119/471 [00:22<01:06,  5.31it/s] 25%|██▌       | 120/471 [00:22<01:06,  5.30it/s] 26%|██▌       | 121/471 [00:22<01:06,  5.30it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.31it/s] 26%|██▌       | 123/471 [00:22<01:05,  5.33it/s] 26%|██▋       | 124/471 [00:23<01:05,  5.31it/s] 27%|██▋       | 125/471 [00:23<01:05,  5.31it/s] 27%|██▋       | 126/471 [00:23<01:05,  5.30it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.31it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.32it/s] 27%|██▋       | 129/471 [00:23<01:04,  5.32it/s] 28%|██▊       | 130/471 [00:24<01:04,  5.32it/s] 28%|██▊       | 131/471 [00:24<01:04,  5.30it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.30it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.29it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.28it/s] 29%|██▊       | 135/471 [00:25<01:03,  5.29it/s] 29%|██▉       | 136/471 [00:25<01:03,  5.30it/s] 29%|██▉       | 137/471 [00:25<01:03,  5.30it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.29it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.31it/s] 30%|██▉       | 140/471 [00:26<01:02,  5.28it/s] 30%|██▉       | 141/471 [00:26<01:02,  5.31it/s] 30%|███       | 142/471 [00:26<01:01,  5.32it/s] 30%|███       | 143/471 [00:26<01:01,  5.31it/s] 31%|███       | 144/471 [00:26<01:01,  5.31it/s] 31%|███       | 145/471 [00:26<01:01,  5.32it/s] 31%|███       | 146/471 [00:27<01:01,  5.31it/s] 31%|███       | 147/471 [00:27<01:01,  5.30it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.30it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.29it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.29it/s] 32%|███▏      | 151/471 [00:28<01:00,  5.28it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.29it/s] 32%|███▏      | 153/471 [00:28<01:00,  5.28it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.31it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.31it/s] 33%|███▎      | 156/471 [00:29<00:59,  5.31it/s] 33%|███▎      | 157/471 [00:29<00:59,  5.31it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.31it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.32it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.32it/s] 34%|███▍      | 161/471 [00:30<00:58,  5.30it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.29it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.28it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.30it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.30it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.29it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.28it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.29it/s] 36%|███▌      | 169/471 [00:31<00:57,  5.28it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.30it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.30it/s] 37%|███▋      | 172/471 [00:32<00:56,  5.30it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.30it/s] 37%|███▋      | 174/471 [00:32<00:56,  5.29it/s] 37%|███▋      | 175/471 [00:32<00:56,  5.28it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.30it/s] 38%|███▊      | 177/471 [00:33<00:55,  5.31it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.31it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.31it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.30it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.28it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.28it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.28it/s] 39%|███▉      | 184/471 [00:34<00:54,  5.30it/s] 39%|███▉      | 185/471 [00:34<00:54,  5.29it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.28it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.26it/s] 40%|███▉      | 188/471 [00:35<00:53,  5.25it/s] 40%|████      | 189/471 [00:35<00:53,  5.27it/s] 40%|████      | 190/471 [00:35<00:53,  5.27it/s] 41%|████      | 191/471 [00:35<00:53,  5.26it/s] 41%|████      | 192/471 [00:35<00:52,  5.28it/s] 41%|████      | 193/471 [00:36<00:52,  5.30it/s] 41%|████      | 194/471 [00:36<00:52,  5.29it/s] 41%|████▏     | 195/471 [00:36<00:52,  5.29it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.29it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.31it/s] 42%|████▏     | 198/471 [00:37<00:51,  5.30it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.29it/s] 42%|████▏     | 200/471 [00:37<00:51,  5.28it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.30it/s] 43%|████▎     | 204/471 [00:38<00:50,  5.30it/s] 44%|████▎     | 205/471 [00:38<00:50,  5.30it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.30it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.29it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.31it/s] 44%|████▍     | 209/471 [00:39<00:49,  5.32it/s] 45%|████▍     | 210/471 [00:39<00:48,  5.33it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.32it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.30it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.31it/s] 45%|████▌     | 214/471 [00:40<00:48,  5.30it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.31it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.30it/s] 46%|████▌     | 217/471 [00:40<00:48,  5.28it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.28it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.28it/s] 47%|████▋     | 220/471 [00:41<00:47,  5.28it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.28it/s] 47%|████▋     | 222/471 [00:41<00:47,  5.29it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.31it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.30it/s] 48%|████▊     | 225/471 [00:42<00:46,  5.28it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.28it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.27it/s] 48%|████▊     | 228/471 [00:42<00:46,  5.28it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.26it/s] 49%|████▉     | 230/471 [00:43<00:45,  5.26it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.26it/s] 49%|████▉     | 232/471 [00:43<00:45,  5.29it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.29it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.29it/s] 50%|████▉     | 235/471 [00:44<00:44,  5.27it/s] 50%|█████     | 236/471 [00:44<00:44,  5.29it/s] 50%|█████     | 237/471 [00:44<00:44,  5.29it/s] 51%|█████     | 238/471 [00:44<00:44,  5.28it/s] 51%|█████     | 239/471 [00:44<00:43,  5.30it/s] 51%|█████     | 240/471 [00:44<00:43,  5.28it/s] 51%|█████     | 241/471 [00:45<00:43,  5.27it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.28it/s] 52%|█████▏    | 243/471 [00:45<00:43,  5.26it/s] 52%|█████▏    | 244/471 [00:45<00:43,  5.27it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.27it/s] 52%|█████▏    | 246/471 [00:46<00:42,  5.29it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.31it/s] 53%|█████▎    | 248/471 [00:46<00:42,  5.31it/s] 53%|█████▎    | 249/471 [00:46<00:42,  5.28it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.29it/s] 53%|█████▎    | 251/471 [00:47<00:41,  5.29it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.28it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.28it/s] 54%|█████▍    | 254/471 [00:47<00:41,  5.27it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.28it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.28it/s] 55%|█████▍    | 257/471 [00:48<00:40,  5.27it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.28it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.27it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.28it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.28it/s] 56%|█████▌    | 262/471 [00:49<00:39,  5.30it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.29it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.29it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.28it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.28it/s] 57%|█████▋    | 267/471 [00:50<00:38,  5.28it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.27it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.28it/s] 57%|█████▋    | 270/471 [00:50<00:38,  5.29it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.28it/s] 58%|█████▊    | 272/471 [00:51<00:37,  5.30it/s] 58%|█████▊    | 273/471 [00:51<00:37,  5.31it/s] 58%|█████▊    | 274/471 [00:51<00:36,  5.34it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.32it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.30it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.29it/s] 59%|█████▉    | 278/471 [00:52<00:36,  5.29it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.31it/s] 59%|█████▉    | 280/471 [00:52<00:35,  5.32it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.29it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.29it/s] 60%|██████    | 283/471 [00:53<00:35,  5.29it/s] 60%|██████    | 284/471 [00:53<00:35,  5.30it/s] 61%|██████    | 285/471 [00:53<00:35,  5.29it/s] 61%|██████    | 286/471 [00:53<00:35,  5.29it/s] 61%|██████    | 287/471 [00:53<00:34,  5.29it/s] 61%|██████    | 288/471 [00:54<00:34,  5.28it/s] 61%|██████▏   | 289/471 [00:54<00:34,  5.31it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.32it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.31it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.31it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.32it/s] 62%|██████▏   | 294/471 [00:55<00:33,  5.32it/s] 63%|██████▎   | 295/471 [00:55<00:33,  5.33it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.32it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.32it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.30it/s] 63%|██████▎   | 299/471 [00:56<00:32,  5.30it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.30it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.30it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.30it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.30it/s] 65%|██████▍   | 304/471 [00:57<00:31,  5.31it/s] 65%|██████▍   | 305/471 [00:57<00:31,  5.30it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.29it/s] 65%|██████▌   | 307/471 [00:57<00:31,  5.28it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.28it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.27it/s] 66%|██████▌   | 310/471 [00:58<00:30,  5.29it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.29it/s] 66%|██████▌   | 312/471 [00:58<00:29,  5.30it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.30it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.30it/s] 67%|██████▋   | 315/471 [00:59<00:29,  5.30it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.31it/s] 67%|██████▋   | 317/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.31it/s] 68%|██████▊   | 320/471 [01:00<00:28,  5.29it/s] 68%|██████▊   | 321/471 [01:00<00:28,  5.28it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.28it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.28it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.26it/s] 69%|██████▉   | 325/471 [01:01<00:27,  5.28it/s] 69%|██████▉   | 326/471 [01:01<00:27,  5.28it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.29it/s] 70%|██████▉   | 328/471 [01:01<00:27,  5.29it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.27it/s] 70%|███████   | 330/471 [01:01<00:26,  5.29it/s] 70%|███████   | 331/471 [01:02<00:26,  5.29it/s] 70%|███████   | 332/471 [01:02<00:26,  5.28it/s] 71%|███████   | 333/471 [01:02<00:26,  5.29it/s] 71%|███████   | 334/471 [01:02<00:25,  5.29it/s] 71%|███████   | 335/471 [01:02<00:25,  5.28it/s] 71%|███████▏  | 336/471 [01:03<00:25,  5.29it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.31it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.30it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.29it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.28it/s] 72%|███████▏  | 341/471 [01:04<00:24,  5.29it/s] 73%|███████▎  | 342/471 [01:04<00:24,  5.30it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.29it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.30it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.28it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.27it/s] 74%|███████▎  | 347/471 [01:05<00:23,  5.30it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.29it/s] 74%|███████▍  | 349/471 [01:05<00:23,  5.28it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.27it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.29it/s] 75%|███████▍  | 352/471 [01:06<00:22,  5.28it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.26it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.27it/s] 75%|███████▌  | 355/471 [01:06<00:22,  5.27it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.26it/s] 76%|███████▌  | 357/471 [01:07<00:21,  5.27it/s] 76%|███████▌  | 358/471 [01:07<00:21,  5.28it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.27it/s] 76%|███████▋  | 360/471 [01:07<00:21,  5.28it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.29it/s] 77%|███████▋  | 362/471 [01:08<00:20,  5.30it/s] 77%|███████▋  | 363/471 [01:08<00:20,  5.30it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.30it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.29it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.28it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.29it/s] 78%|███████▊  | 368/471 [01:09<00:19,  5.29it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.30it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.29it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.29it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 373/471 [01:10<00:18,  5.29it/s] 79%|███████▉  | 374/471 [01:10<00:18,  5.31it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.29it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.30it/s] 80%|████████  | 377/471 [01:10<00:17,  5.30it/s] 80%|████████  | 378/471 [01:11<00:17,  5.33it/s] 80%|████████  | 379/471 [01:11<00:17,  5.32it/s] 81%|████████  | 380/471 [01:11<00:17,  5.30it/s] 81%|████████  | 381/471 [01:11<00:16,  5.30it/s] 81%|████████  | 382/471 [01:11<00:16,  5.29it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.28it/s] 82%|████████▏ | 384/471 [01:12<00:16,  5.27it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.28it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.27it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.27it/s] 83%|████████▎ | 389/471 [01:13<00:15,  5.28it/s] 83%|████████▎ | 390/471 [01:13<00:15,  5.28it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.29it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.29it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.30it/s] 84%|████████▎ | 394/471 [01:14<00:14,  5.28it/s] 84%|████████▍ | 395/471 [01:14<00:14,  5.28it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.27it/s] 84%|████████▍ | 397/471 [01:14<00:13,  5.29it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.29it/s] 85%|████████▍ | 399/471 [01:15<00:13,  5.27it/s] 85%|████████▍ | 400/471 [01:15<00:13,  5.27it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.28it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.27it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.28it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.28it/s] 86%|████████▌ | 405/471 [01:16<00:12,  5.27it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.28it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.30it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.29it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.28it/s] 87%|████████▋ | 410/471 [01:17<00:11,  5.30it/s] 87%|████████▋ | 411/471 [01:17<00:11,  5.31it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.30it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.30it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.28it/s] 88%|████████▊ | 415/471 [01:18<00:10,  5.30it/s] 88%|████████▊ | 416/471 [01:18<00:10,  5.29it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.30it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.29it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.30it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.33it/s] 89%|████████▉ | 421/471 [01:19<00:09,  5.31it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.31it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.32it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.32it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.34it/s] 90%|█████████ | 426/471 [01:20<00:08,  5.30it/s] 91%|█████████ | 427/471 [01:20<00:08,  5.30it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.29it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.30it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.30it/s] 92%|█████████▏| 431/471 [01:21<00:07,  5.28it/s] 92%|█████████▏| 432/471 [01:21<00:07,  5.29it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.29it/s] 92%|█████████▏| 434/471 [01:21<00:06,  5.29it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.28it/s] 93%|█████████▎| 436/471 [01:21<00:06,  5.30it/s] 93%|█████████▎| 437/471 [01:22<00:06,  5.28it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.28it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.30it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.27it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.31it/s] 94%|█████████▍| 442/471 [01:23<00:05,  5.32it/s] 94%|█████████▍| 443/471 [01:23<00:05,  5.32it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.30it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.29it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.28it/s] 95%|█████████▍| 447/471 [01:24<00:04,  5.29it/s] 95%|█████████▌| 448/471 [01:24<00:04,  5.30it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.30it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.30it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.31it/s] 96%|█████████▌| 452/471 [01:25<00:03,  5.31it/s] 96%|█████████▌| 453/471 [01:25<00:03,  5.28it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.27it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.28it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.28it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.28it/s] 97%|█████████▋| 458/471 [01:26<00:02,  5.28it/s] 97%|█████████▋| 459/471 [01:26<00:02,  5.30it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.31it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.30it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.30it/s] 98%|█████████▊| 463/471 [01:27<00:01,  5.29it/s] 99%|█████████▊| 464/471 [01:27<00:01,  5.29it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.30it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.29it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.28it/s] 99%|█████████▉| 468/471 [01:28<00:00,  5.27it/s]100%|█████████▉| 469/471 [01:28<00:00,  5.29it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.30it/s]100%|██████████| 471/471 [01:28<00:00,  5.67it/s]100%|██████████| 471/471 [01:28<00:00,  5.32it/s]
{'eval_loss': 3.1458640098571777, 'eval_model_preparation_time': 0.005, 'eval_acc': 0.24429102496016994, 'eval_runtime': 88.7385, 'eval_samples_per_second': 84.879, 'eval_steps_per_second': 5.308}
ROUND:9
CLIENT:8
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]                                              {'loss': 2.8052, 'grad_norm': 6.737730979919434, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.8416, 'grad_norm': 7.216056823730469, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.7174, 'grad_norm': 7.4757513999938965, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.2252, 'grad_norm': 13.746155738830566, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.2152, 'grad_norm': 14.717303276062012, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.6717, 'grad_norm': 14.972677230834961, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 1.5647, 'grad_norm': 13.84950065612793, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 0.0528, 'grad_norm': 2.6265487670898438, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.98it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 0.5637, 'grad_norm': 6.843684673309326, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 0.3857, 'grad_norm': 7.106994152069092, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 0.6848, 'grad_norm': 8.78305435180664, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 1.132, 'grad_norm': 7.38579797744751, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.8521, 'grad_norm': 6.631694316864014, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.1134, 'grad_norm': 9.107065200805664, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.8609, 'grad_norm': 8.468888282775879, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.0122, 'grad_norm': 0.6013278365135193, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.61it/s]                                               {'loss': 0.3587, 'grad_norm': 3.8003718852996826, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.61it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.2198, 'grad_norm': 3.5434248447418213, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.41it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.30it/s]                                               {'loss': 0.1704, 'grad_norm': 2.686056137084961, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.30it/s] 50%|█████     | 20/40 [00:06<00:06,  3.20it/s]                                               {'loss': 0.1085, 'grad_norm': 2.1229183673858643, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.20it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.12it/s]                                               {'loss': 0.1863, 'grad_norm': 2.843222141265869, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.12it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s]                                               {'loss': 0.1374, 'grad_norm': 2.8862922191619873, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.4172, 'grad_norm': 2.135418176651001, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.0212, 'grad_norm': 1.1286734342575073, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.04it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s]                                               {'loss': 0.0739, 'grad_norm': 2.3958258628845215, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s]                                               {'loss': 0.0463, 'grad_norm': 1.8354790210723877, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.1454, 'grad_norm': 3.5731279850006104, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s] 70%|███████   | 28/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.342, 'grad_norm': 1.5922633409500122, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.22it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s]                                               {'loss': 0.0775, 'grad_norm': 1.7097511291503906, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.08it/s]                                               {'loss': 0.1032, 'grad_norm': 3.941344738006592, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.08it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.04it/s]                                               {'loss': 0.0332, 'grad_norm': 0.7274373769760132, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.04it/s]                                               {'loss': 0.0079, 'grad_norm': 0.5809173583984375, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.04it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.73it/s]                                               {'loss': 0.0152, 'grad_norm': 0.33600038290023804, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.73it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.2868, 'grad_norm': 4.181975364685059, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0708, 'grad_norm': 2.388545036315918, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.23it/s]                                               {'loss': 0.0893, 'grad_norm': 3.7276771068573, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.23it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0589, 'grad_norm': 1.6040898561477661, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0785, 'grad_norm': 3.7302937507629395, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.06it/s]                                               {'loss': 0.1607, 'grad_norm': 8.831685066223145, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.06it/s]                                               {'loss': 0.0035, 'grad_norm': 0.29684337973594666, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]                                               {'train_runtime': 12.3652, 'train_samples_per_second': 45.693, 'train_steps_per_second': 3.235, 'train_loss': 0.6227816964325029, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.23it/s]
CLIENT:93
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.531, 'grad_norm': 7.298038005828857, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.1792, 'grad_norm': 9.559751510620117, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.7099, 'grad_norm': 11.802614212036133, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.7854, 'grad_norm': 11.578245162963867, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 1.9872, 'grad_norm': 11.262467384338379, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s]                                              {'loss': 1.9307, 'grad_norm': 11.540128707885742, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 2.4279, 'grad_norm': 11.365617752075195, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 0.8687, 'grad_norm': 48.08599853515625, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 0.8975, 'grad_norm': 9.827310562133789, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 0.6846, 'grad_norm': 7.858453750610352, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 0.6743, 'grad_norm': 5.993509769439697, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 0.7921, 'grad_norm': 6.279303073883057, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.8808, 'grad_norm': 6.443485260009766, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.6662, 'grad_norm': 9.024712562561035, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.7246, 'grad_norm': 7.538071155548096, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.7205, 'grad_norm': 20.741716384887695, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.2219, 'grad_norm': 4.8489885330200195, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.2451, 'grad_norm': 3.619109869003296, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.729, 'grad_norm': 7.076564311981201, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.4725, 'grad_norm': 5.962048053741455, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.1278, 'grad_norm': 2.9870264530181885, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.08it/s]                                               {'loss': 0.1134, 'grad_norm': 2.545978546142578, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.08it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.5609, 'grad_norm': 2.6784253120422363, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.346, 'grad_norm': 31.622957229614258, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.0723, 'grad_norm': 1.6447280645370483, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.0514, 'grad_norm': 1.5190179347991943, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.027, 'grad_norm': 0.5814860463142395, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.3355, 'grad_norm': 1.0324863195419312, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.085, 'grad_norm': 1.6972486972808838, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.4379, 'grad_norm': 1.2992641925811768, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0647, 'grad_norm': 1.284049391746521, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0309, 'grad_norm': 2.1094799041748047, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.0347, 'grad_norm': 1.220233678817749, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.131, 'grad_norm': 9.191010475158691, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.0648, 'grad_norm': 3.0802321434020996, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.6037, 'grad_norm': 1.2416239976882935, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0258, 'grad_norm': 1.1948579549789429, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1109, 'grad_norm': 3.2622952461242676, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0348, 'grad_norm': 0.9820829629898071, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.1473, 'grad_norm': 10.637872695922852, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.2377, 'train_samples_per_second': 46.169, 'train_steps_per_second': 3.269, 'train_loss': 0.7133831347338855, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.27it/s]
CLIENT:4
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.2319, 'grad_norm': 6.330028533935547, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]                                              {'loss': 3.7392, 'grad_norm': 8.894116401672363, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.3288, 'grad_norm': 11.915443420410156, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.1704, 'grad_norm': 12.135272026062012, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.3891, 'grad_norm': 15.59732437133789, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.7622, 'grad_norm': 10.254532814025879, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.07it/s]                                              {'loss': 2.1926, 'grad_norm': 18.11803436279297, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.07it/s]                                              {'loss': 0.0932, 'grad_norm': 4.788687705993652, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.07it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s]                                              {'loss': 0.9041, 'grad_norm': 9.512112617492676, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s]                                               {'loss': 1.8186, 'grad_norm': 16.091405868530273, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.49it/s]                                               {'loss': 0.6967, 'grad_norm': 8.3885498046875, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.49it/s] 30%|███       | 12/40 [00:03<00:08,  3.32it/s]                                               {'loss': 0.9406, 'grad_norm': 6.960311412811279, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.32it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s]                                               {'loss': 0.8583, 'grad_norm': 5.6734843254089355, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.957, 'grad_norm': 6.95486307144165, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.15it/s]                                               {'loss': 1.2715, 'grad_norm': 8.481023788452148, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.15it/s]                                               {'loss': 0.9998, 'grad_norm': 34.236000061035156, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.15it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s]                                               {'loss': 0.2011, 'grad_norm': 4.580316543579102, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s]                                               {'loss': 0.3859, 'grad_norm': 4.262186527252197, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s]                                               {'loss': 0.662, 'grad_norm': 3.8240139484405518, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.6977, 'grad_norm': 9.042180061340332, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s]                                               {'loss': 0.7679, 'grad_norm': 4.383822441101074, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.164, 'grad_norm': 2.8971385955810547, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s] 57%|█████▊    | 23/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.5249, 'grad_norm': 3.897681474685669, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:06<00:05,  3.13it/s]                                               {'loss': 1.0721, 'grad_norm': 0.9786168932914734, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.13it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s]                                               {'loss': 0.1985, 'grad_norm': 1.705910086631775, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s]                                               {'loss': 0.2567, 'grad_norm': 4.810391426086426, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.50it/s]                                               {'loss': 0.4772, 'grad_norm': 3.0511081218719482, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.50it/s] 70%|███████   | 28/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.4518, 'grad_norm': 0.9585572481155396, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.36it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.1477, 'grad_norm': 2.6035473346710205, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s]                                               {'loss': 0.5981, 'grad_norm': 1.345566987991333, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0671, 'grad_norm': 1.5006752014160156, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0088, 'grad_norm': 0.518864095211029, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.3559, 'grad_norm': 0.3948074281215668, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.65it/s]                                               {'loss': 0.1451, 'grad_norm': 0.5454530119895935, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.65it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.47it/s]                                               {'loss': 0.4459, 'grad_norm': 0.9888216853141785, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.47it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s]                                               {'loss': 0.0843, 'grad_norm': 0.6421292424201965, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s]                                               {'loss': 0.1703, 'grad_norm': 1.4687039852142334, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.4972, 'grad_norm': 2.432147979736328, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.18it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0259, 'grad_norm': 0.637896716594696, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.1227, 'grad_norm': 7.209078311920166, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.14it/s]                                               {'train_runtime': 11.973, 'train_samples_per_second': 47.189, 'train_steps_per_second': 3.341, 'train_loss': 0.8470737354597077, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.14it/s]100%|██████████| 40/40 [00:11<00:00,  3.34it/s]
CLIENT:5
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.9354, 'grad_norm': 6.417722225189209, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 2.6878, 'grad_norm': 8.958431243896484, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:01<00:12,  2.98it/s]                                              {'loss': 1.5876, 'grad_norm': 7.46202278137207, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.98it/s] 10%|█         | 4/40 [00:01<00:12,  2.98it/s]                                              {'loss': 1.8771, 'grad_norm': 11.52624797821045, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.98it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 3.2424, 'grad_norm': 16.1299991607666, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.8571, 'grad_norm': 16.87066650390625, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 2.6774, 'grad_norm': 16.207080841064453, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 1.202, 'grad_norm': 47.373695373535156, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.98it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 0.5615, 'grad_norm': 10.889148712158203, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s]                                               {'loss': 0.7977, 'grad_norm': 7.8405866622924805, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 1.0929, 'grad_norm': 7.742812156677246, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 1.1109, 'grad_norm': 6.543449878692627, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 1.3254, 'grad_norm': 7.579892158508301, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.8034, 'grad_norm': 5.824418544769287, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.7266, 'grad_norm': 6.045753002166748, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.1292, 'grad_norm': 7.890941619873047, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.2321, 'grad_norm': 3.7308716773986816, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.6975, 'grad_norm': 5.1707353591918945, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.294, 'grad_norm': 2.155811071395874, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.2638, 'grad_norm': 4.55443811416626, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.9079, 'grad_norm': 3.7033491134643555, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.2157, 'grad_norm': 4.011051177978516, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.3894, 'grad_norm': 4.212502956390381, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0746, 'grad_norm': 5.578682899475098, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.4238, 'grad_norm': 0.8913264274597168, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.1366, 'grad_norm': 2.458949565887451, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.5709, 'grad_norm': 4.204806804656982, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.1926, 'grad_norm': 1.6653512716293335, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.1923, 'grad_norm': 6.710592746734619, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.0658, 'grad_norm': 1.3809343576431274, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0551, 'grad_norm': 1.3199712038040161, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.2246, 'grad_norm': 13.210372924804688, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.091, 'grad_norm': 3.4160706996917725, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.4151, 'grad_norm': 1.0752934217453003, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.0762, 'grad_norm': 2.944636821746826, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.6056, 'grad_norm': 0.6885500550270081, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.0652, 'grad_norm': 2.028388500213623, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.1214, 'grad_norm': 2.2614266872406006, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0332, 'grad_norm': 0.9755030274391174, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0185, 'grad_norm': 1.7154277563095093, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1633, 'train_samples_per_second': 46.451, 'train_steps_per_second': 3.289, 'train_loss': 0.7744365944061429, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:52
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]                                              {'loss': 4.0302, 'grad_norm': 7.614468097686768, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.09it/s]                                              {'loss': 2.554, 'grad_norm': 11.991185188293457, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.09it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 2.3162, 'grad_norm': 9.77645492553711, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:12,  3.00it/s]                                              {'loss': 2.226, 'grad_norm': 14.295259475708008, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.4006, 'grad_norm': 15.035197257995605, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.3142, 'grad_norm': 23.918254852294922, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 2.0114, 'grad_norm': 23.292987823486328, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.0395, 'grad_norm': 3.670565366744995, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 0.544, 'grad_norm': 4.082732200622559, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 0.9656, 'grad_norm': 11.451117515563965, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 1.0143, 'grad_norm': 10.378963470458984, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 0.7298, 'grad_norm': 13.042410850524902, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.2015, 'grad_norm': 7.121805667877197, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.1017, 'grad_norm': 10.19549560546875, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.6992, 'grad_norm': 7.5087809562683105, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.0443, 'grad_norm': 1.8740942478179932, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.05it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.4207, 'grad_norm': 6.211363315582275, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s]                                               {'loss': 0.5706, 'grad_norm': 5.797924041748047, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s]                                               {'loss': 0.2415, 'grad_norm': 3.883394956588745, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.637, 'grad_norm': 3.9692981243133545, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.3095, 'grad_norm': 6.0202555656433105, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.3094, 'grad_norm': 4.77503776550293, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.6679, 'grad_norm': 4.3087334632873535, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.375, 'grad_norm': 21.78131103515625, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s]                                               {'loss': 0.2206, 'grad_norm': 5.090528964996338, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.1985, 'grad_norm': 4.589127063751221, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.4157, 'grad_norm': 2.2427423000335693, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.1228, 'grad_norm': 2.811143159866333, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.4243, 'grad_norm': 1.2648327350616455, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.1265, 'grad_norm': 9.372318267822266, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.124, 'grad_norm': 3.1877281665802, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.0024, 'grad_norm': 0.09569992870092392, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s]                                               {'loss': 0.056, 'grad_norm': 1.4731101989746094, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s]                                               {'loss': 0.0442, 'grad_norm': 0.8518513441085815, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.3737, 'grad_norm': 1.2461762428283691, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s]                                               {'loss': 0.069, 'grad_norm': 1.7242083549499512, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0414, 'grad_norm': 1.460850715637207, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.4353, 'grad_norm': 2.0641884803771973, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0818, 'grad_norm': 2.7054057121276855, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.1622, 'grad_norm': 24.611875534057617, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.2153, 'train_samples_per_second': 46.253, 'train_steps_per_second': 3.275, 'train_loss': 0.7655645173159428, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.27it/s]
CLIENT:41
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 3.5772, 'grad_norm': 7.295320987701416, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 2.3027, 'grad_norm': 8.635723114013672, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.7502, 'grad_norm': 10.615281105041504, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.07it/s]                                              {'loss': 2.1477, 'grad_norm': 15.185785293579102, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.07it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.09it/s]                                              {'loss': 2.3096, 'grad_norm': 15.710527420043945, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.09it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 3.0465, 'grad_norm': 21.872867584228516, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 2.0398, 'grad_norm': 20.71306037902832, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 5.4042, 'grad_norm': 72.71994018554688, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.05it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s]                                              {'loss': 0.6966, 'grad_norm': 10.315800666809082, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.64it/s]                                               {'loss': 0.8594, 'grad_norm': 12.028141021728516, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.64it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.45it/s]                                               {'loss': 0.9444, 'grad_norm': 11.987703323364258, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.45it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.9624, 'grad_norm': 11.252508163452148, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 1.0837, 'grad_norm': 11.237010955810547, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.7536, 'grad_norm': 6.052650451660156, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.2298, 'grad_norm': 5.555028438568115, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.083, 'grad_norm': 6.416995525360107, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.12it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.7841, 'grad_norm': 6.223909378051758, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.6945, 'grad_norm': 5.4017252922058105, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.6091, 'grad_norm': 6.755274772644043, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.3121, 'grad_norm': 4.311402320861816, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.3678, 'grad_norm': 7.0306315422058105, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.3223, 'grad_norm': 6.773540019989014, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.7012, 'grad_norm': 9.14778995513916, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.8227, 'grad_norm': 38.42649841308594, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.543, 'grad_norm': 3.524007558822632, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s]                                               {'loss': 0.2165, 'grad_norm': 2.873671770095825, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.1028, 'grad_norm': 1.660576343536377, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.0934, 'grad_norm': 2.286161184310913, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.1484, 'grad_norm': 3.292435646057129, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.164, 'grad_norm': 3.6369783878326416, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1757, 'grad_norm': 3.010901927947998, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 5.8506, 'grad_norm': 6.316789627075195, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.0668, 'grad_norm': 1.5718857049942017, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.4773, 'grad_norm': 1.567615270614624, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.1182, 'grad_norm': 3.9275031089782715, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.1276, 'grad_norm': 5.599187850952148, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.1096, 'grad_norm': 5.875800609588623, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.2754, 'grad_norm': 6.8371381759643555, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.3897, 'grad_norm': 5.894708633422852, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0211, 'grad_norm': 1.620607614517212, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.0936, 'train_samples_per_second': 46.719, 'train_steps_per_second': 3.308, 'train_loss': 1.0671148964669555, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:0
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 3.1436, 'grad_norm': 7.317488670349121, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.15it/s]                                              {'loss': 2.9599, 'grad_norm': 9.198535919189453, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.15it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 1.7707, 'grad_norm': 11.838356018066406, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.1893, 'grad_norm': 13.073230743408203, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.08it/s]                                              {'loss': 1.8347, 'grad_norm': 14.287409782409668, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.08it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.8079, 'grad_norm': 18.146381378173828, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.8494, 'grad_norm': 16.044477462768555, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 0.0383, 'grad_norm': 3.080221652984619, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 0.8671, 'grad_norm': 7.560023784637451, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 0.7294, 'grad_norm': 10.084644317626953, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.0676, 'grad_norm': 11.293835639953613, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.468, 'grad_norm': 7.414798259735107, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.5703, 'grad_norm': 4.372974872589111, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.7347, 'grad_norm': 6.5197248458862305, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.0623, 'grad_norm': 7.096012115478516, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.1016, 'grad_norm': 37.75151824951172, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s]                                               {'loss': 0.4273, 'grad_norm': 4.116352558135986, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.2769, 'grad_norm': 4.560558795928955, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.2442, 'grad_norm': 3.7766225337982178, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.38, 'grad_norm': 4.639615058898926, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.3851, 'grad_norm': 3.594209671020508, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.3809, 'grad_norm': 2.4118459224700928, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.2181, 'grad_norm': 4.113367080688477, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0693, 'grad_norm': 6.244442462921143, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.4844, 'grad_norm': 6.405135631561279, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s]                                               {'loss': 0.1855, 'grad_norm': 6.808000564575195, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.0886, 'grad_norm': 2.6211156845092773, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.0888, 'grad_norm': 3.224108934402466, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.224, 'grad_norm': 2.289534330368042, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.2185, 'grad_norm': 3.0277576446533203, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.2409, 'grad_norm': 1.52812659740448, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.033, 'grad_norm': 1.6284040212631226, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.1222, 'grad_norm': 2.658745050430298, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.2221, 'grad_norm': 2.8789315223693848, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.3201, 'grad_norm': 1.9959393739700317, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.0954, 'grad_norm': 4.1506123542785645, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.148, 'grad_norm': 7.462138652801514, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.2706, 'grad_norm': 10.740819931030273, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0667, 'grad_norm': 2.575587749481201, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0314, 'grad_norm': 3.349156141281128, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.077, 'train_samples_per_second': 46.783, 'train_steps_per_second': 3.312, 'train_loss': 0.6854128675535321, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:73
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]                                              {'loss': 4.0755, 'grad_norm': 7.0843825340271, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 2.7273, 'grad_norm': 8.468624114990234, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:00<00:11,  3.10it/s]                                              {'loss': 1.8999, 'grad_norm': 11.416468620300293, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.10it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.1818, 'grad_norm': 11.867537498474121, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 1.5285, 'grad_norm': 12.652609825134277, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s]                                              {'loss': 0.9964, 'grad_norm': 10.685266494750977, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.1192, 'grad_norm': 9.856743812561035, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 0.767, 'grad_norm': 30.294546127319336, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 0.9016, 'grad_norm': 11.501579284667969, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 0.1654, 'grad_norm': 3.5498297214508057, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.9443, 'grad_norm': 10.505667686462402, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.4953, 'grad_norm': 11.999191284179688, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.3129, 'grad_norm': 6.028415679931641, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.6829, 'grad_norm': 8.13722038269043, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.4642, 'grad_norm': 5.125178337097168, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.2242, 'grad_norm': 12.181693077087402, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.1918, 'grad_norm': 3.8173182010650635, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.1026, 'grad_norm': 1.6215589046478271, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.1335, 'grad_norm': 2.9208152294158936, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.2081, 'grad_norm': 3.2658979892730713, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.2629, 'grad_norm': 3.6377217769622803, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.1426, 'grad_norm': 2.367110252380371, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.1005, 'grad_norm': 2.758800745010376, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0022, 'grad_norm': 0.13737429678440094, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.0356, 'grad_norm': 1.0402158498764038, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.088, 'grad_norm': 3.4783291816711426, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.0252, 'grad_norm': 1.748232364654541, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.0286, 'grad_norm': 0.7604619264602661, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.0235, 'grad_norm': 0.5492788553237915, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.0325, 'grad_norm': 1.0822231769561768, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0295, 'grad_norm': 0.9933904409408569, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0429, 'grad_norm': 2.414520263671875, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s]                                               {'loss': 0.0137, 'grad_norm': 0.3324200212955475, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s]                                               {'loss': 0.0416, 'grad_norm': 1.5719817876815796, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.0588, 'grad_norm': 2.131192207336426, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0422, 'grad_norm': 1.1419094800949097, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0433, 'grad_norm': 1.0517842769622803, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.157, 'grad_norm': 3.582118272781372, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0738, 'grad_norm': 1.9097621440887451, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0161, 'grad_norm': 0.7211764454841614, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.1823, 'train_samples_per_second': 46.379, 'train_steps_per_second': 3.283, 'train_loss': 0.5345746951643378, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:88
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.0648, 'grad_norm': 9.51226806640625, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.8335, 'grad_norm': 9.143966674804688, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.0516, 'grad_norm': 8.443480491638184, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 2.2261, 'grad_norm': 12.151772499084473, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.8824, 'grad_norm': 12.715316772460938, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 0.9415, 'grad_norm': 17.01085662841797, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.7725, 'grad_norm': 15.619369506835938, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.6112, 'grad_norm': 77.27809143066406, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 0.7248, 'grad_norm': 10.940057754516602, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 0.6796, 'grad_norm': 13.984979629516602, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 0.4298, 'grad_norm': 8.201617240905762, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 1.2263, 'grad_norm': 8.481183052062988, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.3187, 'grad_norm': 4.85455846786499, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.5321, 'grad_norm': 4.274631023406982, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.8155, 'grad_norm': 8.188949584960938, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.0608, 'grad_norm': 3.4198338985443115, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.3155, 'grad_norm': 3.363199472427368, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s]                                               {'loss': 1.0924, 'grad_norm': 6.037024974822998, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.294, 'grad_norm': 4.560706615447998, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.2897, 'grad_norm': 3.7064788341522217, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.2689, 'grad_norm': 5.2048492431640625, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.3838, 'grad_norm': 5.413519859313965, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.5633, 'grad_norm': 9.118399620056152, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.071, 'grad_norm': 4.577197551727295, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.4777, 'grad_norm': 2.260732412338257, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.0955, 'grad_norm': 3.167652130126953, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.2462, 'grad_norm': 5.325667381286621, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.1514, 'grad_norm': 5.018645763397217, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.1586, 'grad_norm': 6.491349220275879, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.401, 'grad_norm': 3.481264114379883, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.1885, 'grad_norm': 3.7751598358154297, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0022, 'grad_norm': 0.10429325699806213, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.0296, 'grad_norm': 0.6997573375701904, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.2371, 'grad_norm': 4.171427249908447, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.0707, 'grad_norm': 2.0732836723327637, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.3387, 'grad_norm': 0.9522495269775391, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.6325, 'grad_norm': 6.207607269287109, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0297, 'grad_norm': 0.5783830881118774, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0679, 'grad_norm': 2.6404685974121094, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0512, 'grad_norm': 3.459603786468506, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.1189, 'train_samples_per_second': 46.621, 'train_steps_per_second': 3.301, 'train_loss': 0.690701983764302, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:68
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 2.1149, 'grad_norm': 6.7856645584106445, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 2.5054, 'grad_norm': 6.299849033355713, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 1.4011, 'grad_norm': 10.534884452819824, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:12,  2.98it/s]                                              {'loss': 2.3069, 'grad_norm': 13.057772636413574, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.98it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s]                                              {'loss': 2.0201, 'grad_norm': 18.369976043701172, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.08it/s]                                              {'loss': 3.2895, 'grad_norm': 24.757570266723633, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.08it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 1.7692, 'grad_norm': 21.515621185302734, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 0.9452, 'grad_norm': 51.74326705932617, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.05it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 1.0194, 'grad_norm': 11.687792778015137, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.6577, 'grad_norm': 8.418977737426758, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 1.0697, 'grad_norm': 9.23414421081543, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 1.1891, 'grad_norm': 8.797402381896973, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.5523, 'grad_norm': 7.4492692947387695, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.7958, 'grad_norm': 7.001773834228516, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.298, 'grad_norm': 3.921100616455078, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.2476, 'grad_norm': 11.714140892028809, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.3425, 'grad_norm': 4.77645206451416, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.5915, 'grad_norm': 7.565587997436523, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.2199, 'grad_norm': 3.052929162979126, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.2483, 'grad_norm': 4.495785236358643, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.2992, 'grad_norm': 4.2411208152771, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.6804, 'grad_norm': 5.157391548156738, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.602, 'grad_norm': 17.255918502807617, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.2411, 'grad_norm': 14.006818771362305, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s]                                               {'loss': 0.1513, 'grad_norm': 5.00843620300293, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s]                                               {'loss': 0.1474, 'grad_norm': 2.8352789878845215, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.1308, 'grad_norm': 2.3539085388183594, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.4923, 'grad_norm': 1.9208935499191284, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.067, 'grad_norm': 1.4447646141052246, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.1205, 'grad_norm': 3.2510766983032227, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.148, 'grad_norm': 4.112561225891113, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.2806, 'grad_norm': 20.4593448638916, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.0649, 'grad_norm': 2.0782012939453125, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0605, 'grad_norm': 1.685636281967163, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.0809, 'grad_norm': 2.9163005352020264, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.21it/s]                                               {'loss': 0.0871, 'grad_norm': 1.9164575338363647, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.21it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1244, 'grad_norm': 3.2462191581726074, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0754, 'grad_norm': 2.302962303161621, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.509, 'grad_norm': 2.3634448051452637, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0188, 'grad_norm': 1.0066680908203125, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.2157, 'train_samples_per_second': 46.252, 'train_steps_per_second': 3.274, 'train_loss': 0.6991453311406076, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.27it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:43, 10.90it/s]  1%|          | 4/471 [00:00<01:07,  6.88it/s]  1%|          | 5/471 [00:00<01:13,  6.36it/s]  1%|▏         | 6/471 [00:00<01:17,  5.99it/s]  1%|▏         | 7/471 [00:01<01:20,  5.78it/s]  2%|▏         | 8/471 [00:01<01:21,  5.67it/s]  2%|▏         | 9/471 [00:01<01:22,  5.58it/s]  2%|▏         | 10/471 [00:01<01:23,  5.54it/s]  2%|▏         | 11/471 [00:01<01:23,  5.48it/s]  3%|▎         | 12/471 [00:02<01:24,  5.43it/s]  3%|▎         | 13/471 [00:02<01:24,  5.41it/s]  3%|▎         | 14/471 [00:02<01:24,  5.39it/s]  3%|▎         | 15/471 [00:02<01:24,  5.39it/s]  3%|▎         | 16/471 [00:02<01:24,  5.39it/s]  4%|▎         | 17/471 [00:02<01:24,  5.38it/s]  4%|▍         | 18/471 [00:03<01:24,  5.36it/s]  4%|▍         | 19/471 [00:03<01:24,  5.36it/s]  4%|▍         | 20/471 [00:03<01:24,  5.36it/s]  4%|▍         | 21/471 [00:03<01:24,  5.35it/s]  5%|▍         | 22/471 [00:03<01:23,  5.35it/s]  5%|▍         | 23/471 [00:04<01:23,  5.37it/s]  5%|▌         | 24/471 [00:04<01:23,  5.35it/s]  5%|▌         | 25/471 [00:04<01:23,  5.36it/s]  6%|▌         | 26/471 [00:04<01:22,  5.37it/s]  6%|▌         | 27/471 [00:04<01:22,  5.37it/s]  6%|▌         | 28/471 [00:05<01:22,  5.37it/s]  6%|▌         | 29/471 [00:05<01:22,  5.37it/s]  6%|▋         | 30/471 [00:05<01:22,  5.34it/s]  7%|▋         | 31/471 [00:05<01:22,  5.35it/s]  7%|▋         | 32/471 [00:05<01:21,  5.37it/s]  7%|▋         | 33/471 [00:05<01:21,  5.39it/s]  7%|▋         | 34/471 [00:06<01:20,  5.40it/s]  7%|▋         | 35/471 [00:06<01:21,  5.37it/s]  8%|▊         | 36/471 [00:06<01:20,  5.39it/s]  8%|▊         | 37/471 [00:06<01:20,  5.36it/s]  8%|▊         | 38/471 [00:06<01:21,  5.34it/s]  8%|▊         | 39/471 [00:07<01:20,  5.34it/s]  8%|▊         | 40/471 [00:07<01:20,  5.36it/s]  9%|▊         | 41/471 [00:07<01:20,  5.35it/s]  9%|▉         | 42/471 [00:07<01:20,  5.34it/s]  9%|▉         | 43/471 [00:07<01:20,  5.34it/s]  9%|▉         | 44/471 [00:08<01:19,  5.36it/s] 10%|▉         | 45/471 [00:08<01:19,  5.35it/s] 10%|▉         | 46/471 [00:08<01:19,  5.36it/s] 10%|▉         | 47/471 [00:08<01:18,  5.37it/s] 10%|█         | 48/471 [00:08<01:18,  5.37it/s] 10%|█         | 49/471 [00:08<01:18,  5.37it/s] 11%|█         | 50/471 [00:09<01:18,  5.35it/s] 11%|█         | 51/471 [00:09<01:18,  5.35it/s] 11%|█         | 52/471 [00:09<01:18,  5.36it/s] 11%|█▏        | 53/471 [00:09<01:18,  5.35it/s] 11%|█▏        | 54/471 [00:09<01:18,  5.34it/s] 12%|█▏        | 55/471 [00:10<01:18,  5.33it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.33it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.34it/s] 12%|█▏        | 58/471 [00:10<01:17,  5.33it/s] 13%|█▎        | 59/471 [00:10<01:17,  5.32it/s] 13%|█▎        | 60/471 [00:11<01:16,  5.34it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.35it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.33it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.32it/s] 14%|█▎        | 64/471 [00:11<01:16,  5.32it/s] 14%|█▍        | 65/471 [00:11<01:16,  5.32it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.34it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.32it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.32it/s] 15%|█▍        | 69/471 [00:12<01:15,  5.31it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.31it/s] 15%|█▌        | 71/471 [00:13<01:15,  5.31it/s] 15%|█▌        | 72/471 [00:13<01:15,  5.32it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.32it/s] 16%|█▌        | 74/471 [00:13<01:14,  5.32it/s] 16%|█▌        | 75/471 [00:13<01:14,  5.32it/s] 16%|█▌        | 76/471 [00:14<01:13,  5.34it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.33it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.32it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.31it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.31it/s] 17%|█▋        | 81/471 [00:14<01:13,  5.33it/s] 17%|█▋        | 82/471 [00:15<01:13,  5.33it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.32it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.32it/s] 18%|█▊        | 86/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 87/471 [00:16<01:12,  5.33it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.34it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.34it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.33it/s] 19%|█▉        | 91/471 [00:16<01:11,  5.33it/s] 20%|█▉        | 92/471 [00:17<01:11,  5.34it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.34it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.35it/s] 20%|██        | 95/471 [00:17<01:10,  5.35it/s] 20%|██        | 96/471 [00:17<01:09,  5.36it/s] 21%|██        | 97/471 [00:17<01:10,  5.33it/s] 21%|██        | 98/471 [00:18<01:09,  5.34it/s] 21%|██        | 99/471 [00:18<01:09,  5.35it/s] 21%|██        | 100/471 [00:18<01:09,  5.37it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.37it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.35it/s] 22%|██▏       | 103/471 [00:19<01:09,  5.33it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.32it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.32it/s] 23%|██▎       | 106/471 [00:19<01:08,  5.35it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.37it/s] 23%|██▎       | 108/471 [00:20<01:07,  5.35it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.34it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.37it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.35it/s] 24%|██▍       | 112/471 [00:20<01:07,  5.34it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.36it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.35it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.35it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.35it/s] 25%|██▌       | 118/471 [00:21<01:06,  5.33it/s] 25%|██▌       | 119/471 [00:22<01:05,  5.33it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.33it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.33it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.34it/s] 26%|██▌       | 123/471 [00:22<01:05,  5.33it/s] 26%|██▋       | 124/471 [00:23<01:05,  5.33it/s] 27%|██▋       | 125/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 129/471 [00:23<01:03,  5.35it/s] 28%|██▊       | 130/471 [00:24<01:03,  5.34it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.32it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.32it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.32it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.32it/s] 29%|██▊       | 135/471 [00:25<01:03,  5.31it/s] 29%|██▉       | 136/471 [00:25<01:03,  5.32it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.31it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.31it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.35it/s] 30%|██▉       | 140/471 [00:26<01:02,  5.32it/s] 30%|██▉       | 141/471 [00:26<01:01,  5.33it/s] 30%|███       | 142/471 [00:26<01:01,  5.33it/s] 30%|███       | 143/471 [00:26<01:01,  5.33it/s] 31%|███       | 144/471 [00:26<01:01,  5.32it/s] 31%|███       | 145/471 [00:26<01:01,  5.34it/s] 31%|███       | 146/471 [00:27<01:01,  5.33it/s] 31%|███       | 147/471 [00:27<01:00,  5.32it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.32it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.31it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.30it/s] 32%|███▏      | 151/471 [00:28<01:00,  5.29it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.30it/s] 32%|███▏      | 153/471 [00:28<00:59,  5.31it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.33it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.33it/s] 33%|███▎      | 156/471 [00:29<00:59,  5.32it/s] 33%|███▎      | 157/471 [00:29<00:59,  5.32it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.33it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.35it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.34it/s] 34%|███▍      | 161/471 [00:29<00:58,  5.32it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.31it/s] 35%|███▍      | 163/471 [00:30<00:57,  5.31it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.33it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.32it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.30it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.29it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.29it/s] 36%|███▌      | 169/471 [00:31<00:57,  5.30it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.31it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.32it/s] 37%|███▋      | 172/471 [00:32<00:56,  5.32it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.30it/s] 37%|███▋      | 174/471 [00:32<00:56,  5.30it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.29it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.31it/s] 38%|███▊      | 177/471 [00:32<00:55,  5.31it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.31it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.32it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.31it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.31it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.31it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.32it/s] 39%|███▉      | 184/471 [00:34<00:53,  5.33it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.31it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.31it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.30it/s] 40%|███▉      | 188/471 [00:35<00:53,  5.29it/s] 40%|████      | 189/471 [00:35<00:53,  5.31it/s] 40%|████      | 190/471 [00:35<00:52,  5.32it/s] 41%|████      | 191/471 [00:35<00:52,  5.30it/s] 41%|████      | 192/471 [00:35<00:52,  5.30it/s] 41%|████      | 193/471 [00:35<00:52,  5.33it/s] 41%|████      | 194/471 [00:36<00:51,  5.33it/s] 41%|████▏     | 195/471 [00:36<00:51,  5.33it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.33it/s] 42%|████▏     | 198/471 [00:36<00:51,  5.33it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.32it/s] 42%|████▏     | 200/471 [00:37<00:50,  5.32it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.33it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 204/471 [00:38<00:50,  5.31it/s] 44%|████▎     | 205/471 [00:38<00:49,  5.34it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.32it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.31it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.33it/s] 44%|████▍     | 209/471 [00:38<00:48,  5.36it/s] 45%|████▍     | 210/471 [00:39<00:48,  5.35it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.34it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.34it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.32it/s] 45%|████▌     | 214/471 [00:39<00:48,  5.32it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.31it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.30it/s] 46%|████▌     | 217/471 [00:40<00:48,  5.29it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.29it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.30it/s] 47%|████▋     | 220/471 [00:41<00:47,  5.30it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.30it/s] 47%|████▋     | 222/471 [00:41<00:46,  5.32it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.32it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.31it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.32it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.32it/s] 48%|████▊     | 227/471 [00:42<00:45,  5.31it/s] 48%|████▊     | 228/471 [00:42<00:45,  5.30it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.30it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.29it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.30it/s] 49%|████▉     | 232/471 [00:43<00:44,  5.32it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.32it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.30it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.29it/s] 50%|█████     | 236/471 [00:44<00:44,  5.30it/s] 50%|█████     | 237/471 [00:44<00:44,  5.32it/s] 51%|█████     | 238/471 [00:44<00:43,  5.32it/s] 51%|█████     | 239/471 [00:44<00:43,  5.32it/s] 51%|█████     | 240/471 [00:44<00:43,  5.30it/s] 51%|█████     | 241/471 [00:45<00:43,  5.29it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.31it/s] 52%|█████▏    | 243/471 [00:45<00:42,  5.31it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.33it/s] 53%|█████▎    | 248/471 [00:46<00:41,  5.32it/s] 53%|█████▎    | 249/471 [00:46<00:41,  5.31it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.32it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.31it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.30it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.30it/s] 54%|█████▍    | 254/471 [00:47<00:40,  5.30it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.31it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.31it/s] 55%|█████▍    | 257/471 [00:48<00:40,  5.30it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.30it/s] 55%|█████▍    | 259/471 [00:48<00:39,  5.31it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.29it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.29it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.31it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.30it/s] 56%|█████▌    | 264/471 [00:49<00:38,  5.31it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.31it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.29it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.29it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.29it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.29it/s] 57%|█████▋    | 270/471 [00:50<00:37,  5.30it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.29it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 273/471 [00:51<00:37,  5.33it/s] 58%|█████▊    | 274/471 [00:51<00:36,  5.33it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.34it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.32it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 278/471 [00:51<00:36,  5.32it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.32it/s] 59%|█████▉    | 280/471 [00:52<00:35,  5.32it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.32it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.31it/s] 60%|██████    | 283/471 [00:52<00:35,  5.31it/s] 60%|██████    | 284/471 [00:53<00:35,  5.30it/s] 61%|██████    | 285/471 [00:53<00:35,  5.29it/s] 61%|██████    | 286/471 [00:53<00:34,  5.29it/s] 61%|██████    | 287/471 [00:53<00:34,  5.29it/s] 61%|██████    | 288/471 [00:53<00:34,  5.28it/s] 61%|██████▏   | 289/471 [00:54<00:34,  5.32it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.32it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.31it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.31it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.32it/s] 62%|██████▏   | 294/471 [00:54<00:33,  5.33it/s] 63%|██████▎   | 295/471 [00:55<00:33,  5.33it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.33it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.32it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.29it/s] 63%|██████▎   | 299/471 [00:55<00:32,  5.30it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.30it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.31it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.30it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.30it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.31it/s] 65%|██████▍   | 305/471 [00:57<00:31,  5.29it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.29it/s] 65%|██████▌   | 307/471 [00:57<00:31,  5.29it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.27it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.27it/s] 66%|██████▌   | 310/471 [00:58<00:30,  5.28it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.28it/s] 66%|██████▌   | 312/471 [00:58<00:29,  5.31it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.32it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.31it/s] 67%|██████▋   | 315/471 [00:58<00:29,  5.30it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.31it/s] 67%|██████▋   | 317/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.33it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.31it/s] 68%|██████▊   | 320/471 [00:59<00:28,  5.29it/s] 68%|██████▊   | 321/471 [01:00<00:28,  5.29it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.28it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.27it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.27it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.28it/s] 69%|██████▉   | 326/471 [01:01<00:27,  5.29it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.29it/s] 70%|██████▉   | 328/471 [01:01<00:27,  5.29it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.28it/s] 70%|███████   | 330/471 [01:01<00:26,  5.31it/s] 70%|███████   | 331/471 [01:01<00:26,  5.30it/s] 70%|███████   | 332/471 [01:02<00:26,  5.28it/s] 71%|███████   | 333/471 [01:02<00:26,  5.29it/s] 71%|███████   | 334/471 [01:02<00:25,  5.28it/s] 71%|███████   | 335/471 [01:02<00:25,  5.27it/s] 71%|███████▏  | 336/471 [01:02<00:25,  5.28it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.30it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.30it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.31it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.30it/s] 72%|███████▏  | 341/471 [01:03<00:24,  5.30it/s] 73%|███████▎  | 342/471 [01:04<00:24,  5.31it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.30it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.31it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.29it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.29it/s] 74%|███████▎  | 347/471 [01:05<00:23,  5.30it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.31it/s] 74%|███████▍  | 349/471 [01:05<00:22,  5.30it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.29it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.31it/s] 75%|███████▍  | 352/471 [01:05<00:22,  5.29it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.29it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.28it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.28it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.27it/s] 76%|███████▌  | 357/471 [01:06<00:21,  5.27it/s] 76%|███████▌  | 358/471 [01:07<00:21,  5.27it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.27it/s] 76%|███████▋  | 360/471 [01:07<00:21,  5.27it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.28it/s] 77%|███████▋  | 362/471 [01:07<00:20,  5.28it/s] 77%|███████▋  | 363/471 [01:08<00:20,  5.29it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.29it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.28it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.28it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.27it/s] 78%|███████▊  | 368/471 [01:08<00:19,  5.28it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.29it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.28it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.28it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.27it/s] 79%|███████▉  | 373/471 [01:09<00:18,  5.27it/s] 79%|███████▉  | 374/471 [01:10<00:18,  5.29it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.29it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.28it/s] 80%|████████  | 377/471 [01:10<00:17,  5.28it/s] 80%|████████  | 378/471 [01:10<00:17,  5.30it/s] 80%|████████  | 379/471 [01:11<00:17,  5.31it/s] 81%|████████  | 380/471 [01:11<00:17,  5.30it/s] 81%|████████  | 381/471 [01:11<00:16,  5.30it/s] 81%|████████  | 382/471 [01:11<00:16,  5.27it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.27it/s] 82%|████████▏ | 384/471 [01:12<00:16,  5.27it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.27it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.26it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.26it/s] 83%|████████▎ | 389/471 [01:12<00:15,  5.27it/s] 83%|████████▎ | 390/471 [01:13<00:15,  5.27it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.27it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.28it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.28it/s] 84%|████████▎ | 394/471 [01:13<00:14,  5.26it/s] 84%|████████▍ | 395/471 [01:14<00:14,  5.26it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.26it/s] 84%|████████▍ | 397/471 [01:14<00:14,  5.26it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.27it/s] 85%|████████▍ | 399/471 [01:14<00:13,  5.25it/s] 85%|████████▍ | 400/471 [01:15<00:13,  5.26it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.26it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.26it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.27it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.27it/s] 86%|████████▌ | 405/471 [01:15<00:12,  5.25it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.28it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.29it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.28it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.26it/s] 87%|████████▋ | 410/471 [01:16<00:11,  5.28it/s] 87%|████████▋ | 411/471 [01:17<00:11,  5.30it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.28it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.29it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.28it/s] 88%|████████▊ | 415/471 [01:17<00:10,  5.29it/s] 88%|████████▊ | 416/471 [01:18<00:10,  5.27it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.28it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.28it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.29it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.32it/s] 89%|████████▉ | 421/471 [01:19<00:09,  5.30it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.31it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.32it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.30it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.31it/s] 90%|█████████ | 426/471 [01:19<00:08,  5.29it/s] 91%|█████████ | 427/471 [01:20<00:08,  5.29it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.29it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.28it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.27it/s] 92%|█████████▏| 431/471 [01:20<00:07,  5.26it/s] 92%|█████████▏| 432/471 [01:21<00:07,  5.28it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.28it/s] 92%|█████████▏| 434/471 [01:21<00:07,  5.28it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.27it/s] 93%|█████████▎| 436/471 [01:21<00:06,  5.28it/s] 93%|█████████▎| 437/471 [01:22<00:06,  5.28it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.28it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.29it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.30it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.29it/s] 94%|█████████▍| 442/471 [01:22<00:05,  5.30it/s] 94%|█████████▍| 443/471 [01:23<00:05,  5.29it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.29it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.27it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.27it/s] 95%|█████████▍| 447/471 [01:23<00:04,  5.27it/s] 95%|█████████▌| 448/471 [01:24<00:04,  5.29it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.30it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.29it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.28it/s] 96%|█████████▌| 452/471 [01:24<00:03,  5.29it/s] 96%|█████████▌| 453/471 [01:25<00:03,  5.27it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.26it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.26it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.28it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.29it/s] 97%|█████████▋| 458/471 [01:26<00:02,  5.29it/s] 97%|█████████▋| 459/471 [01:26<00:02,  5.30it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.27it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.27it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.28it/s] 98%|█████████▊| 463/471 [01:26<00:01,  5.28it/s] 99%|█████████▊| 464/471 [01:27<00:01,  5.29it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.29it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.28it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.27it/s] 99%|█████████▉| 468/471 [01:27<00:00,  5.26it/s]100%|█████████▉| 469/471 [01:28<00:00,  5.26it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.27it/s]100%|██████████| 471/471 [01:28<00:00,  5.63it/s]100%|██████████| 471/471 [01:28<00:00,  5.33it/s]
{'eval_loss': 2.902334451675415, 'eval_model_preparation_time': 0.0051, 'eval_acc': 0.27655337227827936, 'eval_runtime': 88.6152, 'eval_samples_per_second': 84.997, 'eval_steps_per_second': 5.315}
ROUND:10
CLIENT:26
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 1.819, 'grad_norm': 6.055306911468506, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 2.5793, 'grad_norm': 8.677452087402344, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.5355, 'grad_norm': 11.308881759643555, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.7314, 'grad_norm': 13.996944427490234, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s]                                              {'loss': 3.7673, 'grad_norm': 24.766530990600586, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s]                                              {'loss': 1.2197, 'grad_norm': 12.910970687866211, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.94it/s]                                              {'loss': 1.7346, 'grad_norm': 13.072444915771484, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.94it/s]                                              {'loss': 0.1068, 'grad_norm': 5.396076202392578, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.94it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.58it/s]                                              {'loss': 0.6712, 'grad_norm': 11.124463081359863, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.58it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.38it/s]                                               {'loss': 0.7662, 'grad_norm': 10.4890718460083, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.38it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.24it/s]                                               {'loss': 0.3473, 'grad_norm': 6.6109747886657715, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.24it/s] 30%|███       | 12/40 [00:03<00:08,  3.16it/s]                                               {'loss': 0.5709, 'grad_norm': 7.379969120025635, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.16it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.7072, 'grad_norm': 7.329430103302002, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.10it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.2218, 'grad_norm': 8.803705215454102, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.6566, 'grad_norm': 7.205868721008301, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.0268, 'grad_norm': 1.1220238208770752, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.05it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s]                                               {'loss': 0.234, 'grad_norm': 3.906107187271118, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s]                                               {'loss': 0.3468, 'grad_norm': 4.137908458709717, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.2474, 'grad_norm': 2.4455068111419678, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.141, 'grad_norm': 2.6919984817504883, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.3738, 'grad_norm': 5.669216156005859, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.5554, 'grad_norm': 11.554350852966309, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.1789, 'grad_norm': 3.4143407344818115, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0898, 'grad_norm': 3.817636489868164, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.057, 'grad_norm': 1.39805006980896, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s]                                               {'loss': 0.061, 'grad_norm': 0.9992043375968933, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s]                                               {'loss': 0.1022, 'grad_norm': 3.323269844055176, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.1665, 'grad_norm': 0.9940221309661865, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.1033, 'grad_norm': 1.857491374015808, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0272, 'grad_norm': 0.6092212200164795, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0606, 'grad_norm': 1.7353439331054688, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0367, 'grad_norm': 1.8987855911254883, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.037, 'grad_norm': 1.9431052207946777, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0232, 'grad_norm': 0.6931653022766113, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.0208, 'grad_norm': 0.6093635559082031, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.1624, 'grad_norm': 1.1989630460739136, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.0236, 'grad_norm': 0.6109607815742493, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0815, 'grad_norm': 3.759143114089966, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.0318, 'grad_norm': 0.9690883159637451, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.0578, 'grad_norm': 8.8341646194458, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]                                               {'train_runtime': 12.3448, 'train_samples_per_second': 45.768, 'train_steps_per_second': 3.24, 'train_loss': 0.5920295145828277, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]100%|██████████| 40/40 [00:12<00:00,  3.24it/s]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 2.6332, 'grad_norm': 6.947619915008545, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]                                              {'loss': 2.5105, 'grad_norm': 10.897878646850586, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]  8%|▊         | 3/40 [00:01<00:12,  2.98it/s]                                              {'loss': 1.3549, 'grad_norm': 8.198860168457031, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.98it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 1.907, 'grad_norm': 15.782448768615723, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.9135, 'grad_norm': 22.4903507232666, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.4936, 'grad_norm': 17.307025909423828, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 2.3523, 'grad_norm': 17.1422061920166, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 0.3895, 'grad_norm': 22.764036178588867, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.97it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s]                                              {'loss': 0.9333, 'grad_norm': 7.752225399017334, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.43it/s]                                               {'loss': 0.5144, 'grad_norm': 7.0680437088012695, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.43it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.8743, 'grad_norm': 9.818196296691895, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.30it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 1.2944, 'grad_norm': 9.776060104370117, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.6188, 'grad_norm': 7.339411735534668, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.5312, 'grad_norm': 5.304206371307373, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.6086, 'grad_norm': 6.581973552703857, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.1222, 'grad_norm': 7.039762496948242, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.1354, 'grad_norm': 2.3061838150024414, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s]                                               {'loss': 0.1396, 'grad_norm': 4.668480396270752, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.147, 'grad_norm': 3.0281267166137695, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.1529, 'grad_norm': 2.8763582706451416, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.1951, 'grad_norm': 5.003335475921631, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.2039, 'grad_norm': 7.339669704437256, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.5043, 'grad_norm': 3.127830743789673, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.4591, 'grad_norm': 19.89237403869629, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s]                                               {'loss': 0.1212, 'grad_norm': 3.4655308723449707, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s]                                               {'loss': 0.0593, 'grad_norm': 1.2313684225082397, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s]                                               {'loss': 0.0425, 'grad_norm': 0.7965381741523743, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.4741, 'grad_norm': 3.2747278213500977, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.0675, 'grad_norm': 1.3887609243392944, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.0886, 'grad_norm': 1.512671709060669, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0461, 'grad_norm': 1.4494194984436035, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.2581, 'grad_norm': 20.780704498291016, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.0959, 'grad_norm': 3.7491726875305176, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.448, 'grad_norm': 5.8361735343933105, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.157, 'grad_norm': 8.450413703918457, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.0521, 'grad_norm': 1.9709488153457642, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0557, 'grad_norm': 2.2846412658691406, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0291, 'grad_norm': 0.6430800557136536, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0284, 'grad_norm': 0.7159008979797363, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.2654, 'grad_norm': 11.081692695617676, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]                                               {'train_runtime': 12.264, 'train_samples_per_second': 46.07, 'train_steps_per_second': 3.262, 'train_loss': 0.6569363019429147, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.2687, 'grad_norm': 8.35153579711914, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.4149, 'grad_norm': 9.554973602294922, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.6523, 'grad_norm': 8.01434326171875, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.1331, 'grad_norm': 18.023223876953125, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.5099, 'grad_norm': 13.77769947052002, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.3131, 'grad_norm': 22.054458618164062, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.789, 'grad_norm': 12.785618782043457, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.4502, 'grad_norm': 35.3914794921875, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 0.9512, 'grad_norm': 14.257841110229492, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.4064, 'grad_norm': 11.30126667022705, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 0.8488, 'grad_norm': 11.15133285522461, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.4259, 'grad_norm': 6.666463851928711, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.7673, 'grad_norm': 8.87502670288086, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.5288, 'grad_norm': 7.007959365844727, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.6453, 'grad_norm': 7.092491626739502, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 2.8631, 'grad_norm': 62.64892578125, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.12it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.3818, 'grad_norm': 2.9568417072296143, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.62it/s]                                               {'loss': 0.1606, 'grad_norm': 3.557938814163208, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.62it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s]                                               {'loss': 0.3888, 'grad_norm': 3.1442365646362305, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s] 50%|█████     | 20/40 [00:06<00:06,  3.33it/s]                                               {'loss': 0.365, 'grad_norm': 5.659883499145508, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.33it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s]                                               {'loss': 0.3223, 'grad_norm': 4.929330348968506, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.3129, 'grad_norm': 10.50170612335205, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.2745, 'grad_norm': 6.097959041595459, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.0593, 'grad_norm': 6.600823402404785, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.13it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s]                                               {'loss': 0.4848, 'grad_norm': 3.46321702003479, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s]                                               {'loss': 0.073, 'grad_norm': 5.231997966766357, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.46it/s]                                               {'loss': 0.4164, 'grad_norm': 1.4325649738311768, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.46it/s] 70%|███████   | 28/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.0838, 'grad_norm': 1.954393744468689, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.33it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.2076, 'grad_norm': 5.254213809967041, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.1191, 'grad_norm': 2.372072458267212, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0697, 'grad_norm': 1.6233309507369995, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.2283, 'grad_norm': 12.392280578613281, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.87it/s]                                               {'loss': 0.044, 'grad_norm': 2.2067344188690186, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.87it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s]                                               {'loss': 0.0838, 'grad_norm': 4.472291469573975, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.45it/s]                                               {'loss': 0.1322, 'grad_norm': 1.6435116529464722, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.45it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s]                                               {'loss': 0.0178, 'grad_norm': 0.5992054343223572, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.0288, 'grad_norm': 0.6338109970092773, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0444, 'grad_norm': 1.0575898885726929, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.6589, 'grad_norm': 1.8476420640945435, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0043, 'grad_norm': 0.33318760991096497, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.14it/s]                                               {'train_runtime': 12.0383, 'train_samples_per_second': 46.934, 'train_steps_per_second': 3.323, 'train_loss': 0.6732487667934037, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.14it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:86
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.24it/s]                                              {'loss': 2.3621, 'grad_norm': 6.971746444702148, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.24it/s]  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]                                              {'loss': 1.9709, 'grad_norm': 9.145613670349121, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]  8%|▊         | 3/40 [00:00<00:12,  3.06it/s]                                              {'loss': 1.4893, 'grad_norm': 10.576359748840332, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.06it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.8149, 'grad_norm': 10.6675443649292, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.0775, 'grad_norm': 18.13100814819336, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 3.3225, 'grad_norm': 23.276723861694336, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.8727, 'grad_norm': 25.13311004638672, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s] 20%|██        | 8/40 [00:02<00:08,  3.84it/s]                                              {'loss': 6.2025, 'grad_norm': 131.82568359375, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:08,  3.84it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.52it/s]                                              {'loss': 0.7627, 'grad_norm': 9.197477340698242, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.52it/s] 25%|██▌       | 10/40 [00:03<00:09,  3.32it/s]                                               {'loss': 0.9056, 'grad_norm': 13.504498481750488, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:09,  3.32it/s] 28%|██▊       | 11/40 [00:03<00:09,  3.20it/s]                                               {'loss': 0.7794, 'grad_norm': 13.146900177001953, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:09,  3.20it/s] 30%|███       | 12/40 [00:03<00:08,  3.12it/s]                                               {'loss': 0.4632, 'grad_norm': 11.315319061279297, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.12it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.07it/s]                                               {'loss': 1.3046, 'grad_norm': 9.23236083984375, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.07it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.7712, 'grad_norm': 8.30276107788086, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.05it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.8458, 'grad_norm': 4.5600361824035645, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 1.5625, 'grad_norm': 30.786954879760742, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.05it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.4106, 'grad_norm': 5.802864074707031, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.436, 'grad_norm': 7.3135552406311035, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.8153, 'grad_norm': 3.6990537643432617, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.3595, 'grad_norm': 4.332698345184326, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.4064, 'grad_norm': 9.080680847167969, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.1673, 'grad_norm': 3.507580518722534, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.2264, 'grad_norm': 3.6462342739105225, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.4344, 'grad_norm': 28.682880401611328, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s]                                               {'loss': 0.0751, 'grad_norm': 1.6907215118408203, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s]                                               {'loss': 0.4717, 'grad_norm': 1.523857831954956, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.1342, 'grad_norm': 3.7088685035705566, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.1206, 'grad_norm': 2.4262611865997314, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.24it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.2784, 'grad_norm': 4.538037300109863, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.191, 'grad_norm': 1.9085890054702759, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1444, 'grad_norm': 3.611778497695923, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1301, 'grad_norm': 7.562180042266846, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.0746, 'grad_norm': 2.7810115814208984, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.4137, 'grad_norm': 0.715027391910553, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.1396, 'grad_norm': 0.6147462725639343, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0521, 'grad_norm': 1.8695385456085205, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.1142, 'grad_norm': 3.5078651905059814, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0513, 'grad_norm': 1.3830528259277344, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0695, 'grad_norm': 5.5204596519470215, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0058, 'grad_norm': 0.40526828169822693, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.1886, 'train_samples_per_second': 46.355, 'train_steps_per_second': 3.282, 'train_loss': 0.8807299103238619, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:76
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 2.7676, 'grad_norm': 8.346136093139648, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 2.0263, 'grad_norm': 10.069097518920898, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.6091, 'grad_norm': 11.93517017364502, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.2714, 'grad_norm': 18.176774978637695, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.7281, 'grad_norm': 23.431182861328125, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.3194, 'grad_norm': 16.742345809936523, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 2.0122, 'grad_norm': 15.896416664123535, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.8904, 'grad_norm': 36.5449104309082, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 1.0038, 'grad_norm': 8.228232383728027, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.7057, 'grad_norm': 10.123112678527832, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 0.519, 'grad_norm': 5.092668533325195, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.29it/s]                                               {'loss': 1.0497, 'grad_norm': 6.126349925994873, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.29it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s]                                               {'loss': 0.2644, 'grad_norm': 4.0108256340026855, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.1767, 'grad_norm': 15.639298439025879, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.6477, 'grad_norm': 9.014902114868164, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.025, 'grad_norm': 0.9935353398323059, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.3031, 'grad_norm': 4.643253803253174, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.2289, 'grad_norm': 4.396185398101807, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.1933, 'grad_norm': 3.8064770698547363, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.3344, 'grad_norm': 2.71016001701355, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.3448, 'grad_norm': 5.223287582397461, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.2248, 'grad_norm': 6.193647384643555, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.15it/s]                                               {'loss': 0.617, 'grad_norm': 8.491536140441895, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.15it/s]                                               {'loss': 0.4039, 'grad_norm': 17.671001434326172, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.15it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s]                                               {'loss': 0.0766, 'grad_norm': 1.8049510717391968, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s]                                               {'loss': 0.0858, 'grad_norm': 1.5400657653808594, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s]                                               {'loss': 0.0977, 'grad_norm': 1.9034391641616821, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s] 70%|███████   | 28/40 [00:08<00:03,  3.32it/s]                                               {'loss': 0.3015, 'grad_norm': 1.4417842626571655, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.32it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.3152, 'grad_norm': 3.515134334564209, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s]                                               {'loss': 0.0481, 'grad_norm': 1.1821444034576416, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.15it/s]                                               {'loss': 0.1008, 'grad_norm': 4.537753582000732, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.15it/s]                                               {'loss': 0.553, 'grad_norm': 51.690887451171875, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.15it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.89it/s]                                               {'loss': 0.0299, 'grad_norm': 1.2334080934524536, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.89it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.66it/s]                                               {'loss': 0.2216, 'grad_norm': 0.8318637013435364, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.66it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.47it/s]                                               {'loss': 0.0803, 'grad_norm': 4.041075229644775, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.47it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s]                                               {'loss': 0.0769, 'grad_norm': 2.6424806118011475, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.24it/s]                                               {'loss': 0.0909, 'grad_norm': 4.389786243438721, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.24it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.4118, 'grad_norm': 9.799674987792969, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0524, 'grad_norm': 2.0381102561950684, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.073, 'grad_norm': 4.640280246734619, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]                                               {'train_runtime': 12.0173, 'train_samples_per_second': 47.015, 'train_steps_per_second': 3.329, 'train_loss': 0.7070496294647455, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.13it/s]100%|██████████| 40/40 [00:12<00:00,  3.33it/s]
CLIENT:14
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.9188, 'grad_norm': 8.047659873962402, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  3.09it/s]                                              {'loss': 2.2778, 'grad_norm': 12.482173919677734, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.09it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 2.5035, 'grad_norm': 15.610063552856445, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.1015, 'grad_norm': 12.525737762451172, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.7288, 'grad_norm': 17.919981002807617, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.6329, 'grad_norm': 16.986783981323242, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 2.6222, 'grad_norm': 22.885881423950195, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 4.3038, 'grad_norm': 161.99168395996094, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.05it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s]                                              {'loss': 1.8691, 'grad_norm': 18.331876754760742, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 1.4958, 'grad_norm': 17.77201271057129, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 0.846, 'grad_norm': 13.492313385009766, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.8482, 'grad_norm': 8.940730094909668, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s]                                               {'loss': 1.5323, 'grad_norm': 11.096309661865234, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.5936, 'grad_norm': 5.119385242462158, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.5822, 'grad_norm': 6.4055070877075195, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.267, 'grad_norm': 17.836095809936523, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.4699, 'grad_norm': 5.444557189941406, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.5776, 'grad_norm': 6.540211200714111, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.6349, 'grad_norm': 7.802351951599121, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.3837, 'grad_norm': 5.092250347137451, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.5967, 'grad_norm': 7.288864612579346, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.9084, 'grad_norm': 12.854717254638672, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 1.2112, 'grad_norm': 8.307445526123047, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.0049, 'grad_norm': 0.2544666528701782, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s]                                               {'loss': 0.1381, 'grad_norm': 3.336090087890625, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s]                                               {'loss': 0.0979, 'grad_norm': 2.555786609649658, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.2644, 'grad_norm': 6.927639007568359, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.2306, 'grad_norm': 6.592144966125488, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.6022, 'grad_norm': 3.951359987258911, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.398, 'grad_norm': 4.473694801330566, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.1424, 'grad_norm': 2.7168185710906982, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.1667, 'grad_norm': 5.8707709312438965, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.0858, 'grad_norm': 1.4325385093688965, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.0471, 'grad_norm': 1.298766851425171, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.1334, 'grad_norm': 3.477856159210205, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.2073, 'grad_norm': 4.966235160827637, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s]                                               {'loss': 0.5014, 'grad_norm': 2.052797317504883, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0662, 'grad_norm': 1.7303823232650757, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.18it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1004, 'grad_norm': 2.579008102416992, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0072, 'grad_norm': 0.6091930270195007, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]                                               {'train_runtime': 12.07, 'train_samples_per_second': 46.81, 'train_steps_per_second': 3.314, 'train_loss': 0.8774943532072939, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.13it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:88
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.19it/s]                                              {'loss': 2.6797, 'grad_norm': 9.254887580871582, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.19it/s]  5%|▌         | 2/40 [00:00<00:12,  3.10it/s]                                              {'loss': 2.3571, 'grad_norm': 10.742271423339844, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.10it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 0.9282, 'grad_norm': 9.851162910461426, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.0567, 'grad_norm': 12.476197242736816, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.6563, 'grad_norm': 12.32174015045166, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 0.704, 'grad_norm': 9.296950340270996, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.7304, 'grad_norm': 15.079233169555664, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 2.559, 'grad_norm': 78.31671905517578, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s]                                              {'loss': 0.5024, 'grad_norm': 9.344539642333984, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s]                                               {'loss': 0.3942, 'grad_norm': 9.820907592773438, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s]                                               {'loss': 0.4173, 'grad_norm': 7.290963649749756, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 1.2505, 'grad_norm': 11.81796646118164, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.21it/s]                                               {'loss': 0.2399, 'grad_norm': 4.546273708343506, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.4489, 'grad_norm': 3.5614161491394043, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.5168, 'grad_norm': 7.671152114868164, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.0256, 'grad_norm': 1.4424968957901, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s]                                               {'loss': 0.2407, 'grad_norm': 2.78421950340271, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s]                                               {'loss': 0.8524, 'grad_norm': 6.5144362449646, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.1278, 'grad_norm': 2.0963337421417236, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.136, 'grad_norm': 2.2371840476989746, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.2579, 'grad_norm': 5.5311503410339355, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.3646, 'grad_norm': 6.6457414627075195, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.5753, 'grad_norm': 6.648590564727783, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.193, 'grad_norm': 14.937383651733398, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.4745, 'grad_norm': 2.166961908340454, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s]                                               {'loss': 0.0315, 'grad_norm': 0.7987575531005859, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s]                                               {'loss': 0.1804, 'grad_norm': 1.7309088706970215, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.0553, 'grad_norm': 1.7321439981460571, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.0634, 'grad_norm': 1.263105034828186, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.356, 'grad_norm': 1.1470873355865479, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0479, 'grad_norm': 0.9608575701713562, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0011, 'grad_norm': 0.056245479732751846, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.012, 'grad_norm': 0.2439568191766739, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.0753, 'grad_norm': 1.9927195310592651, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0347, 'grad_norm': 1.243777871131897, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.3395, 'grad_norm': 1.4111886024475098, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.5795, 'grad_norm': 4.748656749725342, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0109, 'grad_norm': 0.30474966764450073, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0445, 'grad_norm': 1.2299203872680664, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.005, 'grad_norm': 0.321677029132843, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0833, 'train_samples_per_second': 46.759, 'train_steps_per_second': 3.31, 'train_loss': 0.5881616935337661, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:48
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.3918, 'grad_norm': 6.4950737953186035, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]                                              {'loss': 2.6772, 'grad_norm': 9.242877960205078, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]  8%|▊         | 3/40 [00:00<00:11,  3.10it/s]                                              {'loss': 2.606, 'grad_norm': 12.174351692199707, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.10it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.1584, 'grad_norm': 12.029267311096191, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.9647, 'grad_norm': 8.61574649810791, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.1955, 'grad_norm': 12.396981239318848, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.9715, 'grad_norm': 14.542328834533691, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 3.5035, 'grad_norm': 44.82673263549805, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s]                                              {'loss': 0.3891, 'grad_norm': 5.520524024963379, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 0.8336, 'grad_norm': 10.727143287658691, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 1.0656, 'grad_norm': 13.551377296447754, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 0.7165, 'grad_norm': 5.886667728424072, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.7552, 'grad_norm': 6.471950531005859, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.3338, 'grad_norm': 7.746417999267578, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.888, 'grad_norm': 6.6654510498046875, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.0854, 'grad_norm': 4.059726238250732, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.3212, 'grad_norm': 3.6516382694244385, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.1807, 'grad_norm': 2.992614269256592, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.2326, 'grad_norm': 4.562687397003174, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.4553, 'grad_norm': 7.537638187408447, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.1852, 'grad_norm': 3.493140935897827, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.1783, 'grad_norm': 2.962467670440674, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.6198, 'grad_norm': 4.595160484313965, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0624, 'grad_norm': 2.7737629413604736, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.0542, 'grad_norm': 1.2216055393218994, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.0688, 'grad_norm': 1.5346429347991943, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.055, 'grad_norm': 1.5205260515213013, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.1282, 'grad_norm': 3.5477051734924316, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s]                                               {'loss': 0.0943, 'grad_norm': 3.203491687774658, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.4751, 'grad_norm': 1.9873281717300415, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.151, 'grad_norm': 4.235229969024658, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0195, 'grad_norm': 0.9543027281761169, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s]                                               {'loss': 0.1137, 'grad_norm': 2.16399884223938, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s]                                               {'loss': 0.07, 'grad_norm': 2.4363627433776855, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0723, 'grad_norm': 1.8039988279342651, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0911, 'grad_norm': 2.464345932006836, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.0404, 'grad_norm': 1.078412652015686, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.4791, 'grad_norm': 1.9984163045883179, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.068, 'grad_norm': 2.396981954574585, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0481, 'grad_norm': 4.463486194610596, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.2014, 'train_samples_per_second': 46.306, 'train_steps_per_second': 3.278, 'train_loss': 0.74499916061759, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:71
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.4265, 'grad_norm': 8.287137985229492, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 2.9148, 'grad_norm': 10.791576385498047, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.3184, 'grad_norm': 13.93391227722168, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.07it/s]                                              {'loss': 1.8839, 'grad_norm': 14.742287635803223, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.07it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.1352, 'grad_norm': 18.89311981201172, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.4199, 'grad_norm': 14.260957717895508, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.07it/s]                                              {'loss': 1.1241, 'grad_norm': 15.605023384094238, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.07it/s]                                              {'loss': 0.1147, 'grad_norm': 11.305221557617188, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.07it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s]                                              {'loss': 0.9226, 'grad_norm': 11.787178993225098, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.64it/s]                                               {'loss': 1.0131, 'grad_norm': 13.141493797302246, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.64it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.45it/s]                                               {'loss': 0.8545, 'grad_norm': 9.02956485748291, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.45it/s] 30%|███       | 12/40 [00:03<00:08,  3.32it/s]                                               {'loss': 0.5115, 'grad_norm': 7.03198766708374, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.32it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.21it/s]                                               {'loss': 0.4387, 'grad_norm': 7.5423078536987305, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.3962, 'grad_norm': 6.792415618896484, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.5151, 'grad_norm': 6.408754825592041, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.1789, 'grad_norm': 31.343429565429688, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.1694, 'grad_norm': 2.5522878170013428, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.5313, 'grad_norm': 2.5666964054107666, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.1851, 'grad_norm': 2.5368776321411133, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.8353, 'grad_norm': 7.357723236083984, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.4299, 'grad_norm': 4.834878921508789, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.1756, 'grad_norm': 3.0031206607818604, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.3168, 'grad_norm': 5.624809741973877, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.0118, 'grad_norm': 0.6903316974639893, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.0404, 'grad_norm': 1.2281873226165771, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.0797, 'grad_norm': 2.181722402572632, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.0437, 'grad_norm': 0.946290910243988, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.1094, 'grad_norm': 2.7388365268707275, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.2119, 'grad_norm': 4.453959941864014, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.1057, 'grad_norm': 1.8083773851394653, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.4762, 'grad_norm': 2.0919461250305176, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0354, 'grad_norm': 1.829018473625183, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.72it/s]                                               {'loss': 0.0375, 'grad_norm': 1.1201982498168945, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.72it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.4246, 'grad_norm': 1.8631070852279663, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.184, 'grad_norm': 5.630242347717285, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s]                                               {'loss': 0.0195, 'grad_norm': 0.5625902414321899, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0934, 'grad_norm': 3.0249013900756836, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0484, 'grad_norm': 1.3967955112457275, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0395, 'grad_norm': 1.286160945892334, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.003, 'grad_norm': 0.1260373294353485, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.1117, 'train_samples_per_second': 46.649, 'train_steps_per_second': 3.303, 'train_loss': 0.61939017973491, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:67
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.8963, 'grad_norm': 7.132543087005615, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 1.76, 'grad_norm': 10.15632438659668, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.00it/s]                                              {'loss': 1.5695, 'grad_norm': 11.417193412780762, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.00it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.65, 'grad_norm': 14.10755729675293, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.7922, 'grad_norm': 15.238231658935547, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.4896, 'grad_norm': 15.421091079711914, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.1933, 'grad_norm': 17.27576446533203, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 5.1394, 'grad_norm': 60.403663635253906, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s]                                              {'loss': 1.0175, 'grad_norm': 18.712125778198242, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 1.3361, 'grad_norm': 12.659305572509766, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.7159, 'grad_norm': 7.690730094909668, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.3907, 'grad_norm': 5.902527809143066, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s]                                               {'loss': 1.054, 'grad_norm': 10.93532657623291, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.381, 'grad_norm': 4.6841721534729, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.7953, 'grad_norm': 9.372415542602539, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 2.9647, 'grad_norm': 48.56804656982422, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s]                                               {'loss': 0.286, 'grad_norm': 4.274075984954834, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.2135, 'grad_norm': 2.9472339153289795, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.2325, 'grad_norm': 3.9344711303710938, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.6542, 'grad_norm': 9.361696243286133, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.2845, 'grad_norm': 12.96312141418457, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.1711, 'grad_norm': 4.812305450439453, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.1655, 'grad_norm': 3.769585371017456, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0619, 'grad_norm': 4.045446872711182, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.1187, 'grad_norm': 4.121466159820557, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.1873, 'grad_norm': 4.213355541229248, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.0674, 'grad_norm': 1.391095757484436, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.0786, 'grad_norm': 1.7833706140518188, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.0798, 'grad_norm': 1.7808647155761719, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0715, 'grad_norm': 1.4610811471939087, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.156, 'grad_norm': 3.8202145099639893, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0521, 'grad_norm': 3.252290725708008, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.0678, 'grad_norm': 2.688612699508667, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.0312, 'grad_norm': 0.6292401552200317, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.1023, 'grad_norm': 2.2844765186309814, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0904, 'grad_norm': 2.0528507232666016, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0727, 'grad_norm': 2.3363068103790283, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0543, 'grad_norm': 1.5714874267578125, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0511, 'grad_norm': 2.9076955318450928, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.4611, 'grad_norm': 45.05904769897461, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.1349, 'train_samples_per_second': 46.56, 'train_steps_per_second': 3.296, 'train_loss': 0.7739246786106377, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:42, 10.93it/s]  1%|          | 4/471 [00:00<01:08,  6.85it/s]  1%|          | 5/471 [00:00<01:13,  6.32it/s]  1%|▏         | 6/471 [00:00<01:17,  5.99it/s]  1%|▏         | 7/471 [00:01<01:20,  5.79it/s]  2%|▏         | 8/471 [00:01<01:21,  5.66it/s]  2%|▏         | 9/471 [00:01<01:22,  5.58it/s]  2%|▏         | 10/471 [00:01<01:23,  5.53it/s]  2%|▏         | 11/471 [00:01<01:23,  5.49it/s]  3%|▎         | 12/471 [00:02<01:24,  5.45it/s]  3%|▎         | 13/471 [00:02<01:24,  5.41it/s]  3%|▎         | 14/471 [00:02<01:24,  5.40it/s]  3%|▎         | 15/471 [00:02<01:24,  5.42it/s]  3%|▎         | 16/471 [00:02<01:24,  5.40it/s]  4%|▎         | 17/471 [00:02<01:24,  5.40it/s]  4%|▍         | 18/471 [00:03<01:24,  5.38it/s]  4%|▍         | 19/471 [00:03<01:24,  5.38it/s]  4%|▍         | 20/471 [00:03<01:23,  5.37it/s]  4%|▍         | 21/471 [00:03<01:23,  5.37it/s]  5%|▍         | 22/471 [00:03<01:23,  5.37it/s]  5%|▍         | 23/471 [00:04<01:23,  5.37it/s]  5%|▌         | 24/471 [00:04<01:23,  5.37it/s]  5%|▌         | 25/471 [00:04<01:22,  5.38it/s]  6%|▌         | 26/471 [00:04<01:22,  5.37it/s]  6%|▌         | 27/471 [00:04<01:22,  5.38it/s]  6%|▌         | 28/471 [00:05<01:22,  5.36it/s]  6%|▌         | 29/471 [00:05<01:22,  5.36it/s]  6%|▋         | 30/471 [00:05<01:22,  5.36it/s]  7%|▋         | 31/471 [00:05<01:22,  5.36it/s]  7%|▋         | 32/471 [00:05<01:21,  5.38it/s]  7%|▋         | 33/471 [00:05<01:21,  5.40it/s]  7%|▋         | 34/471 [00:06<01:20,  5.42it/s]  7%|▋         | 35/471 [00:06<01:20,  5.39it/s]  8%|▊         | 36/471 [00:06<01:20,  5.39it/s]  8%|▊         | 37/471 [00:06<01:20,  5.38it/s]  8%|▊         | 38/471 [00:06<01:20,  5.36it/s]  8%|▊         | 39/471 [00:07<01:20,  5.37it/s]  8%|▊         | 40/471 [00:07<01:20,  5.37it/s]  9%|▊         | 41/471 [00:07<01:20,  5.36it/s]  9%|▉         | 42/471 [00:07<01:20,  5.35it/s]  9%|▉         | 43/471 [00:07<01:19,  5.37it/s]  9%|▉         | 44/471 [00:07<01:19,  5.38it/s] 10%|▉         | 45/471 [00:08<01:19,  5.38it/s] 10%|▉         | 46/471 [00:08<01:19,  5.37it/s] 10%|▉         | 47/471 [00:08<01:18,  5.37it/s] 10%|█         | 48/471 [00:08<01:18,  5.38it/s] 10%|█         | 49/471 [00:08<01:18,  5.37it/s] 11%|█         | 50/471 [00:09<01:18,  5.36it/s] 11%|█         | 51/471 [00:09<01:18,  5.36it/s] 11%|█         | 52/471 [00:09<01:18,  5.36it/s] 11%|█▏        | 53/471 [00:09<01:18,  5.36it/s] 11%|█▏        | 54/471 [00:09<01:17,  5.36it/s] 12%|█▏        | 55/471 [00:10<01:17,  5.35it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.35it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.37it/s] 12%|█▏        | 58/471 [00:10<01:17,  5.35it/s] 13%|█▎        | 59/471 [00:10<01:16,  5.35it/s] 13%|█▎        | 60/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.36it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.37it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.36it/s] 14%|█▎        | 64/471 [00:11<01:16,  5.35it/s] 14%|█▍        | 65/471 [00:11<01:15,  5.35it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.35it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.35it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.36it/s] 15%|█▍        | 69/471 [00:12<01:14,  5.37it/s] 15%|█▍        | 70/471 [00:12<01:14,  5.35it/s] 15%|█▌        | 71/471 [00:13<01:14,  5.34it/s] 15%|█▌        | 72/471 [00:13<01:14,  5.34it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.35it/s] 16%|█▌        | 74/471 [00:13<01:13,  5.38it/s] 16%|█▌        | 75/471 [00:13<01:13,  5.37it/s] 16%|█▌        | 76/471 [00:13<01:13,  5.37it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.37it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.36it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 81/471 [00:14<01:12,  5.37it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.36it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.36it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.36it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.36it/s] 18%|█▊        | 86/471 [00:15<01:11,  5.35it/s] 18%|█▊        | 87/471 [00:16<01:11,  5.37it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.37it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.38it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.36it/s] 19%|█▉        | 91/471 [00:16<01:10,  5.37it/s] 20%|█▉        | 92/471 [00:16<01:10,  5.38it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.37it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.37it/s] 20%|██        | 95/471 [00:17<01:09,  5.38it/s] 20%|██        | 96/471 [00:17<01:09,  5.36it/s] 21%|██        | 97/471 [00:17<01:09,  5.36it/s] 21%|██        | 98/471 [00:18<01:09,  5.37it/s] 21%|██        | 99/471 [00:18<01:09,  5.36it/s] 21%|██        | 100/471 [00:18<01:08,  5.39it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.38it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.38it/s] 22%|██▏       | 103/471 [00:18<01:08,  5.36it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.33it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.33it/s] 23%|██▎       | 106/471 [00:19<01:08,  5.36it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.37it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.38it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.37it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.37it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.37it/s] 24%|██▍       | 112/471 [00:20<01:07,  5.36it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.37it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.36it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.34it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.34it/s] 25%|██▌       | 118/471 [00:21<01:06,  5.33it/s] 25%|██▌       | 119/471 [00:21<01:06,  5.33it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.33it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.32it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.33it/s] 26%|██▌       | 123/471 [00:22<01:05,  5.35it/s] 26%|██▋       | 124/471 [00:22<01:05,  5.33it/s] 27%|██▋       | 125/471 [00:23<01:05,  5.32it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.32it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 129/471 [00:23<01:04,  5.33it/s] 28%|██▊       | 130/471 [00:24<01:03,  5.34it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.33it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.33it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.32it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.30it/s] 29%|██▊       | 135/471 [00:24<01:03,  5.30it/s] 29%|██▉       | 136/471 [00:25<01:03,  5.31it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.32it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.32it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.32it/s] 30%|██▉       | 140/471 [00:25<01:02,  5.31it/s] 30%|██▉       | 141/471 [00:26<01:02,  5.32it/s] 30%|███       | 142/471 [00:26<01:01,  5.34it/s] 30%|███       | 143/471 [00:26<01:01,  5.34it/s] 31%|███       | 144/471 [00:26<01:01,  5.31it/s] 31%|███       | 145/471 [00:26<01:01,  5.33it/s] 31%|███       | 146/471 [00:27<01:01,  5.32it/s] 31%|███       | 147/471 [00:27<01:00,  5.32it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.32it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.30it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.29it/s] 32%|███▏      | 151/471 [00:28<01:00,  5.29it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.30it/s] 32%|███▏      | 153/471 [00:28<01:00,  5.30it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.34it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.33it/s] 33%|███▎      | 156/471 [00:28<00:59,  5.32it/s] 33%|███▎      | 157/471 [00:29<00:59,  5.32it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.33it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.34it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.32it/s] 34%|███▍      | 161/471 [00:29<00:58,  5.32it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.31it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.30it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.33it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.32it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.29it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.30it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.30it/s] 36%|███▌      | 169/471 [00:31<00:57,  5.30it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.30it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.31it/s] 37%|███▋      | 172/471 [00:31<00:56,  5.33it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.31it/s] 37%|███▋      | 174/471 [00:32<00:55,  5.31it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.30it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.32it/s] 38%|███▊      | 177/471 [00:32<00:55,  5.32it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.31it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.31it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.31it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.32it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.32it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.31it/s] 39%|███▉      | 184/471 [00:34<00:54,  5.31it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.31it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.30it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.30it/s] 40%|███▉      | 188/471 [00:34<00:53,  5.29it/s] 40%|████      | 189/471 [00:35<00:53,  5.31it/s] 40%|████      | 190/471 [00:35<00:52,  5.31it/s] 41%|████      | 191/471 [00:35<00:52,  5.30it/s] 41%|████      | 192/471 [00:35<00:52,  5.31it/s] 41%|████      | 193/471 [00:35<00:52,  5.33it/s] 41%|████      | 194/471 [00:36<00:51,  5.33it/s] 41%|████▏     | 195/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.31it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.33it/s] 42%|████▏     | 198/471 [00:36<00:51,  5.33it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.32it/s] 42%|████▏     | 200/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.33it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 204/471 [00:37<00:50,  5.31it/s] 44%|████▎     | 205/471 [00:38<00:49,  5.34it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.32it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.30it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.32it/s] 44%|████▍     | 209/471 [00:38<00:49,  5.34it/s] 45%|████▍     | 210/471 [00:39<00:48,  5.34it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.32it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.31it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.30it/s] 45%|████▌     | 214/471 [00:39<00:48,  5.30it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.32it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.31it/s] 46%|████▌     | 217/471 [00:40<00:47,  5.30it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.29it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.29it/s] 47%|████▋     | 220/471 [00:40<00:47,  5.30it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.30it/s] 47%|████▋     | 222/471 [00:41<00:46,  5.32it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.33it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.31it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.31it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.30it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.30it/s] 48%|████▊     | 228/471 [00:42<00:45,  5.31it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.30it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.29it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.30it/s] 49%|████▉     | 232/471 [00:43<00:44,  5.32it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.32it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.31it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.29it/s] 50%|█████     | 236/471 [00:44<00:44,  5.31it/s] 50%|█████     | 237/471 [00:44<00:44,  5.31it/s] 51%|█████     | 238/471 [00:44<00:43,  5.31it/s] 51%|█████     | 239/471 [00:44<00:43,  5.32it/s] 51%|█████     | 240/471 [00:44<00:43,  5.31it/s] 51%|█████     | 241/471 [00:44<00:43,  5.31it/s] 51%|█████▏    | 242/471 [00:45<00:42,  5.33it/s] 52%|█████▏    | 243/471 [00:45<00:43,  5.30it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.30it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.30it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.31it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.33it/s] 53%|█████▎    | 248/471 [00:46<00:41,  5.32it/s] 53%|█████▎    | 249/471 [00:46<00:41,  5.31it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.31it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.30it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.29it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.31it/s] 54%|█████▍    | 254/471 [00:47<00:40,  5.32it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.31it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.30it/s] 55%|█████▍    | 257/471 [00:47<00:40,  5.29it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.30it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.30it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.30it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.31it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.32it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.30it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.30it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.30it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.29it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.30it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.30it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.31it/s] 57%|█████▋    | 270/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.30it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 273/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 274/471 [00:51<00:36,  5.35it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.35it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 278/471 [00:51<00:36,  5.32it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.33it/s] 59%|█████▉    | 280/471 [00:52<00:35,  5.34it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.33it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.33it/s] 60%|██████    | 283/471 [00:52<00:35,  5.32it/s] 60%|██████    | 284/471 [00:53<00:35,  5.32it/s] 61%|██████    | 285/471 [00:53<00:35,  5.31it/s] 61%|██████    | 286/471 [00:53<00:34,  5.30it/s] 61%|██████    | 287/471 [00:53<00:34,  5.32it/s] 61%|██████    | 288/471 [00:53<00:34,  5.31it/s] 61%|██████▏   | 289/471 [00:53<00:34,  5.33it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.32it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.31it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.33it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.35it/s] 62%|██████▏   | 294/471 [00:54<00:33,  5.34it/s] 63%|██████▎   | 295/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.33it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.32it/s] 63%|██████▎   | 299/471 [00:55<00:32,  5.32it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.32it/s] 64%|██████▍   | 301/471 [00:56<00:31,  5.32it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.31it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.32it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.32it/s] 65%|██████▍   | 305/471 [00:56<00:31,  5.32it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.31it/s] 65%|██████▌   | 307/471 [00:57<00:30,  5.30it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.29it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.29it/s] 66%|██████▌   | 310/471 [00:57<00:30,  5.31it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.30it/s] 66%|██████▌   | 312/471 [00:58<00:29,  5.31it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.31it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.32it/s] 67%|██████▋   | 315/471 [00:58<00:29,  5.32it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.32it/s] 67%|██████▋   | 317/471 [00:59<00:28,  5.33it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 320/471 [00:59<00:28,  5.31it/s] 68%|██████▊   | 321/471 [00:59<00:28,  5.29it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.29it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.28it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.27it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.29it/s] 69%|██████▉   | 326/471 [01:00<00:27,  5.30it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.32it/s] 70%|██████▉   | 328/471 [01:01<00:26,  5.32it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.30it/s] 70%|███████   | 330/471 [01:01<00:26,  5.31it/s] 70%|███████   | 331/471 [01:01<00:26,  5.31it/s] 70%|███████   | 332/471 [01:02<00:26,  5.30it/s] 71%|███████   | 333/471 [01:02<00:25,  5.32it/s] 71%|███████   | 334/471 [01:02<00:25,  5.31it/s] 71%|███████   | 335/471 [01:02<00:25,  5.30it/s] 71%|███████▏  | 336/471 [01:02<00:25,  5.31it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.32it/s] 72%|███████▏  | 338/471 [01:03<00:24,  5.34it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.33it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.32it/s] 72%|███████▏  | 341/471 [01:03<00:24,  5.32it/s] 73%|███████▎  | 342/471 [01:03<00:24,  5.32it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.32it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.35it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.33it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.31it/s] 74%|███████▎  | 347/471 [01:04<00:23,  5.33it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.33it/s] 74%|███████▍  | 349/471 [01:05<00:22,  5.33it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.31it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.33it/s] 75%|███████▍  | 352/471 [01:05<00:22,  5.32it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.31it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.31it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.30it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 357/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 358/471 [01:06<00:21,  5.31it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.30it/s] 76%|███████▋  | 360/471 [01:07<00:20,  5.30it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.31it/s] 77%|███████▋  | 362/471 [01:07<00:20,  5.31it/s] 77%|███████▋  | 363/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.32it/s] 77%|███████▋  | 365/471 [01:08<00:19,  5.33it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.32it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.32it/s] 78%|███████▊  | 368/471 [01:08<00:19,  5.32it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.32it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.31it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.31it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.32it/s] 79%|███████▉  | 373/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 374/471 [01:09<00:18,  5.31it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.31it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.30it/s] 80%|████████  | 377/471 [01:10<00:17,  5.31it/s] 80%|████████  | 378/471 [01:10<00:17,  5.34it/s] 80%|████████  | 379/471 [01:10<00:17,  5.31it/s] 81%|████████  | 380/471 [01:11<00:17,  5.30it/s] 81%|████████  | 381/471 [01:11<00:16,  5.30it/s] 81%|████████  | 382/471 [01:11<00:16,  5.29it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.29it/s] 82%|████████▏ | 384/471 [01:11<00:16,  5.28it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.28it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.28it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.27it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.27it/s] 83%|████████▎ | 389/471 [01:12<00:15,  5.28it/s] 83%|████████▎ | 390/471 [01:12<00:15,  5.30it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.31it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.32it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.31it/s] 84%|████████▎ | 394/471 [01:13<00:14,  5.28it/s] 84%|████████▍ | 395/471 [01:13<00:14,  5.29it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.28it/s] 84%|████████▍ | 397/471 [01:14<00:13,  5.30it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.31it/s] 85%|████████▍ | 399/471 [01:14<00:13,  5.29it/s] 85%|████████▍ | 400/471 [01:14<00:13,  5.30it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.29it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.29it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.29it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.30it/s] 86%|████████▌ | 405/471 [01:15<00:12,  5.30it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.31it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.32it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.30it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.29it/s] 87%|████████▋ | 410/471 [01:16<00:11,  5.31it/s] 87%|████████▋ | 411/471 [01:16<00:11,  5.33it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.33it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.32it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.31it/s] 88%|████████▊ | 415/471 [01:17<00:10,  5.30it/s] 88%|████████▊ | 416/471 [01:17<00:10,  5.29it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.30it/s] 89%|████████▊ | 418/471 [01:18<00:09,  5.30it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.31it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.33it/s] 89%|████████▉ | 421/471 [01:18<00:09,  5.32it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.32it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.33it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.32it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.33it/s] 90%|█████████ | 426/471 [01:19<00:08,  5.30it/s] 91%|█████████ | 427/471 [01:19<00:08,  5.30it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.30it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.31it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.31it/s] 92%|█████████▏| 431/471 [01:20<00:07,  5.29it/s] 92%|█████████▏| 432/471 [01:20<00:07,  5.30it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.29it/s] 92%|█████████▏| 434/471 [01:21<00:06,  5.29it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.29it/s] 93%|█████████▎| 436/471 [01:21<00:06,  5.30it/s] 93%|█████████▎| 437/471 [01:21<00:06,  5.30it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.30it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.31it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.32it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.31it/s] 94%|█████████▍| 442/471 [01:22<00:05,  5.32it/s] 94%|█████████▍| 443/471 [01:22<00:05,  5.31it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.31it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.31it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.29it/s] 95%|█████████▍| 447/471 [01:23<00:04,  5.31it/s] 95%|█████████▌| 448/471 [01:23<00:04,  5.30it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.31it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.29it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.30it/s] 96%|█████████▌| 452/471 [01:24<00:03,  5.31it/s] 96%|█████████▌| 453/471 [01:24<00:03,  5.30it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.30it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.29it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.29it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.29it/s] 97%|█████████▋| 458/471 [01:25<00:02,  5.29it/s] 97%|█████████▋| 459/471 [01:26<00:02,  5.31it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.32it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.31it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.30it/s] 98%|█████████▊| 463/471 [01:26<00:01,  5.29it/s] 99%|█████████▊| 464/471 [01:26<00:01,  5.31it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.31it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.30it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.27it/s] 99%|█████████▉| 468/471 [01:27<00:00,  5.26it/s]100%|█████████▉| 469/471 [01:27<00:00,  5.26it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.28it/s]100%|██████████| 471/471 [01:28<00:00,  5.65it/s]100%|██████████| 471/471 [01:28<00:00,  5.34it/s]
{'eval_loss': 2.709036350250244, 'eval_model_preparation_time': 0.005, 'eval_acc': 0.3069569835369092, 'eval_runtime': 88.4065, 'eval_samples_per_second': 85.197, 'eval_steps_per_second': 5.328}
ROUND:11
CLIENT:23
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.316, 'grad_norm': 7.462130546569824, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 1.4464, 'grad_norm': 9.167041778564453, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.1584, 'grad_norm': 16.1942138671875, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.051, 'grad_norm': 23.000102996826172, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.527, 'grad_norm': 16.638912200927734, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.7512, 'grad_norm': 11.88591480255127, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 0.9711, 'grad_norm': 10.038278579711914, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 0.2523, 'grad_norm': 19.006624221801758, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 0.7738, 'grad_norm': 12.99836254119873, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 1.2632, 'grad_norm': 4.858922481536865, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 0.9646, 'grad_norm': 6.771398067474365, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.4627, 'grad_norm': 7.264465808868408, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.7453, 'grad_norm': 12.375788688659668, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.3251, 'grad_norm': 4.284089088439941, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.7411, 'grad_norm': 6.354917049407959, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.4612, 'grad_norm': 20.014080047607422, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.2571, 'grad_norm': 3.8687186241149902, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.1509, 'grad_norm': 3.001807928085327, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.8051, 'grad_norm': 8.03210735321045, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.2402, 'grad_norm': 3.067066192626953, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.2092, 'grad_norm': 4.382669925689697, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.8273, 'grad_norm': 7.428372383117676, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.2145, 'grad_norm': 1.6603803634643555, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 1.5361, 'grad_norm': 43.90856170654297, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.5013, 'grad_norm': 2.764561414718628, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.0557, 'grad_norm': 1.1374788284301758, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.1872, 'grad_norm': 1.7506946325302124, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.0663, 'grad_norm': 1.8510956764221191, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.0773, 'grad_norm': 1.5616965293884277, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.1388, 'grad_norm': 0.8729913234710693, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.4668, 'grad_norm': 2.0263431072235107, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0182, 'grad_norm': 1.3194420337677002, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.63it/s]                                               {'loss': 0.0667, 'grad_norm': 7.803508281707764, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.63it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.45it/s]                                               {'loss': 0.0167, 'grad_norm': 0.4905968904495239, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.45it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s]                                               {'loss': 0.5083, 'grad_norm': 0.8579211235046387, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s]                                               {'loss': 0.0708, 'grad_norm': 1.673500657081604, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0433, 'grad_norm': 1.4965895414352417, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.0655, 'grad_norm': 4.464372158050537, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.05it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.837, 'grad_norm': 17.016555786132812, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.0077, 'grad_norm': 0.5976747870445251, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]                                               {'train_runtime': 12.3378, 'train_samples_per_second': 45.794, 'train_steps_per_second': 3.242, 'train_loss': 0.7144666061503813, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]100%|██████████| 40/40 [00:12<00:00,  3.24it/s]
CLIENT:81
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.9733, 'grad_norm': 7.918699741363525, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.3212, 'grad_norm': 11.322153091430664, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.08it/s]                                              {'loss': 2.0136, 'grad_norm': 9.934234619140625, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.08it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.6464, 'grad_norm': 13.814146041870117, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.2744, 'grad_norm': 15.32960033416748, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.09it/s]                                              {'loss': 2.7085, 'grad_norm': 16.179162979125977, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.09it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.026, 'grad_norm': 10.244195938110352, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.5272, 'grad_norm': 54.557682037353516, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s]                                              {'loss': 0.3298, 'grad_norm': 6.901391506195068, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 1.4248, 'grad_norm': 10.837087631225586, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 0.6233, 'grad_norm': 8.554777145385742, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.7351, 'grad_norm': 5.438839435577393, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s]                                               {'loss': 1.4847, 'grad_norm': 11.216097831726074, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.2014, 'grad_norm': 8.445911407470703, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.4276, 'grad_norm': 8.869709968566895, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.2477, 'grad_norm': 33.56367874145508, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.12it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.5229, 'grad_norm': 4.008603096008301, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.3981, 'grad_norm': 4.6685991287231445, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 1.2784, 'grad_norm': 7.1878204345703125, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.3572, 'grad_norm': 7.780990123748779, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.0633, 'grad_norm': 2.2932324409484863, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.6939, 'grad_norm': 17.23767852783203, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.9364, 'grad_norm': 13.192802429199219, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.1062, 'grad_norm': 12.270956039428711, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.4261, 'grad_norm': 2.7891030311584473, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s]                                               {'loss': 0.4285, 'grad_norm': 2.9668447971343994, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.3277, 'grad_norm': 7.140360355377197, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.7209, 'grad_norm': 3.1063485145568848, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.1431, 'grad_norm': 4.088491439819336, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.3648, 'grad_norm': 9.02431869506836, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1098, 'grad_norm': 2.973450183868408, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0646, 'grad_norm': 6.458230018615723, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.9381, 'grad_norm': 2.2863662242889404, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.1103, 'grad_norm': 7.020408630371094, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.1181, 'grad_norm': 3.272261142730713, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.1422, 'grad_norm': 8.25395679473877, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.5303, 'grad_norm': 1.5052344799041748, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.2527, 'grad_norm': 14.326404571533203, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0534, 'grad_norm': 2.0775725841522217, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0889, 'grad_norm': 5.0090250968933105, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.1931, 'train_samples_per_second': 46.338, 'train_steps_per_second': 3.281, 'train_loss': 0.8535265095531941, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:85
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]                                              {'loss': 0.1624, 'grad_norm': 1.8637170791625977, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 0.0253, 'grad_norm': 0.7242118120193481, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 0.0197, 'grad_norm': 0.5863656401634216, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 0.3183, 'grad_norm': 0.34613826870918274, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s]                                              {'loss': 0.0854, 'grad_norm': 0.5429961681365967, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 0.0084, 'grad_norm': 0.11139791458845139, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.3233, 'grad_norm': 0.43289443850517273, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.0012, 'grad_norm': 0.03443567082285881, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 0.0085, 'grad_norm': 0.23639258742332458, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.0059, 'grad_norm': 0.07905351370573044, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 0.0082, 'grad_norm': 0.10793536901473999, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.4343, 'grad_norm': 0.18448150157928467, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 0.0042, 'grad_norm': 0.04704759269952774, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.177, 'grad_norm': 0.2550904154777527, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.1587, 'grad_norm': 0.2974375784397125, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.0, 'grad_norm': 0.000912660441827029, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.12it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.0025, 'grad_norm': 0.03024759516119957, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.0014, 'grad_norm': 0.01872219145298004, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.0021, 'grad_norm': 0.022644028067588806, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.1497, 'grad_norm': 0.31143832206726074, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.0782, 'grad_norm': 0.24910548329353333, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.2614, 'grad_norm': 0.3256690502166748, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.2802, 'grad_norm': 0.44891345500946045, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.003, 'grad_norm': 0.16121430695056915, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.13it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.0016, 'grad_norm': 0.01722184754908085, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s]                                               {'loss': 0.0026, 'grad_norm': 0.03670521453022957, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.49it/s]                                               {'loss': 0.146, 'grad_norm': 0.31888648867607117, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.49it/s] 70%|███████   | 28/40 [00:08<00:03,  3.34it/s]                                               {'loss': 0.2706, 'grad_norm': 0.43656131625175476, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.34it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.1652, 'grad_norm': 0.41164880990982056, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.24it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.22it/s]                                               {'loss': 0.0039, 'grad_norm': 0.05664471164345741, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.22it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.15it/s]                                               {'loss': 0.1912, 'grad_norm': 0.44466543197631836, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.15it/s]                                               {'loss': 0.0, 'grad_norm': 0.0002909547183662653, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.15it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0764, 'grad_norm': 0.18210469186306, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.1147, 'grad_norm': 0.09985476732254028, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.2522, 'grad_norm': 0.26461896300315857, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s]                                               {'loss': 0.0017, 'grad_norm': 0.024009212851524353, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.1471, 'grad_norm': 0.2748768627643585, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0016, 'grad_norm': 0.01686425507068634, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.1838, 'grad_norm': 0.2941302955150604, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0023, 'grad_norm': 0.06990186870098114, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.0641, 'train_samples_per_second': 46.833, 'train_steps_per_second': 3.316, 'train_loss': 0.10200006700868017, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:34
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.7793, 'grad_norm': 8.708632469177246, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.433, 'grad_norm': 8.657541275024414, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.6704, 'grad_norm': 14.985376358032227, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.3432, 'grad_norm': 16.18208885192871, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.8159, 'grad_norm': 19.477153778076172, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.2535, 'grad_norm': 12.961078643798828, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.1982, 'grad_norm': 14.14992618560791, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 0.4082, 'grad_norm': 50.941898345947266, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 0.3953, 'grad_norm': 3.9474101066589355, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 0.1952, 'grad_norm': 3.367823600769043, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.6166, 'grad_norm': 4.941880226135254, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 0.8939, 'grad_norm': 25.877304077148438, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.6061, 'grad_norm': 8.46716022491455, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.3517, 'grad_norm': 4.647960662841797, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.3899, 'grad_norm': 4.670787334442139, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 1.5839, 'grad_norm': 71.37628936767578, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s]                                               {'loss': 0.0639, 'grad_norm': 1.6286430358886719, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s]                                               {'loss': 0.2189, 'grad_norm': 1.9100450277328491, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.2824, 'grad_norm': 3.081418991088867, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.1334, 'grad_norm': 2.4610049724578857, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.1659, 'grad_norm': 4.45692777633667, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.0803, 'grad_norm': 3.0499303340911865, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.1758, 'grad_norm': 5.444525241851807, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.0118, 'grad_norm': 0.7395864725112915, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.12it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s]                                               {'loss': 0.0334, 'grad_norm': 0.9622198939323425, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.1169, 'grad_norm': 4.079999923706055, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.1425, 'grad_norm': 3.5613441467285156, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.0589, 'grad_norm': 1.7454277276992798, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.2283, 'grad_norm': 1.8233277797698975, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.0446, 'grad_norm': 0.9680168032646179, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0542, 'grad_norm': 1.4337103366851807, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.01, 'grad_norm': 0.7738949060440063, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0248, 'grad_norm': 0.7296091914176941, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.0344, 'grad_norm': 0.8807778358459473, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.153, 'grad_norm': 0.6373066902160645, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0217, 'grad_norm': 0.4839220345020294, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0769, 'grad_norm': 3.048927068710327, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1103, 'grad_norm': 7.659623146057129, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0349, 'grad_norm': 1.4858695268630981, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0134, 'grad_norm': 1.2635560035705566, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0674, 'train_samples_per_second': 46.82, 'train_steps_per_second': 3.315, 'train_loss': 0.5306141277309507, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:62
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]                                              {'loss': 2.6426, 'grad_norm': 8.688104629516602, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]  5%|▌         | 2/40 [00:00<00:12,  3.11it/s]                                              {'loss': 1.9844, 'grad_norm': 10.20570182800293, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.11it/s]  8%|▊         | 3/40 [00:00<00:12,  3.06it/s]                                              {'loss': 1.0129, 'grad_norm': 9.342615127563477, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.06it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.2294, 'grad_norm': 10.58353042602539, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.9363, 'grad_norm': 16.152015686035156, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.4121, 'grad_norm': 13.068334579467773, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.3748, 'grad_norm': 15.782102584838867, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 4.2039, 'grad_norm': 67.91865539550781, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 0.6326, 'grad_norm': 8.180990219116211, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 0.9939, 'grad_norm': 7.932419300079346, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 1.0398, 'grad_norm': 9.820767402648926, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.4977, 'grad_norm': 8.478014945983887, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.3746, 'grad_norm': 4.619715213775635, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.7219, 'grad_norm': 5.906190395355225, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.3711, 'grad_norm': 4.8160786628723145, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.5212, 'grad_norm': 1.1079585552215576, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.3198, 'grad_norm': 4.063593864440918, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.4771, 'grad_norm': 4.578138828277588, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.1636, 'grad_norm': 3.4411654472351074, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.1084, 'grad_norm': 2.3806517124176025, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s]                                               {'loss': 0.1723, 'grad_norm': 3.7517924308776855, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.1239, 'grad_norm': 3.4227497577667236, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.1483, 'grad_norm': 4.161514759063721, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.0827, 'grad_norm': 4.223264694213867, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.12it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.0338, 'grad_norm': 0.9029445648193359, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.0813, 'grad_norm': 1.9116871356964111, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.0763, 'grad_norm': 1.7184646129608154, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.0603, 'grad_norm': 1.6164494752883911, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0387, 'grad_norm': 0.736839234828949, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.1779, 'grad_norm': 3.362740993499756, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0281, 'grad_norm': 0.5674546957015991, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.041, 'grad_norm': 2.548203468322754, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.017, 'grad_norm': 0.5688192844390869, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.023, 'grad_norm': 0.9982367157936096, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.019, 'grad_norm': 0.4917876720428467, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.0286, 'grad_norm': 0.8598237037658691, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0322, 'grad_norm': 0.8753905892372131, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0529, 'grad_norm': 2.5646867752075195, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.117, 'grad_norm': 1.227316975593567, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0301, 'grad_norm': 1.7231234312057495, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0839, 'train_samples_per_second': 46.756, 'train_steps_per_second': 3.31, 'train_loss': 0.6350667552091182, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:46
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]                                              {'loss': 2.3864, 'grad_norm': 8.481284141540527, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.7956, 'grad_norm': 9.824197769165039, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:01<00:12,  3.00it/s]                                              {'loss': 3.2025, 'grad_norm': 14.114686965942383, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  3.00it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.6941, 'grad_norm': 9.435456275939941, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.2068, 'grad_norm': 12.58625316619873, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s]                                              {'loss': 2.1719, 'grad_norm': 12.496373176574707, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.252, 'grad_norm': 13.67624568939209, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.6277, 'grad_norm': 41.61023712158203, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.70it/s]                                              {'loss': 0.484, 'grad_norm': 6.992035388946533, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.70it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.6282, 'grad_norm': 7.588250160217285, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 0.8378, 'grad_norm': 9.01815128326416, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.2793, 'grad_norm': 4.225783348083496, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s]                                               {'loss': 0.8283, 'grad_norm': 6.943883895874023, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.7451, 'grad_norm': 4.606682777404785, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.5385, 'grad_norm': 6.599471569061279, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.4313, 'grad_norm': 62.86677932739258, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.83it/s]                                               {'loss': 0.3189, 'grad_norm': 5.119787216186523, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.569, 'grad_norm': 2.182014226913452, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.6047, 'grad_norm': 3.5887441635131836, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.1468, 'grad_norm': 2.948490858078003, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.4719, 'grad_norm': 14.020868301391602, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.1312, 'grad_norm': 2.6805858612060547, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.3116, 'grad_norm': 8.113463401794434, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.0087, 'grad_norm': 0.5214220881462097, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.1388, 'grad_norm': 4.62776517868042, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.0869, 'grad_norm': 3.1259448528289795, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s]                                               {'loss': 0.1022, 'grad_norm': 2.232811689376831, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.4971, 'grad_norm': 2.632256507873535, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.4284, 'grad_norm': 1.7769160270690918, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0451, 'grad_norm': 0.9619596004486084, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.1824, 'grad_norm': 3.8747613430023193, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0056, 'grad_norm': 0.34961873292922974, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.3214, 'grad_norm': 1.4039937257766724, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.1072, 'grad_norm': 4.185765743255615, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.3823, 'grad_norm': 2.5449416637420654, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.1221, 'grad_norm': 10.45587158203125, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0375, 'grad_norm': 1.4008904695510864, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0209, 'grad_norm': 0.6330944895744324, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0544, 'grad_norm': 1.7290507555007935, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 1.9691, 'grad_norm': 5.985822677612305, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.1166, 'train_samples_per_second': 46.63, 'train_steps_per_second': 3.301, 'train_loss': 0.7293467654963024, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.0417, 'grad_norm': 7.869412422180176, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 2.7204, 'grad_norm': 10.918187141418457, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.5275, 'grad_norm': 11.223345756530762, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.0307, 'grad_norm': 16.77451515197754, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.2214, 'grad_norm': 10.749059677124023, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.0117, 'grad_norm': 16.208097457885742, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 1.6744, 'grad_norm': 15.978838920593262, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 0.6305, 'grad_norm': 28.05862045288086, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 1.1215, 'grad_norm': 9.518348693847656, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s]                                               {'loss': 0.6361, 'grad_norm': 5.7478814125061035, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 1.1181, 'grad_norm': 5.215953350067139, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.23it/s]                                               {'loss': 0.5072, 'grad_norm': 5.248061180114746, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.23it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 0.6326, 'grad_norm': 6.823166847229004, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.7015, 'grad_norm': 6.685163497924805, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.7911, 'grad_norm': 8.41458797454834, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.7839, 'grad_norm': 38.81192398071289, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.1036, 'grad_norm': 1.4892609119415283, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.1159, 'grad_norm': 3.262826919555664, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.1077, 'grad_norm': 2.782134532928467, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.4561, 'grad_norm': 1.4427223205566406, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.4314, 'grad_norm': 3.2177155017852783, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.3839, 'grad_norm': 6.152390003204346, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.1651, 'grad_norm': 4.170623302459717, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0407, 'grad_norm': 2.176384687423706, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.0543, 'grad_norm': 1.5759128332138062, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s]                                               {'loss': 0.7425, 'grad_norm': 2.5334577560424805, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.0473, 'grad_norm': 1.0220296382904053, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.0493, 'grad_norm': 1.184461236000061, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0087, 'grad_norm': 0.18851245939731598, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.1118, 'grad_norm': 3.596442699432373, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0583, 'grad_norm': 4.041432857513428, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0302, 'grad_norm': 3.364452600479126, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s]                                               {'loss': 0.028, 'grad_norm': 1.3816994428634644, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.0175, 'grad_norm': 0.6859722137451172, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.035, 'grad_norm': 1.018131971359253, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.3328, 'grad_norm': 1.694655418395996, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0827, 'grad_norm': 2.415574312210083, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.4502, 'grad_norm': 2.7769713401794434, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0788, 'grad_norm': 1.7372386455535889, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0013, 'grad_norm': 0.09092506766319275, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1314, 'train_samples_per_second': 46.573, 'train_steps_per_second': 3.297, 'train_loss': 0.6020885563804768, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.3727, 'grad_norm': 7.19149112701416, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 2.3027, 'grad_norm': 11.954289436340332, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:01<00:12,  2.99it/s]                                              {'loss': 1.1602, 'grad_norm': 8.24099063873291, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.99it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.974, 'grad_norm': 17.180604934692383, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.5559, 'grad_norm': 23.283117294311523, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.3923, 'grad_norm': 16.694068908691406, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 2.1173, 'grad_norm': 16.12864112854004, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 0.2596, 'grad_norm': 14.723870277404785, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s]                                              {'loss': 0.7689, 'grad_norm': 7.462337017059326, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.63it/s]                                               {'loss': 0.3692, 'grad_norm': 6.016446590423584, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.63it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s]                                               {'loss': 0.8158, 'grad_norm': 9.731586456298828, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 1.117, 'grad_norm': 8.559226036071777, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.5059, 'grad_norm': 6.592376232147217, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.5946, 'grad_norm': 7.024387836456299, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.5418, 'grad_norm': 6.542924404144287, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.0468, 'grad_norm': 3.069175958633423, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.1006, 'grad_norm': 1.9271032810211182, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.60it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.0833, 'grad_norm': 2.681549549102783, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.42it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.31it/s]                                               {'loss': 0.1494, 'grad_norm': 3.880939245223999, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.31it/s] 50%|█████     | 20/40 [00:06<00:06,  3.21it/s]                                               {'loss': 0.1196, 'grad_norm': 2.7055928707122803, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.21it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.2176, 'grad_norm': 6.870728015899658, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.1843, 'grad_norm': 5.281977653503418, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.4706, 'grad_norm': 2.6631553173065186, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.2064, 'grad_norm': 9.479532241821289, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.06it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s]                                               {'loss': 0.3145, 'grad_norm': 14.24130916595459, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.0606, 'grad_norm': 2.06453537940979, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.0389, 'grad_norm': 0.7477648258209229, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.5085, 'grad_norm': 3.4572877883911133, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0581, 'grad_norm': 1.418797254562378, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0679, 'grad_norm': 1.4050096273422241, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0217, 'grad_norm': 0.41897156834602356, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0285, 'grad_norm': 2.169135093688965, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0706, 'grad_norm': 3.0191702842712402, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.4156, 'grad_norm': 3.0456442832946777, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0225, 'grad_norm': 0.5599325299263, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.0683, 'grad_norm': 2.692962408065796, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0821, 'grad_norm': 2.504992723464966, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0369, 'grad_norm': 1.7235122919082642, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0379, 'grad_norm': 1.0415749549865723, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.718, 'grad_norm': 29.568632125854492, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.2104, 'train_samples_per_second': 46.272, 'train_steps_per_second': 3.276, 'train_loss': 0.5994210302829742, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:93
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 3.0496, 'grad_norm': 8.518630981445312, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.11it/s]                                              {'loss': 1.5753, 'grad_norm': 12.367995262145996, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.11it/s]  8%|▊         | 3/40 [00:00<00:12,  3.08it/s]                                              {'loss': 2.7233, 'grad_norm': 22.67610740661621, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.08it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.0106, 'grad_norm': 16.548730850219727, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.6139, 'grad_norm': 11.2945556640625, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.8635, 'grad_norm': 12.550166130065918, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 2.1268, 'grad_norm': 11.342348098754883, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.6771, 'grad_norm': 45.93321228027344, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 0.8317, 'grad_norm': 9.828843116760254, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 0.8014, 'grad_norm': 9.816625595092773, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 0.5959, 'grad_norm': 5.311089038848877, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.636, 'grad_norm': 3.6768059730529785, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.7459, 'grad_norm': 6.096118450164795, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.6161, 'grad_norm': 10.514466285705566, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.8661, 'grad_norm': 9.85877799987793, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.3969, 'grad_norm': 36.64137649536133, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 0.2176, 'grad_norm': 5.546473979949951, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.3088, 'grad_norm': 4.927229404449463, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.4291, 'grad_norm': 3.3588860034942627, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.2972, 'grad_norm': 4.941524028778076, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.0957, 'grad_norm': 1.8089370727539062, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.08it/s]                                               {'loss': 0.1157, 'grad_norm': 2.928812265396118, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.08it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.5107, 'grad_norm': 3.1072347164154053, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.1584, 'grad_norm': 23.899953842163086, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s]                                               {'loss': 0.0569, 'grad_norm': 2.0689351558685303, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.1321, 'grad_norm': 6.8340911865234375, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.028, 'grad_norm': 0.9439923763275146, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.3136, 'grad_norm': 1.2417300939559937, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.0569, 'grad_norm': 1.5649138689041138, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.434, 'grad_norm': 2.1300299167633057, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0918, 'grad_norm': 4.558084011077881, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0196, 'grad_norm': 1.1463254690170288, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.0401, 'grad_norm': 0.9700331687927246, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.0194, 'grad_norm': 0.5664785504341125, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0438, 'grad_norm': 1.6174522638320923, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.6019, 'grad_norm': 1.5277998447418213, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.0894, 'grad_norm': 8.242583274841309, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0586, 'grad_norm': 1.4515248537063599, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0243, 'grad_norm': 0.7419628500938416, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0544, 'grad_norm': 3.221036434173584, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.1337, 'train_samples_per_second': 46.565, 'train_steps_per_second': 3.297, 'train_loss': 0.6582014908082783, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:11
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]                                              {'loss': 2.074, 'grad_norm': 7.526021480560303, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 1.5788, 'grad_norm': 8.147595405578613, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  2.98it/s]                                              {'loss': 2.001, 'grad_norm': 13.125130653381348, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.98it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 1.2321, 'grad_norm': 9.948822021484375, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s]                                              {'loss': 2.6681, 'grad_norm': 23.65909767150879, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.2421, 'grad_norm': 19.7593936920166, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 3.7297, 'grad_norm': 23.619003295898438, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.7176, 'grad_norm': 42.53731918334961, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 0.9433, 'grad_norm': 7.644282817840576, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 0.4002, 'grad_norm': 6.977616786956787, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 1.1057, 'grad_norm': 10.609474182128906, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 0.9534, 'grad_norm': 6.619078159332275, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.821, 'grad_norm': 5.64511251449585, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.8221, 'grad_norm': 6.456284999847412, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.4746, 'grad_norm': 7.559817790985107, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.0144, 'grad_norm': 0.5630747675895691, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.594, 'grad_norm': 3.9431846141815186, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s]                                               {'loss': 0.2007, 'grad_norm': 2.439251184463501, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s]                                               {'loss': 0.1975, 'grad_norm': 4.301246166229248, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.7364, 'grad_norm': 7.233394622802734, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.0814, 'grad_norm': 1.735207200050354, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.2415, 'grad_norm': 4.8321332931518555, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.3399, 'grad_norm': 7.079209804534912, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.0034, 'grad_norm': 0.19187535345554352, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.7854, 'grad_norm': 1.0868877172470093, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.0801, 'grad_norm': 2.9729013442993164, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s]                                               {'loss': 0.0195, 'grad_norm': 0.33247700333595276, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s] 70%|███████   | 28/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.0533, 'grad_norm': 1.2707505226135254, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.24it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.0203, 'grad_norm': 0.8826212882995605, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.08it/s]                                               {'loss': 0.1042, 'grad_norm': 2.861480951309204, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.08it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.0399, 'grad_norm': 1.3736352920532227, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.0096, 'grad_norm': 0.9625271558761597, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s]                                               {'loss': 0.0147, 'grad_norm': 0.4652975797653198, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s]                                               {'loss': 0.021, 'grad_norm': 0.861648440361023, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.1393, 'grad_norm': 1.9978567361831665, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0181, 'grad_norm': 0.6994693279266357, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.2546, 'grad_norm': 3.110349178314209, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.3226, 'grad_norm': 0.6355791091918945, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0297, 'grad_norm': 1.4175925254821777, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0053, 'grad_norm': 0.384306401014328, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]                                               {'train_runtime': 12.2134, 'train_samples_per_second': 46.261, 'train_steps_per_second': 3.275, 'train_loss': 0.6772653201071079, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:43, 10.82it/s]  1%|          | 4/471 [00:00<01:08,  6.80it/s]  1%|          | 5/471 [00:00<01:14,  6.28it/s]  1%|▏         | 6/471 [00:00<01:17,  5.97it/s]  1%|▏         | 7/471 [00:01<01:20,  5.77it/s]  2%|▏         | 8/471 [00:01<01:22,  5.64it/s]  2%|▏         | 9/471 [00:01<01:22,  5.57it/s]  2%|▏         | 10/471 [00:01<01:23,  5.52it/s]  2%|▏         | 11/471 [00:01<01:24,  5.47it/s]  3%|▎         | 12/471 [00:02<01:24,  5.43it/s]  3%|▎         | 13/471 [00:02<01:24,  5.39it/s]  3%|▎         | 14/471 [00:02<01:25,  5.37it/s]  3%|▎         | 15/471 [00:02<01:24,  5.38it/s]  3%|▎         | 16/471 [00:02<01:24,  5.37it/s]  4%|▎         | 17/471 [00:02<01:24,  5.36it/s]  4%|▍         | 18/471 [00:03<01:24,  5.35it/s]  4%|▍         | 19/471 [00:03<01:24,  5.35it/s]  4%|▍         | 20/471 [00:03<01:24,  5.34it/s]  4%|▍         | 21/471 [00:03<01:24,  5.34it/s]  5%|▍         | 22/471 [00:03<01:24,  5.33it/s]  5%|▍         | 23/471 [00:04<01:23,  5.36it/s]  5%|▌         | 24/471 [00:04<01:23,  5.35it/s]  5%|▌         | 25/471 [00:04<01:23,  5.36it/s]  6%|▌         | 26/471 [00:04<01:22,  5.36it/s]  6%|▌         | 27/471 [00:04<01:22,  5.35it/s]  6%|▌         | 28/471 [00:05<01:22,  5.34it/s]  6%|▌         | 29/471 [00:05<01:22,  5.35it/s]  6%|▋         | 30/471 [00:05<01:22,  5.33it/s]  7%|▋         | 31/471 [00:05<01:22,  5.33it/s]  7%|▋         | 32/471 [00:05<01:22,  5.35it/s]  7%|▋         | 33/471 [00:05<01:21,  5.38it/s]  7%|▋         | 34/471 [00:06<01:21,  5.37it/s]  7%|▋         | 35/471 [00:06<01:21,  5.37it/s]  8%|▊         | 36/471 [00:06<01:21,  5.36it/s]  8%|▊         | 37/471 [00:06<01:21,  5.34it/s]  8%|▊         | 38/471 [00:06<01:21,  5.33it/s]  8%|▊         | 39/471 [00:07<01:20,  5.34it/s]  8%|▊         | 40/471 [00:07<01:20,  5.33it/s]  9%|▊         | 41/471 [00:07<01:20,  5.33it/s]  9%|▉         | 42/471 [00:07<01:20,  5.32it/s]  9%|▉         | 43/471 [00:07<01:20,  5.33it/s]  9%|▉         | 44/471 [00:08<01:19,  5.35it/s] 10%|▉         | 45/471 [00:08<01:19,  5.33it/s] 10%|▉         | 46/471 [00:08<01:19,  5.34it/s] 10%|▉         | 47/471 [00:08<01:19,  5.35it/s] 10%|█         | 48/471 [00:08<01:19,  5.35it/s] 10%|█         | 49/471 [00:08<01:18,  5.34it/s] 11%|█         | 50/471 [00:09<01:18,  5.33it/s] 11%|█         | 51/471 [00:09<01:18,  5.33it/s] 11%|█         | 52/471 [00:09<01:18,  5.33it/s] 11%|█▏        | 53/471 [00:09<01:18,  5.32it/s] 11%|█▏        | 54/471 [00:09<01:18,  5.32it/s] 12%|█▏        | 55/471 [00:10<01:18,  5.32it/s] 12%|█▏        | 56/471 [00:10<01:18,  5.32it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.34it/s] 12%|█▏        | 58/471 [00:10<01:17,  5.31it/s] 13%|█▎        | 59/471 [00:10<01:17,  5.31it/s] 13%|█▎        | 60/471 [00:11<01:17,  5.32it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.33it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.34it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.33it/s] 14%|█▎        | 64/471 [00:11<01:16,  5.31it/s] 14%|█▍        | 65/471 [00:11<01:16,  5.32it/s] 14%|█▍        | 66/471 [00:12<01:16,  5.33it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.33it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.31it/s] 15%|█▍        | 69/471 [00:12<01:15,  5.30it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.29it/s] 15%|█▌        | 71/471 [00:13<01:15,  5.30it/s] 15%|█▌        | 72/471 [00:13<01:15,  5.30it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.32it/s] 16%|█▌        | 74/471 [00:13<01:14,  5.32it/s] 16%|█▌        | 75/471 [00:13<01:14,  5.30it/s] 16%|█▌        | 76/471 [00:14<01:14,  5.31it/s] 16%|█▋        | 77/471 [00:14<01:14,  5.32it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.32it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.31it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.30it/s] 17%|█▋        | 81/471 [00:14<01:13,  5.31it/s] 17%|█▋        | 82/471 [00:15<01:13,  5.32it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.31it/s] 18%|█▊        | 86/471 [00:15<01:12,  5.31it/s] 18%|█▊        | 87/471 [00:16<01:12,  5.31it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.33it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.33it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.31it/s] 19%|█▉        | 91/471 [00:16<01:11,  5.32it/s] 20%|█▉        | 92/471 [00:17<01:11,  5.31it/s] 20%|█▉        | 93/471 [00:17<01:11,  5.32it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.34it/s] 20%|██        | 95/471 [00:17<01:10,  5.33it/s] 20%|██        | 96/471 [00:17<01:10,  5.33it/s] 21%|██        | 97/471 [00:17<01:10,  5.31it/s] 21%|██        | 98/471 [00:18<01:10,  5.32it/s] 21%|██        | 99/471 [00:18<01:09,  5.33it/s] 21%|██        | 100/471 [00:18<01:09,  5.34it/s] 21%|██▏       | 101/471 [00:18<01:09,  5.35it/s] 22%|██▏       | 102/471 [00:18<01:09,  5.33it/s] 22%|██▏       | 103/471 [00:19<01:09,  5.32it/s] 22%|██▏       | 104/471 [00:19<01:09,  5.31it/s] 22%|██▏       | 105/471 [00:19<01:09,  5.29it/s] 23%|██▎       | 106/471 [00:19<01:08,  5.33it/s] 23%|██▎       | 107/471 [00:19<01:08,  5.35it/s] 23%|██▎       | 108/471 [00:20<01:07,  5.34it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.33it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.34it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.33it/s] 24%|██▍       | 112/471 [00:20<01:07,  5.33it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.36it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.34it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.33it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.32it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.32it/s] 25%|██▌       | 118/471 [00:21<01:06,  5.31it/s] 25%|██▌       | 119/471 [00:22<01:06,  5.31it/s] 25%|██▌       | 120/471 [00:22<01:06,  5.30it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.30it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.31it/s] 26%|██▌       | 123/471 [00:22<01:05,  5.31it/s] 26%|██▋       | 124/471 [00:23<01:05,  5.31it/s] 27%|██▋       | 125/471 [00:23<01:05,  5.30it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.31it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.31it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.31it/s] 27%|██▋       | 129/471 [00:24<01:04,  5.32it/s] 28%|██▊       | 130/471 [00:24<01:04,  5.31it/s] 28%|██▊       | 131/471 [00:24<01:04,  5.30it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.30it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.31it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.30it/s] 29%|██▊       | 135/471 [00:25<01:03,  5.30it/s] 29%|██▉       | 136/471 [00:25<01:03,  5.30it/s] 29%|██▉       | 137/471 [00:25<01:03,  5.30it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.30it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.30it/s] 30%|██▉       | 140/471 [00:26<01:02,  5.30it/s] 30%|██▉       | 141/471 [00:26<01:02,  5.32it/s] 30%|███       | 142/471 [00:26<01:01,  5.33it/s] 30%|███       | 143/471 [00:26<01:01,  5.32it/s] 31%|███       | 144/471 [00:26<01:01,  5.29it/s] 31%|███       | 145/471 [00:27<01:01,  5.31it/s] 31%|███       | 146/471 [00:27<01:01,  5.30it/s] 31%|███       | 147/471 [00:27<01:00,  5.31it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.33it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.29it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.28it/s] 32%|███▏      | 151/471 [00:28<01:00,  5.28it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.29it/s] 32%|███▏      | 153/471 [00:28<01:00,  5.29it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.32it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.31it/s] 33%|███▎      | 156/471 [00:29<00:59,  5.32it/s] 33%|███▎      | 157/471 [00:29<00:59,  5.32it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.32it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.32it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.32it/s] 34%|███▍      | 161/471 [00:30<00:58,  5.30it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.29it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.28it/s] 35%|███▍      | 164/471 [00:30<00:58,  5.29it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.30it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.29it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.28it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.28it/s] 36%|███▌      | 169/471 [00:31<00:57,  5.27it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.29it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.29it/s] 37%|███▋      | 172/471 [00:32<00:56,  5.30it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.30it/s] 37%|███▋      | 174/471 [00:32<00:56,  5.30it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.30it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.31it/s] 38%|███▊      | 177/471 [00:33<00:55,  5.29it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.29it/s] 38%|███▊      | 179/471 [00:33<00:55,  5.30it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.30it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.29it/s] 39%|███▊      | 182/471 [00:34<00:54,  5.28it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.28it/s] 39%|███▉      | 184/471 [00:34<00:54,  5.29it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.30it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.28it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.28it/s] 40%|███▉      | 188/471 [00:35<00:53,  5.27it/s] 40%|████      | 189/471 [00:35<00:53,  5.28it/s] 40%|████      | 190/471 [00:35<00:53,  5.29it/s] 41%|████      | 191/471 [00:35<00:53,  5.28it/s] 41%|████      | 192/471 [00:35<00:52,  5.30it/s] 41%|████      | 193/471 [00:36<00:52,  5.32it/s] 41%|████      | 194/471 [00:36<00:52,  5.31it/s] 41%|████▏     | 195/471 [00:36<00:52,  5.30it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.30it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 198/471 [00:37<00:51,  5.32it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.31it/s] 42%|████▏     | 200/471 [00:37<00:51,  5.30it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.33it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.30it/s] 43%|████▎     | 204/471 [00:38<00:50,  5.29it/s] 44%|████▎     | 205/471 [00:38<00:50,  5.30it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.31it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.31it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.33it/s] 44%|████▍     | 209/471 [00:39<00:49,  5.33it/s] 45%|████▍     | 210/471 [00:39<00:49,  5.32it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.32it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.32it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.31it/s] 45%|████▌     | 214/471 [00:40<00:48,  5.30it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.29it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.29it/s] 46%|████▌     | 217/471 [00:40<00:48,  5.27it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.28it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.28it/s] 47%|████▋     | 220/471 [00:41<00:47,  5.27it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.26it/s] 47%|████▋     | 222/471 [00:41<00:47,  5.29it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.31it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.31it/s] 48%|████▊     | 225/471 [00:42<00:46,  5.30it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.30it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.29it/s] 48%|████▊     | 228/471 [00:42<00:45,  5.29it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.29it/s] 49%|████▉     | 230/471 [00:43<00:45,  5.27it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.28it/s] 49%|████▉     | 232/471 [00:43<00:45,  5.30it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.30it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.31it/s] 50%|████▉     | 235/471 [00:44<00:44,  5.29it/s] 50%|█████     | 236/471 [00:44<00:44,  5.31it/s] 50%|█████     | 237/471 [00:44<00:44,  5.30it/s] 51%|█████     | 238/471 [00:44<00:43,  5.30it/s] 51%|█████     | 239/471 [00:44<00:43,  5.31it/s] 51%|█████     | 240/471 [00:44<00:43,  5.31it/s] 51%|█████     | 241/471 [00:45<00:43,  5.30it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.30it/s] 52%|█████▏    | 243/471 [00:45<00:43,  5.28it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.28it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.29it/s] 52%|█████▏    | 246/471 [00:46<00:42,  5.30it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.32it/s] 53%|█████▎    | 248/471 [00:46<00:42,  5.31it/s] 53%|█████▎    | 249/471 [00:46<00:42,  5.29it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.29it/s] 53%|█████▎    | 251/471 [00:47<00:41,  5.30it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.31it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.29it/s] 54%|█████▍    | 254/471 [00:47<00:41,  5.28it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.28it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.28it/s] 55%|█████▍    | 257/471 [00:48<00:40,  5.28it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.28it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.29it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.29it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.28it/s] 56%|█████▌    | 262/471 [00:49<00:39,  5.31it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.31it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.30it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.29it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.28it/s] 57%|█████▋    | 267/471 [00:50<00:38,  5.28it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.28it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.29it/s] 57%|█████▋    | 270/471 [00:50<00:37,  5.29it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.29it/s] 58%|█████▊    | 272/471 [00:51<00:37,  5.31it/s] 58%|█████▊    | 273/471 [00:51<00:37,  5.31it/s] 58%|█████▊    | 274/471 [00:51<00:37,  5.32it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.32it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.30it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.30it/s] 59%|█████▉    | 278/471 [00:52<00:36,  5.30it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.30it/s] 59%|█████▉    | 280/471 [00:52<00:36,  5.29it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.29it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.29it/s] 60%|██████    | 283/471 [00:53<00:35,  5.28it/s] 60%|██████    | 284/471 [00:53<00:35,  5.29it/s] 61%|██████    | 285/471 [00:53<00:35,  5.27it/s] 61%|██████    | 286/471 [00:53<00:35,  5.27it/s] 61%|██████    | 287/471 [00:53<00:34,  5.28it/s] 61%|██████    | 288/471 [00:54<00:34,  5.27it/s] 61%|██████▏   | 289/471 [00:54<00:34,  5.29it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.29it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.29it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.30it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.30it/s] 62%|██████▏   | 294/471 [00:55<00:33,  5.30it/s] 63%|██████▎   | 295/471 [00:55<00:33,  5.30it/s] 63%|██████▎   | 296/471 [00:55<00:33,  5.30it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.31it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.33it/s] 63%|██████▎   | 299/471 [00:56<00:32,  5.31it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.29it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.28it/s] 64%|██████▍   | 302/471 [00:56<00:32,  5.28it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.28it/s] 65%|██████▍   | 304/471 [00:57<00:31,  5.30it/s] 65%|██████▍   | 305/471 [00:57<00:31,  5.28it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.27it/s] 65%|██████▌   | 307/471 [00:57<00:31,  5.26it/s] 65%|██████▌   | 308/471 [00:57<00:31,  5.26it/s] 66%|██████▌   | 309/471 [00:58<00:30,  5.27it/s] 66%|██████▌   | 310/471 [00:58<00:30,  5.27it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.26it/s] 66%|██████▌   | 312/471 [00:58<00:30,  5.28it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.28it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.29it/s] 67%|██████▋   | 315/471 [00:59<00:29,  5.30it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.31it/s] 67%|██████▋   | 317/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.30it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.29it/s] 68%|██████▊   | 320/471 [01:00<00:28,  5.28it/s] 68%|██████▊   | 321/471 [01:00<00:28,  5.28it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.28it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.27it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.25it/s] 69%|██████▉   | 325/471 [01:01<00:27,  5.28it/s] 69%|██████▉   | 326/471 [01:01<00:27,  5.28it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.29it/s] 70%|██████▉   | 328/471 [01:01<00:27,  5.29it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.31it/s] 70%|███████   | 330/471 [01:01<00:26,  5.32it/s] 70%|███████   | 331/471 [01:02<00:26,  5.30it/s] 70%|███████   | 332/471 [01:02<00:26,  5.28it/s] 71%|███████   | 333/471 [01:02<00:26,  5.29it/s] 71%|███████   | 334/471 [01:02<00:25,  5.29it/s] 71%|███████   | 335/471 [01:02<00:25,  5.28it/s] 71%|███████▏  | 336/471 [01:03<00:25,  5.29it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.31it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.31it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.30it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.31it/s] 72%|███████▏  | 341/471 [01:04<00:24,  5.29it/s] 73%|███████▎  | 342/471 [01:04<00:24,  5.31it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.29it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.30it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.29it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.30it/s] 74%|███████▎  | 347/471 [01:05<00:23,  5.32it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.30it/s] 74%|███████▍  | 349/471 [01:05<00:23,  5.30it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.28it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.30it/s] 75%|███████▍  | 352/471 [01:06<00:22,  5.28it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.28it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.27it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.28it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.25it/s] 76%|███████▌  | 357/471 [01:07<00:21,  5.25it/s] 76%|███████▌  | 358/471 [01:07<00:21,  5.27it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.27it/s] 76%|███████▋  | 360/471 [01:07<00:21,  5.27it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.28it/s] 77%|███████▋  | 362/471 [01:08<00:20,  5.28it/s] 77%|███████▋  | 363/471 [01:08<00:20,  5.28it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.29it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.29it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.28it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.27it/s] 78%|███████▊  | 368/471 [01:09<00:19,  5.27it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.28it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.28it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.29it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.27it/s] 79%|███████▉  | 373/471 [01:10<00:18,  5.27it/s] 79%|███████▉  | 374/471 [01:10<00:18,  5.28it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.29it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.28it/s] 80%|████████  | 377/471 [01:10<00:17,  5.28it/s] 80%|████████  | 378/471 [01:11<00:17,  5.30it/s] 80%|████████  | 379/471 [01:11<00:17,  5.29it/s] 81%|████████  | 380/471 [01:11<00:17,  5.27it/s] 81%|████████  | 381/471 [01:11<00:17,  5.27it/s] 81%|████████  | 382/471 [01:11<00:16,  5.27it/s] 81%|████████▏ | 383/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 384/471 [01:12<00:16,  5.25it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.25it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.24it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.26it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.25it/s] 83%|████████▎ | 389/471 [01:13<00:15,  5.27it/s] 83%|████████▎ | 390/471 [01:13<00:15,  5.26it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.27it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.27it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.28it/s] 84%|████████▎ | 394/471 [01:14<00:14,  5.26it/s] 84%|████████▍ | 395/471 [01:14<00:14,  5.26it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.26it/s] 84%|████████▍ | 397/471 [01:14<00:14,  5.27it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.27it/s] 85%|████████▍ | 399/471 [01:15<00:13,  5.26it/s] 85%|████████▍ | 400/471 [01:15<00:13,  5.25it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.27it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.26it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.27it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.27it/s] 86%|████████▌ | 405/471 [01:16<00:12,  5.27it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.27it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.28it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.26it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.26it/s] 87%|████████▋ | 410/471 [01:17<00:11,  5.29it/s] 87%|████████▋ | 411/471 [01:17<00:11,  5.30it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.29it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.29it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.29it/s] 88%|████████▊ | 415/471 [01:18<00:10,  5.29it/s] 88%|████████▊ | 416/471 [01:18<00:10,  5.27it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.28it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.27it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.29it/s] 89%|████████▉ | 420/471 [01:19<00:09,  5.30it/s] 89%|████████▉ | 421/471 [01:19<00:09,  5.29it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.29it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.29it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.29it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.29it/s] 90%|█████████ | 426/471 [01:20<00:08,  5.28it/s] 91%|█████████ | 427/471 [01:20<00:08,  5.28it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.26it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.27it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.26it/s] 92%|█████████▏| 431/471 [01:21<00:07,  5.25it/s] 92%|█████████▏| 432/471 [01:21<00:07,  5.25it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 434/471 [01:21<00:07,  5.25it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.24it/s] 93%|█████████▎| 436/471 [01:22<00:06,  5.27it/s] 93%|█████████▎| 437/471 [01:22<00:06,  5.25it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.26it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.26it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.27it/s] 94%|█████████▎| 441/471 [01:23<00:05,  5.27it/s] 94%|█████████▍| 442/471 [01:23<00:05,  5.27it/s] 94%|█████████▍| 443/471 [01:23<00:05,  5.26it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.25it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.25it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.25it/s] 95%|█████████▍| 447/471 [01:24<00:04,  5.26it/s] 95%|█████████▌| 448/471 [01:24<00:04,  5.27it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.26it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.26it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.26it/s] 96%|█████████▌| 452/471 [01:25<00:03,  5.28it/s] 96%|█████████▌| 453/471 [01:25<00:03,  5.26it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.26it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.25it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.27it/s] 97%|█████████▋| 457/471 [01:26<00:02,  5.26it/s] 97%|█████████▋| 458/471 [01:26<00:02,  5.28it/s] 97%|█████████▋| 459/471 [01:26<00:02,  5.30it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.28it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.27it/s] 98%|█████████▊| 462/471 [01:27<00:01,  5.27it/s] 98%|█████████▊| 463/471 [01:27<00:01,  5.28it/s] 99%|█████████▊| 464/471 [01:27<00:01,  5.27it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.29it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.27it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.26it/s] 99%|█████████▉| 468/471 [01:28<00:00,  5.24it/s]100%|█████████▉| 469/471 [01:28<00:00,  5.25it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.26it/s]100%|██████████| 471/471 [01:28<00:00,  5.63it/s]100%|██████████| 471/471 [01:28<00:00,  5.31it/s]
{'eval_loss': 2.5792298316955566, 'eval_model_preparation_time': 0.0051, 'eval_acc': 0.33337758895379715, 'eval_runtime': 88.8414, 'eval_samples_per_second': 84.78, 'eval_steps_per_second': 5.302}
ROUND:12
CLIENT:80
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.4818, 'grad_norm': 6.769168376922607, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.3441, 'grad_norm': 10.79593276977539, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.5092, 'grad_norm': 9.916377067565918, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 2.2385, 'grad_norm': 13.174029350280762, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 2.2665, 'grad_norm': 14.100592613220215, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.6856, 'grad_norm': 18.632816314697266, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 1.9049, 'grad_norm': 17.444448471069336, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.2173, 'grad_norm': 13.151886940002441, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s]                                              {'loss': 0.6655, 'grad_norm': 10.084772109985352, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s]                                               {'loss': 0.6474, 'grad_norm': 8.046953201293945, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s]                                               {'loss': 0.2569, 'grad_norm': 4.368268966674805, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s] 30%|███       | 12/40 [00:03<00:08,  3.21it/s]                                               {'loss': 0.8835, 'grad_norm': 8.627243995666504, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.21it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.9704, 'grad_norm': 5.653270244598389, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.1014, 'grad_norm': 8.274809837341309, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 1.2352, 'grad_norm': 8.166028022766113, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.0098, 'grad_norm': 1.0698039531707764, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.5145, 'grad_norm': 2.114170551300049, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.5059, 'grad_norm': 3.3688488006591797, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.5411, 'grad_norm': 1.9181994199752808, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.2442, 'grad_norm': 3.6402759552001953, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.3092, 'grad_norm': 10.983275413513184, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.4266, 'grad_norm': 9.856732368469238, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.2538, 'grad_norm': 4.286590576171875, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.255, 'grad_norm': 10.840446472167969, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.4195, 'grad_norm': 1.2715462446212769, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.0722, 'grad_norm': 2.155663013458252, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s]                                               {'loss': 0.2965, 'grad_norm': 1.5802807807922363, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.2625, 'grad_norm': 1.5975031852722168, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.2597, 'grad_norm': 7.896224498748779, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.0885, 'grad_norm': 4.245746612548828, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.1697, 'grad_norm': 7.780831336975098, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 5.6174, 'grad_norm': 7.347692489624023, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s]                                               {'loss': 0.0322, 'grad_norm': 0.8326996564865112, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.3988, 'grad_norm': 2.7596187591552734, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.0845, 'grad_norm': 2.73830509185791, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.4549, 'grad_norm': 1.3310233354568481, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0385, 'grad_norm': 1.2217687368392944, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0124, 'grad_norm': 0.42545270919799805, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.3658, 'grad_norm': 0.9120239019393921, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.001, 'grad_norm': 0.0644306093454361, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.1803, 'train_samples_per_second': 46.386, 'train_steps_per_second': 3.284, 'train_loss': 0.8260579964320641, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:84
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.91it/s]                                              {'loss': 1.3863, 'grad_norm': 5.803069114685059, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.91it/s]  5%|▌         | 2/40 [00:00<00:12,  2.96it/s]                                              {'loss': 1.8568, 'grad_norm': 8.12979507446289, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.96it/s]  8%|▊         | 3/40 [00:01<00:12,  2.96it/s]                                              {'loss': 1.4245, 'grad_norm': 9.52537727355957, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.96it/s] 10%|█         | 4/40 [00:01<00:12,  2.96it/s]                                              {'loss': 1.1302, 'grad_norm': 12.527551651000977, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.96it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s]                                              {'loss': 0.7136, 'grad_norm': 11.105204582214355, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.2287, 'grad_norm': 20.04234504699707, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 1.8298, 'grad_norm': 18.54112434387207, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 0.1865, 'grad_norm': 10.80041217803955, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 0.9229, 'grad_norm': 7.971638202667236, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.61it/s]                                               {'loss': 0.62, 'grad_norm': 7.286739349365234, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.61it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 0.2987, 'grad_norm': 5.08715295791626, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 0.3597, 'grad_norm': 5.824307918548584, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.485, 'grad_norm': 7.798536777496338, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.4917, 'grad_norm': 13.882806777954102, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.5131, 'grad_norm': 7.619638919830322, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.077, 'grad_norm': 4.274413585662842, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s]                                               {'loss': 0.0399, 'grad_norm': 0.9632584452629089, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s]                                               {'loss': 0.1938, 'grad_norm': 1.8077116012573242, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s]                                               {'loss': 0.0838, 'grad_norm': 1.5960599184036255, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.3562, 'grad_norm': 8.892759323120117, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.1368, 'grad_norm': 2.6632354259490967, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.5847, 'grad_norm': 3.7580435276031494, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.2, 'grad_norm': 3.572143316268921, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.0122, 'grad_norm': 0.6141201853752136, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.0427, 'grad_norm': 0.9913762211799622, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s]                                               {'loss': 0.4877, 'grad_norm': 2.0414445400238037, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.0411, 'grad_norm': 1.7598034143447876, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.0879, 'grad_norm': 3.0809340476989746, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.0253, 'grad_norm': 0.7646377086639404, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.1874, 'grad_norm': 3.148952007293701, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0802, 'grad_norm': 2.326972723007202, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0524, 'grad_norm': 2.873053789138794, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.75it/s]                                               {'loss': 0.0123, 'grad_norm': 0.30346789956092834, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.75it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.48it/s]                                               {'loss': 0.0101, 'grad_norm': 0.33505862951278687, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.48it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s]                                               {'loss': 0.0154, 'grad_norm': 0.415365070104599, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.4389, 'grad_norm': 0.75246661901474, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.1244, 'grad_norm': 0.7268347144126892, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0508, 'grad_norm': 1.446155071258545, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0088, 'grad_norm': 0.2536904811859131, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0056, 'grad_norm': 0.34045132994651794, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.1984, 'train_samples_per_second': 46.318, 'train_steps_per_second': 3.279, 'train_loss': 0.44507165575632823, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:33
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.17it/s]                                              {'loss': 3.0588, 'grad_norm': 10.729948997497559, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.17it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.4853, 'grad_norm': 10.803771018981934, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  2.99it/s]                                              {'loss': 1.8374, 'grad_norm': 13.964542388916016, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  2.99it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 1.3412, 'grad_norm': 12.765650749206543, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.7696, 'grad_norm': 20.3947696685791, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.9781, 'grad_norm': 12.701467514038086, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 2.2687, 'grad_norm': 21.43701171875, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.029, 'grad_norm': 2.338923692703247, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 0.7589, 'grad_norm': 11.456497192382812, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 0.857, 'grad_norm': 12.63733959197998, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s]                                               {'loss': 0.9171, 'grad_norm': 11.233924865722656, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 1.2067, 'grad_norm': 14.397198677062988, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 1.3314, 'grad_norm': 6.884220123291016, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.9582, 'grad_norm': 7.8773603439331055, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.4821, 'grad_norm': 6.41806697845459, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.4688, 'grad_norm': 17.526317596435547, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.1655, 'grad_norm': 4.3525071144104, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.4532, 'grad_norm': 6.216363906860352, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.616, 'grad_norm': 4.247203350067139, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.3525, 'grad_norm': 6.53253698348999, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.5202, 'grad_norm': 12.941498756408691, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.6978, 'grad_norm': 5.202934265136719, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.2862, 'grad_norm': 6.070903778076172, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.2223, 'grad_norm': 14.128613471984863, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.0867, 'grad_norm': 2.4886865615844727, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s]                                               {'loss': 0.087, 'grad_norm': 2.150886297225952, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.1062, 'grad_norm': 1.9310506582260132, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.4983, 'grad_norm': 2.0084335803985596, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.1058, 'grad_norm': 2.7712209224700928, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.4188, 'grad_norm': 1.4034734964370728, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.131, 'grad_norm': 3.123201370239258, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.6489, 'grad_norm': 88.70258331298828, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.0492, 'grad_norm': 1.3204593658447266, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0598, 'grad_norm': 2.460437297821045, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.0404, 'grad_norm': 1.884049654006958, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.756, 'grad_norm': 4.170044898986816, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0524, 'grad_norm': 1.5964664220809937, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0597, 'grad_norm': 4.011842250823975, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0267, 'grad_norm': 0.8695841431617737, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0107, 'grad_norm': 0.8306180834770203, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.1985, 'train_samples_per_second': 46.317, 'train_steps_per_second': 3.279, 'train_loss': 0.7049838568316773, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:81
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 2.7991, 'grad_norm': 7.874445915222168, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.0825, 'grad_norm': 11.601318359375, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.8511, 'grad_norm': 9.718029975891113, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.09it/s]                                              {'loss': 2.5116, 'grad_norm': 14.5759916305542, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.09it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.08it/s]                                              {'loss': 2.1191, 'grad_norm': 16.316314697265625, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.08it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.07it/s]                                              {'loss': 2.5628, 'grad_norm': 16.725257873535156, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.07it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.9677, 'grad_norm': 10.614001274108887, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.3599, 'grad_norm': 57.980812072753906, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 0.2373, 'grad_norm': 5.833271503448486, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 1.2362, 'grad_norm': 13.923233032226562, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 0.6013, 'grad_norm': 9.489680290222168, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 0.6748, 'grad_norm': 6.6652445793151855, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.2367, 'grad_norm': 13.18114948272705, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.1141, 'grad_norm': 19.320026397705078, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.2945, 'grad_norm': 6.57604455947876, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 1.1934, 'grad_norm': 33.247379302978516, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.70it/s]                                               {'loss': 0.5059, 'grad_norm': 4.666453838348389, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.70it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.50it/s]                                               {'loss': 0.3702, 'grad_norm': 4.596251964569092, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.50it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s]                                               {'loss': 1.2267, 'grad_norm': 6.695206642150879, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.5413, 'grad_norm': 10.794844627380371, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.0619, 'grad_norm': 1.863130807876587, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.2545, 'grad_norm': 6.569545269012451, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.8395, 'grad_norm': 10.833807945251465, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.4811, 'grad_norm': 37.76375961303711, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.4181, 'grad_norm': 2.4530251026153564, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s]                                               {'loss': 0.5444, 'grad_norm': 6.073411464691162, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.6001, 'grad_norm': 10.064262390136719, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.741, 'grad_norm': 2.5834872722625732, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1303, 'grad_norm': 4.2314372062683105, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.2384, 'grad_norm': 2.1277170181274414, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.1927, 'grad_norm': 5.109327793121338, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.513, 'grad_norm': 53.39564895629883, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.9829, 'grad_norm': 2.104053497314453, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.0736, 'grad_norm': 5.843867301940918, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.147, 'grad_norm': 9.778555870056152, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.1269, 'grad_norm': 7.365950584411621, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.5238, 'grad_norm': 2.062896490097046, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.2109, 'grad_norm': 8.65098762512207, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0798, 'grad_norm': 3.2128000259399414, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0417, 'grad_norm': 2.8104324340820312, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1074, 'train_samples_per_second': 46.666, 'train_steps_per_second': 3.304, 'train_loss': 0.8171941080130637, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:93
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 2.8129, 'grad_norm': 9.283479690551758, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]                                              {'loss': 1.3509, 'grad_norm': 11.394364356994629, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]  8%|▊         | 3/40 [00:01<00:12,  2.96it/s]                                              {'loss': 2.6415, 'grad_norm': 24.486814498901367, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.96it/s] 10%|█         | 4/40 [00:01<00:12,  2.95it/s]                                              {'loss': 2.0859, 'grad_norm': 17.025314331054688, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.95it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.94it/s]                                              {'loss': 1.4764, 'grad_norm': 12.81574535369873, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.94it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.6356, 'grad_norm': 13.369842529296875, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 1.8498, 'grad_norm': 13.125617027282715, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.4739, 'grad_norm': 37.29751968383789, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 0.6041, 'grad_norm': 10.717029571533203, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 0.7414, 'grad_norm': 9.510845184326172, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 0.5947, 'grad_norm': 6.82369327545166, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 0.6257, 'grad_norm': 4.257242679595947, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.8052, 'grad_norm': 6.818282604217529, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.5398, 'grad_norm': 10.140944480895996, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.7985, 'grad_norm': 9.287073135375977, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.7805, 'grad_norm': 47.03677749633789, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s]                                               {'loss': 0.1809, 'grad_norm': 3.308617353439331, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.23, 'grad_norm': 4.019908905029297, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.407, 'grad_norm': 2.917668342590332, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.2116, 'grad_norm': 5.006162166595459, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.1391, 'grad_norm': 3.6566426753997803, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.081, 'grad_norm': 2.4148669242858887, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.621, 'grad_norm': 8.571779251098633, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 1.4408, 'grad_norm': 146.33934020996094, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.064, 'grad_norm': 2.871424913406372, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.0573, 'grad_norm': 1.6891424655914307, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.46it/s]                                               {'loss': 0.0342, 'grad_norm': 1.163553237915039, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.46it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.3139, 'grad_norm': 1.4696623086929321, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.0983, 'grad_norm': 3.0114073753356934, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.20it/s]                                               {'loss': 0.4656, 'grad_norm': 2.3579864501953125, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.20it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.15it/s]                                               {'loss': 0.1329, 'grad_norm': 2.7917158603668213, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.15it/s]                                               {'loss': 0.0227, 'grad_norm': 1.2976632118225098, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.15it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.0803, 'grad_norm': 4.982131481170654, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s]                                               {'loss': 0.33, 'grad_norm': 10.85716724395752, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s]                                               {'loss': 0.1112, 'grad_norm': 3.9881961345672607, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s]                                               {'loss': 0.6172, 'grad_norm': 1.3617323637008667, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.32it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.0656, 'grad_norm': 2.901042938232422, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.047, 'grad_norm': 1.337397813796997, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0356, 'grad_norm': 0.9462293386459351, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.1236, 'grad_norm': 7.473899841308594, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.123, 'train_samples_per_second': 46.606, 'train_steps_per_second': 3.3, 'train_loss': 0.6681890042498708, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:17
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.92it/s]                                              {'loss': 2.5158, 'grad_norm': 7.89265775680542, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.92it/s]  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]                                              {'loss': 1.9716, 'grad_norm': 11.732433319091797, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]  8%|▊         | 3/40 [00:01<00:12,  2.98it/s]                                              {'loss': 0.9672, 'grad_norm': 9.427447319030762, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.98it/s] 10%|█         | 4/40 [00:01<00:12,  2.97it/s]                                              {'loss': 1.6889, 'grad_norm': 13.556529998779297, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.97it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.0987, 'grad_norm': 19.532230377197266, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.7772, 'grad_norm': 19.63416862487793, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.855, 'grad_norm': 21.06846046447754, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.0008, 'grad_norm': 92.61955261230469, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.86it/s]                                              {'loss': 1.5421, 'grad_norm': 14.501724243164062, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.86it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.60it/s]                                               {'loss': 0.6205, 'grad_norm': 13.709343910217285, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.60it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 0.8227, 'grad_norm': 9.390960693359375, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.6453, 'grad_norm': 8.487083435058594, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.4234, 'grad_norm': 6.81327486038208, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.6857, 'grad_norm': 6.463343143463135, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.8292, 'grad_norm': 7.322325229644775, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.004, 'grad_norm': 0.18361468613147736, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.6413, 'grad_norm': 3.0921900272369385, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.203, 'grad_norm': 3.747377634048462, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.239, 'grad_norm': 3.937814474105835, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.5465, 'grad_norm': 5.579525947570801, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.2446, 'grad_norm': 8.272003173828125, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.4533, 'grad_norm': 6.987170696258545, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.3887, 'grad_norm': 4.58646297454834, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.1048, 'grad_norm': 6.141536235809326, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.12it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s]                                               {'loss': 0.1611, 'grad_norm': 3.7040486335754395, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.64it/s]                                               {'loss': 0.2887, 'grad_norm': 3.012251377105713, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.64it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.45it/s]                                               {'loss': 0.2019, 'grad_norm': 3.2898824214935303, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.45it/s] 70%|███████   | 28/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.5423, 'grad_norm': 5.356251239776611, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.33it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.3591, 'grad_norm': 4.829374313354492, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.4571, 'grad_norm': 1.3331059217453003, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.2781, 'grad_norm': 2.045729637145996, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0382, 'grad_norm': 2.0501606464385986, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.1114, 'grad_norm': 3.3838090896606445, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.4352, 'grad_norm': 1.5024617910385132, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0456, 'grad_norm': 2.074615478515625, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.2826, 'grad_norm': 1.3538553714752197, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.2658, 'grad_norm': 0.7053402662277222, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.1609, 'grad_norm': 3.953474521636963, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0599, 'grad_norm': 1.85801100730896, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0495, 'grad_norm': 3.431997060775757, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.1261, 'train_samples_per_second': 46.594, 'train_steps_per_second': 3.299, 'train_loss': 0.6751773819443769, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:36
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 2.8502, 'grad_norm': 7.9991583824157715, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.0749, 'grad_norm': 10.825933456420898, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 2.3588, 'grad_norm': 14.329326629638672, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:12,  2.97it/s]                                              {'loss': 2.707, 'grad_norm': 17.303281784057617, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.97it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s]                                              {'loss': 2.2626, 'grad_norm': 19.019716262817383, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.7834, 'grad_norm': 12.375536918640137, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 2.344, 'grad_norm': 18.87374496459961, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 7.5655, 'grad_norm': 66.66597747802734, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s]                                              {'loss': 1.8339, 'grad_norm': 14.932624816894531, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.4397, 'grad_norm': 7.376502513885498, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.6346, 'grad_norm': 9.993318557739258, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 0.8596, 'grad_norm': 9.374403953552246, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.3616, 'grad_norm': 6.622164726257324, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.8783, 'grad_norm': 9.246081352233887, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.9282, 'grad_norm': 5.71763277053833, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.3102, 'grad_norm': 18.829235076904297, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.7543, 'grad_norm': 5.363215446472168, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.2473, 'grad_norm': 5.921257972717285, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.5763, 'grad_norm': 3.0694119930267334, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.6014, 'grad_norm': 3.506305694580078, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s]                                               {'loss': 0.4082, 'grad_norm': 4.424869537353516, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.2192, 'grad_norm': 3.8033676147460938, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.2169, 'grad_norm': 4.8733015060424805, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.0021, 'grad_norm': 0.17629507184028625, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s]                                               {'loss': 1.0292, 'grad_norm': 8.67162036895752, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s]                                               {'loss': 0.0835, 'grad_norm': 2.562028646469116, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s]                                               {'loss': 0.1791, 'grad_norm': 5.6804656982421875, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s] 70%|███████   | 28/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.4857, 'grad_norm': 1.7017830610275269, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.33it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.0959, 'grad_norm': 3.4382567405700684, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.1082, 'grad_norm': 2.6085517406463623, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0558, 'grad_norm': 1.1967153549194336, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.1535, 'grad_norm': 7.749357223510742, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.046, 'grad_norm': 1.5088492631912231, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.0344, 'grad_norm': 0.9064997434616089, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.052, 'grad_norm': 1.3370970487594604, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.5245, 'grad_norm': 3.504000663757324, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.0483, 'grad_norm': 1.5315771102905273, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.5428, 'grad_norm': 3.993485927581787, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.4535, 'grad_norm': 2.243008613586426, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0409, 'grad_norm': 2.8265786170959473, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.0891, 'train_samples_per_second': 46.736, 'train_steps_per_second': 3.309, 'train_loss': 0.953782961226534, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:82
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]                                              {'loss': 3.6423, 'grad_norm': 11.242253303527832, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]                                              {'loss': 1.7359, 'grad_norm': 8.138999938964844, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.08it/s]  8%|▊         | 3/40 [00:00<00:12,  3.06it/s]                                              {'loss': 1.3974, 'grad_norm': 10.109718322753906, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.06it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.3015, 'grad_norm': 21.639251708984375, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.5658, 'grad_norm': 11.616532325744629, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.4861, 'grad_norm': 19.176437377929688, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.09it/s]                                              {'loss': 1.6565, 'grad_norm': 15.856054306030273, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.09it/s]                                              {'loss': 0.0435, 'grad_norm': 2.0230343341827393, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.09it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s]                                              {'loss': 1.0787, 'grad_norm': 10.479535102844238, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.62it/s]                                               {'loss': 0.5523, 'grad_norm': 6.258800506591797, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.62it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.44it/s]                                               {'loss': 0.7505, 'grad_norm': 6.608070373535156, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.44it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 0.4183, 'grad_norm': 8.258442878723145, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.28it/s]                                               {'loss': 1.0125, 'grad_norm': 8.132638931274414, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.28it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.23it/s]                                               {'loss': 0.9751, 'grad_norm': 11.227898597717285, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.23it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.16it/s]                                               {'loss': 0.4317, 'grad_norm': 5.031604766845703, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.16it/s]                                               {'loss': 1.8184, 'grad_norm': 1.5225322246551514, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.16it/s] 42%|████▎     | 17/40 [00:04<00:05,  3.92it/s]                                               {'loss': 0.116, 'grad_norm': 2.322253942489624, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:04<00:05,  3.92it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.66it/s]                                               {'loss': 0.3778, 'grad_norm': 4.897797584533691, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.66it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.48it/s]                                               {'loss': 0.1238, 'grad_norm': 1.0263679027557373, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.48it/s] 50%|█████     | 20/40 [00:05<00:05,  3.34it/s]                                               {'loss': 0.4573, 'grad_norm': 3.7779672145843506, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:05<00:05,  3.34it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.25it/s]                                               {'loss': 0.4273, 'grad_norm': 2.286450147628784, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.25it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.2195, 'grad_norm': 5.20062780380249, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s] 57%|█████▊    | 23/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.5634, 'grad_norm': 4.209528923034668, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.0122, 'grad_norm': 0.8883450031280518, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.13it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.88it/s]                                               {'loss': 0.4411, 'grad_norm': 3.1904845237731934, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.88it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.64it/s]                                               {'loss': 0.0464, 'grad_norm': 1.5164763927459717, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.64it/s] 68%|██████▊   | 27/40 [00:07<00:03,  3.45it/s]                                               {'loss': 0.0161, 'grad_norm': 0.39413318037986755, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:07<00:03,  3.45it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.0188, 'grad_norm': 0.478364497423172, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.3218, 'grad_norm': 2.145350456237793, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.5298, 'grad_norm': 1.321978211402893, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:08<00:03,  3.17it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.3034, 'grad_norm': 8.508056640625, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.0182, 'grad_norm': 1.2781885862350464, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.13it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.0139, 'grad_norm': 0.4686199724674225, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.0351, 'grad_norm': 1.662935495376587, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.1464, 'grad_norm': 1.407182216644287, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0461, 'grad_norm': 2.170518159866333, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s]                                               {'loss': 0.3327, 'grad_norm': 1.6498597860336304, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.281, 'grad_norm': 1.071596622467041, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.5441, 'grad_norm': 1.6374636888504028, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.031, 'grad_norm': 2.2385663986206055, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.15it/s]                                               {'train_runtime': 11.999, 'train_samples_per_second': 47.087, 'train_steps_per_second': 3.334, 'train_loss': 0.6822432243730873, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.15it/s]100%|██████████| 40/40 [00:11<00:00,  3.33it/s]
CLIENT:69
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.447, 'grad_norm': 7.453517436981201, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]                                              {'loss': 1.8133, 'grad_norm': 10.424737930297852, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.6776, 'grad_norm': 13.11324405670166, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.2517, 'grad_norm': 10.068376541137695, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.09it/s]                                              {'loss': 1.5052, 'grad_norm': 16.268407821655273, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.09it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.1133, 'grad_norm': 16.71495819091797, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.6544, 'grad_norm': 13.234357833862305, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.0598, 'grad_norm': 4.074154376983643, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 0.7259, 'grad_norm': 9.194765090942383, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 0.6847, 'grad_norm': 8.844983100891113, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.0418, 'grad_norm': 7.928901672363281, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.4654, 'grad_norm': 5.0751214027404785, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.3317, 'grad_norm': 4.3731303215026855, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.4041, 'grad_norm': 5.259239196777344, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.9147, 'grad_norm': 6.781848907470703, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.1998, 'grad_norm': 7.045642375946045, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s]                                               {'loss': 0.5607, 'grad_norm': 6.428341865539551, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.1192, 'grad_norm': 2.2107255458831787, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.4317, 'grad_norm': 4.292220115661621, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.1713, 'grad_norm': 3.659421443939209, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.4191, 'grad_norm': 8.652335166931152, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.3893, 'grad_norm': 5.439577579498291, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.1295, 'grad_norm': 3.8744072914123535, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.0721, 'grad_norm': 3.3526241779327393, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.0451, 'grad_norm': 1.3074549436569214, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.0752, 'grad_norm': 3.692035436630249, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.2319, 'grad_norm': 2.0887258052825928, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.0887, 'grad_norm': 1.8327299356460571, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.0654, 'grad_norm': 1.357408046722412, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.1459, 'grad_norm': 2.6444902420043945, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.2066, 'grad_norm': 4.348678112030029, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0504, 'grad_norm': 2.194955587387085, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.039, 'grad_norm': 0.9378076195716858, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.0462, 'grad_norm': 1.1375571489334106, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0574, 'grad_norm': 2.0631930828094482, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.0348, 'grad_norm': 0.7224467396736145, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.009, 'grad_norm': 0.1889910250902176, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.2122, 'grad_norm': 1.0448212623596191, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0685, 'grad_norm': 2.8750901222229004, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0564, 'grad_norm': 4.363523006439209, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1165, 'train_samples_per_second': 46.631, 'train_steps_per_second': 3.301, 'train_loss': 0.5253977795829996, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:65
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.07it/s]                                              {'loss': 2.1273, 'grad_norm': 7.949734687805176, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.07it/s]  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]                                              {'loss': 2.5784, 'grad_norm': 11.568717002868652, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.0723, 'grad_norm': 14.420781135559082, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.08it/s]                                              {'loss': 0.8586, 'grad_norm': 9.913517951965332, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.08it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.2262, 'grad_norm': 15.815450668334961, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.06it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.4259, 'grad_norm': 16.242849349975586, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.7777, 'grad_norm': 23.341876983642578, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 0.1569, 'grad_norm': 10.583623886108398, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s]                                              {'loss': 1.1311, 'grad_norm': 12.523350715637207, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 0.8298, 'grad_norm': 13.007555961608887, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.46it/s]                                               {'loss': 0.5214, 'grad_norm': 11.774843215942383, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.46it/s] 30%|███       | 12/40 [00:03<00:08,  3.22it/s]                                               {'loss': 0.5742, 'grad_norm': 10.381765365600586, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.22it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 0.4244, 'grad_norm': 6.9884796142578125, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.8422, 'grad_norm': 16.193246841430664, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.8951, 'grad_norm': 8.800874710083008, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.3293, 'grad_norm': 15.569707870483398, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.88it/s]                                               {'loss': 0.4917, 'grad_norm': 4.592465877532959, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.88it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.64it/s]                                               {'loss': 0.2255, 'grad_norm': 3.1483817100524902, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.64it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.47it/s]                                               {'loss': 0.1187, 'grad_norm': 2.3916358947753906, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.47it/s] 50%|█████     | 20/40 [00:06<00:06,  3.33it/s]                                               {'loss': 0.6003, 'grad_norm': 6.913353443145752, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.33it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.2777, 'grad_norm': 4.353725910186768, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.306, 'grad_norm': 4.774148941040039, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.2153, 'grad_norm': 3.488572835922241, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 1.0515, 'grad_norm': 48.649654388427734, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.1985, 'grad_norm': 4.990474224090576, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.2287, 'grad_norm': 6.125124931335449, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.26, 'grad_norm': 7.447360515594482, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.1087, 'grad_norm': 10.329862594604492, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.0937, 'grad_norm': 2.157726287841797, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.4104, 'grad_norm': 6.788423538208008, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.0781, 'grad_norm': 1.9352283477783203, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.0107, 'grad_norm': 0.4847276508808136, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.14it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s]                                               {'loss': 0.0468, 'grad_norm': 0.9334725737571716, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s]                                               {'loss': 0.0288, 'grad_norm': 0.6989412307739258, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.46it/s]                                               {'loss': 0.0501, 'grad_norm': 0.8816854953765869, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.46it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.0824, 'grad_norm': 2.2789885997772217, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0917, 'grad_norm': 3.2779483795166016, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1167, 'grad_norm': 3.494502544403076, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0699, 'grad_norm': 2.1575300693511963, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.003, 'grad_norm': 0.3117399215698242, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0266, 'train_samples_per_second': 46.979, 'train_steps_per_second': 3.326, 'train_loss': 0.5984003642399329, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.33it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  if task in [Task.SequenceClassification, Task.TokenClassification]:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:42, 11.02it/s]  1%|          | 4/471 [00:00<01:07,  6.90it/s]  1%|          | 5/471 [00:00<01:13,  6.38it/s]  1%|▏         | 6/471 [00:00<01:17,  6.02it/s]  1%|▏         | 7/471 [00:01<01:19,  5.83it/s]  2%|▏         | 8/471 [00:01<01:21,  5.69it/s]  2%|▏         | 9/471 [00:01<01:22,  5.61it/s]  2%|▏         | 10/471 [00:01<01:22,  5.56it/s]  2%|▏         | 11/471 [00:01<01:23,  5.52it/s]  3%|▎         | 12/471 [00:02<01:23,  5.47it/s]  3%|▎         | 13/471 [00:02<01:24,  5.44it/s]  3%|▎         | 14/471 [00:02<01:24,  5.42it/s]  3%|▎         | 15/471 [00:02<01:23,  5.44it/s]  3%|▎         | 16/471 [00:02<01:24,  5.41it/s]  4%|▎         | 17/471 [00:02<01:23,  5.42it/s]  4%|▍         | 18/471 [00:03<01:23,  5.39it/s]  4%|▍         | 19/471 [00:03<01:23,  5.40it/s]  4%|▍         | 20/471 [00:03<01:23,  5.40it/s]  4%|▍         | 21/471 [00:03<01:23,  5.39it/s]  5%|▍         | 22/471 [00:03<01:23,  5.40it/s]  5%|▍         | 23/471 [00:04<01:23,  5.39it/s]  5%|▌         | 24/471 [00:04<01:22,  5.39it/s]  5%|▌         | 25/471 [00:04<01:22,  5.39it/s]  6%|▌         | 26/471 [00:04<01:22,  5.39it/s]  6%|▌         | 27/471 [00:04<01:22,  5.39it/s]  6%|▌         | 28/471 [00:04<01:22,  5.39it/s]  6%|▌         | 29/471 [00:05<01:22,  5.39it/s]  6%|▋         | 30/471 [00:05<01:22,  5.36it/s]  7%|▋         | 31/471 [00:05<01:21,  5.37it/s]  7%|▋         | 32/471 [00:05<01:21,  5.38it/s]  7%|▋         | 33/471 [00:05<01:20,  5.43it/s]  7%|▋         | 34/471 [00:06<01:20,  5.43it/s]  7%|▋         | 35/471 [00:06<01:20,  5.40it/s]  8%|▊         | 36/471 [00:06<01:20,  5.40it/s]  8%|▊         | 37/471 [00:06<01:20,  5.38it/s]  8%|▊         | 38/471 [00:06<01:20,  5.38it/s]  8%|▊         | 39/471 [00:07<01:20,  5.39it/s]  8%|▊         | 40/471 [00:07<01:19,  5.39it/s]  9%|▊         | 41/471 [00:07<01:19,  5.38it/s]  9%|▉         | 42/471 [00:07<01:19,  5.38it/s]  9%|▉         | 43/471 [00:07<01:19,  5.37it/s]  9%|▉         | 44/471 [00:07<01:19,  5.40it/s] 10%|▉         | 45/471 [00:08<01:19,  5.39it/s] 10%|▉         | 46/471 [00:08<01:18,  5.39it/s] 10%|▉         | 47/471 [00:08<01:18,  5.40it/s] 10%|█         | 48/471 [00:08<01:18,  5.39it/s] 10%|█         | 49/471 [00:08<01:18,  5.39it/s] 11%|█         | 50/471 [00:09<01:18,  5.38it/s] 11%|█         | 51/471 [00:09<01:17,  5.39it/s] 11%|█         | 52/471 [00:09<01:17,  5.38it/s] 11%|█▏        | 53/471 [00:09<01:17,  5.37it/s] 11%|█▏        | 54/471 [00:09<01:17,  5.38it/s] 12%|█▏        | 55/471 [00:10<01:17,  5.37it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.36it/s] 12%|█▏        | 57/471 [00:10<01:16,  5.38it/s] 12%|█▏        | 58/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 59/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 60/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.35it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.36it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.36it/s] 14%|█▎        | 64/471 [00:11<01:15,  5.36it/s] 14%|█▍        | 65/471 [00:11<01:15,  5.35it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.35it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.34it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.35it/s] 15%|█▍        | 69/471 [00:12<01:15,  5.36it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.34it/s] 15%|█▌        | 71/471 [00:12<01:14,  5.34it/s] 15%|█▌        | 72/471 [00:13<01:14,  5.33it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.34it/s] 16%|█▌        | 74/471 [00:13<01:14,  5.36it/s] 16%|█▌        | 75/471 [00:13<01:14,  5.34it/s] 16%|█▌        | 76/471 [00:13<01:13,  5.36it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.34it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.34it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.33it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.33it/s] 17%|█▋        | 81/471 [00:14<01:12,  5.35it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.35it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.35it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.35it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.34it/s] 18%|█▊        | 86/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 87/471 [00:15<01:11,  5.35it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.35it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.35it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.34it/s] 19%|█▉        | 91/471 [00:16<01:10,  5.36it/s] 20%|█▉        | 92/471 [00:16<01:10,  5.35it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.34it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.36it/s] 20%|██        | 95/471 [00:17<01:10,  5.35it/s] 20%|██        | 96/471 [00:17<01:09,  5.36it/s] 21%|██        | 97/471 [00:17<01:10,  5.33it/s] 21%|██        | 98/471 [00:18<01:09,  5.34it/s] 21%|██        | 99/471 [00:18<01:09,  5.34it/s] 21%|██        | 100/471 [00:18<01:09,  5.36it/s] 21%|██▏       | 101/471 [00:18<01:09,  5.36it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.35it/s] 22%|██▏       | 103/471 [00:18<01:09,  5.33it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.33it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.31it/s] 23%|██▎       | 106/471 [00:19<01:08,  5.35it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.37it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.35it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.35it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.36it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.34it/s] 24%|██▍       | 112/471 [00:20<01:07,  5.33it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.35it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.36it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.35it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.34it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.32it/s] 25%|██▌       | 118/471 [00:21<01:06,  5.32it/s] 25%|██▌       | 119/471 [00:21<01:06,  5.32it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.32it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.32it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.31it/s] 26%|██▌       | 123/471 [00:22<01:05,  5.32it/s] 26%|██▋       | 124/471 [00:22<01:05,  5.32it/s] 27%|██▋       | 125/471 [00:23<01:05,  5.32it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.32it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.30it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.31it/s] 27%|██▋       | 129/471 [00:23<01:04,  5.32it/s] 28%|██▊       | 130/471 [00:24<01:04,  5.32it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.32it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.30it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.30it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.29it/s] 29%|██▊       | 135/471 [00:24<01:03,  5.29it/s] 29%|██▉       | 136/471 [00:25<01:03,  5.29it/s] 29%|██▉       | 137/471 [00:25<01:03,  5.30it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.30it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.31it/s] 30%|██▉       | 140/471 [00:25<01:02,  5.31it/s] 30%|██▉       | 141/471 [00:26<01:02,  5.31it/s] 30%|███       | 142/471 [00:26<01:02,  5.31it/s] 30%|███       | 143/471 [00:26<01:01,  5.31it/s] 31%|███       | 144/471 [00:26<01:01,  5.30it/s] 31%|███       | 145/471 [00:26<01:01,  5.33it/s] 31%|███       | 146/471 [00:27<01:01,  5.32it/s] 31%|███       | 147/471 [00:27<01:01,  5.30it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.30it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.29it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.28it/s] 32%|███▏      | 151/471 [00:28<01:00,  5.28it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.27it/s] 32%|███▏      | 153/471 [00:28<01:00,  5.26it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.29it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.30it/s] 33%|███▎      | 156/471 [00:28<00:59,  5.31it/s] 33%|███▎      | 157/471 [00:29<00:59,  5.32it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.32it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.31it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.30it/s] 34%|███▍      | 161/471 [00:29<00:58,  5.30it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.30it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.30it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.30it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.28it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.28it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.29it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.29it/s] 36%|███▌      | 169/471 [00:31<00:57,  5.28it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.28it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.29it/s] 37%|███▋      | 172/471 [00:31<00:56,  5.30it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.30it/s] 37%|███▋      | 174/471 [00:32<00:56,  5.29it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.29it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.30it/s] 38%|███▊      | 177/471 [00:32<00:55,  5.29it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.30it/s] 38%|███▊      | 179/471 [00:33<00:55,  5.30it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.29it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.29it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.27it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.27it/s] 39%|███▉      | 184/471 [00:34<00:54,  5.28it/s] 39%|███▉      | 185/471 [00:34<00:54,  5.28it/s] 39%|███▉      | 186/471 [00:34<00:54,  5.27it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.27it/s] 40%|███▉      | 188/471 [00:35<00:53,  5.25it/s] 40%|████      | 189/471 [00:35<00:53,  5.26it/s] 40%|████      | 190/471 [00:35<00:53,  5.27it/s] 41%|████      | 191/471 [00:35<00:53,  5.26it/s] 41%|████      | 192/471 [00:35<00:52,  5.27it/s] 41%|████      | 193/471 [00:35<00:52,  5.29it/s] 41%|████      | 194/471 [00:36<00:52,  5.28it/s] 41%|████▏     | 195/471 [00:36<00:52,  5.27it/s] 42%|████▏     | 196/471 [00:36<00:52,  5.27it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.30it/s] 42%|████▏     | 198/471 [00:36<00:51,  5.30it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.28it/s] 42%|████▏     | 200/471 [00:37<00:51,  5.26it/s] 43%|████▎     | 201/471 [00:37<00:51,  5.29it/s] 43%|████▎     | 202/471 [00:37<00:51,  5.27it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.26it/s] 43%|████▎     | 204/471 [00:38<00:50,  5.26it/s] 44%|████▎     | 205/471 [00:38<00:50,  5.27it/s] 44%|████▎     | 206/471 [00:38<00:50,  5.28it/s] 44%|████▍     | 207/471 [00:38<00:50,  5.25it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.28it/s] 44%|████▍     | 209/471 [00:38<00:49,  5.29it/s] 45%|████▍     | 210/471 [00:39<00:49,  5.29it/s] 45%|████▍     | 211/471 [00:39<00:49,  5.28it/s] 45%|████▌     | 212/471 [00:39<00:49,  5.26it/s] 45%|████▌     | 213/471 [00:39<00:49,  5.25it/s] 45%|████▌     | 214/471 [00:39<00:48,  5.26it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.25it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.24it/s] 46%|████▌     | 217/471 [00:40<00:48,  5.23it/s] 46%|████▋     | 218/471 [00:40<00:48,  5.23it/s] 46%|████▋     | 219/471 [00:40<00:48,  5.24it/s] 47%|████▋     | 220/471 [00:41<00:47,  5.23it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.23it/s] 47%|████▋     | 222/471 [00:41<00:47,  5.23it/s] 47%|████▋     | 223/471 [00:41<00:47,  5.25it/s] 48%|████▊     | 224/471 [00:41<00:47,  5.23it/s] 48%|████▊     | 225/471 [00:42<00:46,  5.25it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.25it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.24it/s] 48%|████▊     | 228/471 [00:42<00:46,  5.24it/s] 49%|████▊     | 229/471 [00:42<00:46,  5.23it/s] 49%|████▉     | 230/471 [00:43<00:46,  5.22it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.23it/s] 49%|████▉     | 232/471 [00:43<00:45,  5.24it/s] 49%|████▉     | 233/471 [00:43<00:45,  5.24it/s] 50%|████▉     | 234/471 [00:43<00:45,  5.24it/s] 50%|████▉     | 235/471 [00:43<00:45,  5.23it/s] 50%|█████     | 236/471 [00:44<00:44,  5.23it/s] 50%|█████     | 237/471 [00:44<00:44,  5.23it/s] 51%|█████     | 238/471 [00:44<00:44,  5.23it/s] 51%|█████     | 239/471 [00:44<00:44,  5.23it/s] 51%|█████     | 240/471 [00:44<00:44,  5.23it/s] 51%|█████     | 241/471 [00:45<00:44,  5.22it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.24it/s] 52%|█████▏    | 243/471 [00:45<00:43,  5.24it/s] 52%|█████▏    | 244/471 [00:45<00:43,  5.24it/s] 52%|█████▏    | 245/471 [00:45<00:43,  5.23it/s] 52%|█████▏    | 246/471 [00:46<00:43,  5.22it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.25it/s] 53%|█████▎    | 248/471 [00:46<00:42,  5.25it/s] 53%|█████▎    | 249/471 [00:46<00:42,  5.24it/s] 53%|█████▎    | 250/471 [00:46<00:42,  5.23it/s] 53%|█████▎    | 251/471 [00:47<00:42,  5.22it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.22it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.23it/s] 54%|█████▍    | 254/471 [00:47<00:41,  5.23it/s] 54%|█████▍    | 255/471 [00:47<00:41,  5.23it/s] 54%|█████▍    | 256/471 [00:47<00:41,  5.21it/s] 55%|█████▍    | 257/471 [00:48<00:41,  5.21it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.23it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.23it/s] 55%|█████▌    | 260/471 [00:48<00:40,  5.22it/s] 55%|█████▌    | 261/471 [00:48<00:40,  5.22it/s] 56%|█████▌    | 262/471 [00:49<00:40,  5.22it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.22it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.23it/s] 56%|█████▋    | 265/471 [00:49<00:39,  5.22it/s] 56%|█████▋    | 266/471 [00:49<00:39,  5.22it/s] 57%|█████▋    | 267/471 [00:50<00:39,  5.21it/s] 57%|█████▋    | 268/471 [00:50<00:39,  5.20it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.22it/s] 57%|█████▋    | 270/471 [00:50<00:38,  5.23it/s] 58%|█████▊    | 271/471 [00:50<00:38,  5.24it/s] 58%|█████▊    | 272/471 [00:51<00:37,  5.24it/s] 58%|█████▊    | 273/471 [00:51<00:37,  5.24it/s] 58%|█████▊    | 274/471 [00:51<00:37,  5.25it/s] 58%|█████▊    | 275/471 [00:51<00:37,  5.26it/s] 59%|█████▊    | 276/471 [00:51<00:37,  5.25it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.25it/s] 59%|█████▉    | 278/471 [00:52<00:36,  5.23it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.23it/s] 59%|█████▉    | 280/471 [00:52<00:36,  5.23it/s] 60%|█████▉    | 281/471 [00:52<00:36,  5.22it/s] 60%|█████▉    | 282/471 [00:52<00:36,  5.23it/s] 60%|██████    | 283/471 [00:53<00:35,  5.22it/s] 60%|██████    | 284/471 [00:53<00:35,  5.22it/s] 61%|██████    | 285/471 [00:53<00:35,  5.21it/s] 61%|██████    | 286/471 [00:53<00:35,  5.21it/s] 61%|██████    | 287/471 [00:53<00:35,  5.22it/s] 61%|██████    | 288/471 [00:54<00:35,  5.20it/s] 61%|██████▏   | 289/471 [00:54<00:34,  5.22it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.22it/s] 62%|██████▏   | 291/471 [00:54<00:34,  5.22it/s] 62%|██████▏   | 292/471 [00:54<00:34,  5.22it/s] 62%|██████▏   | 293/471 [00:55<00:33,  5.24it/s] 62%|██████▏   | 294/471 [00:55<00:33,  5.23it/s] 63%|██████▎   | 295/471 [00:55<00:33,  5.24it/s] 63%|██████▎   | 296/471 [00:55<00:33,  5.25it/s] 63%|██████▎   | 297/471 [00:55<00:33,  5.24it/s] 63%|██████▎   | 298/471 [00:56<00:33,  5.23it/s] 63%|██████▎   | 299/471 [00:56<00:32,  5.23it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.22it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.22it/s] 64%|██████▍   | 302/471 [00:56<00:32,  5.23it/s] 64%|██████▍   | 303/471 [00:56<00:32,  5.22it/s] 65%|██████▍   | 304/471 [00:57<00:31,  5.23it/s] 65%|██████▍   | 305/471 [00:57<00:31,  5.21it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.21it/s] 65%|██████▌   | 307/471 [00:57<00:31,  5.21it/s] 65%|██████▌   | 308/471 [00:57<00:31,  5.20it/s] 66%|██████▌   | 309/471 [00:58<00:31,  5.19it/s] 66%|██████▌   | 310/471 [00:58<00:30,  5.19it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.20it/s] 66%|██████▌   | 312/471 [00:58<00:30,  5.21it/s] 66%|██████▋   | 313/471 [00:58<00:30,  5.23it/s] 67%|██████▋   | 314/471 [00:59<00:30,  5.22it/s] 67%|██████▋   | 315/471 [00:59<00:29,  5.21it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.22it/s] 67%|██████▋   | 317/471 [00:59<00:29,  5.22it/s] 68%|██████▊   | 318/471 [00:59<00:29,  5.23it/s] 68%|██████▊   | 319/471 [01:00<00:29,  5.22it/s] 68%|██████▊   | 320/471 [01:00<00:28,  5.21it/s] 68%|██████▊   | 321/471 [01:00<00:28,  5.20it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.19it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.19it/s] 69%|██████▉   | 324/471 [01:01<00:28,  5.17it/s] 69%|██████▉   | 325/471 [01:01<00:28,  5.19it/s] 69%|██████▉   | 326/471 [01:01<00:27,  5.20it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.22it/s] 70%|██████▉   | 328/471 [01:01<00:27,  5.21it/s] 70%|██████▉   | 329/471 [01:01<00:27,  5.18it/s] 70%|███████   | 330/471 [01:02<00:27,  5.22it/s] 70%|███████   | 331/471 [01:02<00:26,  5.22it/s] 70%|███████   | 332/471 [01:02<00:26,  5.22it/s] 71%|███████   | 333/471 [01:02<00:26,  5.22it/s] 71%|███████   | 334/471 [01:02<00:26,  5.20it/s] 71%|███████   | 335/471 [01:03<00:26,  5.19it/s] 71%|███████▏  | 336/471 [01:03<00:25,  5.22it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.24it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.23it/s] 72%|███████▏  | 339/471 [01:03<00:25,  5.21it/s] 72%|███████▏  | 340/471 [01:04<00:25,  5.21it/s] 72%|███████▏  | 341/471 [01:04<00:24,  5.22it/s] 73%|███████▎  | 342/471 [01:04<00:24,  5.23it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.23it/s] 73%|███████▎  | 344/471 [01:04<00:24,  5.24it/s] 73%|███████▎  | 345/471 [01:05<00:24,  5.23it/s] 73%|███████▎  | 346/471 [01:05<00:23,  5.22it/s] 74%|███████▎  | 347/471 [01:05<00:23,  5.22it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.22it/s] 74%|███████▍  | 349/471 [01:05<00:23,  5.22it/s] 74%|███████▍  | 350/471 [01:05<00:23,  5.22it/s] 75%|███████▍  | 351/471 [01:06<00:22,  5.23it/s] 75%|███████▍  | 352/471 [01:06<00:22,  5.22it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.20it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.20it/s] 75%|███████▌  | 355/471 [01:06<00:22,  5.21it/s] 76%|███████▌  | 356/471 [01:07<00:22,  5.20it/s] 76%|███████▌  | 357/471 [01:07<00:21,  5.20it/s] 76%|███████▌  | 358/471 [01:07<00:21,  5.21it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.21it/s] 76%|███████▋  | 360/471 [01:07<00:21,  5.21it/s] 77%|███████▋  | 361/471 [01:08<00:21,  5.21it/s] 77%|███████▋  | 362/471 [01:08<00:20,  5.21it/s] 77%|███████▋  | 363/471 [01:08<00:20,  5.21it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.22it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.21it/s] 78%|███████▊  | 366/471 [01:09<00:20,  5.20it/s] 78%|███████▊  | 367/471 [01:09<00:20,  5.19it/s] 78%|███████▊  | 368/471 [01:09<00:19,  5.20it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.22it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.22it/s] 79%|███████▉  | 371/471 [01:10<00:19,  5.22it/s] 79%|███████▉  | 372/471 [01:10<00:19,  5.20it/s] 79%|███████▉  | 373/471 [01:10<00:18,  5.19it/s] 79%|███████▉  | 374/471 [01:10<00:18,  5.22it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.22it/s] 80%|███████▉  | 376/471 [01:10<00:18,  5.22it/s] 80%|████████  | 377/471 [01:11<00:18,  5.22it/s] 80%|████████  | 378/471 [01:11<00:17,  5.22it/s] 80%|████████  | 379/471 [01:11<00:17,  5.21it/s] 81%|████████  | 380/471 [01:11<00:17,  5.21it/s] 81%|████████  | 381/471 [01:11<00:17,  5.21it/s] 81%|████████  | 382/471 [01:12<00:17,  5.19it/s] 81%|████████▏ | 383/471 [01:12<00:16,  5.19it/s] 82%|████████▏ | 384/471 [01:12<00:16,  5.19it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.18it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.19it/s] 82%|████████▏ | 387/471 [01:13<00:16,  5.19it/s] 82%|████████▏ | 388/471 [01:13<00:16,  5.18it/s] 83%|████████▎ | 389/471 [01:13<00:15,  5.19it/s] 83%|████████▎ | 390/471 [01:13<00:15,  5.19it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.19it/s] 83%|████████▎ | 392/471 [01:14<00:15,  5.20it/s] 83%|████████▎ | 393/471 [01:14<00:15,  5.19it/s] 84%|████████▎ | 394/471 [01:14<00:14,  5.19it/s] 84%|████████▍ | 395/471 [01:14<00:14,  5.18it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.17it/s] 84%|████████▍ | 397/471 [01:15<00:14,  5.19it/s] 85%|████████▍ | 398/471 [01:15<00:14,  5.20it/s] 85%|████████▍ | 399/471 [01:15<00:13,  5.19it/s] 85%|████████▍ | 400/471 [01:15<00:13,  5.17it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.19it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.18it/s] 86%|████████▌ | 403/471 [01:16<00:13,  5.18it/s] 86%|████████▌ | 404/471 [01:16<00:12,  5.20it/s] 86%|████████▌ | 405/471 [01:16<00:12,  5.18it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.19it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.20it/s] 87%|████████▋ | 408/471 [01:17<00:12,  5.20it/s] 87%|████████▋ | 409/471 [01:17<00:11,  5.20it/s] 87%|████████▋ | 410/471 [01:17<00:11,  5.22it/s] 87%|████████▋ | 411/471 [01:17<00:11,  5.23it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.20it/s] 88%|████████▊ | 413/471 [01:18<00:11,  5.21it/s] 88%|████████▊ | 414/471 [01:18<00:10,  5.21it/s] 88%|████████▊ | 415/471 [01:18<00:10,  5.21it/s] 88%|████████▊ | 416/471 [01:18<00:10,  5.19it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.20it/s] 89%|████████▊ | 418/471 [01:19<00:10,  5.20it/s] 89%|████████▉ | 419/471 [01:19<00:09,  5.21it/s] 89%|████████▉ | 420/471 [01:19<00:09,  5.21it/s] 89%|████████▉ | 421/471 [01:19<00:09,  5.19it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.20it/s] 90%|████████▉ | 423/471 [01:20<00:09,  5.22it/s] 90%|█████████ | 424/471 [01:20<00:09,  5.21it/s] 90%|█████████ | 425/471 [01:20<00:08,  5.21it/s] 90%|█████████ | 426/471 [01:20<00:08,  5.18it/s] 91%|█████████ | 427/471 [01:20<00:08,  5.19it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.20it/s] 91%|█████████ | 429/471 [01:21<00:08,  5.20it/s] 91%|█████████▏| 430/471 [01:21<00:07,  5.19it/s] 92%|█████████▏| 431/471 [01:21<00:07,  5.17it/s] 92%|█████████▏| 432/471 [01:21<00:07,  5.17it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.18it/s] 92%|█████████▏| 434/471 [01:22<00:07,  5.19it/s] 92%|█████████▏| 435/471 [01:22<00:06,  5.18it/s] 93%|█████████▎| 436/471 [01:22<00:06,  5.19it/s] 93%|█████████▎| 437/471 [01:22<00:06,  5.18it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.18it/s] 93%|█████████▎| 439/471 [01:23<00:06,  5.18it/s] 93%|█████████▎| 440/471 [01:23<00:05,  5.20it/s] 94%|█████████▎| 441/471 [01:23<00:05,  5.21it/s] 94%|█████████▍| 442/471 [01:23<00:05,  5.21it/s] 94%|█████████▍| 443/471 [01:23<00:05,  5.19it/s] 94%|█████████▍| 444/471 [01:24<00:05,  5.18it/s] 94%|█████████▍| 445/471 [01:24<00:05,  5.18it/s] 95%|█████████▍| 446/471 [01:24<00:04,  5.18it/s] 95%|█████████▍| 447/471 [01:24<00:04,  5.19it/s] 95%|█████████▌| 448/471 [01:24<00:04,  5.20it/s] 95%|█████████▌| 449/471 [01:25<00:04,  5.20it/s] 96%|█████████▌| 450/471 [01:25<00:04,  5.18it/s] 96%|█████████▌| 451/471 [01:25<00:03,  5.19it/s] 96%|█████████▌| 452/471 [01:25<00:03,  5.21it/s] 96%|█████████▌| 453/471 [01:25<00:03,  5.20it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.17it/s] 97%|█████████▋| 455/471 [01:26<00:03,  5.17it/s] 97%|█████████▋| 456/471 [01:26<00:02,  5.19it/s] 97%|█████████▋| 457/471 [01:26<00:02,  5.19it/s] 97%|█████████▋| 458/471 [01:26<00:02,  5.19it/s] 97%|█████████▋| 459/471 [01:26<00:02,  5.22it/s] 98%|█████████▊| 460/471 [01:27<00:02,  5.21it/s] 98%|█████████▊| 461/471 [01:27<00:01,  5.20it/s] 98%|█████████▊| 462/471 [01:27<00:01,  5.18it/s] 98%|█████████▊| 463/471 [01:27<00:01,  5.21it/s] 99%|█████████▊| 464/471 [01:27<00:01,  5.21it/s] 99%|█████████▊| 465/471 [01:28<00:01,  5.21it/s] 99%|█████████▉| 466/471 [01:28<00:00,  5.19it/s] 99%|█████████▉| 467/471 [01:28<00:00,  5.18it/s] 99%|█████████▉| 468/471 [01:28<00:00,  5.17it/s]100%|█████████▉| 469/471 [01:28<00:00,  5.18it/s]100%|█████████▉| 470/471 [01:29<00:00,  5.19it/s]100%|██████████| 471/471 [01:29<00:00,  5.56it/s]100%|██████████| 471/471 [01:29<00:00,  5.28it/s]
{'eval_loss': 2.409731388092041, 'eval_model_preparation_time': 0.0051, 'eval_acc': 0.3693574083908656, 'eval_runtime': 89.3949, 'eval_samples_per_second': 84.255, 'eval_steps_per_second': 5.269}
ROUND:13
CLIENT:14
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 2.4414, 'grad_norm': 9.06955623626709, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  2.95it/s]                                              {'loss': 1.8338, 'grad_norm': 13.176541328430176, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.95it/s]  8%|▊         | 3/40 [00:01<00:12,  2.95it/s]                                              {'loss': 1.5904, 'grad_norm': 15.180770874023438, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.95it/s] 10%|█         | 4/40 [00:01<00:12,  2.95it/s]                                              {'loss': 0.851, 'grad_norm': 12.39581298828125, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.95it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.94it/s]                                              {'loss': 1.5019, 'grad_norm': 16.426557540893555, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.94it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.95it/s]                                              {'loss': 1.1591, 'grad_norm': 13.278879165649414, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.95it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.96it/s]                                              {'loss': 2.3229, 'grad_norm': 18.845905303955078, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.96it/s]                                              {'loss': 2.4181, 'grad_norm': 110.53119659423828, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.96it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s]                                              {'loss': 1.8251, 'grad_norm': 17.76205062866211, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 0.975, 'grad_norm': 20.881244659423828, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s]                                               {'loss': 0.6947, 'grad_norm': 12.46117877960205, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s] 30%|███       | 12/40 [00:03<00:08,  3.22it/s]                                               {'loss': 0.5853, 'grad_norm': 5.487526893615723, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.22it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s]                                               {'loss': 1.1807, 'grad_norm': 10.239660263061523, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.4487, 'grad_norm': 7.877392292022705, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.06it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.01it/s]                                               {'loss': 0.3872, 'grad_norm': 6.34926700592041, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.01it/s]                                               {'loss': 0.1271, 'grad_norm': 9.010940551757812, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.01it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s]                                               {'loss': 0.169, 'grad_norm': 3.8101389408111572, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s]                                               {'loss': 0.1632, 'grad_norm': 4.030543327331543, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.34it/s]                                               {'loss': 0.4373, 'grad_norm': 7.687163829803467, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.34it/s] 50%|█████     | 20/40 [00:06<00:06,  3.22it/s]                                               {'loss': 0.2918, 'grad_norm': 5.699784755706787, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.22it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s]                                               {'loss': 0.3931, 'grad_norm': 10.970230102539062, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s]                                               {'loss': 0.8229, 'grad_norm': 12.934391021728516, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 1.041, 'grad_norm': 7.919059753417969, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.0118, 'grad_norm': 0.7483662962913513, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s]                                               {'loss': 0.1498, 'grad_norm': 3.7501730918884277, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s]                                               {'loss': 0.0435, 'grad_norm': 1.1246103048324585, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.0731, 'grad_norm': 2.014827013015747, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.31it/s] 70%|███████   | 28/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.23, 'grad_norm': 7.745659351348877, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.20it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s]                                               {'loss': 0.8546, 'grad_norm': 6.808516025543213, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.08it/s]                                               {'loss': 0.1651, 'grad_norm': 3.3912408351898193, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.08it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0588, 'grad_norm': 1.3798469305038452, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.1004, 'grad_norm': 4.694218635559082, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.76it/s]                                               {'loss': 0.0689, 'grad_norm': 2.068291187286377, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.76it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s]                                               {'loss': 0.0735, 'grad_norm': 4.175220489501953, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0324, 'grad_norm': 1.2263481616973877, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.22it/s]                                               {'loss': 0.0335, 'grad_norm': 0.8123862743377686, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.22it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.4595, 'grad_norm': 1.7949135303497314, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0806, 'grad_norm': 2.8315088748931885, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.01it/s]                                               {'loss': 0.065, 'grad_norm': 2.799990177154541, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.01it/s]100%|██████████| 40/40 [00:12<00:00,  3.78it/s]                                               {'loss': 0.0025, 'grad_norm': 0.21927368640899658, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.78it/s]                                               {'train_runtime': 12.5172, 'train_samples_per_second': 45.138, 'train_steps_per_second': 3.196, 'train_loss': 0.6540933859243523, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.78it/s]100%|██████████| 40/40 [00:12<00:00,  3.20it/s]
CLIENT:74
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 3.7774, 'grad_norm': 9.725037574768066, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 1.5774, 'grad_norm': 8.629157066345215, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.7783, 'grad_norm': 13.18262767791748, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 1.3402, 'grad_norm': 12.546679496765137, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 1.6376, 'grad_norm': 14.798840522766113, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.4214, 'grad_norm': 25.056196212768555, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 2.234, 'grad_norm': 17.67702865600586, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 4.3301, 'grad_norm': 69.1240005493164, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s]                                              {'loss': 1.795, 'grad_norm': 14.36928939819336, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 0.5692, 'grad_norm': 6.927975177764893, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 0.9051, 'grad_norm': 9.737730979919434, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 0.8812, 'grad_norm': 6.970956802368164, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.6446, 'grad_norm': 11.737964630126953, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.7093, 'grad_norm': 8.694311141967773, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.6507, 'grad_norm': 11.629804611206055, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s] 40%|████      | 16/40 [00:04<00:06,  3.82it/s]                                               {'loss': 0.9752, 'grad_norm': 34.08065414428711, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:06,  3.82it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.2904, 'grad_norm': 5.532773971557617, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.57it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.37it/s]                                               {'loss': 0.4921, 'grad_norm': 5.214560508728027, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.37it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.23it/s]                                               {'loss': 0.4147, 'grad_norm': 5.2332916259765625, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.23it/s] 50%|█████     | 20/40 [00:06<00:06,  3.14it/s]                                               {'loss': 0.5133, 'grad_norm': 8.35119915008545, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.14it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.08it/s]                                               {'loss': 0.7099, 'grad_norm': 6.928499698638916, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.08it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.01it/s]                                               {'loss': 0.8009, 'grad_norm': 8.887779235839844, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.01it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.01it/s]                                               {'loss': 0.7573, 'grad_norm': 8.76652717590332, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.01it/s]                                               {'loss': 0.0258, 'grad_norm': 2.0530261993408203, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.01it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s]                                               {'loss': 0.0866, 'grad_norm': 2.1657752990722656, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s]                                               {'loss': 0.214, 'grad_norm': 2.7676303386688232, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s]                                               {'loss': 0.1228, 'grad_norm': 2.494872808456421, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s] 70%|███████   | 28/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.112, 'grad_norm': 3.1904261112213135, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.22it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.5504, 'grad_norm': 4.073238849639893, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.7788, 'grad_norm': 5.224590301513672, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.5467, 'grad_norm': 4.877678394317627, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1017, 'grad_norm': 6.179547309875488, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.3678, 'grad_norm': 0.9519742727279663, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.1893, 'grad_norm': 2.696031093597412, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.5862, 'grad_norm': 6.919534206390381, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0766, 'grad_norm': 5.493232250213623, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.4596, 'grad_norm': 1.4001355171203613, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.5455, 'grad_norm': 5.497346878051758, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0736, 'grad_norm': 3.1781835556030273, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0038, 'grad_norm': 0.21139737963676453, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]                                               {'train_runtime': 12.2686, 'train_samples_per_second': 46.052, 'train_steps_per_second': 3.26, 'train_loss': 0.9261636656243354, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
CLIENT:15
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.93it/s]                                              {'loss': 1.9913, 'grad_norm': 8.795303344726562, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.93it/s]  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]                                              {'loss': 1.62, 'grad_norm': 7.530904293060303, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.99it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.8856, 'grad_norm': 16.635820388793945, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.5458, 'grad_norm': 11.004375457763672, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.8366, 'grad_norm': 18.628997802734375, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 3.4649, 'grad_norm': 28.002132415771484, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 1.8313, 'grad_norm': 16.663785934448242, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 0.0917, 'grad_norm': 5.7023162841796875, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.98it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 1.3099, 'grad_norm': 12.669183731079102, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s]                                               {'loss': 0.4961, 'grad_norm': 6.209005832672119, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 0.9506, 'grad_norm': 6.996976852416992, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 0.9306, 'grad_norm': 7.824987888336182, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.8845, 'grad_norm': 11.453621864318848, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.5607, 'grad_norm': 8.799897193908691, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.5858, 'grad_norm': 6.835464954376221, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.0487, 'grad_norm': 1.9440597295761108, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s]                                               {'loss': 0.4652, 'grad_norm': 1.4051488637924194, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.396, 'grad_norm': 1.08967125415802, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.212, 'grad_norm': 7.963335037231445, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.8853, 'grad_norm': 8.83743953704834, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.17it/s]                                               {'loss': 0.5558, 'grad_norm': 11.000497817993164, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.08it/s]                                               {'loss': 0.1713, 'grad_norm': 4.50497579574585, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.08it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.4704, 'grad_norm': 11.199370384216309, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.2605, 'grad_norm': 14.807086944580078, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.06it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.69it/s]                                               {'loss': 0.2325, 'grad_norm': 2.889678716659546, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.69it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.50it/s]                                               {'loss': 0.7041, 'grad_norm': 3.144899368286133, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.50it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.087, 'grad_norm': 2.486253499984741, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s] 70%|███████   | 28/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.1253, 'grad_norm': 3.413330554962158, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.21it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.14it/s]                                               {'loss': 0.6235, 'grad_norm': 14.85562515258789, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.14it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.0286, 'grad_norm': 0.7545880675315857, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.4021, 'grad_norm': 2.6831796169281006, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0013, 'grad_norm': 0.08093591779470444, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s]                                               {'loss': 0.4026, 'grad_norm': 0.808617353439331, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.402, 'grad_norm': 1.9703335762023926, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.0547, 'grad_norm': 1.4586011171340942, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.2574, 'grad_norm': 1.989989995956421, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.6789, 'grad_norm': 27.305072784423828, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.2677, 'grad_norm': 14.40210247039795, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.2437, 'grad_norm': 3.761000394821167, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.014, 'grad_norm': 1.0726046562194824, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]                                               {'train_runtime': 12.2339, 'train_samples_per_second': 46.183, 'train_steps_per_second': 3.27, 'train_loss': 0.6994007426517783, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.27it/s]
CLIENT:4
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 1.5837, 'grad_norm': 7.666227340698242, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  3.10it/s]                                              {'loss': 2.9146, 'grad_norm': 10.53226375579834, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.10it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.9135, 'grad_norm': 19.935213088989258, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.0455, 'grad_norm': 15.630660057067871, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.09it/s]                                              {'loss': 2.5987, 'grad_norm': 20.03177261352539, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.09it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.08it/s]                                              {'loss': 2.0162, 'grad_norm': 12.705011367797852, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.08it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 2.0447, 'grad_norm': 19.28053855895996, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 0.1024, 'grad_norm': 5.435286521911621, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.06it/s] 22%|██▎       | 9/40 [00:02<00:07,  3.88it/s]                                              {'loss': 0.7625, 'grad_norm': 8.5831880569458, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:07,  3.88it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.61it/s]                                               {'loss': 0.9014, 'grad_norm': 10.66665267944336, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.61it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s]                                               {'loss': 0.5844, 'grad_norm': 8.545835494995117, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 0.8801, 'grad_norm': 7.453586578369141, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.23it/s]                                               {'loss': 0.7034, 'grad_norm': 4.884016036987305, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.23it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 1.1041, 'grad_norm': 7.833194255828857, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 1.2865, 'grad_norm': 6.738102436065674, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 0.3256, 'grad_norm': 13.54047679901123, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.14it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.1101, 'grad_norm': 2.0928616523742676, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.3141, 'grad_norm': 3.077544689178467, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.6385, 'grad_norm': 5.444992542266846, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.4714, 'grad_norm': 6.892018795013428, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.6855, 'grad_norm': 2.8090851306915283, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.2598, 'grad_norm': 5.584128379821777, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s] 57%|█████▊    | 23/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.5958, 'grad_norm': 4.788207530975342, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:06<00:05,  3.13it/s]                                               {'loss': 1.0684, 'grad_norm': 1.0732685327529907, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.13it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.88it/s]                                               {'loss': 0.255, 'grad_norm': 20.290752410888672, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.88it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.64it/s]                                               {'loss': 0.1461, 'grad_norm': 1.667521595954895, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.64it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.46it/s]                                               {'loss': 0.4097, 'grad_norm': 1.5618399381637573, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.46it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.5306, 'grad_norm': 2.8485007286071777, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.101, 'grad_norm': 4.5778374671936035, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.6728, 'grad_norm': 3.3323564529418945, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0635, 'grad_norm': 1.6069227457046509, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.6166, 'grad_norm': 31.19345474243164, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.3573, 'grad_norm': 0.5907941460609436, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.14, 'grad_norm': 0.31507816910743713, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.4544, 'grad_norm': 1.4374380111694336, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s]                                               {'loss': 0.076, 'grad_norm': 0.5348853468894958, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.3232, 'grad_norm': 5.975152969360352, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.5399, 'grad_norm': 3.898907423019409, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0327, 'grad_norm': 0.7733109593391418, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0494, 'grad_norm': 2.8496663570404053, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.0628, 'train_samples_per_second': 46.838, 'train_steps_per_second': 3.316, 'train_loss': 0.7669705500826239, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:32
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.6519, 'grad_norm': 12.417618751525879, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.15it/s]                                              {'loss': 2.0262, 'grad_norm': 11.044649124145508, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.15it/s]  8%|▊         | 3/40 [00:00<00:11,  3.09it/s]                                              {'loss': 2.1005, 'grad_norm': 12.201175689697266, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.09it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.7098, 'grad_norm': 12.523490905761719, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.9051, 'grad_norm': 22.04907989501953, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s]                                              {'loss': 2.7589, 'grad_norm': 22.956119537353516, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.734, 'grad_norm': 18.759746551513672, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 0.5361, 'grad_norm': 36.0551643371582, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 1.2113, 'grad_norm': 10.87551498413086, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 0.4051, 'grad_norm': 7.955956935882568, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.1943, 'grad_norm': 8.835991859436035, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 0.9376, 'grad_norm': 7.481494903564453, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.8644, 'grad_norm': 7.978955268859863, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.0341, 'grad_norm': 7.01145076751709, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.5594, 'grad_norm': 5.139330863952637, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.914, 'grad_norm': 29.10527992248535, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s]                                               {'loss': 0.729, 'grad_norm': 5.920391082763672, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s]                                               {'loss': 0.5776, 'grad_norm': 7.502741813659668, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.2092, 'grad_norm': 4.525892734527588, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 1.1875, 'grad_norm': 11.430281639099121, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.2196, 'grad_norm': 5.074530601501465, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.1821, 'grad_norm': 4.5279860496521, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.2602, 'grad_norm': 4.454521179199219, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.0509, 'grad_norm': 2.6716365814208984, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s]                                               {'loss': 0.282, 'grad_norm': 4.805043697357178, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s]                                               {'loss': 0.1275, 'grad_norm': 3.6633851528167725, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.0564, 'grad_norm': 1.2215632200241089, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.2322, 'grad_norm': 2.8199000358581543, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.5353, 'grad_norm': 3.8916966915130615, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.1277, 'grad_norm': 4.198592185974121, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.147, 'grad_norm': 4.064051151275635, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0066, 'grad_norm': 0.5273457765579224, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.1814, 'grad_norm': 5.525010108947754, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.3901, 'grad_norm': 1.6211285591125488, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0707, 'grad_norm': 2.795219898223877, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s]                                               {'loss': 0.2486, 'grad_norm': 7.8666181564331055, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0995, 'grad_norm': 3.248791456222534, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0956, 'grad_norm': 2.9714179039001465, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.1238, 'grad_norm': 4.025575160980225, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0316, 'grad_norm': 1.8204988241195679, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1726, 'train_samples_per_second': 46.416, 'train_steps_per_second': 3.286, 'train_loss': 0.7428770039812662, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:59
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 2.5626, 'grad_norm': 9.11717700958252, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 2.0046, 'grad_norm': 10.155555725097656, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:11,  3.09it/s]                                              {'loss': 2.2213, 'grad_norm': 18.24615478515625, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.09it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.6924, 'grad_norm': 19.605852127075195, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.5324, 'grad_norm': 16.472991943359375, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.5804, 'grad_norm': 18.197391510009766, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.0308, 'grad_norm': 17.272865295410156, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.3102, 'grad_norm': 17.030324935913086, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 1.6617, 'grad_norm': 17.780561447143555, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 1.0337, 'grad_norm': 6.228211402893066, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.3692, 'grad_norm': 7.06087064743042, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.6196, 'grad_norm': 9.218528747558594, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s]                                               {'loss': 1.1158, 'grad_norm': 11.172296524047852, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.9287, 'grad_norm': 8.82820987701416, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.5202, 'grad_norm': 6.051383972167969, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.0359, 'grad_norm': 2.3427116870880127, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.2489, 'grad_norm': 5.138552188873291, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.5026, 'grad_norm': 3.149193286895752, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.2398, 'grad_norm': 4.807221412658691, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 1.2389, 'grad_norm': 12.522299766540527, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.3696, 'grad_norm': 1.329724907875061, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.0626, 'grad_norm': 1.435247540473938, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.502, 'grad_norm': 8.835336685180664, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 1.753, 'grad_norm': 60.040523529052734, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.4681, 'grad_norm': 4.543025493621826, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.1173, 'grad_norm': 2.8331222534179688, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.0432, 'grad_norm': 1.1036083698272705, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.1794, 'grad_norm': 5.624197959899902, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.8817, 'grad_norm': 11.016095161437988, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.1893, 'grad_norm': 5.273991107940674, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.5157, 'grad_norm': 6.487410545349121, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0369, 'grad_norm': 2.950897693634033, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.4284, 'grad_norm': 7.863897800445557, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.0933, 'grad_norm': 4.135348320007324, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.0559, 'grad_norm': 1.595126986503601, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.036, 'grad_norm': 0.9212680459022522, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0805, 'grad_norm': 2.5308377742767334, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 1.0832, 'grad_norm': 3.1698286533355713, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0464, 'grad_norm': 1.6696313619613647, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.3786, 'grad_norm': 27.02446937561035, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.1524, 'train_samples_per_second': 46.493, 'train_steps_per_second': 3.292, 'train_loss': 0.8192635734565556, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:91
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.7802, 'grad_norm': 7.059396743774414, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.3938, 'grad_norm': 8.419107437133789, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.8603, 'grad_norm': 14.393342018127441, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.5068, 'grad_norm': 18.28460121154785, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.6554, 'grad_norm': 13.029803276062012, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.7741, 'grad_norm': 14.211891174316406, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.4026, 'grad_norm': 16.371902465820312, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 0.0499, 'grad_norm': 4.218258380889893, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s]                                              {'loss': 0.841, 'grad_norm': 11.747763633728027, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s]                                               {'loss': 0.9712, 'grad_norm': 14.312945365905762, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s]                                               {'loss': 1.4804, 'grad_norm': 14.575370788574219, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.5521, 'grad_norm': 8.213336944580078, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.23it/s]                                               {'loss': 0.8351, 'grad_norm': 8.43213176727295, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.23it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.4306, 'grad_norm': 7.708624362945557, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.4389, 'grad_norm': 4.791263580322266, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 1.0581, 'grad_norm': 38.55839920043945, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s]                                               {'loss': 0.3695, 'grad_norm': 4.302945137023926, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.64it/s]                                               {'loss': 0.2587, 'grad_norm': 3.0891776084899902, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.64it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s]                                               {'loss': 0.2377, 'grad_norm': 4.717849254608154, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.3176, 'grad_norm': 2.84102725982666, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.2704, 'grad_norm': 4.736672878265381, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.3966, 'grad_norm': 6.217794418334961, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.7218, 'grad_norm': 4.853329181671143, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.0398, 'grad_norm': 2.0492732524871826, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.12it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.1056, 'grad_norm': 2.4216067790985107, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.0662, 'grad_norm': 2.722090005874634, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.229, 'grad_norm': 17.15694808959961, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.5204, 'grad_norm': 1.2829554080963135, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1312, 'grad_norm': 14.638289451599121, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.18it/s]                                               {'loss': 0.2008, 'grad_norm': 3.4137308597564697, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.18it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.0932, 'grad_norm': 3.1775565147399902, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.13it/s]                                               {'loss': 0.0365, 'grad_norm': 2.4152114391326904, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.13it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.87it/s]                                               {'loss': 0.385, 'grad_norm': 1.5683680772781372, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.87it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s]                                               {'loss': 0.0109, 'grad_norm': 0.2838568687438965, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.1129, 'grad_norm': 3.366335868835449, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0619, 'grad_norm': 1.705295205116272, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0677, 'grad_norm': 1.5088751316070557, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.1, 'grad_norm': 2.2514071464538574, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1782, 'grad_norm': 2.5878496170043945, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 1.702, 'grad_norm': 1.813873291015625, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]                                               {'train_runtime': 11.9952, 'train_samples_per_second': 47.102, 'train_steps_per_second': 3.335, 'train_loss': 0.6911012312630191, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]100%|██████████| 40/40 [00:11<00:00,  3.33it/s]
CLIENT:10
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]                                              {'loss': 2.2567, 'grad_norm': 8.31052303314209, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.8246, 'grad_norm': 15.19959545135498, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.00it/s]                                              {'loss': 1.6482, 'grad_norm': 14.418389320373535, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.00it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 0.6811, 'grad_norm': 14.226083755493164, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.2943, 'grad_norm': 20.793445587158203, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.3365, 'grad_norm': 19.612417221069336, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.4624, 'grad_norm': 14.341500282287598, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.0529, 'grad_norm': 45.135169982910156, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 1.1641, 'grad_norm': 10.388083457946777, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s]                                               {'loss': 0.8145, 'grad_norm': 11.637139320373535, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s]                                               {'loss': 0.2149, 'grad_norm': 4.243835926055908, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.7346, 'grad_norm': 9.466136932373047, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.9521, 'grad_norm': 11.58643913269043, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 1.0741, 'grad_norm': 7.86179256439209, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.3933, 'grad_norm': 5.308361053466797, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.5273, 'grad_norm': 24.581087112426758, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.83it/s]                                               {'loss': 0.0976, 'grad_norm': 2.134981155395508, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.0868, 'grad_norm': 2.04337477684021, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.1199, 'grad_norm': 2.8686413764953613, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.172, 'grad_norm': 4.252909183502197, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.5677, 'grad_norm': 4.365339756011963, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.5404, 'grad_norm': 4.255897045135498, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.2557, 'grad_norm': 4.209925174713135, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.611, 'grad_norm': 27.345569610595703, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.13it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s]                                               {'loss': 0.4613, 'grad_norm': 2.7382419109344482, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s]                                               {'loss': 0.0873, 'grad_norm': 2.312309980392456, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s]                                               {'loss': 0.0194, 'grad_norm': 0.39456048607826233, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.0357, 'grad_norm': 0.7199856638908386, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.0561, 'grad_norm': 1.472229242324829, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.4127, 'grad_norm': 1.9739741086959839, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0186, 'grad_norm': 0.45531535148620605, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.006, 'grad_norm': 0.6523452401161194, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0558, 'grad_norm': 3.306004285812378, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.0382, 'grad_norm': 1.2584991455078125, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.3711, 'grad_norm': 1.259071946144104, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.1804, 'grad_norm': 5.374250888824463, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0699, 'grad_norm': 2.121857166290283, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0409, 'grad_norm': 1.6935336589813232, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.404, 'grad_norm': 0.9317653775215149, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0032, 'grad_norm': 0.20286180078983307, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0774, 'train_samples_per_second': 46.782, 'train_steps_per_second': 3.312, 'train_loss': 0.6035764331463724, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:50
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 3.3129, 'grad_norm': 12.2037353515625, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 1.7457, 'grad_norm': 17.004003524780273, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.2554, 'grad_norm': 13.673771858215332, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.8045, 'grad_norm': 18.38518714904785, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.3772, 'grad_norm': 13.085436820983887, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.3671, 'grad_norm': 14.327649116516113, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.0948, 'grad_norm': 11.325130462646484, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 0.1644, 'grad_norm': 6.53802490234375, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.61it/s]                                              {'loss': 0.758, 'grad_norm': 10.645991325378418, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.61it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.40it/s]                                               {'loss': 1.1117, 'grad_norm': 16.55063819885254, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.40it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.7012, 'grad_norm': 9.070479393005371, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.28it/s] 30%|███       | 12/40 [00:03<00:08,  3.22it/s]                                               {'loss': 0.6644, 'grad_norm': 5.691789627075195, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.22it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.6111, 'grad_norm': 8.589659690856934, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.635, 'grad_norm': 9.256093978881836, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.5903, 'grad_norm': 5.868434429168701, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.4348, 'grad_norm': 19.923418045043945, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s]                                               {'loss': 0.3176, 'grad_norm': 3.4852352142333984, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s]                                               {'loss': 0.3842, 'grad_norm': 3.8963661193847656, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s]                                               {'loss': 0.197, 'grad_norm': 3.1312339305877686, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.7775, 'grad_norm': 9.339427947998047, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.2381, 'grad_norm': 6.269597053527832, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.4135, 'grad_norm': 6.808737277984619, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.617, 'grad_norm': 9.70309066772461, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.2089, 'grad_norm': 14.313084602355957, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.18, 'grad_norm': 5.523314476013184, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.1671, 'grad_norm': 3.17234468460083, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.3202, 'grad_norm': 3.9304988384246826, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.2332, 'grad_norm': 5.514649391174316, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1855, 'grad_norm': 3.511772632598877, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0586, 'grad_norm': 1.052062749862671, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1114, 'grad_norm': 3.3738853931427, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1547, 'grad_norm': 7.99667501449585, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.0458, 'grad_norm': 1.4761860370635986, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0871, 'grad_norm': 1.7757318019866943, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.076, 'grad_norm': 2.4000484943389893, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.087, 'grad_norm': 2.23884654045105, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.2093, 'grad_norm': 2.528085708618164, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0821, 'grad_norm': 2.436203956604004, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.152, 'grad_norm': 3.6655774116516113, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0117, 'grad_norm': 0.6126817464828491, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1797, 'train_samples_per_second': 46.389, 'train_steps_per_second': 3.284, 'train_loss': 0.598597318562679, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:53
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  ddp_find_unused_parameters=False,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.2087, 'grad_norm': 12.203598022460938, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 2.9693, 'grad_norm': 11.788188934326172, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 1.9944, 'grad_norm': 10.846680641174316, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:12,  2.94it/s]                                              {'loss': 0.8772, 'grad_norm': 8.960190773010254, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.94it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.94it/s]                                              {'loss': 1.8026, 'grad_norm': 16.98843002319336, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.94it/s] 15%|█▌        | 6/40 [00:02<00:11,  3.01it/s]                                              {'loss': 2.2701, 'grad_norm': 24.04216194152832, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.7336, 'grad_norm': 17.656435012817383, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.0094, 'grad_norm': 0.7152594327926636, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 0.5735, 'grad_norm': 6.5580549240112305, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s]                                               {'loss': 0.9538, 'grad_norm': 13.873507499694824, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s]                                               {'loss': 0.3481, 'grad_norm': 5.801713466644287, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 0.9451, 'grad_norm': 6.928720951080322, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.2756, 'grad_norm': 4.327417850494385, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.6772, 'grad_norm': 7.051617622375488, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.6021, 'grad_norm': 6.62634801864624, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.2802, 'grad_norm': 10.089595794677734, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 0.3034, 'grad_norm': 4.602607250213623, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.3238, 'grad_norm': 6.76248025894165, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.2265, 'grad_norm': 3.2160446643829346, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.2522, 'grad_norm': 5.35990571975708, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.2197, 'grad_norm': 4.123680591583252, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.2092, 'grad_norm': 1.788906455039978, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.171, 'grad_norm': 2.878669500350952, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 1.2462, 'grad_norm': 32.25272750854492, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.0596, 'grad_norm': 1.459038257598877, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.0617, 'grad_norm': 1.8417798280715942, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.0811, 'grad_norm': 1.8775326013565063, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.1234, 'grad_norm': 5.43010950088501, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.213, 'grad_norm': 4.7868428230285645, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.1627, 'grad_norm': 1.1828484535217285, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0466, 'grad_norm': 0.9413163661956787, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.045, 'grad_norm': 2.231781005859375, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.0955, 'grad_norm': 2.542848587036133, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.084, 'grad_norm': 2.06816029548645, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.0942, 'grad_norm': 2.5354819297790527, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.1637, 'grad_norm': 1.328330159187317, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0436, 'grad_norm': 1.3867783546447754, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0591, 'grad_norm': 1.54132080078125, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0232, 'grad_norm': 0.6013821959495544, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0055, 'grad_norm': 0.3968718349933624, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1504, 'train_samples_per_second': 46.501, 'train_steps_per_second': 3.292, 'train_loss': 0.5708706605480984, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  eval_data = data[validation_key]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:42, 10.92it/s]  1%|          | 4/471 [00:00<01:07,  6.90it/s]  1%|          | 5/471 [00:00<01:13,  6.38it/s]  1%|▏         | 6/471 [00:00<01:17,  6.02it/s]  1%|▏         | 7/471 [00:01<01:19,  5.82it/s]  2%|▏         | 8/471 [00:01<01:21,  5.70it/s]  2%|▏         | 9/471 [00:01<01:21,  5.64it/s]  2%|▏         | 10/471 [00:01<01:22,  5.58it/s]  2%|▏         | 11/471 [00:01<01:23,  5.50it/s]  3%|▎         | 12/471 [00:02<01:23,  5.47it/s]  3%|▎         | 13/471 [00:02<01:24,  5.44it/s]  3%|▎         | 14/471 [00:02<01:24,  5.43it/s]  3%|▎         | 15/471 [00:02<01:23,  5.45it/s]  3%|▎         | 16/471 [00:02<01:23,  5.42it/s]  4%|▎         | 17/471 [00:02<01:23,  5.42it/s]  4%|▍         | 18/471 [00:03<01:23,  5.40it/s]  4%|▍         | 19/471 [00:03<01:23,  5.40it/s]  4%|▍         | 20/471 [00:03<01:23,  5.40it/s]  4%|▍         | 21/471 [00:03<01:23,  5.40it/s]  5%|▍         | 22/471 [00:03<01:23,  5.39it/s]  5%|▍         | 23/471 [00:04<01:23,  5.40it/s]  5%|▌         | 24/471 [00:04<01:23,  5.38it/s]  5%|▌         | 25/471 [00:04<01:22,  5.38it/s]  6%|▌         | 26/471 [00:04<01:22,  5.39it/s]  6%|▌         | 27/471 [00:04<01:22,  5.39it/s]  6%|▌         | 28/471 [00:04<01:21,  5.41it/s]  6%|▌         | 29/471 [00:05<01:22,  5.39it/s]  6%|▋         | 30/471 [00:05<01:22,  5.37it/s]  7%|▋         | 31/471 [00:05<01:21,  5.38it/s]  7%|▋         | 32/471 [00:05<01:21,  5.39it/s]  7%|▋         | 33/471 [00:05<01:20,  5.42it/s]  7%|▋         | 34/471 [00:06<01:20,  5.45it/s]  7%|▋         | 35/471 [00:06<01:20,  5.41it/s]  8%|▊         | 36/471 [00:06<01:20,  5.42it/s]  8%|▊         | 37/471 [00:06<01:20,  5.40it/s]  8%|▊         | 38/471 [00:06<01:20,  5.39it/s]  8%|▊         | 39/471 [00:07<01:19,  5.40it/s]  8%|▊         | 40/471 [00:07<01:19,  5.41it/s]  9%|▊         | 41/471 [00:07<01:19,  5.40it/s]  9%|▉         | 42/471 [00:07<01:19,  5.40it/s]  9%|▉         | 43/471 [00:07<01:19,  5.39it/s]  9%|▉         | 44/471 [00:07<01:19,  5.40it/s] 10%|▉         | 45/471 [00:08<01:18,  5.41it/s] 10%|▉         | 46/471 [00:08<01:18,  5.40it/s] 10%|▉         | 47/471 [00:08<01:18,  5.41it/s] 10%|█         | 48/471 [00:08<01:18,  5.40it/s] 10%|█         | 49/471 [00:08<01:18,  5.39it/s] 11%|█         | 50/471 [00:09<01:18,  5.39it/s] 11%|█         | 51/471 [00:09<01:17,  5.39it/s] 11%|█         | 52/471 [00:09<01:17,  5.39it/s] 11%|█▏        | 53/471 [00:09<01:17,  5.39it/s] 11%|█▏        | 54/471 [00:09<01:17,  5.38it/s] 12%|█▏        | 55/471 [00:09<01:17,  5.38it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.38it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.37it/s] 12%|█▏        | 58/471 [00:10<01:16,  5.38it/s] 13%|█▎        | 59/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 60/471 [00:10<01:16,  5.38it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.39it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.37it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.36it/s] 14%|█▎        | 64/471 [00:11<01:15,  5.37it/s] 14%|█▍        | 65/471 [00:11<01:15,  5.36it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.36it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.37it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.37it/s] 15%|█▍        | 69/471 [00:12<01:14,  5.38it/s] 15%|█▍        | 70/471 [00:12<01:14,  5.36it/s] 15%|█▌        | 71/471 [00:12<01:14,  5.36it/s] 15%|█▌        | 72/471 [00:13<01:14,  5.37it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.37it/s] 16%|█▌        | 74/471 [00:13<01:13,  5.37it/s] 16%|█▌        | 75/471 [00:13<01:13,  5.38it/s] 16%|█▌        | 76/471 [00:13<01:13,  5.38it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.39it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.38it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.37it/s] 17%|█▋        | 80/471 [00:14<01:12,  5.37it/s] 17%|█▋        | 81/471 [00:14<01:12,  5.38it/s] 17%|█▋        | 82/471 [00:15<01:11,  5.41it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.38it/s] 18%|█▊        | 84/471 [00:15<01:11,  5.38it/s] 18%|█▊        | 85/471 [00:15<01:11,  5.37it/s] 18%|█▊        | 86/471 [00:15<01:11,  5.36it/s] 18%|█▊        | 87/471 [00:15<01:11,  5.38it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.38it/s] 19%|█▉        | 89/471 [00:16<01:10,  5.38it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.37it/s] 19%|█▉        | 91/471 [00:16<01:10,  5.37it/s] 20%|█▉        | 92/471 [00:16<01:10,  5.38it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.36it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.37it/s] 20%|██        | 95/471 [00:17<01:09,  5.38it/s] 20%|██        | 96/471 [00:17<01:09,  5.37it/s] 21%|██        | 97/471 [00:17<01:09,  5.37it/s] 21%|██        | 98/471 [00:18<01:09,  5.38it/s] 21%|██        | 99/471 [00:18<01:09,  5.37it/s] 21%|██        | 100/471 [00:18<01:08,  5.40it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.39it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.38it/s] 22%|██▏       | 103/471 [00:18<01:08,  5.37it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.35it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.34it/s] 23%|██▎       | 106/471 [00:19<01:07,  5.37it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.39it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.39it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.38it/s] 23%|██▎       | 110/471 [00:20<01:06,  5.39it/s] 24%|██▎       | 111/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 112/471 [00:20<01:06,  5.37it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.41it/s] 24%|██▍       | 114/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.38it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.37it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.36it/s] 25%|██▌       | 118/471 [00:21<01:05,  5.37it/s] 25%|██▌       | 119/471 [00:21<01:05,  5.35it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.34it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.34it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.35it/s] 26%|██▌       | 123/471 [00:22<01:04,  5.36it/s] 26%|██▋       | 124/471 [00:22<01:04,  5.35it/s] 27%|██▋       | 125/471 [00:23<01:04,  5.35it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.34it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.34it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.35it/s] 27%|██▋       | 129/471 [00:23<01:03,  5.37it/s] 28%|██▊       | 130/471 [00:23<01:03,  5.37it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.37it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.36it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.35it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.34it/s] 29%|██▊       | 135/471 [00:24<01:02,  5.35it/s] 29%|██▉       | 136/471 [00:25<01:02,  5.36it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.35it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.35it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.35it/s] 30%|██▉       | 140/471 [00:25<01:01,  5.35it/s] 30%|██▉       | 141/471 [00:26<01:01,  5.38it/s] 30%|███       | 142/471 [00:26<01:01,  5.37it/s] 30%|███       | 143/471 [00:26<01:01,  5.37it/s] 31%|███       | 144/471 [00:26<01:01,  5.35it/s] 31%|███       | 145/471 [00:26<01:00,  5.36it/s] 31%|███       | 146/471 [00:26<01:00,  5.37it/s] 31%|███       | 147/471 [00:27<01:00,  5.37it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.36it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.34it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.33it/s] 32%|███▏      | 151/471 [00:27<01:00,  5.33it/s] 32%|███▏      | 152/471 [00:28<00:59,  5.33it/s] 32%|███▏      | 153/471 [00:28<00:59,  5.33it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.37it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.34it/s] 33%|███▎      | 156/471 [00:28<00:58,  5.35it/s] 33%|███▎      | 157/471 [00:29<00:58,  5.35it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.36it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.37it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.35it/s] 34%|███▍      | 161/471 [00:29<00:58,  5.34it/s] 34%|███▍      | 162/471 [00:29<00:57,  5.33it/s] 35%|███▍      | 163/471 [00:30<00:57,  5.32it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.35it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.34it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.34it/s] 35%|███▌      | 167/471 [00:30<00:56,  5.33it/s] 36%|███▌      | 168/471 [00:31<00:56,  5.33it/s] 36%|███▌      | 169/471 [00:31<00:56,  5.33it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.33it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.33it/s] 37%|███▋      | 172/471 [00:31<00:55,  5.36it/s] 37%|███▋      | 173/471 [00:32<00:55,  5.34it/s] 37%|███▋      | 174/471 [00:32<00:55,  5.33it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.33it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.35it/s] 38%|███▊      | 177/471 [00:32<00:55,  5.34it/s] 38%|███▊      | 178/471 [00:32<00:54,  5.34it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.35it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.35it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.33it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.33it/s] 39%|███▉      | 183/471 [00:33<00:54,  5.33it/s] 39%|███▉      | 184/471 [00:34<00:53,  5.35it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.34it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.36it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.34it/s] 40%|███▉      | 188/471 [00:34<00:53,  5.32it/s] 40%|████      | 189/471 [00:35<00:52,  5.34it/s] 40%|████      | 190/471 [00:35<00:52,  5.34it/s] 41%|████      | 191/471 [00:35<00:52,  5.33it/s] 41%|████      | 192/471 [00:35<00:52,  5.34it/s] 41%|████      | 193/471 [00:35<00:51,  5.35it/s] 41%|████      | 194/471 [00:35<00:51,  5.34it/s] 41%|████▏     | 195/471 [00:36<00:51,  5.33it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.33it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.36it/s] 42%|████▏     | 198/471 [00:36<00:50,  5.35it/s] 42%|████▏     | 199/471 [00:36<00:50,  5.34it/s] 42%|████▏     | 200/471 [00:37<00:50,  5.33it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.35it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.35it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.33it/s] 43%|████▎     | 204/471 [00:37<00:50,  5.33it/s] 44%|████▎     | 205/471 [00:37<00:49,  5.35it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.35it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.33it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.35it/s] 44%|████▍     | 209/471 [00:38<00:48,  5.38it/s] 45%|████▍     | 210/471 [00:38<00:48,  5.37it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.37it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.35it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.34it/s] 45%|████▌     | 214/471 [00:39<00:48,  5.33it/s] 46%|████▌     | 215/471 [00:39<00:47,  5.35it/s] 46%|████▌     | 216/471 [00:40<00:47,  5.34it/s] 46%|████▌     | 217/471 [00:40<00:47,  5.32it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.30it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.31it/s] 47%|████▋     | 220/471 [00:40<00:47,  5.32it/s] 47%|████▋     | 221/471 [00:40<00:46,  5.33it/s] 47%|████▋     | 222/471 [00:41<00:46,  5.34it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.34it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.33it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.34it/s] 48%|████▊     | 226/471 [00:41<00:45,  5.34it/s] 48%|████▊     | 227/471 [00:42<00:45,  5.33it/s] 48%|████▊     | 228/471 [00:42<00:45,  5.32it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.31it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.32it/s] 49%|████▉     | 231/471 [00:42<00:45,  5.32it/s] 49%|████▉     | 232/471 [00:43<00:44,  5.34it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.34it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.32it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.32it/s] 50%|█████     | 236/471 [00:43<00:44,  5.33it/s] 50%|█████     | 237/471 [00:43<00:43,  5.34it/s] 51%|█████     | 238/471 [00:44<00:43,  5.35it/s] 51%|█████     | 239/471 [00:44<00:43,  5.34it/s] 51%|█████     | 240/471 [00:44<00:43,  5.33it/s] 51%|█████     | 241/471 [00:44<00:43,  5.32it/s] 51%|█████▏    | 242/471 [00:44<00:42,  5.34it/s] 52%|█████▏    | 243/471 [00:45<00:42,  5.33it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.31it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.33it/s] 52%|█████▏    | 247/471 [00:45<00:41,  5.35it/s] 53%|█████▎    | 248/471 [00:46<00:41,  5.35it/s] 53%|█████▎    | 249/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.36it/s] 54%|█████▎    | 252/471 [00:46<00:40,  5.34it/s] 54%|█████▎    | 253/471 [00:46<00:40,  5.34it/s] 54%|█████▍    | 254/471 [00:47<00:40,  5.32it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.32it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.32it/s] 55%|█████▍    | 257/471 [00:47<00:40,  5.31it/s] 55%|█████▍    | 258/471 [00:47<00:40,  5.32it/s] 55%|█████▍    | 259/471 [00:48<00:39,  5.32it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.31it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.31it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.32it/s] 56%|█████▌    | 263/471 [00:48<00:39,  5.31it/s] 56%|█████▌    | 264/471 [00:49<00:38,  5.31it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.31it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.30it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.29it/s] 57%|█████▋    | 268/471 [00:49<00:38,  5.29it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.30it/s] 57%|█████▋    | 270/471 [00:50<00:37,  5.31it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.31it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.33it/s] 58%|█████▊    | 273/471 [00:50<00:37,  5.33it/s] 58%|█████▊    | 274/471 [00:50<00:36,  5.35it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.35it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 278/471 [00:51<00:36,  5.31it/s] 59%|█████▉    | 279/471 [00:51<00:36,  5.32it/s] 59%|█████▉    | 280/471 [00:52<00:35,  5.34it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.33it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.32it/s] 60%|██████    | 283/471 [00:52<00:35,  5.31it/s] 60%|██████    | 284/471 [00:52<00:35,  5.30it/s] 61%|██████    | 285/471 [00:53<00:35,  5.31it/s] 61%|██████    | 286/471 [00:53<00:34,  5.32it/s] 61%|██████    | 287/471 [00:53<00:34,  5.31it/s] 61%|██████    | 288/471 [00:53<00:34,  5.30it/s] 61%|██████▏   | 289/471 [00:53<00:34,  5.31it/s] 62%|██████▏   | 290/471 [00:53<00:34,  5.31it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.32it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.32it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.34it/s] 62%|██████▏   | 294/471 [00:54<00:33,  5.32it/s] 63%|██████▎   | 295/471 [00:54<00:33,  5.32it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.33it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.32it/s] 63%|██████▎   | 299/471 [00:55<00:32,  5.32it/s] 64%|██████▎   | 300/471 [00:55<00:32,  5.30it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.29it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.30it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.30it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.32it/s] 65%|██████▍   | 305/471 [00:56<00:31,  5.32it/s] 65%|██████▍   | 306/471 [00:56<00:31,  5.29it/s] 65%|██████▌   | 307/471 [00:57<00:31,  5.28it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.28it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.28it/s] 66%|██████▌   | 310/471 [00:57<00:30,  5.30it/s] 66%|██████▌   | 311/471 [00:57<00:30,  5.29it/s] 66%|██████▌   | 312/471 [00:58<00:29,  5.30it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.31it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.31it/s] 67%|██████▋   | 315/471 [00:58<00:29,  5.30it/s] 67%|██████▋   | 316/471 [00:58<00:29,  5.31it/s] 67%|██████▋   | 317/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.31it/s] 68%|██████▊   | 320/471 [00:59<00:28,  5.30it/s] 68%|██████▊   | 321/471 [00:59<00:28,  5.30it/s] 68%|██████▊   | 322/471 [00:59<00:28,  5.29it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.29it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.28it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.28it/s] 69%|██████▉   | 326/471 [01:00<00:27,  5.29it/s] 69%|██████▉   | 327/471 [01:00<00:27,  5.30it/s] 70%|██████▉   | 328/471 [01:01<00:26,  5.31it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.30it/s] 70%|███████   | 330/471 [01:01<00:26,  5.31it/s] 70%|███████   | 331/471 [01:01<00:26,  5.30it/s] 70%|███████   | 332/471 [01:01<00:26,  5.29it/s] 71%|███████   | 333/471 [01:02<00:26,  5.31it/s] 71%|███████   | 334/471 [01:02<00:25,  5.31it/s] 71%|███████   | 335/471 [01:02<00:25,  5.29it/s] 71%|███████▏  | 336/471 [01:02<00:25,  5.29it/s] 72%|███████▏  | 337/471 [01:02<00:25,  5.32it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.31it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.30it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.29it/s] 72%|███████▏  | 341/471 [01:03<00:24,  5.30it/s] 73%|███████▎  | 342/471 [01:03<00:24,  5.32it/s] 73%|███████▎  | 343/471 [01:03<00:24,  5.31it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.32it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.31it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.30it/s] 74%|███████▎  | 347/471 [01:04<00:23,  5.31it/s] 74%|███████▍  | 348/471 [01:04<00:23,  5.31it/s] 74%|███████▍  | 349/471 [01:05<00:22,  5.32it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.30it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.31it/s] 75%|███████▍  | 352/471 [01:05<00:22,  5.30it/s] 75%|███████▍  | 353/471 [01:05<00:22,  5.27it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.28it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 357/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 358/471 [01:06<00:21,  5.28it/s] 76%|███████▌  | 359/471 [01:06<00:21,  5.28it/s] 76%|███████▋  | 360/471 [01:07<00:20,  5.30it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.31it/s] 77%|███████▋  | 362/471 [01:07<00:20,  5.31it/s] 77%|███████▋  | 363/471 [01:07<00:20,  5.29it/s] 77%|███████▋  | 364/471 [01:07<00:20,  5.29it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.28it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.27it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.28it/s] 78%|███████▊  | 368/471 [01:08<00:19,  5.28it/s] 78%|███████▊  | 369/471 [01:08<00:19,  5.28it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.27it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.28it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.27it/s] 79%|███████▉  | 373/471 [01:09<00:18,  5.26it/s] 79%|███████▉  | 374/471 [01:09<00:18,  5.28it/s] 80%|███████▉  | 375/471 [01:09<00:18,  5.29it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.28it/s] 80%|████████  | 377/471 [01:10<00:17,  5.29it/s] 80%|████████  | 378/471 [01:10<00:17,  5.31it/s] 80%|████████  | 379/471 [01:10<00:17,  5.29it/s] 81%|████████  | 380/471 [01:10<00:17,  5.28it/s] 81%|████████  | 381/471 [01:11<00:17,  5.29it/s] 81%|████████  | 382/471 [01:11<00:16,  5.29it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.28it/s] 82%|████████▏ | 384/471 [01:11<00:16,  5.27it/s] 82%|████████▏ | 385/471 [01:11<00:16,  5.26it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.27it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.26it/s] 83%|████████▎ | 389/471 [01:12<00:15,  5.28it/s] 83%|████████▎ | 390/471 [01:12<00:15,  5.28it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.27it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.28it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.30it/s] 84%|████████▎ | 394/471 [01:13<00:14,  5.29it/s] 84%|████████▍ | 395/471 [01:13<00:14,  5.28it/s] 84%|████████▍ | 396/471 [01:13<00:14,  5.27it/s] 84%|████████▍ | 397/471 [01:14<00:14,  5.27it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.28it/s] 85%|████████▍ | 399/471 [01:14<00:13,  5.27it/s] 85%|████████▍ | 400/471 [01:14<00:13,  5.26it/s] 85%|████████▌ | 401/471 [01:14<00:13,  5.27it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.26it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.27it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.28it/s] 86%|████████▌ | 405/471 [01:15<00:12,  5.26it/s] 86%|████████▌ | 406/471 [01:15<00:12,  5.28it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.28it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.27it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.26it/s] 87%|████████▋ | 410/471 [01:16<00:11,  5.28it/s] 87%|████████▋ | 411/471 [01:16<00:11,  5.29it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.28it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.28it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.28it/s] 88%|████████▊ | 415/471 [01:17<00:10,  5.27it/s] 88%|████████▊ | 416/471 [01:17<00:10,  5.26it/s] 89%|████████▊ | 417/471 [01:17<00:10,  5.27it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.27it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.28it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.31it/s] 89%|████████▉ | 421/471 [01:18<00:09,  5.30it/s] 90%|████████▉ | 422/471 [01:18<00:09,  5.29it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.29it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.28it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.28it/s] 90%|█████████ | 426/471 [01:19<00:08,  5.27it/s] 91%|█████████ | 427/471 [01:19<00:08,  5.28it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.27it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.26it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.25it/s] 92%|█████████▏| 431/471 [01:20<00:07,  5.25it/s] 92%|█████████▏| 432/471 [01:20<00:07,  5.26it/s] 92%|█████████▏| 433/471 [01:20<00:07,  5.25it/s] 92%|█████████▏| 434/471 [01:21<00:07,  5.25it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.24it/s] 93%|█████████▎| 436/471 [01:21<00:06,  5.26it/s] 93%|█████████▎| 437/471 [01:21<00:06,  5.26it/s] 93%|█████████▎| 438/471 [01:21<00:06,  5.26it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.26it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.26it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.26it/s] 94%|█████████▍| 442/471 [01:22<00:05,  5.28it/s] 94%|█████████▍| 443/471 [01:22<00:05,  5.28it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.27it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.26it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.25it/s] 95%|█████████▍| 447/471 [01:23<00:04,  5.25it/s] 95%|█████████▌| 448/471 [01:23<00:04,  5.27it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.27it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.26it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.25it/s] 96%|█████████▌| 452/471 [01:24<00:03,  5.26it/s] 96%|█████████▌| 453/471 [01:24<00:03,  5.26it/s] 96%|█████████▋| 454/471 [01:24<00:03,  5.25it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.24it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.25it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.25it/s] 97%|█████████▋| 458/471 [01:25<00:02,  5.26it/s] 97%|█████████▋| 459/471 [01:25<00:02,  5.28it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.27it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.25it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.24it/s] 98%|█████████▊| 463/471 [01:26<00:01,  5.25it/s] 99%|█████████▊| 464/471 [01:26<00:01,  5.26it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.27it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.26it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.24it/s] 99%|█████████▉| 468/471 [01:27<00:00,  5.24it/s]100%|█████████▉| 469/471 [01:27<00:00,  5.25it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.25it/s]100%|██████████| 471/471 [01:28<00:00,  5.61it/s]100%|██████████| 471/471 [01:28<00:00,  5.34it/s]
{'eval_loss': 2.278113842010498, 'eval_model_preparation_time': 0.0051, 'eval_acc': 0.39657461497610197, 'eval_runtime': 88.351, 'eval_samples_per_second': 85.251, 'eval_steps_per_second': 5.331}
ROUND:14
CLIENT:72
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  per_device_train_batch_size=self.args.batch_size, do_train=True,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]                                              {'loss': 2.4035, 'grad_norm': 12.942115783691406, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.96it/s]  5%|▌         | 2/40 [00:00<00:12,  2.94it/s]                                              {'loss': 2.4297, 'grad_norm': 11.292241096496582, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.94it/s]  8%|▊         | 3/40 [00:01<00:12,  2.95it/s]                                              {'loss': 1.3429, 'grad_norm': 9.83852481842041, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.95it/s] 10%|█         | 4/40 [00:01<00:12,  2.95it/s]                                              {'loss': 1.952, 'grad_norm': 16.256580352783203, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.95it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.93it/s]                                              {'loss': 0.7129, 'grad_norm': 14.340107917785645, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.93it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.93it/s]                                              {'loss': 1.966, 'grad_norm': 19.00908088684082, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.93it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.94it/s]                                              {'loss': 1.6973, 'grad_norm': 13.804553985595703, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.94it/s]                                              {'loss': 0.0562, 'grad_norm': 4.781181812286377, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.94it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.66it/s]                                              {'loss': 0.7281, 'grad_norm': 9.476158142089844, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.66it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.42it/s]                                               {'loss': 0.3189, 'grad_norm': 6.4573073387146, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.42it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.27it/s]                                               {'loss': 0.6334, 'grad_norm': 9.341530799865723, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.27it/s] 30%|███       | 12/40 [00:03<00:08,  3.16it/s]                                               {'loss': 0.7846, 'grad_norm': 9.913599967956543, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.16it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.8262, 'grad_norm': 7.747721195220947, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.09it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.03it/s]                                               {'loss': 0.5678, 'grad_norm': 10.788827896118164, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.03it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.00it/s]                                               {'loss': 0.7591, 'grad_norm': 8.332301139831543, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.00it/s]                                               {'loss': 0.0043, 'grad_norm': 0.2003890872001648, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:08,  3.00it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.65it/s]                                               {'loss': 0.1893, 'grad_norm': 2.9660964012145996, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.65it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.1982, 'grad_norm': 3.1028456687927246, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.43it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.27it/s]                                               {'loss': 0.4576, 'grad_norm': 6.4849443435668945, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.27it/s] 50%|█████     | 20/40 [00:06<00:06,  3.17it/s]                                               {'loss': 0.1105, 'grad_norm': 2.8646106719970703, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.17it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.11it/s]                                               {'loss': 0.4329, 'grad_norm': 8.948160171508789, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.11it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.06it/s]                                               {'loss': 0.5857, 'grad_norm': 4.5771484375, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.06it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s]                                               {'loss': 0.5294, 'grad_norm': 10.979957580566406, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s]                                               {'loss': 0.0157, 'grad_norm': 0.8936665058135986, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.02it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s]                                               {'loss': 0.0958, 'grad_norm': 5.760878086090088, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s] 65%|██████▌   | 26/40 [00:08<00:03,  3.51it/s]                                               {'loss': 0.4821, 'grad_norm': 2.4129960536956787, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:08<00:03,  3.51it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s]                                               {'loss': 0.1664, 'grad_norm': 3.95935320854187, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s] 70%|███████   | 28/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.0328, 'grad_norm': 0.7802212834358215, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.22it/s] 72%|███████▎  | 29/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0908, 'grad_norm': 3.0729453563690186, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:09<00:03,  3.13it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.08it/s]                                               {'loss': 0.278, 'grad_norm': 3.681589126586914, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.08it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.03it/s]                                               {'loss': 0.1559, 'grad_norm': 5.325873374938965, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.03it/s]                                               {'loss': 0.0072, 'grad_norm': 0.5662440061569214, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.03it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.75it/s]                                               {'loss': 0.0338, 'grad_norm': 0.9784292578697205, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.75it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s]                                               {'loss': 0.027, 'grad_norm': 0.89995276927948, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0234, 'grad_norm': 0.44548243284225464, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.22it/s]                                               {'loss': 0.5239, 'grad_norm': 2.5833380222320557, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.22it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0505, 'grad_norm': 1.160722017288208, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.2091, 'grad_norm': 0.9964354038238525, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.03it/s]                                               {'loss': 0.0278, 'grad_norm': 0.8477444052696228, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.03it/s]                                               {'loss': 0.013, 'grad_norm': 1.3922264575958252, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.03it/s]                                               {'train_runtime': 12.4149, 'train_samples_per_second': 45.51, 'train_steps_per_second': 3.222, 'train_loss': 0.5479875692515634, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.03it/s]100%|██████████| 40/40 [00:12<00:00,  3.22it/s]
CLIENT:33
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr, weight_decay=0.02, betas=(0.9, 0.999), amsgrad=True)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 2.527, 'grad_norm': 11.003437995910645, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 1.1912, 'grad_norm': 11.000836372375488, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 1.7471, 'grad_norm': 14.853532791137695, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:12,  2.98it/s]                                              {'loss': 1.2725, 'grad_norm': 14.92257022857666, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.98it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.5951, 'grad_norm': 21.08600616455078, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:02<00:11,  3.00it/s]                                              {'loss': 1.9477, 'grad_norm': 12.48317813873291, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 2.0514, 'grad_norm': 19.017005920410156, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 0.0116, 'grad_norm': 0.7874398827552795, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.98it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.70it/s]                                              {'loss': 0.5316, 'grad_norm': 8.140932083129883, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.70it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.46it/s]                                               {'loss': 0.5192, 'grad_norm': 10.12823486328125, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.46it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.31it/s]                                               {'loss': 0.7243, 'grad_norm': 10.009424209594727, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.31it/s] 30%|███       | 12/40 [00:03<00:08,  3.21it/s]                                               {'loss': 1.1305, 'grad_norm': 12.435922622680664, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.21it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.304, 'grad_norm': 6.544724941253662, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.1619, 'grad_norm': 8.284831047058105, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.4636, 'grad_norm': 6.559128284454346, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.59, 'grad_norm': 22.119064331054688, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s]                                               {'loss': 0.1241, 'grad_norm': 3.7706050872802734, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.50it/s]                                               {'loss': 0.2094, 'grad_norm': 4.586111068725586, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.50it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s]                                               {'loss': 0.5421, 'grad_norm': 3.3930163383483887, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s] 50%|█████     | 20/40 [00:06<00:06,  3.21it/s]                                               {'loss': 0.2733, 'grad_norm': 5.990499019622803, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.21it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.13it/s]                                               {'loss': 0.7098, 'grad_norm': 22.773313522338867, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.13it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s]                                               {'loss': 0.6501, 'grad_norm': 6.238710403442383, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.3782, 'grad_norm': 6.789152145385742, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.1476, 'grad_norm': 8.395918846130371, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.04it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s]                                               {'loss': 0.0566, 'grad_norm': 1.4337382316589355, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s]                                               {'loss': 0.0579, 'grad_norm': 1.1339274644851685, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.0601, 'grad_norm': 1.1372162103652954, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.4555, 'grad_norm': 2.170320987701416, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.24it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.14it/s]                                               {'loss': 0.0602, 'grad_norm': 1.2208460569381714, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.14it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.4097, 'grad_norm': 1.995782494544983, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.085, 'grad_norm': 2.427464008331299, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.115, 'grad_norm': 11.843964576721191, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.76it/s]                                               {'loss': 0.0434, 'grad_norm': 2.341965675354004, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.76it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s]                                               {'loss': 0.0234, 'grad_norm': 1.0697906017303467, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0575, 'grad_norm': 2.302706003189087, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.24it/s]                                               {'loss': 0.7034, 'grad_norm': 1.8031115531921387, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0524, 'grad_norm': 1.758268117904663, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0367, 'grad_norm': 1.1529182195663452, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.05it/s]                                               {'loss': 0.0483, 'grad_norm': 2.032876491546631, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.05it/s]                                               {'loss': 0.0033, 'grad_norm': 0.2384844869375229, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]                                               {'train_runtime': 12.3104, 'train_samples_per_second': 45.896, 'train_steps_per_second': 3.249, 'train_loss': 0.6267939776123967, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
CLIENT:58
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr, weight_decay=0.02, betas=(0.9, 0.999), amsgrad=True)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.4428, 'grad_norm': 8.211280822753906, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 2.6162, 'grad_norm': 11.18575382232666, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.632, 'grad_norm': 13.512706756591797, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.7426, 'grad_norm': 17.7587890625, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.735, 'grad_norm': 24.007192611694336, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.7639, 'grad_norm': 16.468128204345703, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.09it/s]                                              {'loss': 1.507, 'grad_norm': 16.226516723632812, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.09it/s]                                              {'loss': 0.1238, 'grad_norm': 10.199444770812988, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.09it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s]                                              {'loss': 0.4584, 'grad_norm': 6.713229179382324, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s]                                               {'loss': 1.3196, 'grad_norm': 18.225143432617188, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.1391, 'grad_norm': 14.222360610961914, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 0.8548, 'grad_norm': 9.751346588134766, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.8865, 'grad_norm': 8.478466987609863, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.6, 'grad_norm': 7.47274112701416, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.5011, 'grad_norm': 5.877017498016357, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.0379, 'grad_norm': 1.9809995889663696, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.3115, 'grad_norm': 3.944047451019287, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s]                                               {'loss': 0.7834, 'grad_norm': 9.337066650390625, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s]                                               {'loss': 0.8454, 'grad_norm': 8.224427223205566, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.7477, 'grad_norm': 6.778659820556641, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 1.3354, 'grad_norm': 12.84023666381836, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.2593, 'grad_norm': 4.631063461303711, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.3299, 'grad_norm': 6.967101573944092, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.1173, 'grad_norm': 4.440246105194092, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.06it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.75it/s]                                               {'loss': 0.0475, 'grad_norm': 2.360135793685913, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.75it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s]                                               {'loss': 0.2702, 'grad_norm': 6.586408615112305, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.5505, 'grad_norm': 5.696143627166748, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.5017, 'grad_norm': 2.3217718601226807, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.1451, 'grad_norm': 3.616455316543579, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.2269, 'grad_norm': 5.834668159484863, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.04it/s]                                               {'loss': 0.0877, 'grad_norm': 8.406970024108887, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.04it/s]                                               {'loss': 0.1735, 'grad_norm': 8.315641403198242, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.04it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s]                                               {'loss': 0.0386, 'grad_norm': 1.0975490808486938, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.5615, 'grad_norm': 5.450414657592773, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.1524, 'grad_norm': 4.189629554748535, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.58, 'grad_norm': 4.064180374145508, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0498, 'grad_norm': 1.014407753944397, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.1326, 'grad_norm': 2.829713821411133, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.2634, 'grad_norm': 13.719602584838867, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.035, 'grad_norm': 2.258134126663208, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1491, 'train_samples_per_second': 46.506, 'train_steps_per_second': 3.292, 'train_loss': 0.6976751188747585, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:2
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr, weight_decay=0.02, betas=(0.9, 0.999), amsgrad=True)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 2.3897, 'grad_norm': 8.798285484313965, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 2.3773, 'grad_norm': 10.55898666381836, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.2602, 'grad_norm': 11.003960609436035, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:12,  3.00it/s]                                              {'loss': 2.362, 'grad_norm': 15.267126083374023, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s]                                              {'loss': 2.0741, 'grad_norm': 16.48562240600586, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.9883, 'grad_norm': 13.19820785522461, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 1.3954, 'grad_norm': 21.195709228515625, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 0.0159, 'grad_norm': 1.1605342626571655, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.97it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 0.7912, 'grad_norm': 7.465108394622803, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 1.1593, 'grad_norm': 14.750574111938477, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s]                                               {'loss': 0.5643, 'grad_norm': 7.938891887664795, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s] 30%|███       | 12/40 [00:03<00:08,  3.23it/s]                                               {'loss': 0.9847, 'grad_norm': 12.91029167175293, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.23it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.3994, 'grad_norm': 8.605191230773926, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.7424, 'grad_norm': 15.950663566589355, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.6423, 'grad_norm': 5.592021465301514, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.0076, 'grad_norm': 0.4706605076789856, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.1414, 'grad_norm': 2.6627955436706543, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.2508, 'grad_norm': 4.271040439605713, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s]                                               {'loss': 0.1022, 'grad_norm': 2.396676778793335, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s] 50%|█████     | 20/40 [00:06<00:06,  3.23it/s]                                               {'loss': 0.3326, 'grad_norm': 5.7359442710876465, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.23it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s]                                               {'loss': 0.6353, 'grad_norm': 6.4638752937316895, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.7311, 'grad_norm': 32.94906234741211, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.1979, 'grad_norm': 6.864113807678223, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.1567, 'grad_norm': 13.839163780212402, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s]                                               {'loss': 0.2298, 'grad_norm': 5.843231201171875, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.74it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s]                                               {'loss': 0.0561, 'grad_norm': 1.396066427230835, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.133, 'grad_norm': 3.564443826675415, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.33it/s] 70%|███████   | 28/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.329, 'grad_norm': 5.1945109367370605, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.22it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s]                                               {'loss': 0.0854, 'grad_norm': 1.764681100845337, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.2925, 'grad_norm': 5.774878978729248, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0799, 'grad_norm': 1.6925698518753052, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0492, 'grad_norm': 2.681051254272461, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.1003, 'grad_norm': 3.787353277206421, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.0899, 'grad_norm': 2.4729671478271484, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.0393, 'grad_norm': 1.3887646198272705, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s]                                               {'loss': 0.0696, 'grad_norm': 1.9806115627288818, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0551, 'grad_norm': 2.7607076168060303, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.106, 'grad_norm': 2.6423327922821045, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.04it/s]                                               {'loss': 0.1517, 'grad_norm': 5.156094074249268, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.04it/s]                                               {'loss': 0.0492, 'grad_norm': 3.808101177215576, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]                                               {'train_runtime': 12.2677, 'train_samples_per_second': 46.056, 'train_steps_per_second': 3.261, 'train_loss': 0.5904476512223482, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
CLIENT:55
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr, weight_decay=0.02, betas=(0.9, 0.999), amsgrad=True)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 2.0377, 'grad_norm': 9.503668785095215, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 1.5735, 'grad_norm': 11.703024864196777, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:01<00:12,  2.99it/s]                                              {'loss': 1.9586, 'grad_norm': 15.867396354675293, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.99it/s] 10%|█         | 4/40 [00:01<00:12,  2.98it/s]                                              {'loss': 1.9916, 'grad_norm': 12.428752899169922, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.98it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 2.3789, 'grad_norm': 16.269393920898438, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s]                                              {'loss': 1.2399, 'grad_norm': 14.190766334533691, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 2.231, 'grad_norm': 20.4732608795166, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 0.7917, 'grad_norm': 50.43046951293945, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.98it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 2.3739, 'grad_norm': 35.521018981933594, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 1.5897, 'grad_norm': 23.572355270385742, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 0.8544, 'grad_norm': 14.22459888458252, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.8762, 'grad_norm': 10.25125789642334, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.9813, 'grad_norm': 10.082437515258789, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.633, 'grad_norm': 7.184221267700195, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.4102, 'grad_norm': 5.22763729095459, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.0278, 'grad_norm': 1.4864002466201782, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.6259, 'grad_norm': 8.099190711975098, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.6733, 'grad_norm': 6.896205902099609, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s]                                               {'loss': 0.3888, 'grad_norm': 6.461929798126221, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.3435, 'grad_norm': 6.036698818206787, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s]                                               {'loss': 0.5897, 'grad_norm': 5.497353553771973, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.3623, 'grad_norm': 5.15977144241333, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.5035, 'grad_norm': 6.018222332000732, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0138, 'grad_norm': 0.845025897026062, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.2209, 'grad_norm': 3.8902499675750732, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.2766, 'grad_norm': 4.9055962562561035, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.2212, 'grad_norm': 4.6609721183776855, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.2864, 'grad_norm': 7.103786945343018, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.2236, 'grad_norm': 5.1744537353515625, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.0945, 'grad_norm': 2.1790013313293457, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.3319, 'grad_norm': 5.5527825355529785, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0009, 'grad_norm': 0.05390264093875885, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s]                                               {'loss': 0.1398, 'grad_norm': 2.167609930038452, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s]                                               {'loss': 0.0672, 'grad_norm': 1.2618231773376465, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.0615, 'grad_norm': 1.800562858581543, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s]                                               {'loss': 0.1727, 'grad_norm': 4.340818881988525, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0985, 'grad_norm': 3.3271164894104004, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.116, 'grad_norm': 3.9781816005706787, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.0786, 'grad_norm': 2.1331982612609863, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.1469, 'grad_norm': 9.597458839416504, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]                                               {'train_runtime': 12.2626, 'train_samples_per_second': 46.075, 'train_steps_per_second': 3.262, 'train_loss': 0.699683162184374, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
CLIENT:84
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr, weight_decay=0.02, betas=(0.9, 0.999), amsgrad=True)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 1.1264, 'grad_norm': 5.214650630950928, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  3.14it/s]                                              {'loss': 1.6258, 'grad_norm': 7.657097816467285, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.14it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 1.2904, 'grad_norm': 10.288933753967285, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 0.9005, 'grad_norm': 11.433237075805664, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 0.7152, 'grad_norm': 11.418397903442383, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.1994, 'grad_norm': 20.437475204467773, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.1891, 'grad_norm': 20.77912712097168, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.1, 'grad_norm': 6.647603988647461, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s]                                              {'loss': 0.8035, 'grad_norm': 7.735705375671387, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.60it/s]                                               {'loss': 0.3701, 'grad_norm': 5.140635967254639, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.60it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.47it/s]                                               {'loss': 0.3074, 'grad_norm': 7.365762710571289, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.47it/s] 30%|███       | 12/40 [00:03<00:08,  3.34it/s]                                               {'loss': 0.3381, 'grad_norm': 6.497717380523682, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.34it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s]                                               {'loss': 0.4157, 'grad_norm': 7.66475248336792, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.3882, 'grad_norm': 12.149843215942383, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.6475, 'grad_norm': 10.75087833404541, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.1369, 'grad_norm': 7.841805934906006, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.0208, 'grad_norm': 0.48174265027046204, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.172, 'grad_norm': 1.8835477828979492, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.0588, 'grad_norm': 1.4750301837921143, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.2183, 'grad_norm': 10.097589492797852, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.1193, 'grad_norm': 2.629504442214966, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.7515, 'grad_norm': 7.0787129402160645, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.256, 'grad_norm': 4.185891628265381, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.0055, 'grad_norm': 0.2556079626083374, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.0354, 'grad_norm': 0.7962982058525085, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.4881, 'grad_norm': 1.8873357772827148, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s]                                               {'loss': 0.0233, 'grad_norm': 0.5724343657493591, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.0331, 'grad_norm': 0.872848629951477, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.0189, 'grad_norm': 0.5928586721420288, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.1488, 'grad_norm': 1.5916314125061035, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0603, 'grad_norm': 2.307620048522949, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0759, 'grad_norm': 5.032183647155762, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0184, 'grad_norm': 0.48307478427886963, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0231, 'grad_norm': 0.8473237156867981, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0203, 'grad_norm': 0.6055018305778503, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.4392, 'grad_norm': 1.531491994857788, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.114, 'grad_norm': 0.7143669724464417, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0907, 'grad_norm': 5.233161926269531, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0314, 'grad_norm': 1.5078386068344116, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0024, 'grad_norm': 0.15825708210468292, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.0934, 'train_samples_per_second': 46.72, 'train_steps_per_second': 3.308, 'train_loss': 0.41949109415872954, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:54
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr, weight_decay=0.02, betas=(0.9, 0.999), amsgrad=True)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.00it/s]                                              {'loss': 2.4473, 'grad_norm': 9.019901275634766, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.7132, 'grad_norm': 10.902502059936523, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.7103, 'grad_norm': 17.114225387573242, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.2521, 'grad_norm': 10.035896301269531, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 0.8889, 'grad_norm': 8.429206848144531, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.8217, 'grad_norm': 12.76994800567627, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 1.8907, 'grad_norm': 10.160907745361328, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 5.3554, 'grad_norm': 53.250946044921875, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 1.0913, 'grad_norm': 6.936172962188721, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s]                                               {'loss': 0.9171, 'grad_norm': 7.120539665222168, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s]                                               {'loss': 0.9873, 'grad_norm': 5.979856967926025, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s] 30%|███       | 12/40 [00:03<00:08,  3.21it/s]                                               {'loss': 0.5084, 'grad_norm': 8.68705940246582, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.21it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.373, 'grad_norm': 6.602847576141357, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.2887, 'grad_norm': 4.610509395599365, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.3666, 'grad_norm': 6.237476348876953, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.335, 'grad_norm': 16.142927169799805, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.73it/s]                                               {'loss': 0.4333, 'grad_norm': 6.431192874908447, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.73it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.48it/s]                                               {'loss': 0.0466, 'grad_norm': 0.8845062255859375, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.48it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.33it/s]                                               {'loss': 0.1741, 'grad_norm': 3.426614284515381, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.33it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.978, 'grad_norm': 7.375214099884033, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.1857, 'grad_norm': 7.114718437194824, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.2073, 'grad_norm': 4.950658798217773, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.1718, 'grad_norm': 4.196119785308838, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0256, 'grad_norm': 1.4087295532226562, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s]                                               {'loss': 0.4097, 'grad_norm': 2.876143217086792, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.1066, 'grad_norm': 3.43550443649292, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.1103, 'grad_norm': 2.4202401638031006, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.1047, 'grad_norm': 2.1967008113861084, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.1002, 'grad_norm': 1.7876182794570923, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.2076, 'grad_norm': 7.017536163330078, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.4133, 'grad_norm': 3.441450834274292, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0039, 'grad_norm': 0.24008610844612122, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s]                                               {'loss': 0.0368, 'grad_norm': 0.8005029559135437, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s]                                               {'loss': 0.0236, 'grad_norm': 0.786086916923523, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.2885, 'grad_norm': 1.063391923904419, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.1188, 'grad_norm': 3.751002788543701, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0436, 'grad_norm': 1.3429620265960693, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.2428, 'grad_norm': 0.5774818062782288, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0291, 'grad_norm': 1.1242221593856812, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0032, 'grad_norm': 0.2568868398666382, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.2194, 'train_samples_per_second': 46.238, 'train_steps_per_second': 3.273, 'train_loss': 0.6603011674364098, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.27it/s]
CLIENT:75
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr, weight_decay=0.02, betas=(0.9, 0.999), amsgrad=True)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 2.5063, 'grad_norm': 7.664498805999756, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.3004, 'grad_norm': 8.396242141723633, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.1498, 'grad_norm': 11.834936141967773, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.1877, 'grad_norm': 12.509940147399902, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.934, 'grad_norm': 20.162500381469727, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.7842, 'grad_norm': 16.201847076416016, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 1.4272, 'grad_norm': 10.795921325683594, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.0282, 'grad_norm': 2.6954500675201416, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 0.7779, 'grad_norm': 11.970305442810059, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 0.0945, 'grad_norm': 4.629003524780273, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.8436, 'grad_norm': 9.126675605773926, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 1.0815, 'grad_norm': 5.820807933807373, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.24it/s]                                               {'loss': 0.4921, 'grad_norm': 5.721439361572266, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.24it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.5122, 'grad_norm': 5.441160202026367, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 0.4552, 'grad_norm': 5.447956085205078, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 0.0108, 'grad_norm': 0.6447545886039734, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.13it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 0.1345, 'grad_norm': 2.5809645652770996, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.3183, 'grad_norm': 6.3277587890625, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.0694, 'grad_norm': 1.9662400484085083, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.485, 'grad_norm': 3.5186591148376465, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.25it/s]                                               {'loss': 0.4021, 'grad_norm': 4.195730686187744, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.25it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.1586, 'grad_norm': 3.7132692337036133, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.1773, 'grad_norm': 4.7530951499938965, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]                                               {'loss': 0.5522, 'grad_norm': 20.434057235717773, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.13it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.93it/s]                                               {'loss': 0.2936, 'grad_norm': 1.3114819526672363, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.93it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.66it/s]                                               {'loss': 0.1185, 'grad_norm': 2.710385799407959, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.66it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.47it/s]                                               {'loss': 0.0862, 'grad_norm': 3.063624858856201, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.47it/s] 70%|███████   | 28/40 [00:08<00:03,  3.34it/s]                                               {'loss': 0.2327, 'grad_norm': 5.05188512802124, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.34it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.3983, 'grad_norm': 2.51289439201355, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.26it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.18it/s]                                               {'loss': 0.0471, 'grad_norm': 1.5512992143630981, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.18it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.1507, 'grad_norm': 8.106217384338379, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.0464, 'grad_norm': 2.700519561767578, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.14it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.073, 'grad_norm': 1.6712011098861694, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s]                                               {'loss': 0.3674, 'grad_norm': 4.325752258300781, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.0213, 'grad_norm': 0.45443445444107056, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0721, 'grad_norm': 3.2765562534332275, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s]                                               {'loss': 0.3627, 'grad_norm': 1.6364787817001343, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0203, 'grad_norm': 0.38819319009780884, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0455, 'grad_norm': 1.112792730331421, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0082, 'grad_norm': 0.5541993975639343, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.0802, 'train_samples_per_second': 46.771, 'train_steps_per_second': 3.311, 'train_loss': 0.5056755129713565, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:28
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  lr = self.args.lr
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.19it/s]                                              {'loss': 2.2049, 'grad_norm': 8.484234809875488, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.19it/s]  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.2148, 'grad_norm': 14.161577224731445, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.493, 'grad_norm': 18.016695022583008, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.992, 'grad_norm': 16.305044174194336, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.966, 'grad_norm': 19.159589767456055, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.6914, 'grad_norm': 24.04226303100586, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.0909, 'grad_norm': 11.681266784667969, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.8565, 'grad_norm': 5.831315517425537, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s]                                              {'loss': 1.3874, 'grad_norm': 16.714717864990234, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.45it/s]                                               {'loss': 1.5515, 'grad_norm': 20.169431686401367, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.45it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.8397, 'grad_norm': 13.264945030212402, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.30it/s] 30%|███       | 12/40 [00:03<00:08,  3.20it/s]                                               {'loss': 0.6977, 'grad_norm': 14.543774604797363, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.20it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.6057, 'grad_norm': 9.154376983642578, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.13it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.9311, 'grad_norm': 8.640583992004395, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.3605, 'grad_norm': 4.974147319793701, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.7253, 'grad_norm': 35.460025787353516, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 0.4613, 'grad_norm': 5.345141410827637, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.496, 'grad_norm': 6.447941780090332, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.9323, 'grad_norm': 12.312045097351074, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.552, 'grad_norm': 7.855426788330078, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.6171, 'grad_norm': 10.223011016845703, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.1321, 'grad_norm': 2.8592116832733154, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.41, 'grad_norm': 5.569290637969971, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.1955, 'grad_norm': 13.179573059082031, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s]                                               {'loss': 0.2807, 'grad_norm': 4.21781587600708, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.0862, 'grad_norm': 2.5715560913085938, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s]                                               {'loss': 0.3562, 'grad_norm': 6.4602532386779785, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s] 70%|███████   | 28/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.1609, 'grad_norm': 3.162261962890625, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.23it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.2482, 'grad_norm': 4.4783525466918945, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.0965, 'grad_norm': 2.4512665271759033, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.2182, 'grad_norm': 4.199769973754883, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0321, 'grad_norm': 1.9373838901519775, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.2727, 'grad_norm': 6.121866226196289, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.0739, 'grad_norm': 1.3222787380218506, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.0952, 'grad_norm': 3.4651050567626953, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.262, 'grad_norm': 2.5021719932556152, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.1698, 'grad_norm': 4.141739845275879, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.056, 'grad_norm': 1.838738203048706, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.1178, 'grad_norm': 9.838661193847656, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0245, 'grad_norm': 1.5127134323120117, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.2021, 'train_samples_per_second': 46.303, 'train_steps_per_second': 3.278, 'train_loss': 0.7488856896758079, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:40
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  lr = self.args.lr
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.90it/s]                                              {'loss': 2.3298, 'grad_norm': 9.93378734588623, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.90it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 2.2118, 'grad_norm': 10.401290893554688, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  3.00it/s]                                              {'loss': 2.3901, 'grad_norm': 16.936071395874023, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  3.00it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.1983, 'grad_norm': 18.969505310058594, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.3043, 'grad_norm': 12.448305130004883, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.511, 'grad_norm': 18.11744499206543, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.8995, 'grad_norm': 17.446470260620117, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 4.6697, 'grad_norm': 42.80439376831055, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 0.7537, 'grad_norm': 6.2555766105651855, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 1.1199, 'grad_norm': 7.488612174987793, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.0103, 'grad_norm': 10.159039497375488, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 1.1414, 'grad_norm': 37.40895080566406, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 1.2898, 'grad_norm': 13.199014663696289, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.5074, 'grad_norm': 7.3705220222473145, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.609, 'grad_norm': 6.9129462242126465, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.0542, 'grad_norm': 2.7540388107299805, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s]                                               {'loss': 0.4439, 'grad_norm': 6.1428422927856445, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.3629, 'grad_norm': 6.644097328186035, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.33it/s]                                               {'loss': 0.5399, 'grad_norm': 8.820279121398926, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.33it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.4688, 'grad_norm': 5.06664514541626, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s]                                               {'loss': 0.3913, 'grad_norm': 12.964314460754395, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.3653, 'grad_norm': 5.82135534286499, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 1.1721, 'grad_norm': 31.18669891357422, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.3542, 'grad_norm': 54.291534423828125, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.0972, 'grad_norm': 2.5621557235717773, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s]                                               {'loss': 1.0399, 'grad_norm': 8.849465370178223, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s]                                               {'loss': 0.8546, 'grad_norm': 12.2510986328125, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s] 70%|███████   | 28/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.2889, 'grad_norm': 13.484241485595703, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.24it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.5454, 'grad_norm': 9.13481330871582, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.1906, 'grad_norm': 7.857203006744385, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.5036, 'grad_norm': 7.729038238525391, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0081, 'grad_norm': 0.8498147130012512, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s]                                               {'loss': 0.1912, 'grad_norm': 3.4640519618988037, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s]                                               {'loss': 0.3862, 'grad_norm': 3.1208677291870117, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.51it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.8174, 'grad_norm': 4.997778415679932, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s]                                               {'loss': 0.1511, 'grad_norm': 3.709498882293701, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.2365, 'grad_norm': 4.456770420074463, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.11it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.336, 'grad_norm': 3.9695520401000977, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.1033, 'grad_norm': 2.502427101135254, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.0799, 'grad_norm': 5.327920436859131, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]                                               {'train_runtime': 12.3516, 'train_samples_per_second': 45.743, 'train_steps_per_second': 3.238, 'train_loss': 0.8982207337860018, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]100%|██████████| 40/40 [00:12<00:00,  3.24it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer.train()
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:42, 11.08it/s]  1%|          | 4/471 [00:00<01:07,  6.91it/s]  1%|          | 5/471 [00:00<01:12,  6.39it/s]  1%|▏         | 6/471 [00:00<01:17,  6.02it/s]  1%|▏         | 7/471 [00:01<01:19,  5.83it/s]  2%|▏         | 8/471 [00:01<01:21,  5.71it/s]  2%|▏         | 9/471 [00:01<01:22,  5.63it/s]  2%|▏         | 10/471 [00:01<01:22,  5.59it/s]  2%|▏         | 11/471 [00:01<01:23,  5.52it/s]  3%|▎         | 12/471 [00:02<01:23,  5.48it/s]  3%|▎         | 13/471 [00:02<01:24,  5.44it/s]  3%|▎         | 14/471 [00:02<01:24,  5.44it/s]  3%|▎         | 15/471 [00:02<01:23,  5.45it/s]  3%|▎         | 16/471 [00:02<01:23,  5.44it/s]  4%|▎         | 17/471 [00:02<01:23,  5.43it/s]  4%|▍         | 18/471 [00:03<01:23,  5.42it/s]  4%|▍         | 19/471 [00:03<01:23,  5.41it/s]  4%|▍         | 20/471 [00:03<01:23,  5.41it/s]  4%|▍         | 21/471 [00:03<01:23,  5.41it/s]  5%|▍         | 22/471 [00:03<01:22,  5.41it/s]  5%|▍         | 23/471 [00:04<01:22,  5.40it/s]  5%|▌         | 24/471 [00:04<01:22,  5.40it/s]  5%|▌         | 25/471 [00:04<01:22,  5.40it/s]  6%|▌         | 26/471 [00:04<01:22,  5.41it/s]  6%|▌         | 27/471 [00:04<01:22,  5.40it/s]  6%|▌         | 28/471 [00:04<01:21,  5.41it/s]  6%|▌         | 29/471 [00:05<01:21,  5.39it/s]  6%|▋         | 30/471 [00:05<01:21,  5.38it/s]  7%|▋         | 31/471 [00:05<01:21,  5.39it/s]  7%|▋         | 32/471 [00:05<01:21,  5.40it/s]  7%|▋         | 33/471 [00:05<01:20,  5.43it/s]  7%|▋         | 34/471 [00:06<01:20,  5.44it/s]  7%|▋         | 35/471 [00:06<01:20,  5.41it/s]  8%|▊         | 36/471 [00:06<01:20,  5.42it/s]  8%|▊         | 37/471 [00:06<01:20,  5.40it/s]  8%|▊         | 38/471 [00:06<01:20,  5.39it/s]  8%|▊         | 39/471 [00:07<01:20,  5.40it/s]  8%|▊         | 40/471 [00:07<01:19,  5.40it/s]  9%|▊         | 41/471 [00:07<01:19,  5.39it/s]  9%|▉         | 42/471 [00:07<01:19,  5.38it/s]  9%|▉         | 43/471 [00:07<01:19,  5.40it/s]  9%|▉         | 44/471 [00:07<01:19,  5.39it/s] 10%|▉         | 45/471 [00:08<01:18,  5.41it/s] 10%|▉         | 46/471 [00:08<01:18,  5.39it/s] 10%|▉         | 47/471 [00:08<01:18,  5.41it/s] 10%|█         | 48/471 [00:08<01:18,  5.41it/s] 10%|█         | 49/471 [00:08<01:18,  5.40it/s] 11%|█         | 50/471 [00:09<01:18,  5.39it/s] 11%|█         | 51/471 [00:09<01:17,  5.39it/s] 11%|█         | 52/471 [00:09<01:17,  5.39it/s] 11%|█▏        | 53/471 [00:09<01:17,  5.40it/s] 11%|█▏        | 54/471 [00:09<01:17,  5.38it/s] 12%|█▏        | 55/471 [00:09<01:17,  5.37it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.36it/s] 12%|█▏        | 57/471 [00:10<01:16,  5.38it/s] 12%|█▏        | 58/471 [00:10<01:16,  5.39it/s] 13%|█▎        | 59/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 60/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.38it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.37it/s] 13%|█▎        | 63/471 [00:11<01:15,  5.37it/s] 14%|█▎        | 64/471 [00:11<01:15,  5.37it/s] 14%|█▍        | 65/471 [00:11<01:15,  5.36it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.35it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.36it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.37it/s] 15%|█▍        | 69/471 [00:12<01:15,  5.36it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.35it/s] 15%|█▌        | 71/471 [00:12<01:14,  5.35it/s] 15%|█▌        | 72/471 [00:13<01:14,  5.34it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.36it/s] 16%|█▌        | 74/471 [00:13<01:13,  5.38it/s] 16%|█▌        | 75/471 [00:13<01:13,  5.36it/s] 16%|█▌        | 76/471 [00:13<01:13,  5.38it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.36it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.34it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 81/471 [00:14<01:12,  5.37it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.37it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.36it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.35it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.34it/s] 18%|█▊        | 86/471 [00:15<01:12,  5.34it/s] 18%|█▊        | 87/471 [00:15<01:11,  5.36it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.37it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.37it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.35it/s] 19%|█▉        | 91/471 [00:16<01:10,  5.36it/s] 20%|█▉        | 92/471 [00:16<01:10,  5.36it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.36it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.38it/s] 20%|██        | 95/471 [00:17<01:10,  5.37it/s] 20%|██        | 96/471 [00:17<01:09,  5.37it/s] 21%|██        | 97/471 [00:17<01:09,  5.35it/s] 21%|██        | 98/471 [00:18<01:09,  5.37it/s] 21%|██        | 99/471 [00:18<01:09,  5.37it/s] 21%|██        | 100/471 [00:18<01:08,  5.40it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.39it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.38it/s] 22%|██▏       | 103/471 [00:18<01:08,  5.36it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.35it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.34it/s] 23%|██▎       | 106/471 [00:19<01:07,  5.38it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.40it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.39it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.38it/s] 23%|██▎       | 110/471 [00:20<01:06,  5.40it/s] 24%|██▎       | 111/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 112/471 [00:20<01:06,  5.37it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.40it/s] 24%|██▍       | 114/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.37it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.36it/s] 25%|██▍       | 117/471 [00:21<01:05,  5.36it/s] 25%|██▌       | 118/471 [00:21<01:05,  5.36it/s] 25%|██▌       | 119/471 [00:21<01:05,  5.35it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.34it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.34it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.35it/s] 26%|██▌       | 123/471 [00:22<01:04,  5.36it/s] 26%|██▋       | 124/471 [00:22<01:04,  5.36it/s] 27%|██▋       | 125/471 [00:23<01:04,  5.34it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.34it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.34it/s] 27%|██▋       | 128/471 [00:23<01:03,  5.37it/s] 27%|██▋       | 129/471 [00:23<01:03,  5.37it/s] 28%|██▊       | 130/471 [00:23<01:03,  5.36it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.35it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.34it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.34it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.33it/s] 29%|██▊       | 135/471 [00:24<01:02,  5.35it/s] 29%|██▉       | 136/471 [00:25<01:02,  5.34it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.33it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.33it/s] 30%|██▉       | 139/471 [00:25<01:01,  5.36it/s] 30%|██▉       | 140/471 [00:25<01:01,  5.35it/s] 30%|██▉       | 141/471 [00:26<01:01,  5.37it/s] 30%|███       | 142/471 [00:26<01:01,  5.37it/s] 30%|███       | 143/471 [00:26<01:01,  5.35it/s] 31%|███       | 144/471 [00:26<01:01,  5.35it/s] 31%|███       | 145/471 [00:26<01:00,  5.37it/s] 31%|███       | 146/471 [00:26<01:00,  5.36it/s] 31%|███       | 147/471 [00:27<01:00,  5.35it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.35it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.32it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.32it/s] 32%|███▏      | 151/471 [00:27<01:00,  5.32it/s] 32%|███▏      | 152/471 [00:28<00:59,  5.33it/s] 32%|███▏      | 153/471 [00:28<00:59,  5.32it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.35it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.34it/s] 33%|███▎      | 156/471 [00:28<00:58,  5.36it/s] 33%|███▎      | 157/471 [00:29<00:58,  5.35it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.36it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.37it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.34it/s] 34%|███▍      | 161/471 [00:29<00:58,  5.33it/s] 34%|███▍      | 162/471 [00:29<00:58,  5.32it/s] 35%|███▍      | 163/471 [00:30<00:57,  5.31it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.34it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.33it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.31it/s] 35%|███▌      | 167/471 [00:30<00:57,  5.31it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.31it/s] 36%|███▌      | 169/471 [00:31<00:56,  5.31it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.32it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.31it/s] 37%|███▋      | 172/471 [00:31<00:56,  5.32it/s] 37%|███▋      | 173/471 [00:32<00:55,  5.32it/s] 37%|███▋      | 174/471 [00:32<00:55,  5.33it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.33it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.33it/s] 38%|███▊      | 177/471 [00:32<00:55,  5.32it/s] 38%|███▊      | 178/471 [00:32<00:55,  5.32it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.34it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.34it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.32it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.32it/s] 39%|███▉      | 183/471 [00:33<00:54,  5.32it/s] 39%|███▉      | 184/471 [00:34<00:53,  5.33it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.33it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.31it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.31it/s] 40%|███▉      | 188/471 [00:34<00:53,  5.30it/s] 40%|████      | 189/471 [00:35<00:53,  5.32it/s] 40%|████      | 190/471 [00:35<00:52,  5.32it/s] 41%|████      | 191/471 [00:35<00:52,  5.31it/s] 41%|████      | 192/471 [00:35<00:52,  5.32it/s] 41%|████      | 193/471 [00:35<00:51,  5.35it/s] 41%|████      | 194/471 [00:35<00:51,  5.34it/s] 41%|████▏     | 195/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.36it/s] 42%|████▏     | 198/471 [00:36<00:50,  5.36it/s] 42%|████▏     | 199/471 [00:36<00:50,  5.35it/s] 42%|████▏     | 200/471 [00:37<00:50,  5.33it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.36it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.34it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.33it/s] 43%|████▎     | 204/471 [00:37<00:50,  5.33it/s] 44%|████▎     | 205/471 [00:38<00:49,  5.34it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.34it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.32it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.36it/s] 44%|████▍     | 209/471 [00:38<00:48,  5.36it/s] 45%|████▍     | 210/471 [00:38<00:48,  5.37it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.35it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.34it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.33it/s] 45%|████▌     | 214/471 [00:39<00:47,  5.36it/s] 46%|████▌     | 215/471 [00:39<00:47,  5.35it/s] 46%|████▌     | 216/471 [00:40<00:47,  5.34it/s] 46%|████▌     | 217/471 [00:40<00:47,  5.33it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.32it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.33it/s] 47%|████▋     | 220/471 [00:40<00:47,  5.33it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.31it/s] 47%|████▋     | 222/471 [00:41<00:46,  5.33it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.36it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.33it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.33it/s] 48%|████▊     | 226/471 [00:41<00:46,  5.32it/s] 48%|████▊     | 227/471 [00:42<00:45,  5.32it/s] 48%|████▊     | 228/471 [00:42<00:45,  5.34it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.32it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.31it/s] 49%|████▉     | 231/471 [00:42<00:45,  5.31it/s] 49%|████▉     | 232/471 [00:43<00:44,  5.34it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.35it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.33it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.32it/s] 50%|█████     | 236/471 [00:43<00:44,  5.34it/s] 50%|█████     | 237/471 [00:44<00:43,  5.33it/s] 51%|█████     | 238/471 [00:44<00:43,  5.34it/s] 51%|█████     | 239/471 [00:44<00:43,  5.35it/s] 51%|█████     | 240/471 [00:44<00:43,  5.34it/s] 51%|█████     | 241/471 [00:44<00:43,  5.32it/s] 51%|█████▏    | 242/471 [00:44<00:43,  5.32it/s] 52%|█████▏    | 243/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.33it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.34it/s] 52%|█████▏    | 247/471 [00:45<00:41,  5.34it/s] 53%|█████▎    | 248/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 249/471 [00:46<00:41,  5.32it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.33it/s] 54%|█████▎    | 252/471 [00:46<00:41,  5.32it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.30it/s] 54%|█████▍    | 254/471 [00:47<00:40,  5.31it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.32it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.31it/s] 55%|█████▍    | 257/471 [00:47<00:40,  5.30it/s] 55%|█████▍    | 258/471 [00:47<00:40,  5.30it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.29it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.30it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.30it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.34it/s] 56%|█████▌    | 263/471 [00:48<00:39,  5.32it/s] 56%|█████▌    | 264/471 [00:49<00:38,  5.31it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.31it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.30it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.32it/s] 57%|█████▋    | 268/471 [00:49<00:38,  5.31it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.31it/s] 57%|█████▋    | 270/471 [00:50<00:37,  5.31it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.31it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.33it/s] 58%|█████▊    | 273/471 [00:50<00:37,  5.33it/s] 58%|█████▊    | 274/471 [00:50<00:36,  5.34it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.34it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.32it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 278/471 [00:51<00:36,  5.32it/s] 59%|█████▉    | 279/471 [00:51<00:36,  5.32it/s] 59%|█████▉    | 280/471 [00:52<00:35,  5.32it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.30it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.31it/s] 60%|██████    | 283/471 [00:52<00:35,  5.32it/s] 60%|██████    | 284/471 [00:52<00:35,  5.31it/s] 61%|██████    | 285/471 [00:53<00:35,  5.31it/s] 61%|██████    | 286/471 [00:53<00:34,  5.29it/s] 61%|██████    | 287/471 [00:53<00:34,  5.30it/s] 61%|██████    | 288/471 [00:53<00:34,  5.30it/s] 61%|██████▏   | 289/471 [00:53<00:34,  5.33it/s] 62%|██████▏   | 290/471 [00:53<00:33,  5.33it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.31it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.32it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.33it/s] 62%|██████▏   | 294/471 [00:54<00:33,  5.34it/s] 63%|██████▎   | 295/471 [00:54<00:32,  5.34it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.35it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.32it/s] 63%|██████▎   | 299/471 [00:55<00:32,  5.33it/s] 64%|██████▎   | 300/471 [00:55<00:32,  5.32it/s] 64%|██████▍   | 301/471 [00:56<00:31,  5.32it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.33it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.33it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.33it/s] 65%|██████▍   | 305/471 [00:56<00:31,  5.32it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.31it/s] 65%|██████▌   | 307/471 [00:57<00:30,  5.32it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.31it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.30it/s] 66%|██████▌   | 310/471 [00:57<00:30,  5.30it/s] 66%|██████▌   | 311/471 [00:57<00:30,  5.30it/s] 66%|██████▌   | 312/471 [00:58<00:29,  5.32it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.33it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.33it/s] 67%|██████▋   | 315/471 [00:58<00:29,  5.32it/s] 67%|██████▋   | 316/471 [00:58<00:29,  5.32it/s] 67%|██████▋   | 317/471 [00:59<00:28,  5.33it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 320/471 [00:59<00:28,  5.31it/s] 68%|██████▊   | 321/471 [00:59<00:28,  5.30it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.30it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.28it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.28it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.30it/s] 69%|██████▉   | 326/471 [01:00<00:27,  5.31it/s] 69%|██████▉   | 327/471 [01:00<00:27,  5.32it/s] 70%|██████▉   | 328/471 [01:01<00:26,  5.30it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.30it/s] 70%|███████   | 330/471 [01:01<00:26,  5.32it/s] 70%|███████   | 331/471 [01:01<00:26,  5.33it/s] 70%|███████   | 332/471 [01:01<00:26,  5.32it/s] 71%|███████   | 333/471 [01:02<00:25,  5.31it/s] 71%|███████   | 334/471 [01:02<00:25,  5.31it/s] 71%|███████   | 335/471 [01:02<00:25,  5.30it/s] 71%|███████▏  | 336/471 [01:02<00:25,  5.32it/s] 72%|███████▏  | 337/471 [01:02<00:25,  5.35it/s] 72%|███████▏  | 338/471 [01:03<00:24,  5.33it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.31it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.30it/s] 72%|███████▏  | 341/471 [01:03<00:24,  5.32it/s] 73%|███████▎  | 342/471 [01:03<00:24,  5.34it/s] 73%|███████▎  | 343/471 [01:03<00:24,  5.32it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.32it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.31it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.31it/s] 74%|███████▎  | 347/471 [01:04<00:23,  5.33it/s] 74%|███████▍  | 348/471 [01:04<00:23,  5.32it/s] 74%|███████▍  | 349/471 [01:05<00:22,  5.31it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.30it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.32it/s] 75%|███████▍  | 352/471 [01:05<00:22,  5.32it/s] 75%|███████▍  | 353/471 [01:05<00:22,  5.31it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.31it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.30it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 357/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 358/471 [01:06<00:21,  5.31it/s] 76%|███████▌  | 359/471 [01:06<00:21,  5.30it/s] 76%|███████▋  | 360/471 [01:07<00:20,  5.31it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 362/471 [01:07<00:20,  5.31it/s] 77%|███████▋  | 363/471 [01:07<00:20,  5.31it/s] 77%|███████▋  | 364/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 365/471 [01:08<00:19,  5.31it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.30it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.30it/s] 78%|███████▊  | 368/471 [01:08<00:19,  5.30it/s] 78%|███████▊  | 369/471 [01:08<00:19,  5.31it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.30it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 373/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 374/471 [01:09<00:18,  5.31it/s] 80%|███████▉  | 375/471 [01:09<00:18,  5.32it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.30it/s] 80%|████████  | 377/471 [01:10<00:17,  5.31it/s] 80%|████████  | 378/471 [01:10<00:17,  5.33it/s] 80%|████████  | 379/471 [01:10<00:17,  5.32it/s] 81%|████████  | 380/471 [01:10<00:17,  5.31it/s] 81%|████████  | 381/471 [01:11<00:16,  5.31it/s] 81%|████████  | 382/471 [01:11<00:16,  5.30it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.29it/s] 82%|████████▏ | 384/471 [01:11<00:16,  5.29it/s] 82%|████████▏ | 385/471 [01:11<00:16,  5.29it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.29it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.28it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.28it/s] 83%|████████▎ | 389/471 [01:12<00:15,  5.30it/s] 83%|████████▎ | 390/471 [01:12<00:15,  5.31it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.31it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.30it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.31it/s] 84%|████████▎ | 394/471 [01:13<00:14,  5.29it/s] 84%|████████▍ | 395/471 [01:13<00:14,  5.30it/s] 84%|████████▍ | 396/471 [01:13<00:14,  5.30it/s] 84%|████████▍ | 397/471 [01:14<00:13,  5.30it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.30it/s] 85%|████████▍ | 399/471 [01:14<00:13,  5.29it/s] 85%|████████▍ | 400/471 [01:14<00:13,  5.28it/s] 85%|████████▌ | 401/471 [01:14<00:13,  5.30it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.29it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.30it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.30it/s] 86%|████████▌ | 405/471 [01:15<00:12,  5.29it/s] 86%|████████▌ | 406/471 [01:15<00:12,  5.31it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.32it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.30it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.30it/s] 87%|████████▋ | 410/471 [01:16<00:11,  5.30it/s] 87%|████████▋ | 411/471 [01:16<00:11,  5.32it/s] 87%|████████▋ | 412/471 [01:16<00:11,  5.31it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.31it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.30it/s] 88%|████████▊ | 415/471 [01:17<00:10,  5.30it/s] 88%|████████▊ | 416/471 [01:17<00:10,  5.28it/s] 89%|████████▊ | 417/471 [01:17<00:10,  5.30it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.30it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.30it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.33it/s] 89%|████████▉ | 421/471 [01:18<00:09,  5.32it/s] 90%|████████▉ | 422/471 [01:18<00:09,  5.31it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.32it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.31it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.33it/s] 90%|█████████ | 426/471 [01:19<00:08,  5.32it/s] 91%|█████████ | 427/471 [01:19<00:08,  5.31it/s] 91%|█████████ | 428/471 [01:19<00:08,  5.30it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.30it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.30it/s] 92%|█████████▏| 431/471 [01:20<00:07,  5.28it/s] 92%|█████████▏| 432/471 [01:20<00:07,  5.28it/s] 92%|█████████▏| 433/471 [01:20<00:07,  5.28it/s] 92%|█████████▏| 434/471 [01:21<00:06,  5.30it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.30it/s] 93%|█████████▎| 436/471 [01:21<00:06,  5.31it/s] 93%|█████████▎| 437/471 [01:21<00:06,  5.29it/s] 93%|█████████▎| 438/471 [01:21<00:06,  5.29it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.30it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.31it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.32it/s] 94%|█████████▍| 442/471 [01:22<00:05,  5.34it/s] 94%|█████████▍| 443/471 [01:22<00:05,  5.30it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.29it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.29it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.29it/s] 95%|█████████▍| 447/471 [01:23<00:04,  5.30it/s] 95%|█████████▌| 448/471 [01:23<00:04,  5.32it/s] 95%|█████████▌| 449/471 [01:23<00:04,  5.30it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.29it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.30it/s] 96%|█████████▌| 452/471 [01:24<00:03,  5.31it/s] 96%|█████████▌| 453/471 [01:24<00:03,  5.30it/s] 96%|█████████▋| 454/471 [01:24<00:03,  5.28it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.28it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.28it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.28it/s] 97%|█████████▋| 458/471 [01:25<00:02,  5.30it/s] 97%|█████████▋| 459/471 [01:25<00:02,  5.33it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.32it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.29it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.29it/s] 98%|█████████▊| 463/471 [01:26<00:01,  5.29it/s] 99%|█████████▊| 464/471 [01:26<00:01,  5.31it/s] 99%|█████████▊| 465/471 [01:26<00:01,  5.33it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.30it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.29it/s] 99%|█████████▉| 468/471 [01:27<00:00,  5.28it/s]100%|█████████▉| 469/471 [01:27<00:00,  5.29it/s]100%|█████████▉| 470/471 [01:27<00:00,  5.30it/s]100%|██████████| 471/471 [01:28<00:00,  5.66it/s]100%|██████████| 471/471 [01:28<00:00,  5.35it/s]
{'eval_loss': 2.151637077331543, 'eval_model_preparation_time': 0.0058, 'eval_acc': 0.42379182156133827, 'eval_runtime': 88.2342, 'eval_samples_per_second': 85.364, 'eval_steps_per_second': 5.338}
ROUND:15
CLIENT:2
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 2.1879, 'grad_norm': 8.98421859741211, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]                                              {'loss': 2.226, 'grad_norm': 11.539765357971191, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]  8%|▊         | 3/40 [00:00<00:12,  2.99it/s]                                              {'loss': 1.0727, 'grad_norm': 11.173707962036133, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  2.99it/s] 10%|█         | 4/40 [00:01<00:12,  2.98it/s]                                              {'loss': 2.0814, 'grad_norm': 16.632461547851562, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.98it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.96it/s]                                              {'loss': 2.1407, 'grad_norm': 20.24153709411621, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.96it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s]                                              {'loss': 1.8957, 'grad_norm': 17.223447799682617, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 1.3679, 'grad_norm': 19.472299575805664, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 0.0105, 'grad_norm': 0.8286052346229553, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.95it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.70it/s]                                              {'loss': 0.5337, 'grad_norm': 6.365560054779053, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.70it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s]                                               {'loss': 0.8646, 'grad_norm': 21.12701988220215, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s]                                               {'loss': 0.5707, 'grad_norm': 8.504377365112305, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s] 30%|███       | 12/40 [00:03<00:08,  3.22it/s]                                               {'loss': 0.9411, 'grad_norm': 10.10799503326416, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.22it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.4549, 'grad_norm': 10.322649955749512, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.7488, 'grad_norm': 16.059900283813477, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.5999, 'grad_norm': 5.861647129058838, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.0251, 'grad_norm': 2.2742831707000732, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.1045, 'grad_norm': 2.2404861450195312, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.2641, 'grad_norm': 4.53293514251709, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s]                                               {'loss': 0.0711, 'grad_norm': 1.6786574125289917, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s] 50%|█████     | 20/40 [00:06<00:06,  3.23it/s]                                               {'loss': 0.2189, 'grad_norm': 5.484515190124512, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.23it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s]                                               {'loss': 0.496, 'grad_norm': 7.303067207336426, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.4393, 'grad_norm': 10.99710464477539, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.2002, 'grad_norm': 8.56452751159668, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.3547, 'grad_norm': 31.85334014892578, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s]                                               {'loss': 0.2536, 'grad_norm': 8.192476272583008, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.0642, 'grad_norm': 2.625316619873047, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s]                                               {'loss': 0.0678, 'grad_norm': 1.7569329738616943, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s] 70%|███████   | 28/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.1279, 'grad_norm': 3.5978360176086426, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.23it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.0738, 'grad_norm': 1.8155102729797363, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.2458, 'grad_norm': 5.961149215698242, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.1026, 'grad_norm': 3.1749744415283203, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0566, 'grad_norm': 5.918528079986572, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s]                                               {'loss': 0.1353, 'grad_norm': 6.148392200469971, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0829, 'grad_norm': 5.327334880828857, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.0308, 'grad_norm': 1.1099706888198853, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s]                                               {'loss': 0.1313, 'grad_norm': 3.721957206726074, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0565, 'grad_norm': 2.4439992904663086, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0807, 'grad_norm': 2.422830581665039, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.05it/s]                                               {'loss': 0.1348, 'grad_norm': 6.467490196228027, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.05it/s]                                               {'loss': 0.1469, 'grad_norm': 13.929533958435059, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]                                               {'train_runtime': 12.2971, 'train_samples_per_second': 45.946, 'train_steps_per_second': 3.253, 'train_loss': 0.5415501695126295, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
CLIENT:49
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.4363, 'grad_norm': 7.2285990715026855, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.1676, 'grad_norm': 10.175408363342285, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.2314, 'grad_norm': 9.853893280029297, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.0336, 'grad_norm': 11.01598834991455, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.3204, 'grad_norm': 15.014126777648926, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  2.98it/s]                                              {'loss': 2.734, 'grad_norm': 24.333749771118164, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  2.98it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 1.6423, 'grad_norm': 19.499990463256836, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s] 20%|██        | 8/40 [00:02<00:08,  3.78it/s]                                              {'loss': 1.3552, 'grad_norm': 63.86606216430664, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:08,  3.78it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.57it/s]                                              {'loss': 0.7304, 'grad_norm': 12.902771949768066, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.57it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.36it/s]                                               {'loss': 1.2128, 'grad_norm': 18.021785736083984, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.36it/s] 28%|██▊       | 11/40 [00:03<00:09,  3.18it/s]                                               {'loss': 1.448, 'grad_norm': 10.818371772766113, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:09,  3.18it/s] 30%|███       | 12/40 [00:03<00:09,  3.10it/s]                                               {'loss': 0.7009, 'grad_norm': 7.816284656524658, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:09,  3.10it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.0929, 'grad_norm': 6.048938274383545, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.06it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.02it/s]                                               {'loss': 0.5261, 'grad_norm': 6.190898418426514, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.02it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.02it/s]                                               {'loss': 0.3895, 'grad_norm': 6.344544887542725, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.02it/s]                                               {'loss': 0.3975, 'grad_norm': 17.37685203552246, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.02it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.1619, 'grad_norm': 6.095493316650391, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.4644, 'grad_norm': 3.44558048248291, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.5762, 'grad_norm': 4.656008720397949, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.4935, 'grad_norm': 7.486574649810791, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.5216, 'grad_norm': 6.06764554977417, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.2415, 'grad_norm': 6.711431980133057, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.2358, 'grad_norm': 4.964902877807617, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.0675, 'grad_norm': 4.877766132354736, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.4609, 'grad_norm': 6.585366249084473, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s]                                               {'loss': 0.1013, 'grad_norm': 5.703538417816162, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.5824, 'grad_norm': 6.386155128479004, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.111, 'grad_norm': 6.803927421569824, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.3154, 'grad_norm': 1.427250862121582, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.0553, 'grad_norm': 1.5413262844085693, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0441, 'grad_norm': 1.361595869064331, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.001, 'grad_norm': 0.05165815353393555, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.055, 'grad_norm': 1.2211499214172363, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.3072, 'grad_norm': 0.6878360509872437, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.29, 'grad_norm': 11.93848991394043, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.3971, 'grad_norm': 14.674360275268555, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.3984, 'grad_norm': 6.344480991363525, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.1079, 'grad_norm': 3.466033697128296, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.4556, 'grad_norm': 5.132095813751221, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 2.6552, 'grad_norm': 130.3487548828125, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]                                               {'train_runtime': 12.26, 'train_samples_per_second': 46.085, 'train_steps_per_second': 3.263, 'train_loss': 0.7129825886106118, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
CLIENT:82
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.19it/s]                                              {'loss': 2.9442, 'grad_norm': 12.808520317077637, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.19it/s]  5%|▌         | 2/40 [00:00<00:12,  3.11it/s]                                              {'loss': 1.5846, 'grad_norm': 9.09339427947998, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.11it/s]  8%|▊         | 3/40 [00:00<00:11,  3.13it/s]                                              {'loss': 1.0038, 'grad_norm': 12.130393981933594, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.13it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.0619, 'grad_norm': 21.463356018066406, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.3584, 'grad_norm': 12.857556343078613, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.375, 'grad_norm': 21.406564712524414, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.6162, 'grad_norm': 20.89031219482422, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.013, 'grad_norm': 0.6770819425582886, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 0.8972, 'grad_norm': 33.30174255371094, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 0.6507, 'grad_norm': 7.989766597747803, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 0.5086, 'grad_norm': 4.921401023864746, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 0.6665, 'grad_norm': 17.549638748168945, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 1.0545, 'grad_norm': 16.341402053833008, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.9092, 'grad_norm': 16.080989837646484, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.601, 'grad_norm': 8.222822189331055, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 1.7929, 'grad_norm': 1.7850621938705444, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s]                                               {'loss': 0.2016, 'grad_norm': 3.9792439937591553, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.78it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.2872, 'grad_norm': 3.5692594051361084, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.1807, 'grad_norm': 4.194344997406006, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.4701, 'grad_norm': 4.500641822814941, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.4338, 'grad_norm': 3.1812589168548584, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.4699, 'grad_norm': 10.040196418762207, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.6021, 'grad_norm': 5.466836452484131, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.0149, 'grad_norm': 1.175736904144287, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.12it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s]                                               {'loss': 0.5111, 'grad_norm': 5.196487903594971, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s]                                               {'loss': 0.082, 'grad_norm': 3.033437728881836, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.0378, 'grad_norm': 1.1389223337173462, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.1787, 'grad_norm': 7.787256240844727, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.3795, 'grad_norm': 4.759166717529297, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.8362, 'grad_norm': 13.32455062866211, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.259, 'grad_norm': 6.37664794921875, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.102, 'grad_norm': 6.53403902053833, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.0375, 'grad_norm': 0.8219996094703674, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.0452, 'grad_norm': 1.217407464981079, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.1806, 'grad_norm': 2.593878746032715, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.2235, 'grad_norm': 6.090452194213867, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.4063, 'grad_norm': 3.1270854473114014, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.3542, 'grad_norm': 3.186572790145874, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.6004, 'grad_norm': 3.504957437515259, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0483, 'grad_norm': 3.3182191848754883, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0916, 'train_samples_per_second': 46.726, 'train_steps_per_second': 3.308, 'train_loss': 0.6745003803400322, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]                                              {'loss': 1.8809, 'grad_norm': 7.292102813720703, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 2.0004, 'grad_norm': 12.60915756225586, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.0715, 'grad_norm': 9.339258193969727, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.7047, 'grad_norm': 15.052265167236328, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 2.275, 'grad_norm': 20.775997161865234, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s]                                              {'loss': 1.8878, 'grad_norm': 15.552233695983887, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.96it/s]                                              {'loss': 1.6779, 'grad_norm': 13.710528373718262, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.96it/s]                                              {'loss': 0.0789, 'grad_norm': 4.170148849487305, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.96it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.71it/s]                                              {'loss': 0.4733, 'grad_norm': 5.883923053741455, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.71it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 0.3931, 'grad_norm': 6.290219306945801, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s]                                               {'loss': 0.8354, 'grad_norm': 10.128317832946777, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s] 30%|███       | 12/40 [00:03<00:08,  3.22it/s]                                               {'loss': 0.9354, 'grad_norm': 7.709611415863037, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.22it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.3935, 'grad_norm': 5.898826599121094, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.5674, 'grad_norm': 7.62779426574707, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.3729, 'grad_norm': 6.476657867431641, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.0366, 'grad_norm': 2.3027660846710205, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.05it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s]                                               {'loss': 0.1089, 'grad_norm': 2.6149179935455322, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.76it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s]                                               {'loss': 0.0551, 'grad_norm': 1.8846120834350586, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.2225, 'grad_norm': 6.415065288543701, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.0786, 'grad_norm': 1.6223523616790771, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s]                                               {'loss': 0.224, 'grad_norm': 5.12612771987915, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.16it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.2108, 'grad_norm': 5.312732219696045, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.4298, 'grad_norm': 2.1035139560699463, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.0911, 'grad_norm': 4.711753845214844, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.70it/s]                                               {'loss': 0.173, 'grad_norm': 5.146121025085449, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.70it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.47it/s]                                               {'loss': 0.0519, 'grad_norm': 1.0139803886413574, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.47it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.0175, 'grad_norm': 0.36200326681137085, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.29it/s] 70%|███████   | 28/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.3985, 'grad_norm': 3.0304338932037354, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.20it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.12it/s]                                               {'loss': 0.0306, 'grad_norm': 1.095702052116394, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.12it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s]                                               {'loss': 0.0516, 'grad_norm': 1.6361641883850098, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.06it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.02it/s]                                               {'loss': 0.0295, 'grad_norm': 0.9200080037117004, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.02it/s]                                               {'loss': 0.0547, 'grad_norm': 5.196578025817871, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.02it/s] 82%|████████▎ | 33/40 [00:10<00:01,  3.70it/s]                                               {'loss': 0.0309, 'grad_norm': 0.7851012945175171, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:01,  3.70it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.3944, 'grad_norm': 2.540860891342163, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s]                                               {'loss': 0.0589, 'grad_norm': 2.002439498901367, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.23it/s]                                               {'loss': 0.0355, 'grad_norm': 1.3640985488891602, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.23it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.095, 'grad_norm': 4.180871963500977, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.14it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0216, 'grad_norm': 0.5500262379646301, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.05it/s]                                               {'loss': 0.0125, 'grad_norm': 0.37534239888191223, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.05it/s]                                               {'loss': 0.0784, 'grad_norm': 4.669054985046387, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]                                               {'train_runtime': 12.3171, 'train_samples_per_second': 45.871, 'train_steps_per_second': 3.248, 'train_loss': 0.4884951026877388, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.6821, 'grad_norm': 8.866534233093262, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.0243, 'grad_norm': 12.862021446228027, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.5209, 'grad_norm': 8.801469802856445, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.6596, 'grad_norm': 18.11103630065918, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.042, 'grad_norm': 11.515965461730957, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.5315, 'grad_norm': 16.5617618560791, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 1.5898, 'grad_norm': 12.204024314880371, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 0.0858, 'grad_norm': 8.128153800964355, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.05it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 0.5049, 'grad_norm': 9.714272499084473, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.4732, 'grad_norm': 9.56271743774414, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 0.7782, 'grad_norm': 7.047534465789795, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.19it/s]                                               {'loss': 0.3773, 'grad_norm': 6.124207496643066, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.19it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.7262, 'grad_norm': 6.353460788726807, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.4746, 'grad_norm': 11.521585464477539, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 0.5903, 'grad_norm': 5.646746635437012, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 3.092, 'grad_norm': 70.28123474121094, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.13it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.2722, 'grad_norm': 1.3476927280426025, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.0676, 'grad_norm': 2.4716265201568604, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.29, 'grad_norm': 1.587667465209961, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.3925, 'grad_norm': 6.728609561920166, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.3166, 'grad_norm': 9.186378479003906, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.2268, 'grad_norm': 11.279694557189941, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.209, 'grad_norm': 5.700753211975098, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.1062, 'grad_norm': 10.26083755493164, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.5132, 'grad_norm': 5.471553802490234, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.0206, 'grad_norm': 0.511795699596405, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.4187, 'grad_norm': 3.159944772720337, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.0578, 'grad_norm': 2.0092475414276123, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.0889, 'grad_norm': 3.4723639488220215, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.052, 'grad_norm': 1.1670056581497192, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0501, 'grad_norm': 1.1482073068618774, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0298, 'grad_norm': 2.040184259414673, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s]                                               {'loss': 0.025, 'grad_norm': 1.0797051191329956, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.49it/s]                                               {'loss': 0.0625, 'grad_norm': 5.879740238189697, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.49it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.0928, 'grad_norm': 0.8240629434585571, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.0223, 'grad_norm': 0.7382210493087769, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0196, 'grad_norm': 0.6787025332450867, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1638, 'grad_norm': 4.7375617027282715, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.7102, 'grad_norm': 1.8577406406402588, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0021, 'grad_norm': 0.11603107303380966, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.1244, 'train_samples_per_second': 46.6, 'train_steps_per_second': 3.299, 'train_loss': 0.5840757063357159, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:12
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]                                              {'loss': 1.8551, 'grad_norm': 9.655538558959961, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.9929, 'grad_norm': 9.58200740814209, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:01<00:12,  2.99it/s]                                              {'loss': 1.1691, 'grad_norm': 13.289725303649902, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.99it/s] 10%|█         | 4/40 [00:01<00:12,  3.00it/s]                                              {'loss': 1.9277, 'grad_norm': 23.092792510986328, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.7006, 'grad_norm': 17.09440803527832, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.0429, 'grad_norm': 12.424787521362305, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 1.9458, 'grad_norm': 18.064977645874023, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.3014, 'grad_norm': 19.819303512573242, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 0.383, 'grad_norm': 9.1094970703125, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 1.1394, 'grad_norm': 10.336738586425781, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.5794, 'grad_norm': 8.735309600830078, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.4025, 'grad_norm': 6.993216037750244, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 0.9822, 'grad_norm': 8.075304985046387, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.5408, 'grad_norm': 6.816478252410889, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.4107, 'grad_norm': 5.035534858703613, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.6428, 'grad_norm': 24.178647994995117, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.62it/s]                                               {'loss': 0.0603, 'grad_norm': 1.146713376045227, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.62it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.44it/s]                                               {'loss': 0.594, 'grad_norm': 9.48464584350586, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.44it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.32it/s]                                               {'loss': 1.0018, 'grad_norm': 4.565794944763184, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.32it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.862, 'grad_norm': 11.37191104888916, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.3484, 'grad_norm': 5.48910665512085, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.3656, 'grad_norm': 5.959072589874268, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.2033, 'grad_norm': 3.079634666442871, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.07it/s]                                               {'loss': 0.0059, 'grad_norm': 0.4537135362625122, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.07it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.1645, 'grad_norm': 4.616331100463867, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s]                                               {'loss': 0.1883, 'grad_norm': 6.156996250152588, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.0638, 'grad_norm': 1.5327630043029785, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.6617, 'grad_norm': 11.771690368652344, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.6148, 'grad_norm': 5.43678617477417, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.1021, 'grad_norm': 3.0992417335510254, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.04it/s]                                               {'loss': 0.1023, 'grad_norm': 2.838146924972534, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.04it/s]                                               {'loss': 0.0388, 'grad_norm': 2.683361768722534, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.04it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.72it/s]                                               {'loss': 0.517, 'grad_norm': 4.043086051940918, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.72it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.48it/s]                                               {'loss': 0.213, 'grad_norm': 4.838325500488281, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.48it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s]                                               {'loss': 0.1676, 'grad_norm': 3.8666300773620605, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.33it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.19it/s]                                               {'loss': 0.1064, 'grad_norm': 2.5809121131896973, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.19it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.5609, 'grad_norm': 3.562747001647949, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.12it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0714, 'grad_norm': 1.468353033065796, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.072, 'grad_norm': 1.768368124961853, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.1187, 'grad_norm': 8.437033653259277, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]                                               {'train_runtime': 12.2741, 'train_samples_per_second': 46.032, 'train_steps_per_second': 3.259, 'train_loss': 0.6055297585204243, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
CLIENT:87
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]                                              {'loss': 1.76, 'grad_norm': 7.3451409339904785, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.99it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.1693, 'grad_norm': 8.740205764770508, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.5367, 'grad_norm': 15.76442813873291, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 1.1515, 'grad_norm': 12.738045692443848, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 1.5677, 'grad_norm': 13.306504249572754, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s]                                              {'loss': 2.0725, 'grad_norm': 15.851808547973633, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 2.2699, 'grad_norm': 19.84160041809082, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 5.138, 'grad_norm': 86.13446807861328, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s]                                              {'loss': 0.7658, 'grad_norm': 8.915725708007812, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.67it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.45it/s]                                               {'loss': 0.3026, 'grad_norm': 6.328983783721924, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.45it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s]                                               {'loss': 0.8283, 'grad_norm': 3.1255996227264404, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.7768, 'grad_norm': 5.070174694061279, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.5129, 'grad_norm': 5.608484268188477, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.3458, 'grad_norm': 5.293455600738525, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.4802, 'grad_norm': 6.444492816925049, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.1024, 'grad_norm': 5.127875804901123, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.1468, 'grad_norm': 2.545758008956909, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s]                                               {'loss': 0.129, 'grad_norm': 3.4012038707733154, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.54it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s]                                               {'loss': 0.7116, 'grad_norm': 4.8277482986450195, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.37it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.1076, 'grad_norm': 2.3794100284576416, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.1895, 'grad_norm': 3.5559422969818115, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.1771, 'grad_norm': 4.477605819702148, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.1042, 'grad_norm': 2.6198582649230957, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 2.0424, 'grad_norm': 51.6397705078125, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.3019, 'grad_norm': 11.850830078125, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.0832, 'grad_norm': 4.134146213531494, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.159, 'grad_norm': 4.464325904846191, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.0455, 'grad_norm': 1.8601030111312866, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.0742, 'grad_norm': 2.2189111709594727, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0878, 'grad_norm': 2.3717048168182373, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.593, 'grad_norm': 2.873798370361328, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0577, 'grad_norm': 3.5424230098724365, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.4699, 'grad_norm': 0.6717237830162048, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.0163, 'grad_norm': 0.3851821720600128, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.0361, 'grad_norm': 1.5343855619430542, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.0988, 'grad_norm': 2.889385223388672, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.0364, 'grad_norm': 0.8436111211776733, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0324, 'grad_norm': 1.8279985189437866, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0369, 'grad_norm': 1.055206298828125, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0008, 'grad_norm': 0.04475123807787895, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.2549, 'train_samples_per_second': 46.104, 'train_steps_per_second': 3.264, 'train_loss': 0.6629545654344838, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 1.4631, 'grad_norm': 7.9614667892456055, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.0898, 'grad_norm': 12.616050720214844, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.313, 'grad_norm': 13.380207061767578, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.8176, 'grad_norm': 17.76311683654785, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.2113, 'grad_norm': 13.045269012451172, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.9936, 'grad_norm': 22.997695922851562, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.5938, 'grad_norm': 19.20357894897461, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.3904, 'grad_norm': 27.323558807373047, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s]                                              {'loss': 1.1235, 'grad_norm': 13.34836196899414, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 0.5091, 'grad_norm': 9.221287727355957, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 1.1804, 'grad_norm': 7.361529350280762, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 0.5485, 'grad_norm': 7.512246608734131, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.5858, 'grad_norm': 7.5729804039001465, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.6521, 'grad_norm': 7.181421756744385, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.6107, 'grad_norm': 7.776339054107666, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.9261, 'grad_norm': 38.73609161376953, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.1434, 'grad_norm': 2.802424192428589, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s]                                               {'loss': 0.2102, 'grad_norm': 4.7480149269104, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.1803, 'grad_norm': 3.288623809814453, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.4778, 'grad_norm': 2.9752910137176514, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.3801, 'grad_norm': 2.0042686462402344, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.4263, 'grad_norm': 8.17074966430664, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.1748, 'grad_norm': 4.886894226074219, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.0231, 'grad_norm': 1.5653077363967896, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.06it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.72it/s]                                               {'loss': 0.1717, 'grad_norm': 7.88693904876709, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.72it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s]                                               {'loss': 0.6665, 'grad_norm': 2.4242324829101562, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s]                                               {'loss': 0.0579, 'grad_norm': 1.5413157939910889, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.3489, 'grad_norm': 11.736698150634766, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.0564, 'grad_norm': 2.4155099391937256, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.1301, 'grad_norm': 3.5582613945007324, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.037, 'grad_norm': 2.1822667121887207, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.01, 'grad_norm': 0.8151136040687561, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0276, 'grad_norm': 0.8350827693939209, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.0619, 'grad_norm': 3.1968941688537598, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.0175, 'grad_norm': 0.5721226930618286, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.2773, 'grad_norm': 1.6634963750839233, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0436, 'grad_norm': 1.8885831832885742, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.3769, 'grad_norm': 1.302072286605835, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0531, 'grad_norm': 1.3972182273864746, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.002, 'grad_norm': 0.1578303724527359, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.1568, 'train_samples_per_second': 46.476, 'train_steps_per_second': 3.29, 'train_loss': 0.5590818519354798, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:99
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 1.5785, 'grad_norm': 9.477936744689941, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.8769, 'grad_norm': 13.802275657653809, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.1104, 'grad_norm': 9.6702241897583, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.09it/s]                                              {'loss': 1.5653, 'grad_norm': 15.497014045715332, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.09it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.3381, 'grad_norm': 14.644290924072266, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.4868, 'grad_norm': 16.08376693725586, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 1.0396, 'grad_norm': 10.694892883300781, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s] 20%|██        | 8/40 [00:02<00:10,  3.12it/s]                                              {'loss': 2.5361, 'grad_norm': 13.088232040405273, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.12it/s] 22%|██▎       | 9/40 [00:02<00:10,  3.10it/s]                                              {'loss': 1.4981, 'grad_norm': 11.861503601074219, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:10,  3.10it/s] 25%|██▌       | 10/40 [00:03<00:09,  3.08it/s]                                               {'loss': 0.5483, 'grad_norm': 5.339486598968506, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:09,  3.08it/s] 28%|██▊       | 11/40 [00:03<00:09,  3.05it/s]                                               {'loss': 0.434, 'grad_norm': 4.950845718383789, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:09,  3.05it/s] 30%|███       | 12/40 [00:03<00:09,  3.04it/s]                                               {'loss': 0.315, 'grad_norm': 5.7675299644470215, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:09,  3.04it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.6018, 'grad_norm': 10.689718246459961, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.07it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.05it/s]                                               {'loss': 0.2461, 'grad_norm': 5.539865970611572, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.05it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s]                                               {'loss': 0.9782, 'grad_norm': 8.119237899780273, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s] 40%|████      | 16/40 [00:05<00:07,  3.09it/s]                                               {'loss': 0.3594, 'grad_norm': 4.563597679138184, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:05<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:07,  3.08it/s]                                               {'loss': 0.2247, 'grad_norm': 3.1528055667877197, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:07,  3.08it/s] 45%|████▌     | 18/40 [00:05<00:07,  3.05it/s]                                               {'loss': 0.0654, 'grad_norm': 1.5063350200653076, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:07,  3.05it/s] 48%|████▊     | 19/40 [00:06<00:06,  3.04it/s]                                               {'loss': 0.1238, 'grad_norm': 2.9776971340179443, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:06<00:06,  3.04it/s] 50%|█████     | 20/40 [00:06<00:06,  3.05it/s]                                               {'loss': 0.2787, 'grad_norm': 5.076440811157227, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.05it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.03it/s]                                               {'loss': 0.3519, 'grad_norm': 4.1872453689575195, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.03it/s] 55%|█████▌    | 22/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.7259, 'grad_norm': 4.80227518081665, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:07<00:05,  3.04it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s]                                               {'loss': 0.1677, 'grad_norm': 3.1298911571502686, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.02it/s] 60%|██████    | 24/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.2398, 'grad_norm': 2.1531386375427246, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:08<00:04,  3.06it/s]                                               {'loss': 0.0943, 'grad_norm': 2.09236478805542, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:08<00:04,  3.06it/s] 65%|██████▌   | 26/40 [00:08<00:04,  3.03it/s]                                               {'loss': 0.1916, 'grad_norm': 1.354305386543274, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:08<00:04,  3.03it/s] 68%|██████▊   | 27/40 [00:08<00:04,  3.05it/s]                                               {'loss': 0.5229, 'grad_norm': 1.6043624877929688, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:04,  3.05it/s] 70%|███████   | 28/40 [00:09<00:03,  3.03it/s]                                               {'loss': 0.0616, 'grad_norm': 2.150968074798584, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:09<00:03,  3.03it/s] 72%|███████▎  | 29/40 [00:09<00:03,  3.01it/s]                                               {'loss': 0.05, 'grad_norm': 1.9053610563278198, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:09<00:03,  3.01it/s] 75%|███████▌  | 30/40 [00:09<00:03,  2.99it/s]                                               {'loss': 0.0874, 'grad_norm': 2.3659591674804688, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  2.99it/s] 78%|███████▊  | 31/40 [00:10<00:02,  3.00it/s]                                               {'loss': 0.1294, 'grad_norm': 5.751795291900635, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:10<00:02,  3.00it/s] 80%|████████  | 32/40 [00:10<00:02,  3.06it/s]                                               {'loss': 0.0437, 'grad_norm': 0.8989086747169495, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:10<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:10<00:02,  3.02it/s]                                               {'loss': 0.0553, 'grad_norm': 2.3646392822265625, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:10<00:02,  3.02it/s] 85%|████████▌ | 34/40 [00:11<00:01,  3.00it/s]                                               {'loss': 0.0349, 'grad_norm': 0.8752906918525696, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:11<00:01,  3.00it/s] 88%|████████▊ | 35/40 [00:11<00:01,  3.01it/s]                                               {'loss': 0.0317, 'grad_norm': 0.9029131531715393, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:11<00:01,  3.01it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.00it/s]                                               {'loss': 0.0219, 'grad_norm': 0.6281354427337646, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.00it/s] 92%|█████████▎| 37/40 [00:12<00:00,  3.02it/s]                                               {'loss': 0.1846, 'grad_norm': 1.3990516662597656, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:12<00:00,  3.02it/s] 95%|█████████▌| 38/40 [00:12<00:00,  3.01it/s]                                               {'loss': 0.0231, 'grad_norm': 0.6316348910331726, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:12<00:00,  3.01it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.00it/s]                                               {'loss': 0.4751, 'grad_norm': 1.8012642860412598, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.00it/s]100%|██████████| 40/40 [00:13<00:00,  3.07it/s]                                               {'loss': 0.1419, 'grad_norm': 10.506596565246582, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:13<00:00,  3.07it/s]                                               {'train_runtime': 13.4064, 'train_samples_per_second': 47.365, 'train_steps_per_second': 2.984, 'train_loss': 0.5709984236862511, 'epoch': 5.0}
100%|██████████| 40/40 [00:13<00:00,  3.07it/s]100%|██████████| 40/40 [00:13<00:00,  2.98it/s]
CLIENT:85
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 0.1843, 'grad_norm': 2.8513638973236084, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]                                              {'loss': 0.0521, 'grad_norm': 1.6776005029678345, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.00it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 0.0214, 'grad_norm': 0.5962991118431091, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 0.3079, 'grad_norm': 0.39735355973243713, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 0.0861, 'grad_norm': 0.4542066156864166, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 0.0107, 'grad_norm': 0.16458870470523834, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 0.3248, 'grad_norm': 0.4626184403896332, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 0.0009, 'grad_norm': 0.02698313072323799, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s]                                              {'loss': 0.0181, 'grad_norm': 0.8529986143112183, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s]                                               {'loss': 0.0045, 'grad_norm': 0.055554330348968506, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 0.005, 'grad_norm': 0.05607754737138748, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.32it/s]                                               {'loss': 0.4329, 'grad_norm': 0.1841636747121811, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.32it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s]                                               {'loss': 0.0048, 'grad_norm': 0.05811753123998642, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.1991, 'grad_norm': 0.9230507016181946, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 0.1642, 'grad_norm': 0.33293452858924866, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 0.0, 'grad_norm': 0.0009163760114461184, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.13it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.0036, 'grad_norm': 0.043163545429706573, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.0028, 'grad_norm': 0.041949208825826645, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.0028, 'grad_norm': 0.03165910020470619, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.1554, 'grad_norm': 0.30947962403297424, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.0754, 'grad_norm': 0.19092383980751038, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.2694, 'grad_norm': 0.3302825093269348, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.2726, 'grad_norm': 0.384514182806015, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0032, 'grad_norm': 0.14941269159317017, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.0028, 'grad_norm': 0.046434056013822556, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.0025, 'grad_norm': 0.04516194388270378, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.1485, 'grad_norm': 0.32288509607315063, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.2687, 'grad_norm': 0.4496161937713623, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.165, 'grad_norm': 0.42529693245887756, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.004, 'grad_norm': 0.05818558111786842, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1955, 'grad_norm': 0.49400317668914795, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0, 'grad_norm': 0.00015323176921810955, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s]                                               {'loss': 0.0775, 'grad_norm': 0.19528435170650482, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.78it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.1138, 'grad_norm': 0.10416151583194733, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.2525, 'grad_norm': 0.2673148810863495, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.33it/s]                                               {'loss': 0.0027, 'grad_norm': 0.04352455213665962, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.33it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s]                                               {'loss': 0.1485, 'grad_norm': 0.3013429343700409, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.002, 'grad_norm': 0.02783297933638096, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1823, 'grad_norm': 0.32723236083984375, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0026, 'grad_norm': 0.07641289383172989, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.0739, 'train_samples_per_second': 46.795, 'train_steps_per_second': 3.313, 'train_loss': 0.1042711181773484, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer.train()
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:42, 10.91it/s]  1%|          | 4/471 [00:00<01:07,  6.90it/s]  1%|          | 5/471 [00:00<01:13,  6.38it/s]  1%|▏         | 6/471 [00:00<01:16,  6.08it/s]  1%|▏         | 7/471 [00:01<01:19,  5.84it/s]  2%|▏         | 8/471 [00:01<01:20,  5.72it/s]  2%|▏         | 9/471 [00:01<01:22,  5.63it/s]  2%|▏         | 10/471 [00:01<01:22,  5.57it/s]  2%|▏         | 11/471 [00:01<01:23,  5.53it/s]  3%|▎         | 12/471 [00:02<01:23,  5.48it/s]  3%|▎         | 13/471 [00:02<01:23,  5.46it/s]  3%|▎         | 14/471 [00:02<01:24,  5.44it/s]  3%|▎         | 15/471 [00:02<01:23,  5.45it/s]  3%|▎         | 16/471 [00:02<01:23,  5.43it/s]  4%|▎         | 17/471 [00:02<01:23,  5.44it/s]  4%|▍         | 18/471 [00:03<01:23,  5.42it/s]  4%|▍         | 19/471 [00:03<01:23,  5.42it/s]  4%|▍         | 20/471 [00:03<01:23,  5.41it/s]  4%|▍         | 21/471 [00:03<01:23,  5.41it/s]  5%|▍         | 22/471 [00:03<01:23,  5.40it/s]  5%|▍         | 23/471 [00:04<01:22,  5.42it/s]  5%|▌         | 24/471 [00:04<01:22,  5.40it/s]  5%|▌         | 25/471 [00:04<01:22,  5.42it/s]  6%|▌         | 26/471 [00:04<01:22,  5.41it/s]  6%|▌         | 27/471 [00:04<01:22,  5.41it/s]  6%|▌         | 28/471 [00:04<01:22,  5.40it/s]  6%|▌         | 29/471 [00:05<01:21,  5.40it/s]  6%|▋         | 30/471 [00:05<01:21,  5.39it/s]  7%|▋         | 31/471 [00:05<01:21,  5.38it/s]  7%|▋         | 32/471 [00:05<01:21,  5.40it/s]  7%|▋         | 33/471 [00:05<01:20,  5.45it/s]  7%|▋         | 34/471 [00:06<01:20,  5.44it/s]  7%|▋         | 35/471 [00:06<01:20,  5.43it/s]  8%|▊         | 36/471 [00:06<01:20,  5.43it/s]  8%|▊         | 37/471 [00:06<01:20,  5.40it/s]  8%|▊         | 38/471 [00:06<01:20,  5.39it/s]  8%|▊         | 39/471 [00:07<01:19,  5.41it/s]  8%|▊         | 40/471 [00:07<01:19,  5.40it/s]  9%|▊         | 41/471 [00:07<01:19,  5.40it/s]  9%|▉         | 42/471 [00:07<01:19,  5.37it/s]  9%|▉         | 43/471 [00:07<01:19,  5.37it/s]  9%|▉         | 44/471 [00:07<01:19,  5.40it/s] 10%|▉         | 45/471 [00:08<01:19,  5.39it/s] 10%|▉         | 46/471 [00:08<01:18,  5.39it/s] 10%|▉         | 47/471 [00:08<01:18,  5.39it/s] 10%|█         | 48/471 [00:08<01:18,  5.39it/s] 10%|█         | 49/471 [00:08<01:18,  5.38it/s] 11%|█         | 50/471 [00:09<01:18,  5.38it/s] 11%|█         | 51/471 [00:09<01:18,  5.38it/s] 11%|█         | 52/471 [00:09<01:17,  5.38it/s] 11%|█▏        | 53/471 [00:09<01:17,  5.38it/s] 11%|█▏        | 54/471 [00:09<01:17,  5.37it/s] 12%|█▏        | 55/471 [00:09<01:17,  5.37it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.37it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.37it/s] 12%|█▏        | 58/471 [00:10<01:16,  5.38it/s] 13%|█▎        | 59/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 60/471 [00:10<01:16,  5.38it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.38it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.37it/s] 13%|█▎        | 63/471 [00:11<01:15,  5.37it/s] 14%|█▎        | 64/471 [00:11<01:15,  5.38it/s] 14%|█▍        | 65/471 [00:11<01:15,  5.38it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.38it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.36it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.36it/s] 15%|█▍        | 69/471 [00:12<01:14,  5.38it/s] 15%|█▍        | 70/471 [00:12<01:14,  5.37it/s] 15%|█▌        | 71/471 [00:12<01:14,  5.37it/s] 15%|█▌        | 72/471 [00:13<01:14,  5.36it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.35it/s] 16%|█▌        | 74/471 [00:13<01:13,  5.38it/s] 16%|█▌        | 75/471 [00:13<01:13,  5.36it/s] 16%|█▌        | 76/471 [00:13<01:13,  5.38it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.38it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.37it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.36it/s] 17%|█▋        | 80/471 [00:14<01:12,  5.36it/s] 17%|█▋        | 81/471 [00:14<01:12,  5.37it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.40it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.38it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.37it/s] 18%|█▊        | 85/471 [00:15<01:11,  5.38it/s] 18%|█▊        | 86/471 [00:15<01:11,  5.36it/s] 18%|█▊        | 87/471 [00:15<01:11,  5.39it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.38it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.38it/s] 19%|█▉        | 90/471 [00:16<01:10,  5.37it/s] 19%|█▉        | 91/471 [00:16<01:10,  5.38it/s] 20%|█▉        | 92/471 [00:16<01:10,  5.38it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.38it/s] 20%|█▉        | 94/471 [00:17<01:09,  5.39it/s] 20%|██        | 95/471 [00:17<01:09,  5.39it/s] 20%|██        | 96/471 [00:17<01:09,  5.37it/s] 21%|██        | 97/471 [00:17<01:09,  5.37it/s] 21%|██        | 98/471 [00:17<01:09,  5.37it/s] 21%|██        | 99/471 [00:18<01:09,  5.38it/s] 21%|██        | 100/471 [00:18<01:08,  5.40it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.40it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.38it/s] 22%|██▏       | 103/471 [00:18<01:08,  5.37it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.36it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.35it/s] 23%|██▎       | 106/471 [00:19<01:07,  5.38it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.41it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.39it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.40it/s] 23%|██▎       | 110/471 [00:20<01:06,  5.40it/s] 24%|██▎       | 111/471 [00:20<01:06,  5.39it/s] 24%|██▍       | 112/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.41it/s] 24%|██▍       | 114/471 [00:20<01:06,  5.40it/s] 24%|██▍       | 115/471 [00:21<01:05,  5.39it/s] 25%|██▍       | 116/471 [00:21<01:05,  5.38it/s] 25%|██▍       | 117/471 [00:21<01:05,  5.37it/s] 25%|██▌       | 118/471 [00:21<01:05,  5.37it/s] 25%|██▌       | 119/471 [00:21<01:05,  5.37it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.36it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.37it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.37it/s] 26%|██▌       | 123/471 [00:22<01:04,  5.38it/s] 26%|██▋       | 124/471 [00:22<01:04,  5.37it/s] 27%|██▋       | 125/471 [00:23<01:04,  5.35it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.35it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.36it/s] 27%|██▋       | 128/471 [00:23<01:03,  5.37it/s] 27%|██▋       | 129/471 [00:23<01:03,  5.37it/s] 28%|██▊       | 130/471 [00:23<01:03,  5.37it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.36it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.36it/s] 28%|██▊       | 133/471 [00:24<01:02,  5.37it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.35it/s] 29%|██▊       | 135/471 [00:24<01:02,  5.34it/s] 29%|██▉       | 136/471 [00:25<01:02,  5.35it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.35it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.35it/s] 30%|██▉       | 139/471 [00:25<01:01,  5.36it/s] 30%|██▉       | 140/471 [00:25<01:01,  5.36it/s] 30%|██▉       | 141/471 [00:25<01:01,  5.36it/s] 30%|███       | 142/471 [00:26<01:01,  5.36it/s] 30%|███       | 143/471 [00:26<01:01,  5.36it/s] 31%|███       | 144/471 [00:26<01:01,  5.34it/s] 31%|███       | 145/471 [00:26<01:00,  5.36it/s] 31%|███       | 146/471 [00:26<01:00,  5.36it/s] 31%|███       | 147/471 [00:27<01:00,  5.35it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.34it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.33it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.31it/s] 32%|███▏      | 151/471 [00:27<00:59,  5.33it/s] 32%|███▏      | 152/471 [00:28<00:59,  5.33it/s] 32%|███▏      | 153/471 [00:28<00:59,  5.32it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.34it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.34it/s] 33%|███▎      | 156/471 [00:28<00:58,  5.35it/s] 33%|███▎      | 157/471 [00:28<00:58,  5.36it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.36it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.37it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.36it/s] 34%|███▍      | 161/471 [00:29<00:57,  5.36it/s] 34%|███▍      | 162/471 [00:29<00:57,  5.34it/s] 35%|███▍      | 163/471 [00:30<00:57,  5.34it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.35it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.32it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.30it/s] 35%|███▌      | 167/471 [00:30<00:57,  5.32it/s] 36%|███▌      | 168/471 [00:31<00:56,  5.33it/s] 36%|███▌      | 169/471 [00:31<00:56,  5.34it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.34it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.32it/s] 37%|███▋      | 172/471 [00:31<00:56,  5.33it/s] 37%|███▋      | 173/471 [00:31<00:55,  5.35it/s] 37%|███▋      | 174/471 [00:32<00:55,  5.34it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.34it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.36it/s] 38%|███▊      | 177/471 [00:32<00:55,  5.34it/s] 38%|███▊      | 178/471 [00:32<00:54,  5.34it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.36it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.36it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.35it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.35it/s] 39%|███▉      | 183/471 [00:33<00:53,  5.34it/s] 39%|███▉      | 184/471 [00:34<00:53,  5.35it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.36it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.34it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.34it/s] 40%|███▉      | 188/471 [00:34<00:53,  5.33it/s] 40%|████      | 189/471 [00:34<00:52,  5.34it/s] 40%|████      | 190/471 [00:35<00:52,  5.36it/s] 41%|████      | 191/471 [00:35<00:52,  5.34it/s] 41%|████      | 192/471 [00:35<00:52,  5.34it/s] 41%|████      | 193/471 [00:35<00:51,  5.37it/s] 41%|████      | 194/471 [00:35<00:51,  5.35it/s] 41%|████▏     | 195/471 [00:36<00:51,  5.35it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.34it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.36it/s] 42%|████▏     | 198/471 [00:36<00:50,  5.36it/s] 42%|████▏     | 199/471 [00:36<00:50,  5.35it/s] 42%|████▏     | 200/471 [00:37<00:50,  5.35it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.37it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.35it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.33it/s] 43%|████▎     | 204/471 [00:37<00:50,  5.33it/s] 44%|████▎     | 205/471 [00:37<00:49,  5.35it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.36it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.34it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.37it/s] 44%|████▍     | 209/471 [00:38<00:48,  5.38it/s] 45%|████▍     | 210/471 [00:38<00:48,  5.39it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.37it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.36it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.36it/s] 45%|████▌     | 214/471 [00:39<00:47,  5.36it/s] 46%|████▌     | 215/471 [00:39<00:47,  5.34it/s] 46%|████▌     | 216/471 [00:40<00:47,  5.33it/s] 46%|████▌     | 217/471 [00:40<00:47,  5.32it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.32it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.34it/s] 47%|████▋     | 220/471 [00:40<00:47,  5.32it/s] 47%|████▋     | 221/471 [00:40<00:47,  5.32it/s] 47%|████▋     | 222/471 [00:41<00:46,  5.33it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.35it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.34it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.33it/s] 48%|████▊     | 226/471 [00:41<00:46,  5.32it/s] 48%|████▊     | 227/471 [00:42<00:45,  5.33it/s] 48%|████▊     | 228/471 [00:42<00:45,  5.33it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.32it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.32it/s] 49%|████▉     | 231/471 [00:42<00:45,  5.32it/s] 49%|████▉     | 232/471 [00:43<00:44,  5.35it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.34it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.32it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.32it/s] 50%|█████     | 236/471 [00:43<00:44,  5.34it/s] 50%|█████     | 237/471 [00:43<00:43,  5.34it/s] 51%|█████     | 238/471 [00:44<00:43,  5.32it/s] 51%|█████     | 239/471 [00:44<00:43,  5.33it/s] 51%|█████     | 240/471 [00:44<00:43,  5.33it/s] 51%|█████     | 241/471 [00:44<00:43,  5.33it/s] 51%|█████▏    | 242/471 [00:44<00:42,  5.33it/s] 52%|█████▏    | 243/471 [00:45<00:42,  5.33it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.33it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.33it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.34it/s] 52%|█████▏    | 247/471 [00:45<00:41,  5.34it/s] 53%|█████▎    | 248/471 [00:46<00:41,  5.34it/s] 53%|█████▎    | 249/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.32it/s] 54%|█████▎    | 252/471 [00:46<00:41,  5.32it/s] 54%|█████▎    | 253/471 [00:46<00:41,  5.32it/s] 54%|█████▍    | 254/471 [00:47<00:40,  5.32it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.31it/s] 54%|█████▍    | 256/471 [00:47<00:39,  5.40it/s] 55%|█████▍    | 257/471 [00:47<00:39,  5.36it/s] 55%|█████▍    | 258/471 [00:47<00:39,  5.34it/s] 55%|█████▍    | 259/471 [00:48<00:39,  5.31it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.29it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.29it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.32it/s] 56%|█████▌    | 263/471 [00:48<00:38,  5.33it/s] 56%|█████▌    | 264/471 [00:49<00:38,  5.32it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.30it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.29it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.30it/s] 57%|█████▋    | 268/471 [00:49<00:38,  5.30it/s] 57%|█████▋    | 269/471 [00:49<00:37,  5.32it/s] 57%|█████▋    | 270/471 [00:50<00:37,  5.33it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 273/471 [00:50<00:37,  5.34it/s] 58%|█████▊    | 274/471 [00:50<00:36,  5.36it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.37it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.34it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.34it/s] 59%|█████▉    | 278/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 279/471 [00:51<00:36,  5.33it/s] 59%|█████▉    | 280/471 [00:52<00:35,  5.35it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.34it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.32it/s] 60%|██████    | 283/471 [00:52<00:35,  5.32it/s] 60%|██████    | 284/471 [00:52<00:35,  5.32it/s] 61%|██████    | 285/471 [00:52<00:34,  5.32it/s] 61%|██████    | 286/471 [00:53<00:34,  5.33it/s] 61%|██████    | 287/471 [00:53<00:34,  5.31it/s] 61%|██████    | 288/471 [00:53<00:34,  5.31it/s] 61%|██████▏   | 289/471 [00:53<00:34,  5.32it/s] 62%|██████▏   | 290/471 [00:53<00:33,  5.33it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.34it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.33it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.34it/s] 62%|██████▏   | 294/471 [00:54<00:33,  5.34it/s] 63%|██████▎   | 295/471 [00:54<00:32,  5.34it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.35it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.36it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.33it/s] 63%|██████▎   | 299/471 [00:55<00:32,  5.34it/s] 64%|██████▎   | 300/471 [00:55<00:32,  5.33it/s] 64%|██████▍   | 301/471 [00:55<00:31,  5.32it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.34it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.33it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.33it/s] 65%|██████▍   | 305/471 [00:56<00:31,  5.32it/s] 65%|██████▍   | 306/471 [00:56<00:31,  5.32it/s] 65%|██████▌   | 307/471 [00:57<00:30,  5.32it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.31it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.30it/s] 66%|██████▌   | 310/471 [00:57<00:30,  5.31it/s] 66%|██████▌   | 311/471 [00:57<00:30,  5.32it/s] 66%|██████▌   | 312/471 [00:58<00:29,  5.33it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.33it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.33it/s] 67%|██████▋   | 315/471 [00:58<00:29,  5.33it/s] 67%|██████▋   | 316/471 [00:58<00:28,  5.35it/s] 67%|██████▋   | 317/471 [00:58<00:28,  5.35it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.33it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.33it/s] 68%|██████▊   | 320/471 [00:59<00:28,  5.31it/s] 68%|██████▊   | 321/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 322/471 [00:59<00:28,  5.32it/s] 69%|██████▊   | 323/471 [01:00<00:27,  5.30it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.30it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.31it/s] 69%|██████▉   | 326/471 [01:00<00:27,  5.31it/s] 69%|██████▉   | 327/471 [01:00<00:27,  5.33it/s] 70%|██████▉   | 328/471 [01:01<00:26,  5.32it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.31it/s] 70%|███████   | 330/471 [01:01<00:26,  5.32it/s] 70%|███████   | 331/471 [01:01<00:26,  5.33it/s] 70%|███████   | 332/471 [01:01<00:26,  5.33it/s] 71%|███████   | 333/471 [01:01<00:25,  5.32it/s] 71%|███████   | 334/471 [01:02<00:25,  5.32it/s] 71%|███████   | 335/471 [01:02<00:25,  5.30it/s] 71%|███████▏  | 336/471 [01:02<00:25,  5.32it/s] 72%|███████▏  | 337/471 [01:02<00:25,  5.35it/s] 72%|███████▏  | 338/471 [01:02<00:24,  5.34it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.32it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.31it/s] 72%|███████▏  | 341/471 [01:03<00:24,  5.33it/s] 73%|███████▎  | 342/471 [01:03<00:24,  5.34it/s] 73%|███████▎  | 343/471 [01:03<00:24,  5.32it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.33it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.34it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.32it/s] 74%|███████▎  | 347/471 [01:04<00:23,  5.33it/s] 74%|███████▍  | 348/471 [01:04<00:23,  5.32it/s] 74%|███████▍  | 349/471 [01:04<00:22,  5.32it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.31it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.34it/s] 75%|███████▍  | 352/471 [01:05<00:22,  5.32it/s] 75%|███████▍  | 353/471 [01:05<00:22,  5.30it/s] 75%|███████▌  | 354/471 [01:05<00:22,  5.29it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 357/471 [01:06<00:21,  5.30it/s] 76%|███████▌  | 358/471 [01:06<00:21,  5.31it/s] 76%|███████▌  | 359/471 [01:06<00:21,  5.30it/s] 76%|███████▋  | 360/471 [01:07<00:20,  5.30it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 362/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 363/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 364/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 365/471 [01:08<00:19,  5.31it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.31it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.31it/s] 78%|███████▊  | 368/471 [01:08<00:19,  5.31it/s] 78%|███████▊  | 369/471 [01:08<00:19,  5.33it/s] 79%|███████▊  | 370/471 [01:08<00:18,  5.32it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.32it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.31it/s] 79%|███████▉  | 373/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 374/471 [01:09<00:18,  5.32it/s] 80%|███████▉  | 375/471 [01:09<00:18,  5.33it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.33it/s] 80%|████████  | 377/471 [01:10<00:17,  5.31it/s] 80%|████████  | 378/471 [01:10<00:17,  5.34it/s] 80%|████████  | 379/471 [01:10<00:17,  5.33it/s] 81%|████████  | 380/471 [01:10<00:17,  5.32it/s] 81%|████████  | 381/471 [01:11<00:16,  5.31it/s] 81%|████████  | 382/471 [01:11<00:16,  5.30it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.31it/s] 82%|████████▏ | 384/471 [01:11<00:16,  5.30it/s] 82%|████████▏ | 385/471 [01:11<00:16,  5.30it/s] 82%|████████▏ | 386/471 [01:11<00:16,  5.30it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.30it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.30it/s] 83%|████████▎ | 389/471 [01:12<00:15,  5.31it/s] 83%|████████▎ | 390/471 [01:12<00:15,  5.31it/s] 83%|████████▎ | 391/471 [01:12<00:15,  5.31it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.31it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.32it/s] 84%|████████▎ | 394/471 [01:13<00:14,  5.31it/s] 84%|████████▍ | 395/471 [01:13<00:14,  5.31it/s] 84%|████████▍ | 396/471 [01:13<00:14,  5.30it/s] 84%|████████▍ | 397/471 [01:14<00:13,  5.31it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.30it/s] 85%|████████▍ | 399/471 [01:14<00:13,  5.30it/s] 85%|████████▍ | 400/471 [01:14<00:13,  5.29it/s] 85%|████████▌ | 401/471 [01:14<00:13,  5.30it/s] 85%|████████▌ | 402/471 [01:14<00:13,  5.30it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.31it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.31it/s] 86%|████████▌ | 405/471 [01:15<00:12,  5.30it/s] 86%|████████▌ | 406/471 [01:15<00:12,  5.31it/s] 86%|████████▋ | 407/471 [01:15<00:12,  5.33it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.31it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.31it/s] 87%|████████▋ | 410/471 [01:16<00:11,  5.32it/s] 87%|████████▋ | 411/471 [01:16<00:11,  5.33it/s] 87%|████████▋ | 412/471 [01:16<00:11,  5.33it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.32it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.32it/s] 88%|████████▊ | 415/471 [01:17<00:10,  5.31it/s] 88%|████████▊ | 416/471 [01:17<00:10,  5.30it/s] 89%|████████▊ | 417/471 [01:17<00:10,  5.31it/s] 89%|████████▊ | 418/471 [01:17<00:09,  5.31it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.32it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.34it/s] 89%|████████▉ | 421/471 [01:18<00:09,  5.33it/s] 90%|████████▉ | 422/471 [01:18<00:09,  5.33it/s] 90%|████████▉ | 423/471 [01:18<00:08,  5.34it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.32it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.32it/s] 90%|█████████ | 426/471 [01:19<00:08,  5.32it/s] 91%|█████████ | 427/471 [01:19<00:08,  5.32it/s] 91%|█████████ | 428/471 [01:19<00:08,  5.32it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.31it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.31it/s] 92%|█████████▏| 431/471 [01:20<00:07,  5.30it/s] 92%|█████████▏| 432/471 [01:20<00:07,  5.31it/s] 92%|█████████▏| 433/471 [01:20<00:07,  5.33it/s] 92%|█████████▏| 434/471 [01:20<00:06,  5.32it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.30it/s] 93%|█████████▎| 436/471 [01:21<00:06,  5.32it/s] 93%|█████████▎| 437/471 [01:21<00:06,  5.30it/s] 93%|█████████▎| 438/471 [01:21<00:06,  5.32it/s] 93%|█████████▎| 439/471 [01:21<00:06,  5.32it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.32it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.32it/s] 94%|█████████▍| 442/471 [01:22<00:05,  5.32it/s] 94%|█████████▍| 443/471 [01:22<00:05,  5.34it/s] 94%|█████████▍| 444/471 [01:22<00:05,  5.33it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.31it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.31it/s] 95%|█████████▍| 447/471 [01:23<00:04,  5.31it/s] 95%|█████████▌| 448/471 [01:23<00:04,  5.34it/s] 95%|█████████▌| 449/471 [01:23<00:04,  5.33it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.31it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.31it/s] 96%|█████████▌| 452/471 [01:24<00:03,  5.32it/s] 96%|█████████▌| 453/471 [01:24<00:03,  5.32it/s] 96%|█████████▋| 454/471 [01:24<00:03,  5.32it/s] 97%|█████████▋| 455/471 [01:24<00:03,  5.30it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.31it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.29it/s] 97%|█████████▋| 458/471 [01:25<00:02,  5.30it/s] 97%|█████████▋| 459/471 [01:25<00:02,  5.33it/s] 98%|█████████▊| 460/471 [01:25<00:02,  5.33it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.31it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.30it/s] 98%|█████████▊| 463/471 [01:26<00:01,  5.31it/s] 99%|█████████▊| 464/471 [01:26<00:01,  5.32it/s] 99%|█████████▊| 465/471 [01:26<00:01,  5.34it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.31it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.30it/s] 99%|█████████▉| 468/471 [01:27<00:00,  5.30it/s]100%|█████████▉| 469/471 [01:27<00:00,  5.30it/s]100%|█████████▉| 470/471 [01:27<00:00,  5.31it/s]100%|██████████| 471/471 [01:27<00:00,  5.68it/s]100%|██████████| 471/471 [01:27<00:00,  5.36it/s]
{'eval_loss': 2.09173321723938, 'eval_model_preparation_time': 0.0078, 'eval_acc': 0.43720127456186936, 'eval_runtime': 88.0926, 'eval_samples_per_second': 85.501, 'eval_steps_per_second': 5.347}
ROUND:16
CLIENT:7
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]                                              {'loss': 2.4256, 'grad_norm': 9.975789070129395, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 1.7153, 'grad_norm': 10.960158348083496, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:01<00:12,  2.98it/s]                                              {'loss': 1.5328, 'grad_norm': 12.468147277832031, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.98it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 2.4152, 'grad_norm': 18.062589645385742, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s]                                              {'loss': 2.5431, 'grad_norm': 21.048866271972656, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s]                                              {'loss': 1.0124, 'grad_norm': 18.48408317565918, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 2.4348, 'grad_norm': 18.09526824951172, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.0461, 'grad_norm': 2.763035297393799, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 0.8572, 'grad_norm': 8.200166702270508, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 0.5949, 'grad_norm': 7.947749137878418, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 0.5363, 'grad_norm': 8.70339584350586, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.4069, 'grad_norm': 6.370818614959717, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.1074, 'grad_norm': 10.124076843261719, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.8695, 'grad_norm': 9.967865943908691, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.1646, 'grad_norm': 22.309659957885742, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.1415, 'grad_norm': 7.047296524047852, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.4794, 'grad_norm': 5.570220470428467, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.62it/s]                                               {'loss': 0.1752, 'grad_norm': 4.500716209411621, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.62it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.324, 'grad_norm': 7.9743475914001465, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.6431, 'grad_norm': 5.643924236297607, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.2467, 'grad_norm': 5.241423606872559, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.2361, 'grad_norm': 4.7938923835754395, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.5773, 'grad_norm': 6.460181713104248, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.003, 'grad_norm': 0.16959060728549957, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.2541, 'grad_norm': 6.424462795257568, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.4006, 'grad_norm': 5.376742839813232, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.2352, 'grad_norm': 5.208420276641846, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.4479, 'grad_norm': 14.451233863830566, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.1823, 'grad_norm': 4.517968654632568, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.234, 'grad_norm': 2.489201307296753, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.4887, 'grad_norm': 4.0789337158203125, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.168, 'grad_norm': 8.8380765914917, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0803, 'grad_norm': 2.672847270965576, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.1946, 'grad_norm': 1.8690426349639893, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.0644, 'grad_norm': 2.625223159790039, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.3494, 'grad_norm': 1.6253873109817505, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.3437, 'grad_norm': 1.2446130514144897, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.1098, 'grad_norm': 3.473282814025879, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0576, 'grad_norm': 4.079387187957764, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0504, 'grad_norm': 3.4544386863708496, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1836, 'train_samples_per_second': 46.374, 'train_steps_per_second': 3.283, 'train_loss': 0.6537321514973883, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:25
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.07it/s]                                              {'loss': 1.991, 'grad_norm': 9.774205207824707, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.07it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 0.6936, 'grad_norm': 6.820952892303467, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.1969, 'grad_norm': 10.76904582977295, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.6192, 'grad_norm': 21.202259063720703, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.8802, 'grad_norm': 15.778844833374023, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 3.2805, 'grad_norm': 22.070388793945312, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 1.8597, 'grad_norm': 19.790313720703125, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 0.0598, 'grad_norm': 3.5873959064483643, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 1.0392, 'grad_norm': 14.900132179260254, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.3759, 'grad_norm': 7.695348739624023, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.6599, 'grad_norm': 10.579413414001465, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 0.6871, 'grad_norm': 7.261257171630859, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.3253, 'grad_norm': 8.363404273986816, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.8129, 'grad_norm': 6.332040309906006, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.3165, 'grad_norm': 10.327781677246094, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.2899, 'grad_norm': 20.510526657104492, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.593, 'grad_norm': 5.775816440582275, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.5673, 'grad_norm': 5.190105438232422, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.1903, 'grad_norm': 5.424166202545166, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.5237, 'grad_norm': 8.910507202148438, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.318, 'grad_norm': 7.957885265350342, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.3077, 'grad_norm': 4.612725257873535, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.1452, 'grad_norm': 3.813528299331665, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0993, 'grad_norm': 4.846734523773193, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.4993, 'grad_norm': 2.0630311965942383, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.2089, 'grad_norm': 4.13329553604126, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.0704, 'grad_norm': 1.9602835178375244, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.3655, 'grad_norm': 7.031650066375732, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.0616, 'grad_norm': 1.541908860206604, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.0749, 'grad_norm': 1.4275944232940674, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.1874, 'grad_norm': 3.6048128604888916, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.5588, 'grad_norm': 30.549150466918945, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.0365, 'grad_norm': 0.8685081601142883, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0399, 'grad_norm': 1.0548056364059448, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.1068, 'grad_norm': 4.224844932556152, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.5102, 'grad_norm': 7.959696292877197, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.058, 'grad_norm': 1.3914291858673096, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0811, 'grad_norm': 1.9379090070724487, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.4587, 'grad_norm': 3.0905961990356445, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.09, 'grad_norm': 4.177763938903809, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.1704, 'train_samples_per_second': 46.424, 'train_steps_per_second': 3.287, 'train_loss': 0.6309956673532724, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:71
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.764, 'grad_norm': 10.154732704162598, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.13it/s]                                              {'loss': 1.9054, 'grad_norm': 13.103544235229492, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.13it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 1.7655, 'grad_norm': 16.891361236572266, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.7049, 'grad_norm': 18.185863494873047, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.10it/s]                                              {'loss': 1.7942, 'grad_norm': 20.60726547241211, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.10it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.0173, 'grad_norm': 13.723207473754883, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 1.2071, 'grad_norm': 16.888954162597656, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.0541, 'grad_norm': 4.430601596832275, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s]                                              {'loss': 0.5185, 'grad_norm': 7.643172740936279, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.58it/s]                                               {'loss': 0.4105, 'grad_norm': 6.500401020050049, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.58it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s]                                               {'loss': 0.5505, 'grad_norm': 4.852571964263916, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.4641, 'grad_norm': 6.28232479095459, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.21it/s]                                               {'loss': 0.4285, 'grad_norm': 9.00940990447998, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.2312, 'grad_norm': 4.579012393951416, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.5721, 'grad_norm': 10.056131362915039, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.6837, 'grad_norm': 28.027841567993164, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.1152, 'grad_norm': 2.918177604675293, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.4276, 'grad_norm': 2.537846088409424, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.0847, 'grad_norm': 2.1491172313690186, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.3473, 'grad_norm': 5.814158916473389, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.2187, 'grad_norm': 3.757514715194702, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s]                                               {'loss': 0.1909, 'grad_norm': 4.27310037612915, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.16it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.1302, 'grad_norm': 3.676518678665161, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.0123, 'grad_norm': 0.8922091126441956, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.0236, 'grad_norm': 0.7610008716583252, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.1796, 'grad_norm': 6.371943473815918, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.0638, 'grad_norm': 1.7190486192703247, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.0581, 'grad_norm': 1.9909013509750366, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.1454, 'grad_norm': 3.5994036197662354, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.074, 'grad_norm': 2.4858694076538086, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.4011, 'grad_norm': 1.538704752922058, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0691, 'grad_norm': 4.218038082122803, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0237, 'grad_norm': 1.0406051874160767, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.3539, 'grad_norm': 0.790043830871582, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.2254, 'grad_norm': 6.698711395263672, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0455, 'grad_norm': 3.0513756275177, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0394, 'grad_norm': 1.0879864692687988, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.2064, 'grad_norm': 6.158886432647705, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.1756, 'grad_norm': 5.198117256164551, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0064, 'grad_norm': 0.28193753957748413, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.0634, 'train_samples_per_second': 46.836, 'train_steps_per_second': 3.316, 'train_loss': 0.467245428613387, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]                                              {'loss': 1.3243, 'grad_norm': 7.343950271606445, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.9097, 'grad_norm': 12.470953941345215, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.1552, 'grad_norm': 13.532353401184082, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.5238, 'grad_norm': 16.512371063232422, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 1.2402, 'grad_norm': 15.020886421203613, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.989, 'grad_norm': 25.330944061279297, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 1.5924, 'grad_norm': 22.263280868530273, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.98it/s]                                              {'loss': 0.334, 'grad_norm': 28.60673713684082, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.98it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s]                                              {'loss': 1.1073, 'grad_norm': 19.795547485351562, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 0.6078, 'grad_norm': 12.622170448303223, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 1.1091, 'grad_norm': 7.147263526916504, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.4333, 'grad_norm': 6.987950325012207, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.5449, 'grad_norm': 8.90821361541748, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.588, 'grad_norm': 7.306424617767334, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.5688, 'grad_norm': 7.378285884857178, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.6907, 'grad_norm': 32.93017578125, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.1831, 'grad_norm': 4.2793989181518555, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.2865, 'grad_norm': 6.98396110534668, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.212, 'grad_norm': 4.287832736968994, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.4858, 'grad_norm': 3.0915751457214355, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.3886, 'grad_norm': 2.040692090988159, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.4162, 'grad_norm': 8.732714653015137, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.3343, 'grad_norm': 7.164130210876465, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0092, 'grad_norm': 0.6033492088317871, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.0624, 'grad_norm': 2.0639967918395996, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s]                                               {'loss': 0.6964, 'grad_norm': 3.6517059803009033, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.0807, 'grad_norm': 3.4722466468811035, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.1789, 'grad_norm': 5.604071617126465, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.0374, 'grad_norm': 1.391389012336731, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0965, 'grad_norm': 2.9016001224517822, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0372, 'grad_norm': 1.5507129430770874, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0122, 'grad_norm': 0.7328188419342041, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0234, 'grad_norm': 0.4967544972896576, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.0144, 'grad_norm': 0.4390256106853485, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0156, 'grad_norm': 0.547196626663208, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.3423, 'grad_norm': 2.146334171295166, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.0318, 'grad_norm': 1.368567705154419, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.4042, 'grad_norm': 1.4663174152374268, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0642, 'grad_norm': 2.668088436126709, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0215, 'grad_norm': 2.667102575302124, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1388, 'train_samples_per_second': 46.545, 'train_steps_per_second': 3.295, 'train_loss': 0.528831094573252, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:47
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]                                              {'loss': 1.747, 'grad_norm': 6.810791969299316, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.94it/s]  5%|▌         | 2/40 [00:00<00:12,  2.96it/s]                                              {'loss': 1.8853, 'grad_norm': 15.917328834533691, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.96it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.2481, 'grad_norm': 12.525433540344238, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 2.5085, 'grad_norm': 17.58259391784668, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.2658, 'grad_norm': 20.196996688842773, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.3205, 'grad_norm': 23.623905181884766, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 2.5101, 'grad_norm': 24.227558135986328, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 0.4626, 'grad_norm': 111.82653045654297, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.05it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 0.7638, 'grad_norm': 16.47368049621582, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.7763, 'grad_norm': 14.50818157196045, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 0.9593, 'grad_norm': 8.417391777038574, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 0.3263, 'grad_norm': 4.729215621948242, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 1.1733, 'grad_norm': 15.150842666625977, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.7893, 'grad_norm': 7.439723491668701, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.7948, 'grad_norm': 7.941783428192139, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.0028, 'grad_norm': 0.148845836520195, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.5974, 'grad_norm': 3.945483684539795, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s]                                               {'loss': 0.2985, 'grad_norm': 5.036072254180908, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.1052, 'grad_norm': 2.7767136096954346, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.7212, 'grad_norm': 8.995688438415527, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.7814, 'grad_norm': 13.767289161682129, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.2593, 'grad_norm': 5.475880146026611, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.4415, 'grad_norm': 7.381132125854492, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0577, 'grad_norm': 2.9502792358398438, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.0985, 'grad_norm': 2.4007956981658936, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s]                                               {'loss': 0.3785, 'grad_norm': 1.6717441082000732, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.1262, 'grad_norm': 3.2884137630462646, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.1102, 'grad_norm': 3.799435615539551, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.0839, 'grad_norm': 2.004441738128662, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.184, 'grad_norm': 5.1727824211120605, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0413, 'grad_norm': 1.307638168334961, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.1025, 'grad_norm': 5.839036464691162, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.0668, 'grad_norm': 2.1272060871124268, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.0296, 'grad_norm': 3.0154330730438232, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.4739, 'grad_norm': 4.447642803192139, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.1104, 'grad_norm': 4.018118381500244, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0157, 'grad_norm': 0.40889695286750793, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0826, 'grad_norm': 2.6140449047088623, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0842, 'grad_norm': 2.9451138973236084, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0296, 'grad_norm': 1.6667472124099731, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.0814, 'train_samples_per_second': 46.766, 'train_steps_per_second': 3.311, 'train_loss': 0.6203465799801051, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:29
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.3607, 'grad_norm': 8.350024223327637, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.8035, 'grad_norm': 13.918302536010742, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.6892, 'grad_norm': 15.777750968933105, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.9712, 'grad_norm': 19.44657325744629, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 2.4823, 'grad_norm': 17.50226402282715, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s]                                              {'loss': 1.6748, 'grad_norm': 24.542530059814453, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s]                                              {'loss': 2.7338, 'grad_norm': 13.599621772766113, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.95it/s] 20%|██        | 8/40 [00:02<00:08,  3.77it/s]                                              {'loss': 0.0294, 'grad_norm': 2.45481276512146, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:08,  3.77it/s] 22%|██▎       | 9/40 [00:02<00:09,  3.42it/s]                                              {'loss': 0.7666, 'grad_norm': 9.839553833007812, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:09,  3.42it/s] 25%|██▌       | 10/40 [00:03<00:09,  3.28it/s]                                               {'loss': 1.2364, 'grad_norm': 9.26857852935791, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:09,  3.28it/s] 28%|██▊       | 11/40 [00:03<00:09,  3.17it/s]                                               {'loss': 1.0442, 'grad_norm': 10.142584800720215, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:09,  3.17it/s] 30%|███       | 12/40 [00:03<00:09,  3.10it/s]                                               {'loss': 0.6344, 'grad_norm': 4.5089335441589355, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:09,  3.10it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.8673, 'grad_norm': 9.33600902557373, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.06it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.03it/s]                                               {'loss': 0.4651, 'grad_norm': 7.250072002410889, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.03it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s]                                               {'loss': 0.7899, 'grad_norm': 8.989982604980469, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s]                                               {'loss': 1.5133, 'grad_norm': 96.6094741821289, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.03it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.75it/s]                                               {'loss': 0.3744, 'grad_norm': 5.820745468139648, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.75it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s]                                               {'loss': 0.2426, 'grad_norm': 3.938939094543457, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.53it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 1.1627, 'grad_norm': 8.034502983093262, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.4579, 'grad_norm': 9.466789245605469, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.4048, 'grad_norm': 5.949042797088623, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.3742, 'grad_norm': 4.990744590759277, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.6884, 'grad_norm': 22.30116081237793, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0079, 'grad_norm': 0.49615469574928284, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.3968, 'grad_norm': 1.789888858795166, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.5106, 'grad_norm': 4.1793904304504395, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s]                                               {'loss': 0.2194, 'grad_norm': 6.046903610229492, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.3176, 'grad_norm': 5.5233001708984375, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.3348, 'grad_norm': 8.315924644470215, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.4319, 'grad_norm': 14.517704010009766, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1848, 'grad_norm': 7.187934875488281, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1464, 'grad_norm': 8.007218360900879, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.3451, 'grad_norm': 2.3960649967193604, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.0534, 'grad_norm': 1.4748857021331787, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.3478, 'grad_norm': 1.8915998935699463, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s]                                               {'loss': 0.1307, 'grad_norm': 3.270730495452881, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.26it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.1477, 'grad_norm': 4.311603546142578, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.1407, 'grad_norm': 22.456064224243164, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.1884, 'grad_norm': 8.490074157714844, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0469, 'grad_norm': 4.373913288116455, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]                                               {'train_runtime': 12.2601, 'train_samples_per_second': 46.085, 'train_steps_per_second': 3.263, 'train_loss': 0.7429559456184507, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]                                              {'loss': 2.4288, 'grad_norm': 9.660588264465332, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.09it/s]                                              {'loss': 2.3484, 'grad_norm': 12.612523078918457, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.09it/s]  8%|▊         | 3/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.153, 'grad_norm': 9.619535446166992, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.05it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.993, 'grad_norm': 12.887724876403809, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.8929, 'grad_norm': 13.822866439819336, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.9081, 'grad_norm': 23.838802337646484, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.5098, 'grad_norm': 15.295554161071777, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 10.0272, 'grad_norm': 75.51758575439453, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s]                                              {'loss': 0.5848, 'grad_norm': 9.344422340393066, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s]                                               {'loss': 0.9434, 'grad_norm': 9.19864559173584, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.47it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s]                                               {'loss': 0.6133, 'grad_norm': 6.219700813293457, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 1.0567, 'grad_norm': 11.989391326904297, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.7465, 'grad_norm': 5.783445358276367, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.6977, 'grad_norm': 6.893917560577393, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.4943, 'grad_norm': 6.231541156768799, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.9312, 'grad_norm': 46.4760856628418, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s]                                               {'loss': 0.4482, 'grad_norm': 4.9735517501831055, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.84it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.3676, 'grad_norm': 7.746910572052002, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.1204, 'grad_norm': 2.5972397327423096, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.2498, 'grad_norm': 6.3527607917785645, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.3404, 'grad_norm': 5.910823822021484, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.3414, 'grad_norm': 5.940201759338379, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.4216, 'grad_norm': 6.667949676513672, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.473, 'grad_norm': 20.46965789794922, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.69it/s]                                               {'loss': 0.145, 'grad_norm': 2.997952699661255, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.69it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s]                                               {'loss': 0.1813, 'grad_norm': 1.2748068571090698, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s]                                               {'loss': 0.0945, 'grad_norm': 2.2100675106048584, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.1806, 'grad_norm': 4.689438819885254, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.1127, 'grad_norm': 3.587506055831909, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.1508, 'grad_norm': 5.047351360321045, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.1906, 'grad_norm': 4.80155611038208, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0441, 'grad_norm': 2.9495556354522705, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0267, 'grad_norm': 0.541314959526062, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.0325, 'grad_norm': 0.7563222646713257, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.1691, 'grad_norm': 1.0028231143951416, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.1335, 'grad_norm': 7.040963649749756, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0705, 'grad_norm': 1.8231894969940186, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0582, 'grad_norm': 1.5186524391174316, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0603, 'grad_norm': 1.7313616275787354, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0879, 'grad_norm': 3.1707186698913574, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.1399, 'train_samples_per_second': 46.541, 'train_steps_per_second': 3.295, 'train_loss': 0.87074183402583, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:88
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]                                              {'loss': 1.6084, 'grad_norm': 11.069352149963379, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.5404, 'grad_norm': 14.417584419250488, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  3.08it/s]                                              {'loss': 1.0802, 'grad_norm': 13.47969913482666, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.08it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.5423, 'grad_norm': 16.637121200561523, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.616, 'grad_norm': 12.770285606384277, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 0.7413, 'grad_norm': 23.82942771911621, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 1.7388, 'grad_norm': 16.481931686401367, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 1.2874, 'grad_norm': 54.31344223022461, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 0.3787, 'grad_norm': 6.332846164703369, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 0.6073, 'grad_norm': 10.464377403259277, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.2232, 'grad_norm': 5.801145076751709, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.1636, 'grad_norm': 11.709951400756836, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.2575, 'grad_norm': 5.089033126831055, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.5196, 'grad_norm': 4.656169414520264, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.9358, 'grad_norm': 11.955082893371582, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.0333, 'grad_norm': 1.9867444038391113, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.4627, 'grad_norm': 7.791559219360352, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.5557, 'grad_norm': 5.017245769500732, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s]                                               {'loss': 0.2777, 'grad_norm': 6.92854118347168, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.42it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.2529, 'grad_norm': 4.611268520355225, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.2803, 'grad_norm': 4.521822929382324, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.6213, 'grad_norm': 13.97700023651123, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.6172, 'grad_norm': 6.090538501739502, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.1858, 'grad_norm': 11.240798950195312, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s]                                               {'loss': 0.4743, 'grad_norm': 2.0662059783935547, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.75it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.1803, 'grad_norm': 4.3851237297058105, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.294, 'grad_norm': 5.260678768157959, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.1441, 'grad_norm': 3.6280057430267334, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.23it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.1566, 'grad_norm': 6.027739524841309, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.3958, 'grad_norm': 3.6275386810302734, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0729, 'grad_norm': 2.949490547180176, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0079, 'grad_norm': 0.5223181843757629, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0475, 'grad_norm': 2.623324394226074, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.037, 'grad_norm': 0.9291155338287354, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.023, 'grad_norm': 0.46839916706085205, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.2563, 'grad_norm': 0.7911346554756165, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.5177, 'grad_norm': 0.8950230479240417, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0509, 'grad_norm': 2.851846218109131, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.1485, 'grad_norm': 8.44278621673584, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0028, 'grad_norm': 0.1466701477766037, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1179, 'train_samples_per_second': 46.625, 'train_steps_per_second': 3.301, 'train_loss': 0.5334240461292211, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:50
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 2.748, 'grad_norm': 12.529889106750488, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  3.14it/s]                                              {'loss': 1.7997, 'grad_norm': 22.21603012084961, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.14it/s]  8%|▊         | 3/40 [00:00<00:11,  3.09it/s]                                              {'loss': 1.1481, 'grad_norm': 13.417119026184082, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.09it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.7717, 'grad_norm': 18.388517379760742, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.1323, 'grad_norm': 11.13720989227295, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.4288, 'grad_norm': 11.292546272277832, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.1788, 'grad_norm': 10.255280494689941, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 0.3535, 'grad_norm': 14.530447006225586, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s]                                              {'loss': 0.6398, 'grad_norm': 8.284759521484375, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.74it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s]                                               {'loss': 0.752, 'grad_norm': 11.973443031311035, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 0.4652, 'grad_norm': 4.597841262817383, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 0.4313, 'grad_norm': 5.103163719177246, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.4889, 'grad_norm': 6.2252092361450195, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.6678, 'grad_norm': 20.56459617614746, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.3751, 'grad_norm': 8.74313735961914, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.0216, 'grad_norm': 1.6482839584350586, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s]                                               {'loss': 0.1545, 'grad_norm': 3.025580644607544, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.77it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.1377, 'grad_norm': 3.1654458045959473, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s]                                               {'loss': 0.2124, 'grad_norm': 5.990975379943848, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.36it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.5035, 'grad_norm': 9.041611671447754, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.17it/s]                                               {'loss': 0.0815, 'grad_norm': 2.8601300716400146, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.451, 'grad_norm': 7.694651126861572, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.3966, 'grad_norm': 8.326715469360352, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0428, 'grad_norm': 2.693967342376709, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.0454, 'grad_norm': 1.6639360189437866, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.0945, 'grad_norm': 2.650682210922241, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.2281, 'grad_norm': 1.923408031463623, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.26it/s]                                               {'loss': 0.1486, 'grad_norm': 3.6468911170959473, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.26it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.14it/s]                                               {'loss': 0.1152, 'grad_norm': 4.756146430969238, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.14it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.07it/s]                                               {'loss': 0.0592, 'grad_norm': 1.9136615991592407, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.07it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.03it/s]                                               {'loss': 0.2498, 'grad_norm': 9.293717384338379, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.03it/s]                                               {'loss': 0.139, 'grad_norm': 8.126762390136719, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.03it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.73it/s]                                               {'loss': 0.0329, 'grad_norm': 0.7445452213287354, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.73it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.0417, 'grad_norm': 1.2014797925949097, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s]                                               {'loss': 0.0416, 'grad_norm': 3.0254299640655518, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.34it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s]                                               {'loss': 0.0265, 'grad_norm': 0.8030534982681274, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.1745, 'grad_norm': 1.0938994884490967, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0628, 'grad_norm': 2.9710488319396973, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.075, 'grad_norm': 2.730901002883911, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.001, 'grad_norm': 0.05701650679111481, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.2056, 'train_samples_per_second': 46.29, 'train_steps_per_second': 3.277, 'train_loss': 0.49795070731051966, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:9
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.06it/s]                                              {'loss': 2.0948, 'grad_norm': 8.618985176086426, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.06it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.156, 'grad_norm': 15.244203567504883, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.00it/s]                                              {'loss': 0.61, 'grad_norm': 8.87464714050293, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.00it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.6663, 'grad_norm': 13.930215835571289, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.77, 'grad_norm': 17.842269897460938, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.3784, 'grad_norm': 25.03419303894043, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.9702, 'grad_norm': 25.305675506591797, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.402, 'grad_norm': 104.77362060546875, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 1.1524, 'grad_norm': 22.331024169921875, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 0.366, 'grad_norm': 9.46355152130127, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.5413, 'grad_norm': 9.905888557434082, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.6271, 'grad_norm': 8.752918243408203, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.2753, 'grad_norm': 6.648619174957275, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.4737, 'grad_norm': 5.834658145904541, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.5727, 'grad_norm': 7.345855712890625, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 1.4257, 'grad_norm': 41.046573638916016, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.4593, 'grad_norm': 7.102191925048828, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.1127, 'grad_norm': 2.3297412395477295, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.1765, 'grad_norm': 4.938989639282227, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.1848, 'grad_norm': 3.940197467803955, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.1672, 'grad_norm': 4.812292098999023, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.2964, 'grad_norm': 6.8848876953125, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.6534, 'grad_norm': 15.480595588684082, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.1476, 'grad_norm': 14.515091896057129, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s]                                               {'loss': 0.0519, 'grad_norm': 1.5994514226913452, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s]                                               {'loss': 0.1355, 'grad_norm': 3.702827215194702, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s]                                               {'loss': 0.1734, 'grad_norm': 4.723077297210693, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.2589, 'grad_norm': 2.995274066925049, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.1223, 'grad_norm': 4.798393726348877, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.2628, 'grad_norm': 10.84485912322998, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.4403, 'grad_norm': 11.196612358093262, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0041, 'grad_norm': 0.2750343382358551, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0823, 'grad_norm': 2.1726231575012207, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.198, 'grad_norm': 1.6793080568313599, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.0892, 'grad_norm': 2.2630693912506104, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.0344, 'grad_norm': 0.9589747786521912, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0345, 'grad_norm': 0.9392080307006836, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0515, 'grad_norm': 1.5239372253417969, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0671, 'grad_norm': 1.9979991912841797, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0237, 'grad_norm': 1.4468837976455688, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1628, 'train_samples_per_second': 46.453, 'train_steps_per_second': 3.289, 'train_loss': 0.6177497282973491, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer.train()
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:42, 10.93it/s]  1%|          | 4/471 [00:00<01:08,  6.85it/s]  1%|          | 5/471 [00:00<01:13,  6.36it/s]  1%|▏         | 6/471 [00:00<01:17,  6.01it/s]  1%|▏         | 7/471 [00:01<01:20,  5.80it/s]  2%|▏         | 8/471 [00:01<01:21,  5.69it/s]  2%|▏         | 9/471 [00:01<01:22,  5.60it/s]  2%|▏         | 10/471 [00:01<01:23,  5.55it/s]  2%|▏         | 11/471 [00:01<01:23,  5.50it/s]  3%|▎         | 12/471 [00:02<01:24,  5.46it/s]  3%|▎         | 13/471 [00:02<01:24,  5.42it/s]  3%|▎         | 14/471 [00:02<01:24,  5.42it/s]  3%|▎         | 15/471 [00:02<01:24,  5.41it/s]  3%|▎         | 16/471 [00:02<01:24,  5.40it/s]  4%|▎         | 17/471 [00:02<01:23,  5.41it/s]  4%|▍         | 18/471 [00:03<01:24,  5.39it/s]  4%|▍         | 19/471 [00:03<01:23,  5.39it/s]  4%|▍         | 20/471 [00:03<01:23,  5.37it/s]  4%|▍         | 21/471 [00:03<01:23,  5.38it/s]  5%|▍         | 22/471 [00:03<01:23,  5.38it/s]  5%|▍         | 23/471 [00:04<01:23,  5.38it/s]  5%|▌         | 24/471 [00:04<01:23,  5.38it/s]  5%|▌         | 25/471 [00:04<01:22,  5.38it/s]  6%|▌         | 26/471 [00:04<01:22,  5.38it/s]  6%|▌         | 27/471 [00:04<01:22,  5.39it/s]  6%|▌         | 28/471 [00:05<01:22,  5.37it/s]  6%|▌         | 29/471 [00:05<01:22,  5.38it/s]  6%|▋         | 30/471 [00:05<01:22,  5.36it/s]  7%|▋         | 31/471 [00:05<01:21,  5.37it/s]  7%|▋         | 32/471 [00:05<01:21,  5.39it/s]  7%|▋         | 33/471 [00:05<01:20,  5.41it/s]  7%|▋         | 34/471 [00:06<01:20,  5.41it/s]  7%|▋         | 35/471 [00:06<01:20,  5.40it/s]  8%|▊         | 36/471 [00:06<01:20,  5.40it/s]  8%|▊         | 37/471 [00:06<01:20,  5.38it/s]  8%|▊         | 38/471 [00:06<01:20,  5.38it/s]  8%|▊         | 39/471 [00:07<01:20,  5.37it/s]  8%|▊         | 40/471 [00:07<01:20,  5.37it/s]  9%|▊         | 41/471 [00:07<01:20,  5.37it/s]  9%|▉         | 42/471 [00:07<01:20,  5.35it/s]  9%|▉         | 43/471 [00:07<01:19,  5.36it/s]  9%|▉         | 44/471 [00:07<01:19,  5.37it/s] 10%|▉         | 45/471 [00:08<01:19,  5.37it/s] 10%|▉         | 46/471 [00:08<01:19,  5.37it/s] 10%|▉         | 47/471 [00:08<01:18,  5.38it/s] 10%|█         | 48/471 [00:08<01:18,  5.39it/s] 10%|█         | 49/471 [00:08<01:18,  5.38it/s] 11%|█         | 50/471 [00:09<01:18,  5.37it/s] 11%|█         | 51/471 [00:09<01:18,  5.36it/s] 11%|█         | 52/471 [00:09<01:17,  5.37it/s] 11%|█▏        | 53/471 [00:09<01:18,  5.36it/s] 11%|█▏        | 54/471 [00:09<01:18,  5.34it/s] 12%|█▏        | 55/471 [00:10<01:17,  5.35it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.34it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.36it/s] 12%|█▏        | 58/471 [00:10<01:16,  5.37it/s] 13%|█▎        | 59/471 [00:10<01:17,  5.35it/s] 13%|█▎        | 60/471 [00:10<01:16,  5.35it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.35it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.35it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.35it/s] 14%|█▎        | 64/471 [00:11<01:16,  5.34it/s] 14%|█▍        | 65/471 [00:11<01:15,  5.36it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.35it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.34it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.35it/s] 15%|█▍        | 69/471 [00:12<01:15,  5.35it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.34it/s] 15%|█▌        | 71/471 [00:13<01:14,  5.33it/s] 15%|█▌        | 72/471 [00:13<01:14,  5.34it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.33it/s] 16%|█▌        | 74/471 [00:13<01:14,  5.34it/s] 16%|█▌        | 75/471 [00:13<01:14,  5.33it/s] 16%|█▌        | 76/471 [00:13<01:13,  5.35it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.34it/s] 17%|█▋        | 81/471 [00:14<01:12,  5.35it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.36it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.36it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.36it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.35it/s] 18%|█▊        | 86/471 [00:15<01:11,  5.35it/s] 18%|█▊        | 87/471 [00:16<01:11,  5.36it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.37it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.37it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.35it/s] 19%|█▉        | 91/471 [00:16<01:10,  5.37it/s] 20%|█▉        | 92/471 [00:16<01:10,  5.36it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.35it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.36it/s] 20%|██        | 95/471 [00:17<01:10,  5.37it/s] 20%|██        | 96/471 [00:17<01:09,  5.36it/s] 21%|██        | 97/471 [00:17<01:09,  5.36it/s] 21%|██        | 98/471 [00:18<01:09,  5.36it/s] 21%|██        | 99/471 [00:18<01:09,  5.36it/s] 21%|██        | 100/471 [00:18<01:08,  5.39it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.39it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.39it/s] 22%|██▏       | 103/471 [00:18<01:08,  5.36it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.34it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.32it/s] 23%|██▎       | 106/471 [00:19<01:07,  5.37it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.38it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.39it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.38it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.38it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.37it/s] 24%|██▍       | 112/471 [00:20<01:06,  5.36it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.41it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.39it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.38it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.37it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.36it/s] 25%|██▌       | 118/471 [00:21<01:05,  5.36it/s] 25%|██▌       | 119/471 [00:21<01:05,  5.36it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.35it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.35it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.36it/s] 26%|██▌       | 123/471 [00:22<01:04,  5.37it/s] 26%|██▋       | 124/471 [00:22<01:04,  5.36it/s] 27%|██▋       | 125/471 [00:23<01:04,  5.35it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.34it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.34it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.36it/s] 27%|██▋       | 129/471 [00:23<01:03,  5.35it/s] 28%|██▊       | 130/471 [00:24<01:03,  5.33it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.33it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.33it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.34it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.32it/s] 29%|██▊       | 135/471 [00:24<01:03,  5.32it/s] 29%|██▉       | 136/471 [00:25<01:02,  5.33it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.35it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.33it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.34it/s] 30%|██▉       | 140/471 [00:25<01:01,  5.34it/s] 30%|██▉       | 141/471 [00:26<01:01,  5.36it/s] 30%|███       | 142/471 [00:26<01:01,  5.35it/s] 30%|███       | 143/471 [00:26<01:01,  5.35it/s] 31%|███       | 144/471 [00:26<01:01,  5.34it/s] 31%|███       | 145/471 [00:26<01:00,  5.35it/s] 31%|███       | 146/471 [00:27<01:00,  5.35it/s] 31%|███       | 147/471 [00:27<01:00,  5.34it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.33it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.31it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.30it/s] 32%|███▏      | 151/471 [00:27<01:00,  5.30it/s] 32%|███▏      | 152/471 [00:28<00:59,  5.32it/s] 32%|███▏      | 153/471 [00:28<00:59,  5.32it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.34it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.33it/s] 33%|███▎      | 156/471 [00:28<00:59,  5.33it/s] 33%|███▎      | 157/471 [00:29<00:58,  5.33it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.34it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.35it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.34it/s] 34%|███▍      | 161/471 [00:29<00:58,  5.33it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.32it/s] 35%|███▍      | 163/471 [00:30<00:57,  5.31it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.32it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.33it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.32it/s] 35%|███▌      | 167/471 [00:30<00:57,  5.32it/s] 36%|███▌      | 168/471 [00:31<00:56,  5.32it/s] 36%|███▌      | 169/471 [00:31<00:56,  5.30it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.32it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.32it/s] 37%|███▋      | 172/471 [00:31<00:56,  5.33it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.32it/s] 37%|███▋      | 174/471 [00:32<00:56,  5.30it/s] 37%|███▋      | 175/471 [00:32<00:56,  5.28it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.31it/s] 38%|███▊      | 177/471 [00:32<00:55,  5.31it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.32it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.32it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.31it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.30it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.31it/s] 39%|███▉      | 183/471 [00:33<00:54,  5.31it/s] 39%|███▉      | 184/471 [00:34<00:53,  5.33it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.31it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.29it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.30it/s] 40%|███▉      | 188/471 [00:34<00:53,  5.30it/s] 40%|████      | 189/471 [00:35<00:53,  5.32it/s] 40%|████      | 190/471 [00:35<00:52,  5.33it/s] 41%|████      | 191/471 [00:35<00:52,  5.31it/s] 41%|████      | 192/471 [00:35<00:52,  5.32it/s] 41%|████      | 193/471 [00:35<00:52,  5.34it/s] 41%|████      | 194/471 [00:36<00:51,  5.34it/s] 41%|████▏     | 195/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.35it/s] 42%|████▏     | 198/471 [00:36<00:50,  5.36it/s] 42%|████▏     | 199/471 [00:36<00:50,  5.34it/s] 42%|████▏     | 200/471 [00:37<00:50,  5.32it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.33it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.34it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.34it/s] 43%|████▎     | 204/471 [00:37<00:50,  5.33it/s] 44%|████▎     | 205/471 [00:38<00:49,  5.34it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.34it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.32it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.34it/s] 44%|████▍     | 209/471 [00:38<00:48,  5.36it/s] 45%|████▍     | 210/471 [00:39<00:48,  5.36it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.35it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.34it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.34it/s] 45%|████▌     | 214/471 [00:39<00:48,  5.34it/s] 46%|████▌     | 215/471 [00:39<00:48,  5.33it/s] 46%|████▌     | 216/471 [00:40<00:47,  5.32it/s] 46%|████▌     | 217/471 [00:40<00:47,  5.31it/s] 46%|████▋     | 218/471 [00:40<00:47,  5.31it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.32it/s] 47%|████▋     | 220/471 [00:40<00:47,  5.30it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.29it/s] 47%|████▋     | 222/471 [00:41<00:46,  5.31it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.32it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.32it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.33it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.32it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.30it/s] 48%|████▊     | 228/471 [00:42<00:45,  5.30it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.29it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.29it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.29it/s] 49%|████▉     | 232/471 [00:43<00:44,  5.32it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.32it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.31it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.30it/s] 50%|█████     | 236/471 [00:43<00:44,  5.32it/s] 50%|█████     | 237/471 [00:44<00:43,  5.32it/s] 51%|█████     | 238/471 [00:44<00:43,  5.34it/s] 51%|█████     | 239/471 [00:44<00:43,  5.32it/s] 51%|█████     | 240/471 [00:44<00:43,  5.31it/s] 51%|█████     | 241/471 [00:44<00:43,  5.30it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.32it/s] 52%|█████▏    | 243/471 [00:45<00:42,  5.34it/s] 52%|█████▏    | 244/471 [00:45<00:42,  5.32it/s] 52%|█████▏    | 245/471 [00:45<00:42,  5.31it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.31it/s] 52%|█████▏    | 247/471 [00:46<00:41,  5.35it/s] 53%|█████▎    | 248/471 [00:46<00:41,  5.34it/s] 53%|█████▎    | 249/471 [00:46<00:41,  5.33it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.32it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.31it/s] 54%|█████▎    | 252/471 [00:46<00:41,  5.32it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.31it/s] 54%|█████▍    | 254/471 [00:47<00:40,  5.30it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.31it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.30it/s] 55%|█████▍    | 257/471 [00:47<00:40,  5.30it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.31it/s] 55%|█████▍    | 259/471 [00:48<00:39,  5.31it/s] 55%|█████▌    | 260/471 [00:48<00:39,  5.30it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.30it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.31it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.29it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.31it/s] 56%|█████▋    | 265/471 [00:49<00:38,  5.31it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.31it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.30it/s] 57%|█████▋    | 268/471 [00:49<00:38,  5.29it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.30it/s] 57%|█████▋    | 270/471 [00:50<00:37,  5.31it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.31it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.33it/s] 58%|█████▊    | 273/471 [00:50<00:37,  5.32it/s] 58%|█████▊    | 274/471 [00:51<00:36,  5.34it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.35it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.34it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.34it/s] 59%|█████▉    | 278/471 [00:51<00:36,  5.30it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.31it/s] 59%|█████▉    | 280/471 [00:52<00:35,  5.31it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.31it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.32it/s] 60%|██████    | 283/471 [00:52<00:35,  5.30it/s] 60%|██████    | 284/471 [00:52<00:35,  5.29it/s] 61%|██████    | 285/471 [00:53<00:35,  5.29it/s] 61%|██████    | 286/471 [00:53<00:34,  5.30it/s] 61%|██████    | 287/471 [00:53<00:34,  5.30it/s] 61%|██████    | 288/471 [00:53<00:34,  5.30it/s] 61%|██████▏   | 289/471 [00:53<00:34,  5.32it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.31it/s] 62%|██████▏   | 291/471 [00:54<00:33,  5.31it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.31it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.32it/s] 62%|██████▏   | 294/471 [00:54<00:33,  5.33it/s] 63%|██████▎   | 295/471 [00:55<00:32,  5.33it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.34it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.32it/s] 63%|██████▎   | 299/471 [00:55<00:32,  5.32it/s] 64%|██████▎   | 300/471 [00:55<00:32,  5.31it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.31it/s] 64%|██████▍   | 302/471 [00:56<00:31,  5.31it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.32it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.34it/s] 65%|██████▍   | 305/471 [00:56<00:31,  5.32it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.30it/s] 65%|██████▌   | 307/471 [00:57<00:31,  5.28it/s] 65%|██████▌   | 308/471 [00:57<00:30,  5.26it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.28it/s] 66%|██████▌   | 310/471 [00:57<00:30,  5.29it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.29it/s] 66%|██████▌   | 312/471 [00:58<00:30,  5.30it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.30it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.30it/s] 67%|██████▋   | 315/471 [00:58<00:29,  5.32it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.32it/s] 67%|██████▋   | 317/471 [00:59<00:28,  5.32it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.30it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.29it/s] 68%|██████▊   | 320/471 [00:59<00:28,  5.30it/s] 68%|██████▊   | 321/471 [00:59<00:28,  5.30it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.30it/s] 69%|██████▊   | 323/471 [01:00<00:27,  5.29it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.28it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.30it/s] 69%|██████▉   | 326/471 [01:00<00:27,  5.30it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.31it/s] 70%|██████▉   | 328/471 [01:01<00:26,  5.31it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.30it/s] 70%|███████   | 330/471 [01:01<00:26,  5.33it/s] 70%|███████   | 331/471 [01:01<00:26,  5.31it/s] 70%|███████   | 332/471 [01:02<00:26,  5.29it/s] 71%|███████   | 333/471 [01:02<00:25,  5.31it/s] 71%|███████   | 334/471 [01:02<00:25,  5.31it/s] 71%|███████   | 335/471 [01:02<00:25,  5.30it/s] 71%|███████▏  | 336/471 [01:02<00:25,  5.31it/s] 72%|███████▏  | 337/471 [01:02<00:25,  5.32it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.32it/s] 72%|███████▏  | 339/471 [01:03<00:24,  5.30it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.30it/s] 72%|███████▏  | 341/471 [01:03<00:24,  5.31it/s] 73%|███████▎  | 342/471 [01:03<00:24,  5.32it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.31it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.31it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.30it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.29it/s] 74%|███████▎  | 347/471 [01:04<00:23,  5.31it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.30it/s] 74%|███████▍  | 349/471 [01:05<00:23,  5.30it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.30it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.31it/s] 75%|███████▍  | 352/471 [01:05<00:22,  5.30it/s] 75%|███████▍  | 353/471 [01:05<00:22,  5.26it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.26it/s] 75%|███████▌  | 355/471 [01:06<00:21,  5.27it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.28it/s] 76%|███████▌  | 357/471 [01:06<00:21,  5.29it/s] 76%|███████▌  | 358/471 [01:06<00:21,  5.30it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.28it/s] 76%|███████▋  | 360/471 [01:07<00:20,  5.29it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.29it/s] 77%|███████▋  | 362/471 [01:07<00:20,  5.30it/s] 77%|███████▋  | 363/471 [01:07<00:20,  5.30it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.30it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.29it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.28it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.29it/s] 78%|███████▊  | 368/471 [01:08<00:19,  5.27it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.29it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.28it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.29it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.30it/s] 79%|███████▉  | 373/471 [01:09<00:18,  5.29it/s] 79%|███████▉  | 374/471 [01:09<00:18,  5.31it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.30it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.30it/s] 80%|████████  | 377/471 [01:10<00:17,  5.31it/s] 80%|████████  | 378/471 [01:10<00:17,  5.33it/s] 80%|████████  | 379/471 [01:10<00:17,  5.32it/s] 81%|████████  | 380/471 [01:11<00:17,  5.31it/s] 81%|████████  | 381/471 [01:11<00:16,  5.31it/s] 81%|████████  | 382/471 [01:11<00:16,  5.30it/s] 81%|████████▏ | 383/471 [01:11<00:16,  5.30it/s] 82%|████████▏ | 384/471 [01:11<00:16,  5.28it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.28it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.27it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.27it/s] 82%|████████▏ | 388/471 [01:12<00:15,  5.29it/s] 83%|████████▎ | 389/471 [01:12<00:15,  5.31it/s] 83%|████████▎ | 390/471 [01:12<00:15,  5.30it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.29it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.30it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.30it/s] 84%|████████▎ | 394/471 [01:13<00:14,  5.29it/s] 84%|████████▍ | 395/471 [01:13<00:14,  5.28it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.27it/s] 84%|████████▍ | 397/471 [01:14<00:14,  5.27it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.28it/s] 85%|████████▍ | 399/471 [01:14<00:13,  5.27it/s] 85%|████████▍ | 400/471 [01:14<00:13,  5.26it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.28it/s] 85%|████████▌ | 402/471 [01:15<00:12,  5.32it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.30it/s] 86%|████████▌ | 404/471 [01:15<00:12,  5.30it/s] 86%|████████▌ | 405/471 [01:15<00:12,  5.29it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.30it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.31it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.31it/s] 87%|████████▋ | 409/471 [01:16<00:11,  5.30it/s] 87%|████████▋ | 410/471 [01:16<00:11,  5.30it/s] 87%|████████▋ | 411/471 [01:16<00:11,  5.32it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.32it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.31it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.30it/s] 88%|████████▊ | 415/471 [01:17<00:10,  5.31it/s] 88%|████████▊ | 416/471 [01:17<00:10,  5.30it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.32it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.30it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.30it/s] 89%|████████▉ | 420/471 [01:18<00:09,  5.32it/s] 89%|████████▉ | 421/471 [01:18<00:09,  5.32it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.33it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.33it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.31it/s] 90%|█████████ | 425/471 [01:19<00:08,  5.32it/s] 90%|█████████ | 426/471 [01:19<00:08,  5.31it/s] 91%|█████████ | 427/471 [01:19<00:08,  5.32it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.32it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.31it/s] 91%|█████████▏| 430/471 [01:20<00:07,  5.30it/s] 92%|█████████▏| 431/471 [01:20<00:07,  5.30it/s] 92%|█████████▏| 432/471 [01:20<00:07,  5.31it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.31it/s] 92%|█████████▏| 434/471 [01:21<00:06,  5.30it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.29it/s] 93%|█████████▎| 436/471 [01:21<00:06,  5.31it/s] 93%|█████████▎| 437/471 [01:21<00:06,  5.29it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.30it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.30it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.30it/s] 94%|█████████▎| 441/471 [01:22<00:05,  5.31it/s] 94%|█████████▍| 442/471 [01:22<00:05,  5.32it/s] 94%|█████████▍| 443/471 [01:22<00:05,  5.31it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.30it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.30it/s] 95%|█████████▍| 446/471 [01:23<00:04,  5.29it/s] 95%|█████████▍| 447/471 [01:23<00:04,  5.30it/s] 95%|█████████▌| 448/471 [01:23<00:04,  5.31it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.32it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.29it/s] 96%|█████████▌| 451/471 [01:24<00:03,  5.31it/s] 96%|█████████▌| 452/471 [01:24<00:03,  5.31it/s] 96%|█████████▌| 453/471 [01:24<00:03,  5.29it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.29it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.28it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.29it/s] 97%|█████████▋| 457/471 [01:25<00:02,  5.28it/s] 97%|█████████▋| 458/471 [01:25<00:02,  5.29it/s] 97%|█████████▋| 459/471 [01:25<00:02,  5.31it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.31it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.29it/s] 98%|█████████▊| 462/471 [01:26<00:01,  5.29it/s] 98%|█████████▊| 463/471 [01:26<00:01,  5.30it/s] 99%|█████████▊| 464/471 [01:26<00:01,  5.31it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.32it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.30it/s] 99%|█████████▉| 467/471 [01:27<00:00,  5.28it/s] 99%|█████████▉| 468/471 [01:27<00:00,  5.28it/s]100%|█████████▉| 469/471 [01:27<00:00,  5.30it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.30it/s]100%|██████████| 471/471 [01:28<00:00,  5.67it/s]100%|██████████| 471/471 [01:28<00:00,  5.34it/s]
{'eval_loss': 2.007369041442871, 'eval_model_preparation_time': 0.0053, 'eval_acc': 0.45897503983005844, 'eval_runtime': 88.3854, 'eval_samples_per_second': 85.218, 'eval_steps_per_second': 5.329}
ROUND:17
CLIENT:20
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # lr = self.args.lr / ((round / 15) + 1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.92it/s]                                              {'loss': 1.4233, 'grad_norm': 8.322836875915527, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.92it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.7167, 'grad_norm': 10.736649513244629, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.5609, 'grad_norm': 17.719486236572266, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:12,  2.99it/s]                                              {'loss': 1.7219, 'grad_norm': 15.174568176269531, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.99it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s]                                              {'loss': 1.7065, 'grad_norm': 17.092041015625, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.98it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s]                                              {'loss': 1.6116, 'grad_norm': 14.846956253051758, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.98it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 1.6906, 'grad_norm': 16.961214065551758, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 2.3666, 'grad_norm': 69.35403442382812, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.97it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s]                                              {'loss': 0.6324, 'grad_norm': 11.250288009643555, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.72it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 1.3118, 'grad_norm': 11.416121482849121, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s]                                               {'loss': 0.3981, 'grad_norm': 5.535586833953857, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s] 30%|███       | 12/40 [00:03<00:08,  3.23it/s]                                               {'loss': 0.7428, 'grad_norm': 5.538427352905273, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.23it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.8237, 'grad_norm': 3.606470823287964, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.0346, 'grad_norm': 5.375357151031494, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.3854, 'grad_norm': 9.499305725097656, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 1.5457, 'grad_norm': 96.25563049316406, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 1.3443, 'grad_norm': 8.198766708374023, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.5253, 'grad_norm': 7.997509002685547, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.6944, 'grad_norm': 35.95362854003906, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.2783, 'grad_norm': 10.21627140045166, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.1509, 'grad_norm': 4.005805015563965, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.6085, 'grad_norm': 7.230640888214111, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.4974, 'grad_norm': 9.497394561767578, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.0038, 'grad_norm': 0.23734711110591888, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.06it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s]                                               {'loss': 0.1131, 'grad_norm': 3.164649486541748, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s]                                               {'loss': 0.4771, 'grad_norm': 2.444606065750122, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.4436, 'grad_norm': 1.410923957824707, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.7479, 'grad_norm': 3.8185830116271973, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.4534, 'grad_norm': 1.8807590007781982, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.4669, 'grad_norm': 5.820021629333496, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.1552, 'grad_norm': 4.091500282287598, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0038, 'grad_norm': 0.30999696254730225, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.4748, 'grad_norm': 5.495860576629639, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.1054, 'grad_norm': 3.2137115001678467, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.3859, 'grad_norm': 1.5247316360473633, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.3023, 'grad_norm': 2.4617574214935303, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.4293, 'grad_norm': 2.45111083984375, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.6645, 'grad_norm': 1.3962548971176147, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0643, 'grad_norm': 1.7764737606048584, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.4414, 'grad_norm': 27.918004989624023, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]                                               {'train_runtime': 12.2527, 'train_samples_per_second': 46.112, 'train_steps_per_second': 3.265, 'train_loss': 0.7876059263362549, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
CLIENT:10
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  save_steps = sys.maxsize
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.8236, 'grad_norm': 8.175936698913574, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.8664, 'grad_norm': 15.085204124450684, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.00it/s]                                              {'loss': 1.5159, 'grad_norm': 13.755597114562988, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.00it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 0.3766, 'grad_norm': 7.730846881866455, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.8992, 'grad_norm': 17.591306686401367, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.0968, 'grad_norm': 19.950119018554688, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 2.299, 'grad_norm': 14.206522941589355, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.6365, 'grad_norm': 40.196861267089844, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s]                                              {'loss': 0.9459, 'grad_norm': 10.231852531433105, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.77it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.918, 'grad_norm': 14.30162239074707, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 0.1848, 'grad_norm': 4.623666286468506, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.5182, 'grad_norm': 8.98320484161377, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 1.0413, 'grad_norm': 11.455846786499023, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 1.0261, 'grad_norm': 9.565895080566406, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.2625, 'grad_norm': 4.084319591522217, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.0795, 'grad_norm': 5.382907867431641, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.1197, 'grad_norm': 3.736419439315796, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.0901, 'grad_norm': 2.7134644985198975, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.1178, 'grad_norm': 3.5746970176696777, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.1568, 'grad_norm': 3.0956296920776367, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.5128, 'grad_norm': 3.313108205795288, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.5724, 'grad_norm': 9.096270561218262, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.3637, 'grad_norm': 5.394347667694092, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.2484, 'grad_norm': 13.911053657531738, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s]                                               {'loss': 0.4258, 'grad_norm': 1.6085045337677002, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.84it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s]                                               {'loss': 0.1772, 'grad_norm': 4.627287864685059, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.042, 'grad_norm': 1.432106375694275, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.0314, 'grad_norm': 0.9218113422393799, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.0584, 'grad_norm': 2.2243053913116455, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.4022, 'grad_norm': 3.003012180328369, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0523, 'grad_norm': 3.0562281608581543, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0794, 'grad_norm': 8.386809349060059, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0527, 'grad_norm': 4.6607770919799805, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.0376, 'grad_norm': 1.3604271411895752, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.3612, 'grad_norm': 0.9169366359710693, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.0472, 'grad_norm': 1.84230375289917, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.0744, 'grad_norm': 2.3002405166625977, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0787, 'grad_norm': 3.564452886581421, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.3922, 'grad_norm': 0.9607264399528503, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.001, 'grad_norm': 0.0783967524766922, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1806, 'train_samples_per_second': 46.385, 'train_steps_per_second': 3.284, 'train_loss': 0.5246407722239382, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:96
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.07it/s]                                              {'loss': 2.1507, 'grad_norm': 8.774343490600586, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.07it/s]  5%|▌         | 2/40 [00:00<00:11,  3.17it/s]                                              {'loss': 2.5844, 'grad_norm': 19.112607955932617, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:11,  3.17it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 2.001, 'grad_norm': 17.93841552734375, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.1535, 'grad_norm': 18.825349807739258, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.09it/s]                                              {'loss': 1.5306, 'grad_norm': 18.92896842956543, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.09it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.9765, 'grad_norm': 16.64474105834961, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.9778, 'grad_norm': 11.424084663391113, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 5.4463, 'grad_norm': 68.34766387939453, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s]                                              {'loss': 0.535, 'grad_norm': 8.662492752075195, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.59it/s]                                               {'loss': 1.2453, 'grad_norm': 14.71849250793457, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.59it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s]                                               {'loss': 1.0331, 'grad_norm': 6.6329498291015625, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.43it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 1.3318, 'grad_norm': 11.448893547058105, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s]                                               {'loss': 0.6933, 'grad_norm': 8.312268257141113, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.4367, 'grad_norm': 6.435415744781494, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.5346, 'grad_norm': 7.602124214172363, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.0429, 'grad_norm': 2.0658295154571533, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.5201, 'grad_norm': 6.330216884613037, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.3527, 'grad_norm': 8.437893867492676, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.799, 'grad_norm': 6.833599090576172, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.2825, 'grad_norm': 4.796424865722656, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.146, 'grad_norm': 4.921953201293945, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.45, 'grad_norm': 11.484817504882812, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.7582, 'grad_norm': 9.326983451843262, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.046, 'grad_norm': 3.2395074367523193, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.12it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s]                                               {'loss': 0.1241, 'grad_norm': 3.8326826095581055, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.0637, 'grad_norm': 1.5585355758666992, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s]                                               {'loss': 0.1389, 'grad_norm': 4.300372123718262, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.1113, 'grad_norm': 3.0428032875061035, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.8244, 'grad_norm': 2.936580181121826, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.0741, 'grad_norm': 1.2599700689315796, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.1075, 'grad_norm': 2.8067626953125, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0005, 'grad_norm': 0.03928929939866066, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s]                                               {'loss': 0.0748, 'grad_norm': 2.35339617729187, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.86it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s]                                               {'loss': 0.102, 'grad_norm': 6.692538261413574, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.0235, 'grad_norm': 0.5742719769477844, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0618, 'grad_norm': 2.526866912841797, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.3295, 'grad_norm': 3.7401721477508545, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.4093, 'grad_norm': 0.671574056148529, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0595, 'grad_norm': 1.785573959350586, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.1298, 'grad_norm': 9.077422142028809, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.002, 'train_samples_per_second': 47.075, 'train_steps_per_second': 3.333, 'train_loss': 0.7415657237244886, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.33it/s]
CLIENT:16
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.92it/s]                                              {'loss': 1.7858, 'grad_norm': 9.289067268371582, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.92it/s]  5%|▌         | 2/40 [00:00<00:12,  2.96it/s]                                              {'loss': 1.1247, 'grad_norm': 14.11467170715332, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.96it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 2.1304, 'grad_norm': 19.570682525634766, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:12,  2.98it/s]                                              {'loss': 1.1381, 'grad_norm': 10.215933799743652, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.98it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s]                                              {'loss': 0.9143, 'grad_norm': 13.477109909057617, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.7996, 'grad_norm': 15.00406551361084, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.4931, 'grad_norm': 15.454651832580566, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.1122, 'grad_norm': 39.28206253051758, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s]                                              {'loss': 1.2202, 'grad_norm': 12.176032066345215, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.75it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s]                                               {'loss': 0.3195, 'grad_norm': 9.124197959899902, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s]                                               {'loss': 0.9828, 'grad_norm': 9.051567077636719, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.35it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 0.1808, 'grad_norm': 3.0675039291381836, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.3015, 'grad_norm': 4.205402851104736, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.1881, 'grad_norm': 3.822312116622925, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.3181, 'grad_norm': 5.485215187072754, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.06it/s]                                               {'loss': 0.0044, 'grad_norm': 0.25631991028785706, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.06it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.247, 'grad_norm': 3.8941705226898193, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.3467, 'grad_norm': 4.809926509857178, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.3167, 'grad_norm': 8.841368675231934, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.2889, 'grad_norm': 7.270240783691406, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.1219, 'grad_norm': 2.773549795150757, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.1807, 'grad_norm': 5.683115005493164, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.2117, 'grad_norm': 5.301511764526367, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.0018, 'grad_norm': 0.09402410686016083, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.0413, 'grad_norm': 1.2832547426223755, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s]                                               {'loss': 0.0361, 'grad_norm': 1.1466856002807617, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s]                                               {'loss': 0.0829, 'grad_norm': 1.7082853317260742, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.38it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.137, 'grad_norm': 4.584534645080566, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.0901, 'grad_norm': 2.936490535736084, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.0446, 'grad_norm': 1.249070405960083, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.0983, 'grad_norm': 1.6680904626846313, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.0049, 'grad_norm': 0.31497713923454285, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s]                                               {'loss': 0.1124, 'grad_norm': 3.71215558052063, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s]                                               {'loss': 0.2058, 'grad_norm': 5.513241767883301, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.54it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.0827, 'grad_norm': 2.972416639328003, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s]                                               {'loss': 0.1326, 'grad_norm': 4.315290451049805, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0432, 'grad_norm': 1.1793432235717773, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.01, 'grad_norm': 0.20834214985370636, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.0218, 'grad_norm': 0.8152363300323486, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.0565, 'grad_norm': 2.964667320251465, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]                                               {'train_runtime': 12.2352, 'train_samples_per_second': 46.178, 'train_steps_per_second': 3.269, 'train_loss': 0.4482280934724258, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]100%|██████████| 40/40 [00:12<00:00,  3.27it/s]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.2496, 'grad_norm': 9.93780517578125, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.15it/s]                                              {'loss': 2.198, 'grad_norm': 13.36851692199707, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.15it/s]  8%|▊         | 3/40 [00:00<00:11,  3.11it/s]                                              {'loss': 1.0722, 'grad_norm': 10.125064849853516, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.11it/s] 10%|█         | 4/40 [00:01<00:11,  3.09it/s]                                              {'loss': 1.9408, 'grad_norm': 14.096663475036621, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.09it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.7946, 'grad_norm': 14.60544204711914, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.7789, 'grad_norm': 23.80667495727539, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.3238, 'grad_norm': 15.07669734954834, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 9.5626, 'grad_norm': 77.3990707397461, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s]                                              {'loss': 0.4706, 'grad_norm': 10.857917785644531, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.69it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 0.8655, 'grad_norm': 10.174762725830078, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.671, 'grad_norm': 7.774465560913086, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 1.0882, 'grad_norm': 12.300246238708496, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s]                                               {'loss': 0.686, 'grad_norm': 5.4860968589782715, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.7171, 'grad_norm': 8.180602073669434, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.4499, 'grad_norm': 6.005782604217529, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.5147, 'grad_norm': 46.48088073730469, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.12it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s]                                               {'loss': 0.3891, 'grad_norm': 4.702681064605713, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.86it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s]                                               {'loss': 0.4472, 'grad_norm': 9.758777618408203, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s]                                               {'loss': 0.1171, 'grad_norm': 2.7403810024261475, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.1866, 'grad_norm': 4.868984699249268, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s]                                               {'loss': 0.377, 'grad_norm': 8.115230560302734, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.24it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.2993, 'grad_norm': 4.690433025360107, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.20it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.14it/s]                                               {'loss': 0.3772, 'grad_norm': 6.73602819442749, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.14it/s]                                               {'loss': 0.2063, 'grad_norm': 10.265983581542969, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.14it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s]                                               {'loss': 0.1508, 'grad_norm': 3.257035732269287, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.86it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.63it/s]                                               {'loss': 0.2255, 'grad_norm': 2.9065096378326416, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.63it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.45it/s]                                               {'loss': 0.1188, 'grad_norm': 2.0816540718078613, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.45it/s] 70%|███████   | 28/40 [00:08<00:03,  3.32it/s]                                               {'loss': 0.1662, 'grad_norm': 4.499309062957764, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.32it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.0652, 'grad_norm': 2.0962305068969727, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s]                                               {'loss': 0.1142, 'grad_norm': 3.204746723175049, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.2516, 'grad_norm': 6.733250141143799, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.0533, 'grad_norm': 3.4396233558654785, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.14it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.87it/s]                                               {'loss': 0.0477, 'grad_norm': 1.4377347230911255, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.87it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s]                                               {'loss': 0.0346, 'grad_norm': 0.8191788792610168, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.45it/s]                                               {'loss': 0.1644, 'grad_norm': 0.7207111716270447, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.45it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.1657, 'grad_norm': 7.095731258392334, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0569, 'grad_norm': 1.610812783241272, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0771, 'grad_norm': 4.558529853820801, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0855, 'grad_norm': 2.276292085647583, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0854, 'grad_norm': 2.608325719833374, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 11.9921, 'train_samples_per_second': 47.114, 'train_steps_per_second': 3.336, 'train_loss': 0.8161555718630552, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]100%|██████████| 40/40 [00:11<00:00,  3.34it/s]
CLIENT:24
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.06it/s]                                              {'loss': 1.6953, 'grad_norm': 9.483619689941406, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.06it/s]  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]                                              {'loss': 2.0885, 'grad_norm': 11.3550443649292, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.5803, 'grad_norm': 15.925110816955566, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.7843, 'grad_norm': 22.75210952758789, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.8996, 'grad_norm': 15.820836067199707, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.00it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.5923, 'grad_norm': 24.28887367248535, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.07it/s]                                              {'loss': 1.3952, 'grad_norm': 18.294361114501953, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.07it/s]                                              {'loss': 0.0067, 'grad_norm': 0.7300317287445068, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.07it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s]                                              {'loss': 0.4394, 'grad_norm': 7.1266770362854, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.83it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s]                                               {'loss': 0.2533, 'grad_norm': 6.01218843460083, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.5513, 'grad_norm': 8.509033203125, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.4683, 'grad_norm': 8.541523933410645, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.0649, 'grad_norm': 8.568394660949707, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 1.2085, 'grad_norm': 10.061226844787598, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 1.3417, 'grad_norm': 8.17237663269043, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.1023, 'grad_norm': 3.7062666416168213, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.68it/s]                                               {'loss': 0.216, 'grad_norm': 3.3888425827026367, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.68it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.47it/s]                                               {'loss': 0.8632, 'grad_norm': 10.390589714050293, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.47it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.33it/s]                                               {'loss': 0.3181, 'grad_norm': 5.035656452178955, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.33it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.1719, 'grad_norm': 3.052424669265747, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.791, 'grad_norm': 5.349223613739014, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.727, 'grad_norm': 7.469091892242432, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.3864, 'grad_norm': 8.923803329467773, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0329, 'grad_norm': 3.6169466972351074, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s]                                               {'loss': 0.4822, 'grad_norm': 3.4983317852020264, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.82it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s]                                               {'loss': 0.5038, 'grad_norm': 7.422232151031494, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.8167, 'grad_norm': 21.841995239257812, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.1484, 'grad_norm': 4.414332866668701, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.0769, 'grad_norm': 2.3388547897338867, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.1014, 'grad_norm': 4.354495525360107, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.3685, 'grad_norm': 6.261823654174805, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.4878, 'grad_norm': 35.794776916503906, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.5759, 'grad_norm': 5.2733259201049805, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.109, 'grad_norm': 1.1717618703842163, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.4661, 'grad_norm': 2.138359546661377, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0922, 'grad_norm': 4.202664852142334, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0814, 'grad_norm': 2.152003288269043, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.1115, 'grad_norm': 3.7821884155273438, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.4386, 'grad_norm': 2.1945645809173584, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0154, 'grad_norm': 1.124426007270813, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1169, 'train_samples_per_second': 46.629, 'train_steps_per_second': 3.301, 'train_loss': 0.6713500051177107, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:53
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.00it/s]                                              {'loss': 1.7191, 'grad_norm': 11.338444709777832, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  2.96it/s]                                              {'loss': 2.3305, 'grad_norm': 14.676532745361328, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.96it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 1.7164, 'grad_norm': 12.284309387207031, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 0.5277, 'grad_norm': 7.295359134674072, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.5649, 'grad_norm': 20.61543083190918, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s]                                              {'loss': 2.2178, 'grad_norm': 23.222185134887695, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.99it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 1.7871, 'grad_norm': 22.612977981567383, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.99it/s]                                              {'loss': 0.037, 'grad_norm': 4.315201282501221, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.99it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s]                                              {'loss': 0.6001, 'grad_norm': 12.777520179748535, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.48it/s]                                               {'loss': 0.6951, 'grad_norm': 9.219585418701172, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.48it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s]                                               {'loss': 0.3613, 'grad_norm': 5.9895195960998535, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.33it/s] 30%|███       | 12/40 [00:03<00:08,  3.23it/s]                                               {'loss': 0.8924, 'grad_norm': 7.113539695739746, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.23it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.2599, 'grad_norm': 5.340815544128418, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.7467, 'grad_norm': 15.711175918579102, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.6596, 'grad_norm': 9.442160606384277, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.4089, 'grad_norm': 16.38408660888672, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.75it/s]                                               {'loss': 0.2358, 'grad_norm': 3.6930012702941895, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.75it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.49it/s]                                               {'loss': 0.2987, 'grad_norm': 4.9777913093566895, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.49it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.32it/s]                                               {'loss': 0.1511, 'grad_norm': 3.065190553665161, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.32it/s] 50%|█████     | 20/40 [00:06<00:06,  3.19it/s]                                               {'loss': 0.1249, 'grad_norm': 2.939277410507202, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.19it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.11it/s]                                               {'loss': 0.3219, 'grad_norm': 5.667455196380615, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.11it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s]                                               {'loss': 0.301, 'grad_norm': 8.645227432250977, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.07it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 0.286, 'grad_norm': 4.331486701965332, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.04it/s]                                               {'loss': 1.2013, 'grad_norm': 32.589866638183594, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.04it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s]                                               {'loss': 0.1159, 'grad_norm': 2.4089102745056152, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.77it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s]                                               {'loss': 0.0648, 'grad_norm': 1.39780855178833, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s]                                               {'loss': 0.1705, 'grad_norm': 4.801623344421387, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s] 70%|███████   | 28/40 [00:08<00:03,  3.25it/s]                                               {'loss': 0.0909, 'grad_norm': 2.9193124771118164, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.25it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s]                                               {'loss': 0.0644, 'grad_norm': 1.8097772598266602, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.17it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.1766, 'grad_norm': 1.0258967876434326, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0794, 'grad_norm': 2.2253763675689697, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0715, 'grad_norm': 4.094675064086914, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s]                                               {'loss': 0.0693, 'grad_norm': 2.106849431991577, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.77it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.1492, 'grad_norm': 3.345707416534424, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.2071, 'grad_norm': 6.095115661621094, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.2054, 'grad_norm': 2.011404514312744, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0544, 'grad_norm': 1.785147786140442, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0882, 'grad_norm': 4.004029750823975, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.0746, 'grad_norm': 2.6766347885131836, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.0097, 'grad_norm': 0.6830613613128662, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]                                               {'train_runtime': 12.251, 'train_samples_per_second': 46.119, 'train_steps_per_second': 3.265, 'train_loss': 0.5284345210529864, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]100%|██████████| 40/40 [00:12<00:00,  3.27it/s]
CLIENT:97
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.3315, 'grad_norm': 6.501112937927246, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.6575, 'grad_norm': 13.868124008178711, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  3.08it/s]                                              {'loss': 2.7436, 'grad_norm': 15.629256248474121, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.08it/s] 10%|█         | 4/40 [00:01<00:11,  3.07it/s]                                              {'loss': 2.6573, 'grad_norm': 21.362337112426758, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.07it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.979, 'grad_norm': 14.300142288208008, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.1379, 'grad_norm': 11.95333480834961, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 1.6787, 'grad_norm': 12.85085678100586, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 2.0113, 'grad_norm': 40.42971420288086, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s]                                              {'loss': 0.3339, 'grad_norm': 4.346428394317627, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s]                                               {'loss': 0.7232, 'grad_norm': 7.783982753753662, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.51it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 0.8721, 'grad_norm': 9.796046257019043, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.6779, 'grad_norm': 8.730886459350586, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.3065, 'grad_norm': 8.765737533569336, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.9229, 'grad_norm': 13.547154426574707, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.7047, 'grad_norm': 8.994544982910156, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 4.4493, 'grad_norm': 8.018132209777832, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.0792, 'grad_norm': 1.4893072843551636, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s]                                               {'loss': 0.4463, 'grad_norm': 4.410103797912598, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.59it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.1514, 'grad_norm': 3.647427797317505, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.6317, 'grad_norm': 13.076781272888184, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.2908, 'grad_norm': 12.592381477355957, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.1723, 'grad_norm': 2.3630824089050293, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.4072, 'grad_norm': 7.553798198699951, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.1219, 'grad_norm': 5.519994735717773, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.0635, 'grad_norm': 3.213933229446411, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s]                                               {'loss': 0.0748, 'grad_norm': 2.1619372367858887, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.53it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s]                                               {'loss': 0.1485, 'grad_norm': 7.829360008239746, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s] 70%|███████   | 28/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0716, 'grad_norm': 1.7567358016967773, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.20it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.12it/s]                                               {'loss': 0.0357, 'grad_norm': 1.2222117185592651, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.12it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.4862, 'grad_norm': 9.600883483886719, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.1935, 'grad_norm': 2.881251335144043, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.0228, 'grad_norm': 1.7221840620040894, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.70it/s]                                               {'loss': 0.038, 'grad_norm': 1.5187618732452393, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.70it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s]                                               {'loss': 0.0148, 'grad_norm': 0.3410798907279968, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.50it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.1393, 'grad_norm': 0.8544753193855286, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0288, 'grad_norm': 0.8057340383529663, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.044, 'grad_norm': 5.133709907531738, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.3577, 'grad_norm': 8.601324081420898, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.4282, 'grad_norm': 5.48577356338501, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.0045, 'grad_norm': 0.2768271267414093, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]                                               {'train_runtime': 12.234, 'train_samples_per_second': 46.183, 'train_steps_per_second': 3.27, 'train_loss': 0.7159915366326459, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]100%|██████████| 40/40 [00:12<00:00,  3.27it/s]
CLIENT:41
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]                                              {'loss': 2.1915, 'grad_norm': 10.292818069458008, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.5276, 'grad_norm': 12.933136940002441, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.4194, 'grad_norm': 15.589959144592285, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.4929, 'grad_norm': 15.278120040893555, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.9157, 'grad_norm': 18.086719512939453, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.038, 'grad_norm': 17.00868034362793, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.3486, 'grad_norm': 13.55599594116211, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 4.7552, 'grad_norm': 89.86343383789062, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 0.4873, 'grad_norm': 7.328485012054443, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 0.4578, 'grad_norm': 8.458639144897461, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 0.5656, 'grad_norm': 6.104548931121826, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.24it/s]                                               {'loss': 0.3403, 'grad_norm': 6.737848281860352, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.24it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.6111, 'grad_norm': 9.597909927368164, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.8288, 'grad_norm': 6.175532341003418, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 1.0613, 'grad_norm': 5.199260711669922, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.2554, 'grad_norm': 19.900569915771484, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.75it/s]                                               {'loss': 0.4613, 'grad_norm': 3.697622537612915, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.75it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.49it/s]                                               {'loss': 0.4619, 'grad_norm': 2.6893649101257324, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.49it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.33it/s]                                               {'loss': 0.3755, 'grad_norm': 7.588902950286865, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.33it/s] 50%|█████     | 20/40 [00:06<00:06,  3.25it/s]                                               {'loss': 0.3776, 'grad_norm': 5.507316589355469, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.25it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.229, 'grad_norm': 5.146060943603516, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.2904, 'grad_norm': 5.63026237487793, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.2976, 'grad_norm': 5.047457695007324, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.06it/s]                                               {'loss': 0.0381, 'grad_norm': 2.6186769008636475, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.06it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.71it/s]                                               {'loss': 0.4545, 'grad_norm': 2.2931230068206787, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.71it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s]                                               {'loss': 0.1776, 'grad_norm': 1.774754524230957, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.52it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s]                                               {'loss': 0.1095, 'grad_norm': 1.6753690242767334, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.36it/s] 70%|███████   | 28/40 [00:08<00:03,  3.24it/s]                                               {'loss': 0.0737, 'grad_norm': 2.107532262802124, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.24it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s]                                               {'loss': 0.0725, 'grad_norm': 2.462630033493042, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.16it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.1069, 'grad_norm': 2.9965033531188965, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0579, 'grad_norm': 1.307362675666809, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 5.7193, 'grad_norm': 7.824570178985596, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.0916, 'grad_norm': 3.7278900146484375, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.4199, 'grad_norm': 0.44571977853775024, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0704, 'grad_norm': 3.396033763885498, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.22it/s]                                               {'loss': 0.0887, 'grad_norm': 3.487135887145996, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.22it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.086, 'grad_norm': 4.221578598022461, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.13it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.2866, 'grad_norm': 12.036502838134766, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.2648, 'grad_norm': 1.7372885942459106, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.05it/s]                                               {'loss': 0.0375, 'grad_norm': 5.0128092765808105, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]                                               {'train_runtime': 12.2281, 'train_samples_per_second': 46.205, 'train_steps_per_second': 3.271, 'train_loss': 0.798635296151042, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.05it/s]100%|██████████| 40/40 [00:12<00:00,  3.27it/s]
CLIENT:47
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.5869, 'grad_norm': 6.612273216247559, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.03it/s]  5%|▌         | 2/40 [00:00<00:12,  3.12it/s]                                              {'loss': 1.6844, 'grad_norm': 11.617998123168945, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.12it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.0468, 'grad_norm': 13.253622055053711, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.5317, 'grad_norm': 21.036205291748047, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.2916, 'grad_norm': 22.433841705322266, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.2015, 'grad_norm': 26.44213104248047, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 2.5976, 'grad_norm': 29.23674964904785, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.2675, 'grad_norm': 90.43347930908203, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 0.5258, 'grad_norm': 12.406332015991211, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 0.534, 'grad_norm': 11.369470596313477, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 0.8833, 'grad_norm': 8.094046592712402, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.2985, 'grad_norm': 5.379446983337402, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 1.0215, 'grad_norm': 7.276415824890137, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.9611, 'grad_norm': 11.46668529510498, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.8298, 'grad_norm': 8.80870532989502, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.0122, 'grad_norm': 0.7533441781997681, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.532, 'grad_norm': 3.872983932495117, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.4416, 'grad_norm': 8.886787414550781, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.1016, 'grad_norm': 2.6286587715148926, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.5746, 'grad_norm': 7.998655796051025, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s]                                               {'loss': 0.6269, 'grad_norm': 13.740317344665527, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s]                                               {'loss': 0.343, 'grad_norm': 7.71568489074707, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.10it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.2134, 'grad_norm': 4.466423988342285, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.1914, 'grad_norm': 10.589821815490723, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.69it/s]                                               {'loss': 0.1591, 'grad_norm': 4.046450614929199, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.69it/s] 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s]                                               {'loss': 0.3483, 'grad_norm': 1.5257594585418701, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:04,  3.49it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s]                                               {'loss': 0.0883, 'grad_norm': 2.0912344455718994, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s] 70%|███████   | 28/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.0692, 'grad_norm': 5.450412750244141, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.22it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s]                                               {'loss': 0.0754, 'grad_norm': 1.541546106338501, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.13it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.07it/s]                                               {'loss': 0.1273, 'grad_norm': 4.1216583251953125, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.07it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.1622, 'grad_norm': 12.275435447692871, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.9717, 'grad_norm': 41.639705657958984, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s]                                               {'loss': 0.0258, 'grad_norm': 0.8454205393791199, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s]                                               {'loss': 0.0392, 'grad_norm': 1.4159536361694336, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.53it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.3405, 'grad_norm': 1.4220699071884155, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.1634, 'grad_norm': 6.452754974365234, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0209, 'grad_norm': 0.8607053756713867, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0531, 'grad_norm': 1.5641183853149414, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.0584, 'grad_norm': 2.0469107627868652, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.04it/s]                                               {'loss': 0.0082, 'grad_norm': 0.5830628871917725, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]                                               {'train_runtime': 12.2574, 'train_samples_per_second': 46.095, 'train_steps_per_second': 3.263, 'train_loss': 0.600248233252205, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]100%|██████████| 40/40 [00:12<00:00,  3.26it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  )
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:43, 10.79it/s]  1%|          | 4/471 [00:00<01:08,  6.77it/s]  1%|          | 5/471 [00:00<01:14,  6.28it/s]  1%|▏         | 6/471 [00:00<01:18,  5.96it/s]  1%|▏         | 7/471 [00:01<01:20,  5.77it/s]  2%|▏         | 8/471 [00:01<01:21,  5.65it/s]  2%|▏         | 9/471 [00:01<01:23,  5.57it/s]  2%|▏         | 10/471 [00:01<01:23,  5.50it/s]  2%|▏         | 11/471 [00:01<01:24,  5.45it/s]  3%|▎         | 12/471 [00:02<01:24,  5.42it/s]  3%|▎         | 13/471 [00:02<01:24,  5.39it/s]  3%|▎         | 14/471 [00:02<01:25,  5.38it/s]  3%|▎         | 15/471 [00:02<01:24,  5.39it/s]  3%|▎         | 16/471 [00:02<01:24,  5.37it/s]  4%|▎         | 17/471 [00:02<01:24,  5.36it/s]  4%|▍         | 18/471 [00:03<01:24,  5.36it/s]  4%|▍         | 19/471 [00:03<01:24,  5.36it/s]  4%|▍         | 20/471 [00:03<01:24,  5.36it/s]  4%|▍         | 21/471 [00:03<01:23,  5.37it/s]  5%|▍         | 22/471 [00:03<01:23,  5.36it/s]  5%|▍         | 23/471 [00:04<01:23,  5.36it/s]  5%|▌         | 24/471 [00:04<01:23,  5.35it/s]  5%|▌         | 25/471 [00:04<01:23,  5.37it/s]  6%|▌         | 26/471 [00:04<01:22,  5.37it/s]  6%|▌         | 27/471 [00:04<01:22,  5.37it/s]  6%|▌         | 28/471 [00:05<01:22,  5.35it/s]  6%|▌         | 29/471 [00:05<01:22,  5.34it/s]  6%|▋         | 30/471 [00:05<01:22,  5.33it/s]  7%|▋         | 31/471 [00:05<01:22,  5.34it/s]  7%|▋         | 32/471 [00:05<01:22,  5.35it/s]  7%|▋         | 33/471 [00:05<01:21,  5.38it/s]  7%|▋         | 34/471 [00:06<01:21,  5.38it/s]  7%|▋         | 35/471 [00:06<01:21,  5.35it/s]  8%|▊         | 36/471 [00:06<01:21,  5.36it/s]  8%|▊         | 37/471 [00:06<01:21,  5.34it/s]  8%|▊         | 38/471 [00:06<01:21,  5.34it/s]  8%|▊         | 39/471 [00:07<01:21,  5.33it/s]  8%|▊         | 40/471 [00:07<01:20,  5.33it/s]  9%|▊         | 41/471 [00:07<01:20,  5.33it/s]  9%|▉         | 42/471 [00:07<01:20,  5.33it/s]  9%|▉         | 43/471 [00:07<01:20,  5.33it/s]  9%|▉         | 44/471 [00:08<01:20,  5.34it/s] 10%|▉         | 45/471 [00:08<01:19,  5.33it/s] 10%|▉         | 46/471 [00:08<01:19,  5.33it/s] 10%|▉         | 47/471 [00:08<01:19,  5.34it/s] 10%|█         | 48/471 [00:08<01:19,  5.34it/s] 10%|█         | 49/471 [00:08<01:19,  5.33it/s] 11%|█         | 50/471 [00:09<01:19,  5.33it/s] 11%|█         | 51/471 [00:09<01:18,  5.33it/s] 11%|█         | 52/471 [00:09<01:18,  5.33it/s] 11%|█▏        | 53/471 [00:09<01:18,  5.31it/s] 11%|█▏        | 54/471 [00:09<01:18,  5.31it/s] 12%|█▏        | 55/471 [00:10<01:18,  5.31it/s] 12%|█▏        | 56/471 [00:10<01:18,  5.31it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.31it/s] 12%|█▏        | 58/471 [00:10<01:17,  5.31it/s] 13%|█▎        | 59/471 [00:10<01:17,  5.29it/s] 13%|█▎        | 60/471 [00:11<01:17,  5.31it/s] 13%|█▎        | 61/471 [00:11<01:17,  5.31it/s] 13%|█▎        | 62/471 [00:11<01:17,  5.31it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.32it/s] 14%|█▎        | 64/471 [00:11<01:16,  5.29it/s] 14%|█▍        | 65/471 [00:11<01:16,  5.30it/s] 14%|█▍        | 66/471 [00:12<01:16,  5.30it/s] 14%|█▍        | 67/471 [00:12<01:16,  5.30it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.30it/s] 15%|█▍        | 69/471 [00:12<01:15,  5.31it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.31it/s] 15%|█▌        | 71/471 [00:13<01:15,  5.30it/s] 15%|█▌        | 72/471 [00:13<01:15,  5.30it/s] 15%|█▌        | 73/471 [00:13<01:15,  5.29it/s] 16%|█▌        | 74/471 [00:13<01:14,  5.31it/s] 16%|█▌        | 75/471 [00:13<01:14,  5.31it/s] 16%|█▌        | 76/471 [00:14<01:14,  5.31it/s] 16%|█▋        | 77/471 [00:14<01:14,  5.32it/s] 17%|█▋        | 78/471 [00:14<01:14,  5.30it/s] 17%|█▋        | 79/471 [00:14<01:14,  5.29it/s] 17%|█▋        | 80/471 [00:14<01:14,  5.27it/s] 17%|█▋        | 81/471 [00:15<01:13,  5.31it/s] 17%|█▋        | 82/471 [00:15<01:13,  5.32it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.32it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.31it/s] 18%|█▊        | 85/471 [00:15<01:13,  5.29it/s] 18%|█▊        | 86/471 [00:15<01:12,  5.29it/s] 18%|█▊        | 87/471 [00:16<01:12,  5.31it/s] 19%|█▊        | 88/471 [00:16<01:12,  5.32it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.32it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.30it/s] 19%|█▉        | 91/471 [00:16<01:11,  5.32it/s] 20%|█▉        | 92/471 [00:17<01:11,  5.31it/s] 20%|█▉        | 93/471 [00:17<01:11,  5.30it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.32it/s] 20%|██        | 95/471 [00:17<01:10,  5.33it/s] 20%|██        | 96/471 [00:17<01:10,  5.33it/s] 21%|██        | 97/471 [00:18<01:10,  5.29it/s] 21%|██        | 98/471 [00:18<01:10,  5.31it/s] 21%|██        | 99/471 [00:18<01:09,  5.33it/s] 21%|██        | 100/471 [00:18<01:09,  5.35it/s] 21%|██▏       | 101/471 [00:18<01:09,  5.34it/s] 22%|██▏       | 102/471 [00:18<01:09,  5.32it/s] 22%|██▏       | 103/471 [00:19<01:09,  5.30it/s] 22%|██▏       | 104/471 [00:19<01:09,  5.30it/s] 22%|██▏       | 105/471 [00:19<01:09,  5.28it/s] 23%|██▎       | 106/471 [00:19<01:08,  5.32it/s] 23%|██▎       | 107/471 [00:19<01:08,  5.34it/s] 23%|██▎       | 108/471 [00:20<01:08,  5.32it/s] 23%|██▎       | 109/471 [00:20<01:08,  5.32it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.34it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.31it/s] 24%|██▍       | 112/471 [00:20<01:07,  5.31it/s] 24%|██▍       | 113/471 [00:21<01:07,  5.34it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.34it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.33it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.31it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.30it/s] 25%|██▌       | 118/471 [00:21<01:06,  5.30it/s] 25%|██▌       | 119/471 [00:22<01:06,  5.29it/s] 25%|██▌       | 120/471 [00:22<01:06,  5.30it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.30it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.31it/s] 26%|██▌       | 123/471 [00:22<01:05,  5.31it/s] 26%|██▋       | 124/471 [00:23<01:05,  5.29it/s] 27%|██▋       | 125/471 [00:23<01:05,  5.30it/s] 27%|██▋       | 126/471 [00:23<01:05,  5.29it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.29it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.30it/s] 27%|██▋       | 129/471 [00:24<01:04,  5.31it/s] 28%|██▊       | 130/471 [00:24<01:04,  5.31it/s] 28%|██▊       | 131/471 [00:24<01:04,  5.29it/s] 28%|██▊       | 132/471 [00:24<01:04,  5.29it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.29it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.27it/s] 29%|██▊       | 135/471 [00:25<01:03,  5.27it/s] 29%|██▉       | 136/471 [00:25<01:03,  5.28it/s] 29%|██▉       | 137/471 [00:25<01:03,  5.28it/s] 29%|██▉       | 138/471 [00:25<01:03,  5.28it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.29it/s] 30%|██▉       | 140/471 [00:26<01:02,  5.27it/s] 30%|██▉       | 141/471 [00:26<01:02,  5.28it/s] 30%|███       | 142/471 [00:26<01:02,  5.29it/s] 30%|███       | 143/471 [00:26<01:01,  5.29it/s] 31%|███       | 144/471 [00:26<01:01,  5.29it/s] 31%|███       | 145/471 [00:27<01:01,  5.31it/s] 31%|███       | 146/471 [00:27<01:01,  5.29it/s] 31%|███       | 147/471 [00:27<01:01,  5.29it/s] 31%|███▏      | 148/471 [00:27<01:01,  5.29it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.28it/s] 32%|███▏      | 150/471 [00:28<01:00,  5.28it/s] 32%|███▏      | 151/471 [00:28<01:00,  5.27it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.28it/s] 32%|███▏      | 153/471 [00:28<01:00,  5.26it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.29it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.29it/s] 33%|███▎      | 156/471 [00:29<00:59,  5.29it/s] 33%|███▎      | 157/471 [00:29<00:59,  5.30it/s] 34%|███▎      | 158/471 [00:29<00:59,  5.30it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.30it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.29it/s] 34%|███▍      | 161/471 [00:30<00:58,  5.28it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.28it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.27it/s] 35%|███▍      | 164/471 [00:30<00:58,  5.28it/s] 35%|███▌      | 165/471 [00:30<00:58,  5.27it/s] 35%|███▌      | 166/471 [00:31<00:57,  5.26it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.27it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.26it/s] 36%|███▌      | 169/471 [00:31<00:57,  5.26it/s] 36%|███▌      | 170/471 [00:31<00:57,  5.26it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.27it/s] 37%|███▋      | 172/471 [00:32<00:56,  5.27it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.27it/s] 37%|███▋      | 174/471 [00:32<00:56,  5.26it/s] 37%|███▋      | 175/471 [00:32<00:56,  5.26it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.28it/s] 38%|███▊      | 177/471 [00:33<00:55,  5.28it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.27it/s] 38%|███▊      | 179/471 [00:33<00:55,  5.28it/s] 38%|███▊      | 180/471 [00:33<00:55,  5.27it/s] 38%|███▊      | 181/471 [00:33<00:55,  5.27it/s] 39%|███▊      | 182/471 [00:34<00:54,  5.27it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.26it/s] 39%|███▉      | 184/471 [00:34<00:54,  5.27it/s] 39%|███▉      | 185/471 [00:34<00:54,  5.26it/s] 39%|███▉      | 186/471 [00:34<00:54,  5.25it/s] 40%|███▉      | 187/471 [00:35<00:54,  5.25it/s] 40%|███▉      | 188/471 [00:35<00:53,  5.24it/s] 40%|████      | 189/471 [00:35<00:53,  5.27it/s] 40%|████      | 190/471 [00:35<00:53,  5.26it/s] 41%|████      | 191/471 [00:35<00:53,  5.26it/s] 41%|████      | 192/471 [00:35<00:52,  5.27it/s] 41%|████      | 193/471 [00:36<00:52,  5.29it/s] 41%|████      | 194/471 [00:36<00:52,  5.29it/s] 41%|████▏     | 195/471 [00:36<00:52,  5.28it/s] 42%|████▏     | 196/471 [00:36<00:52,  5.29it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.30it/s] 42%|████▏     | 198/471 [00:37<00:51,  5.30it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.28it/s] 42%|████▏     | 200/471 [00:37<00:51,  5.28it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.29it/s] 43%|████▎     | 203/471 [00:38<00:50,  5.30it/s] 43%|████▎     | 204/471 [00:38<00:50,  5.28it/s] 44%|████▎     | 205/471 [00:38<00:50,  5.30it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.31it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.30it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.32it/s] 44%|████▍     | 209/471 [00:39<00:49,  5.31it/s] 45%|████▍     | 210/471 [00:39<00:49,  5.31it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.31it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.30it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.29it/s] 45%|████▌     | 214/471 [00:40<00:48,  5.29it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.29it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.28it/s] 46%|████▌     | 217/471 [00:40<00:48,  5.27it/s] 46%|████▋     | 218/471 [00:40<00:48,  5.26it/s] 46%|████▋     | 219/471 [00:41<00:47,  5.27it/s] 47%|████▋     | 220/471 [00:41<00:47,  5.26it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.26it/s] 47%|████▋     | 222/471 [00:41<00:47,  5.28it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.30it/s] 48%|████▊     | 224/471 [00:42<00:46,  5.29it/s] 48%|████▊     | 225/471 [00:42<00:46,  5.29it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.28it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.27it/s] 48%|████▊     | 228/471 [00:42<00:46,  5.27it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.27it/s] 49%|████▉     | 230/471 [00:43<00:45,  5.27it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.27it/s] 49%|████▉     | 232/471 [00:43<00:45,  5.27it/s] 49%|████▉     | 233/471 [00:43<00:45,  5.29it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.28it/s] 50%|████▉     | 235/471 [00:44<00:44,  5.27it/s] 50%|█████     | 236/471 [00:44<00:44,  5.27it/s] 50%|█████     | 237/471 [00:44<00:44,  5.26it/s] 51%|█████     | 238/471 [00:44<00:44,  5.26it/s] 51%|█████     | 239/471 [00:44<00:43,  5.27it/s] 51%|█████     | 240/471 [00:45<00:43,  5.27it/s] 51%|█████     | 241/471 [00:45<00:43,  5.26it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.26it/s] 52%|█████▏    | 243/471 [00:45<00:43,  5.26it/s] 52%|█████▏    | 244/471 [00:45<00:43,  5.27it/s] 52%|█████▏    | 245/471 [00:46<00:42,  5.26it/s] 52%|█████▏    | 246/471 [00:46<00:42,  5.27it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.29it/s] 53%|█████▎    | 248/471 [00:46<00:42,  5.29it/s] 53%|█████▎    | 249/471 [00:46<00:42,  5.28it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.28it/s] 53%|█████▎    | 251/471 [00:47<00:41,  5.27it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.28it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.28it/s] 54%|█████▍    | 254/471 [00:47<00:41,  5.27it/s] 54%|█████▍    | 255/471 [00:47<00:40,  5.28it/s] 54%|█████▍    | 256/471 [00:48<00:40,  5.26it/s] 55%|█████▍    | 257/471 [00:48<00:40,  5.27it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.27it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.27it/s] 55%|█████▌    | 260/471 [00:48<00:40,  5.26it/s] 55%|█████▌    | 261/471 [00:49<00:39,  5.27it/s] 56%|█████▌    | 262/471 [00:49<00:39,  5.28it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.27it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.26it/s] 56%|█████▋    | 265/471 [00:49<00:39,  5.27it/s] 56%|█████▋    | 266/471 [00:50<00:39,  5.25it/s] 57%|█████▋    | 267/471 [00:50<00:38,  5.26it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.26it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.26it/s] 57%|█████▋    | 270/471 [00:50<00:38,  5.26it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.26it/s] 58%|█████▊    | 272/471 [00:51<00:37,  5.28it/s] 58%|█████▊    | 273/471 [00:51<00:37,  5.29it/s] 58%|█████▊    | 274/471 [00:51<00:37,  5.31it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.32it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.31it/s] 59%|█████▉    | 277/471 [00:52<00:36,  5.30it/s] 59%|█████▉    | 278/471 [00:52<00:36,  5.29it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.30it/s] 59%|█████▉    | 280/471 [00:52<00:36,  5.30it/s] 60%|█████▉    | 281/471 [00:52<00:35,  5.29it/s] 60%|█████▉    | 282/471 [00:53<00:35,  5.29it/s] 60%|██████    | 283/471 [00:53<00:35,  5.28it/s] 60%|██████    | 284/471 [00:53<00:35,  5.27it/s] 61%|██████    | 285/471 [00:53<00:35,  5.27it/s] 61%|██████    | 286/471 [00:53<00:35,  5.27it/s] 61%|██████    | 287/471 [00:53<00:34,  5.27it/s] 61%|██████    | 288/471 [00:54<00:34,  5.26it/s] 61%|██████▏   | 289/471 [00:54<00:34,  5.28it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.27it/s] 62%|██████▏   | 291/471 [00:54<00:34,  5.28it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.27it/s] 62%|██████▏   | 293/471 [00:55<00:33,  5.28it/s] 62%|██████▏   | 294/471 [00:55<00:33,  5.29it/s] 63%|██████▎   | 295/471 [00:55<00:33,  5.29it/s] 63%|██████▎   | 296/471 [00:55<00:32,  5.31it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.30it/s] 63%|██████▎   | 298/471 [00:56<00:32,  5.28it/s] 63%|██████▎   | 299/471 [00:56<00:32,  5.28it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.26it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.27it/s] 64%|██████▍   | 302/471 [00:56<00:32,  5.27it/s] 64%|██████▍   | 303/471 [00:57<00:31,  5.27it/s] 65%|██████▍   | 304/471 [00:57<00:31,  5.29it/s] 65%|██████▍   | 305/471 [00:57<00:31,  5.28it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.27it/s] 65%|██████▌   | 307/471 [00:57<00:31,  5.26it/s] 65%|██████▌   | 308/471 [00:57<00:31,  5.24it/s] 66%|██████▌   | 309/471 [00:58<00:30,  5.26it/s] 66%|██████▌   | 310/471 [00:58<00:30,  5.28it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.27it/s] 66%|██████▌   | 312/471 [00:58<00:30,  5.28it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.29it/s] 67%|██████▋   | 314/471 [00:59<00:29,  5.29it/s] 67%|██████▋   | 315/471 [00:59<00:29,  5.30it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.31it/s] 67%|██████▋   | 317/471 [00:59<00:29,  5.31it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.28it/s] 68%|██████▊   | 319/471 [01:00<00:28,  5.28it/s] 68%|██████▊   | 320/471 [01:00<00:28,  5.28it/s] 68%|██████▊   | 321/471 [01:00<00:28,  5.26it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.28it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.25it/s] 69%|██████▉   | 324/471 [01:00<00:27,  5.25it/s] 69%|██████▉   | 325/471 [01:01<00:27,  5.26it/s] 69%|██████▉   | 326/471 [01:01<00:27,  5.27it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.29it/s] 70%|██████▉   | 328/471 [01:01<00:27,  5.28it/s] 70%|██████▉   | 329/471 [01:01<00:26,  5.26it/s] 70%|███████   | 330/471 [01:02<00:26,  5.29it/s] 70%|███████   | 331/471 [01:02<00:26,  5.27it/s] 70%|███████   | 332/471 [01:02<00:26,  5.26it/s] 71%|███████   | 333/471 [01:02<00:26,  5.27it/s] 71%|███████   | 334/471 [01:02<00:26,  5.26it/s] 71%|███████   | 335/471 [01:03<00:25,  5.25it/s] 71%|███████▏  | 336/471 [01:03<00:25,  5.28it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.29it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.28it/s] 72%|███████▏  | 339/471 [01:03<00:25,  5.27it/s] 72%|███████▏  | 340/471 [01:04<00:24,  5.28it/s] 72%|███████▏  | 341/471 [01:04<00:24,  5.29it/s] 73%|███████▎  | 342/471 [01:04<00:24,  5.30it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.28it/s] 73%|███████▎  | 344/471 [01:04<00:23,  5.30it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.28it/s] 73%|███████▎  | 346/471 [01:05<00:23,  5.27it/s] 74%|███████▎  | 347/471 [01:05<00:23,  5.29it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.29it/s] 74%|███████▍  | 349/471 [01:05<00:23,  5.28it/s] 74%|███████▍  | 350/471 [01:05<00:23,  5.26it/s] 75%|███████▍  | 351/471 [01:06<00:22,  5.28it/s] 75%|███████▍  | 352/471 [01:06<00:22,  5.28it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.26it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.26it/s] 75%|███████▌  | 355/471 [01:06<00:22,  5.26it/s] 76%|███████▌  | 356/471 [01:07<00:21,  5.25it/s] 76%|███████▌  | 357/471 [01:07<00:21,  5.24it/s] 76%|███████▌  | 358/471 [01:07<00:21,  5.23it/s] 76%|███████▌  | 359/471 [01:07<00:20,  5.39it/s] 76%|███████▋  | 360/471 [01:07<00:20,  5.34it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.32it/s] 77%|███████▋  | 362/471 [01:08<00:20,  5.26it/s] 77%|███████▋  | 363/471 [01:08<00:20,  5.23it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.23it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.24it/s] 78%|███████▊  | 366/471 [01:08<00:20,  5.23it/s] 78%|███████▊  | 367/471 [01:09<00:19,  5.24it/s] 78%|███████▊  | 368/471 [01:09<00:19,  5.25it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.25it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.25it/s] 79%|███████▉  | 371/471 [01:09<00:19,  5.26it/s] 79%|███████▉  | 372/471 [01:10<00:18,  5.26it/s] 79%|███████▉  | 373/471 [01:10<00:18,  5.26it/s] 79%|███████▉  | 374/471 [01:10<00:18,  5.25it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.25it/s] 80%|███████▉  | 376/471 [01:10<00:18,  5.27it/s] 80%|████████  | 377/471 [01:11<00:17,  5.28it/s] 80%|████████  | 378/471 [01:11<00:17,  5.31it/s] 80%|████████  | 379/471 [01:11<00:17,  5.26it/s] 81%|████████  | 380/471 [01:11<00:17,  5.25it/s] 81%|████████  | 381/471 [01:11<00:17,  5.27it/s] 81%|████████  | 382/471 [01:11<00:16,  5.27it/s] 81%|████████▏ | 383/471 [01:12<00:16,  5.28it/s] 82%|████████▏ | 384/471 [01:12<00:16,  5.27it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.25it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.25it/s] 82%|████████▏ | 388/471 [01:13<00:15,  5.26it/s] 83%|████████▎ | 389/471 [01:13<00:15,  5.28it/s] 83%|████████▎ | 390/471 [01:13<00:15,  5.27it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.27it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.27it/s] 83%|████████▎ | 393/471 [01:14<00:14,  5.28it/s] 84%|████████▎ | 394/471 [01:14<00:14,  5.26it/s] 84%|████████▍ | 395/471 [01:14<00:14,  5.26it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.26it/s] 84%|████████▍ | 397/471 [01:14<00:14,  5.27it/s] 85%|████████▍ | 398/471 [01:15<00:13,  5.26it/s] 85%|████████▍ | 399/471 [01:15<00:13,  5.26it/s] 85%|████████▍ | 400/471 [01:15<00:13,  5.25it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.26it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.26it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.28it/s] 86%|████████▌ | 404/471 [01:16<00:12,  5.26it/s] 86%|████████▌ | 405/471 [01:16<00:12,  5.26it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.27it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.28it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.28it/s] 87%|████████▋ | 409/471 [01:17<00:11,  5.27it/s] 87%|████████▋ | 410/471 [01:17<00:11,  5.29it/s] 87%|████████▋ | 411/471 [01:17<00:11,  5.30it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.29it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.30it/s] 88%|████████▊ | 414/471 [01:18<00:10,  5.30it/s] 88%|████████▊ | 415/471 [01:18<00:10,  5.29it/s] 88%|████████▊ | 416/471 [01:18<00:10,  5.26it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.28it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.28it/s] 89%|████████▉ | 419/471 [01:19<00:09,  5.29it/s] 89%|████████▉ | 420/471 [01:19<00:09,  5.31it/s] 89%|████████▉ | 421/471 [01:19<00:09,  5.30it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.30it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.31it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.30it/s] 90%|█████████ | 425/471 [01:20<00:08,  5.31it/s] 90%|█████████ | 426/471 [01:20<00:08,  5.29it/s] 91%|█████████ | 427/471 [01:20<00:08,  5.28it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.28it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.28it/s] 91%|█████████▏| 430/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 431/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 432/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.27it/s] 92%|█████████▏| 434/471 [01:21<00:07,  5.27it/s] 92%|█████████▏| 435/471 [01:22<00:06,  5.27it/s] 93%|█████████▎| 436/471 [01:22<00:06,  5.28it/s] 93%|█████████▎| 437/471 [01:22<00:06,  5.27it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.26it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.26it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.27it/s] 94%|█████████▎| 441/471 [01:23<00:05,  5.27it/s] 94%|█████████▍| 442/471 [01:23<00:05,  5.28it/s] 94%|█████████▍| 443/471 [01:23<00:05,  5.28it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.26it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.25it/s] 95%|█████████▍| 446/471 [01:24<00:04,  5.25it/s] 95%|█████████▍| 447/471 [01:24<00:04,  5.26it/s] 95%|█████████▌| 448/471 [01:24<00:04,  5.27it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.26it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.26it/s] 96%|█████████▌| 451/471 [01:25<00:03,  5.27it/s] 96%|█████████▌| 452/471 [01:25<00:03,  5.28it/s] 96%|█████████▌| 453/471 [01:25<00:03,  5.26it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.25it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.25it/s] 97%|█████████▋| 456/471 [01:26<00:02,  5.26it/s] 97%|█████████▋| 457/471 [01:26<00:02,  5.26it/s] 97%|█████████▋| 458/471 [01:26<00:02,  5.26it/s] 97%|█████████▋| 459/471 [01:26<00:02,  5.28it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.27it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.27it/s] 98%|█████████▊| 462/471 [01:27<00:01,  5.26it/s] 98%|█████████▊| 463/471 [01:27<00:01,  5.27it/s] 99%|█████████▊| 464/471 [01:27<00:01,  5.28it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.28it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.28it/s] 99%|█████████▉| 467/471 [01:28<00:00,  5.27it/s] 99%|█████████▉| 468/471 [01:28<00:00,  5.24it/s]100%|█████████▉| 469/471 [01:28<00:00,  5.25it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.26it/s]100%|██████████| 471/471 [01:28<00:00,  5.63it/s]100%|██████████| 471/471 [01:28<00:00,  5.30it/s]
{'eval_loss': 1.9196252822875977, 'eval_model_preparation_time': 0.0053, 'eval_acc': 0.48181093998937863, 'eval_runtime': 89.0037, 'eval_samples_per_second': 84.626, 'eval_steps_per_second': 5.292}
ROUND:18
CLIENT:83
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  save_steps = sys.maxsize
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:11,  3.25it/s]                                              {'loss': 1.257, 'grad_norm': 11.833093643188477, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:11,  3.25it/s]  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.541, 'grad_norm': 9.15503215789795, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]  8%|▊         | 3/40 [00:00<00:12,  2.98it/s]                                              {'loss': 1.0883, 'grad_norm': 9.902377128601074, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  2.98it/s] 10%|█         | 4/40 [00:01<00:12,  2.97it/s]                                              {'loss': 1.7336, 'grad_norm': 14.728540420532227, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.97it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.96it/s]                                              {'loss': 2.8772, 'grad_norm': 13.983534812927246, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.96it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s]                                              {'loss': 1.4175, 'grad_norm': 11.249080657958984, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.96it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.96it/s]                                              {'loss': 2.6665, 'grad_norm': 15.734185218811035, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.96it/s]                                              {'loss': 0.1914, 'grad_norm': 10.533869743347168, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.96it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.71it/s]                                              {'loss': 0.4802, 'grad_norm': 6.719245433807373, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.71it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s]                                               {'loss': 0.4955, 'grad_norm': 6.501431465148926, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.49it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s]                                               {'loss': 1.0662, 'grad_norm': 8.383070945739746, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s] 30%|███       | 12/40 [00:03<00:08,  3.20it/s]                                               {'loss': 0.4241, 'grad_norm': 5.208273410797119, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.20it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.5162, 'grad_norm': 6.896530628204346, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.761, 'grad_norm': 7.611950397491455, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.09it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s]                                               {'loss': 0.2397, 'grad_norm': 4.704747676849365, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s]                                               {'loss': 0.0134, 'grad_norm': 0.5826889276504517, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.03it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.75it/s]                                               {'loss': 0.2174, 'grad_norm': 3.284437656402588, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.75it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.2563, 'grad_norm': 2.9005255699157715, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s]                                               {'loss': 0.166, 'grad_norm': 3.965843677520752, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.35it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.4323, 'grad_norm': 7.822081565856934, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s]                                               {'loss': 0.1664, 'grad_norm': 2.857600688934326, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.1518, 'grad_norm': 2.5172476768493652, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.1975, 'grad_norm': 3.605921983718872, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.1067, 'grad_norm': 5.703952312469482, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s]                                               {'loss': 0.0405, 'grad_norm': 1.1224952936172485, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s]                                               {'loss': 0.1101, 'grad_norm': 2.8319265842437744, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s]                                               {'loss': 0.0807, 'grad_norm': 2.1943087577819824, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.35it/s] 70%|███████   | 28/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1928, 'grad_norm': 1.8210915327072144, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.22it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s]                                               {'loss': 0.1203, 'grad_norm': 2.7635626792907715, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.1581, 'grad_norm': 4.33859395980835, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.0556, 'grad_norm': 1.3249887228012085, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.1201, 'grad_norm': 12.677132606506348, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s]                                               {'loss': 0.0399, 'grad_norm': 2.1927669048309326, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s]                                               {'loss': 0.0194, 'grad_norm': 0.5587037801742554, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.0195, 'grad_norm': 0.5832874774932861, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.24it/s]                                               {'loss': 0.0163, 'grad_norm': 0.4343894124031067, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.24it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0323, 'grad_norm': 1.414115309715271, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0543, 'grad_norm': 1.9287011623382568, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.08it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.04it/s]                                               {'loss': 0.0253, 'grad_norm': 0.5873681306838989, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.04it/s]                                               {'loss': 1.9617, 'grad_norm': 5.121336936950684, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]                                               {'train_runtime': 12.2929, 'train_samples_per_second': 45.962, 'train_steps_per_second': 3.254, 'train_loss': 0.5377516902051866, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.04it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
CLIENT:1
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  return
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.10it/s]                                              {'loss': 1.8537, 'grad_norm': 9.517909049987793, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.10it/s]  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]                                              {'loss': 2.0176, 'grad_norm': 10.42408561706543, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]  8%|▊         | 3/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.4844, 'grad_norm': 18.339052200317383, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.04it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 2.4922, 'grad_norm': 18.988298416137695, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.8387, 'grad_norm': 25.256376266479492, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s]                                              {'loss': 3.3946, 'grad_norm': 18.181970596313477, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.02it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 3.2415, 'grad_norm': 17.5919132232666, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.1505, 'grad_norm': 9.861226081848145, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s]                                              {'loss': 0.8538, 'grad_norm': 9.105463027954102, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.85it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s]                                               {'loss': 1.4217, 'grad_norm': 13.182872772216797, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 0.9869, 'grad_norm': 11.016361236572266, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 1.1729, 'grad_norm': 8.946831703186035, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.9378, 'grad_norm': 8.389973640441895, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.925, 'grad_norm': 7.556166172027588, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.7886, 'grad_norm': 9.458212852478027, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.09it/s]                                               {'loss': 0.9798, 'grad_norm': 42.63365936279297, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.09it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.3518, 'grad_norm': 5.036851406097412, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s]                                               {'loss': 0.7442, 'grad_norm': 4.0329484939575195, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.61it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s]                                               {'loss': 0.5475, 'grad_norm': 5.583531379699707, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.5502, 'grad_norm': 6.913132190704346, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.3564, 'grad_norm': 7.308741569519043, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.5112, 'grad_norm': 8.644707679748535, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.5802, 'grad_norm': 13.417084693908691, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0023, 'grad_norm': 0.1904938966035843, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.3735, 'grad_norm': 6.114407062530518, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.3187, 'grad_norm': 8.801125526428223, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.2062, 'grad_norm': 7.80462121963501, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.4142, 'grad_norm': 3.7518277168273926, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.7838, 'grad_norm': 7.2521443367004395, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.139, 'grad_norm': 3.287461519241333, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.1672, 'grad_norm': 3.6874423027038574, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0069, 'grad_norm': 0.46820443868637085, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.1549, 'grad_norm': 4.008458614349365, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.0846, 'grad_norm': 6.504863739013672, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.061, 'grad_norm': 1.7820781469345093, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.3002, 'grad_norm': 0.7623728513717651, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0409, 'grad_norm': 0.8806400299072266, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.5627, 'grad_norm': 2.0364112854003906, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0516, 'grad_norm': 2.330420970916748, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0511, 'grad_norm': 4.949961185455322, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.1456, 'train_samples_per_second': 46.519, 'train_steps_per_second': 3.293, 'train_loss': 0.822502098052064, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:55
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  return
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]                                              {'loss': 1.6246, 'grad_norm': 9.488809585571289, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.97it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.4992, 'grad_norm': 11.145687103271484, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.01it/s]                                              {'loss': 2.1169, 'grad_norm': 14.902876853942871, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.01it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.7526, 'grad_norm': 10.604897499084473, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s]                                              {'loss': 2.2477, 'grad_norm': 21.888246536254883, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.02it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.0526, 'grad_norm': 11.341269493103027, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 1.9996, 'grad_norm': 16.34833526611328, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.0609, 'grad_norm': 4.84390926361084, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 0.5064, 'grad_norm': 8.54236888885498, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 0.6261, 'grad_norm': 8.550212860107422, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s]                                               {'loss': 0.8681, 'grad_norm': 9.795875549316406, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.37it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 0.8616, 'grad_norm': 14.968427658081055, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.3847, 'grad_norm': 4.138493061065674, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.658, 'grad_norm': 5.434408664703369, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.1847, 'grad_norm': 2.9915308952331543, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.5001, 'grad_norm': 30.156803131103516, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.457, 'grad_norm': 7.351365566253662, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.4399, 'grad_norm': 5.152812480926514, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.107, 'grad_norm': 1.9177210330963135, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.13, 'grad_norm': 2.899223804473877, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.1914, 'grad_norm': 3.8748791217803955, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.0733, 'grad_norm': 1.7707353830337524, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.1592, 'grad_norm': 3.4745724201202393, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0073, 'grad_norm': 0.4288259744644165, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.163, 'grad_norm': 2.5424797534942627, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.129, 'grad_norm': 3.3729493618011475, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.0413, 'grad_norm': 1.629310131072998, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.4699, 'grad_norm': 12.304213523864746, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.0416, 'grad_norm': 1.3046810626983643, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s]                                               {'loss': 0.0547, 'grad_norm': 1.9112030267715454, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.11it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.1906, 'grad_norm': 4.316671371459961, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0009, 'grad_norm': 0.04512195661664009, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.1053, 'grad_norm': 2.3638832569122314, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.0797, 'grad_norm': 1.6924684047698975, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.1018, 'grad_norm': 2.1931235790252686, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.0585, 'grad_norm': 1.7426931858062744, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.0367, 'grad_norm': 1.7198830842971802, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0387, 'grad_norm': 1.2455382347106934, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0749, 'grad_norm': 2.7053260803222656, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.1101, 'grad_norm': 8.248724937438965, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.15, 'train_samples_per_second': 46.502, 'train_steps_per_second': 3.292, 'train_loss': 0.5051442329713609, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:9
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  return
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.08it/s]                                              {'loss': 1.8346, 'grad_norm': 9.182229995727539, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.08it/s]  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.8513, 'grad_norm': 18.957122802734375, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.05it/s]  8%|▊         | 3/40 [00:00<00:12,  3.00it/s]                                              {'loss': 0.4886, 'grad_norm': 8.026936531066895, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.00it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.5052, 'grad_norm': 13.729764938354492, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s]                                              {'loss': 1.6054, 'grad_norm': 18.19001579284668, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.0145, 'grad_norm': 22.105058670043945, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.7003, 'grad_norm': 23.545978546142578, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.1353, 'grad_norm': 75.88377380371094, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 1.3542, 'grad_norm': 20.86673927307129, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.29, 'grad_norm': 9.820856094360352, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 0.644, 'grad_norm': 16.346271514892578, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 0.4495, 'grad_norm': 6.9409050941467285, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.2379, 'grad_norm': 6.226825714111328, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.4872, 'grad_norm': 6.211122035980225, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.412, 'grad_norm': 6.535575866699219, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.4045, 'grad_norm': 18.607526779174805, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.2321, 'grad_norm': 6.594171047210693, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.1499, 'grad_norm': 6.418266296386719, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.0825, 'grad_norm': 2.3726673126220703, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.154, 'grad_norm': 4.009866237640381, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.1346, 'grad_norm': 3.891601800918579, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.1349, 'grad_norm': 3.9003689289093018, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.6225, 'grad_norm': 10.767172813415527, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.1364, 'grad_norm': 10.371408462524414, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.0467, 'grad_norm': 1.6198855638504028, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s]                                               {'loss': 0.0872, 'grad_norm': 2.798102855682373, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.55it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.2417, 'grad_norm': 7.067702770233154, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.1962, 'grad_norm': 1.2318352460861206, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0486, 'grad_norm': 2.7176289558410645, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.0644, 'grad_norm': 2.305823564529419, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.3758, 'grad_norm': 7.148283958435059, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0114, 'grad_norm': 0.6410630345344543, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.2311, 'grad_norm': 4.458204746246338, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.3845, 'grad_norm': 6.702528953552246, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.0785, 'grad_norm': 2.0624256134033203, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.0416, 'grad_norm': 1.3783332109451294, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.042, 'grad_norm': 1.5424671173095703, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0435, 'grad_norm': 3.3346080780029297, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.1889, 'grad_norm': 7.219058990478516, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0303, 'grad_norm': 2.703235149383545, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.1122, 'train_samples_per_second': 46.647, 'train_steps_per_second': 3.302, 'train_loss': 0.5043377939611673, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  return
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]                                              {'loss': 1.7364, 'grad_norm': 7.990018844604492, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.95it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 1.9555, 'grad_norm': 11.521800994873047, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  2.98it/s]                                              {'loss': 1.0926, 'grad_norm': 8.556581497192383, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.98it/s] 10%|█         | 4/40 [00:01<00:12,  3.00it/s]                                              {'loss': 1.453, 'grad_norm': 12.494025230407715, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.1164, 'grad_norm': 20.337055206298828, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.01it/s] 15%|█▌        | 6/40 [00:02<00:11,  3.01it/s]                                              {'loss': 1.6365, 'grad_norm': 13.706090927124023, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 1.7127, 'grad_norm': 13.474030494689941, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 0.0565, 'grad_norm': 3.0970330238342285, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 0.426, 'grad_norm': 6.607128143310547, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 0.3885, 'grad_norm': 5.983291149139404, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s]                                               {'loss': 0.6364, 'grad_norm': 8.350248336791992, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.34it/s] 30%|███       | 12/40 [00:03<00:08,  3.23it/s]                                               {'loss': 0.6958, 'grad_norm': 5.390781879425049, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.23it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.353, 'grad_norm': 6.911700248718262, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.4589, 'grad_norm': 8.785208702087402, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.2768, 'grad_norm': 6.574305534362793, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.1136, 'grad_norm': 8.076765060424805, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s]                                               {'loss': 0.0882, 'grad_norm': 2.6292057037353516, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.81it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.0675, 'grad_norm': 2.15775990486145, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.2265, 'grad_norm': 6.100107669830322, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.0755, 'grad_norm': 1.5463095903396606, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.272, 'grad_norm': 5.993734359741211, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.3154, 'grad_norm': 6.155040264129639, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.11it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.4294, 'grad_norm': 2.8305623531341553, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0075, 'grad_norm': 0.5199587941169739, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.1016, 'grad_norm': 2.6211888790130615, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.058, 'grad_norm': 1.7814234495162964, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.0257, 'grad_norm': 0.7589267492294312, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.3586, 'grad_norm': 1.3609915971755981, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0298, 'grad_norm': 0.7231214046478271, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s]                                               {'loss': 0.0393, 'grad_norm': 1.1081180572509766, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.13it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.0218, 'grad_norm': 0.9995396137237549, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]                                               {'loss': 0.021, 'grad_norm': 1.9457699060440063, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.08it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.0127, 'grad_norm': 0.3392898738384247, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s]                                               {'loss': 0.3092, 'grad_norm': 1.1607158184051514, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.56it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s]                                               {'loss': 0.0236, 'grad_norm': 1.089223027229309, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.39it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s]                                               {'loss': 0.0295, 'grad_norm': 2.047999620437622, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.27it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0811, 'grad_norm': 5.428117275238037, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.16it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0165, 'grad_norm': 0.4759560525417328, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0127, 'grad_norm': 0.36835190653800964, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.06it/s]                                               {'loss': 0.0382, 'grad_norm': 2.3041253089904785, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.06it/s]                                               {'train_runtime': 12.2035, 'train_samples_per_second': 46.298, 'train_steps_per_second': 3.278, 'train_loss': 0.4442507565021515, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.06it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:28
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]                                              {'loss': 1.8664, 'grad_norm': 8.897327423095703, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]                                              {'loss': 0.9541, 'grad_norm': 13.054835319519043, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.98it/s]  8%|▊         | 3/40 [00:00<00:12,  3.08it/s]                                              {'loss': 1.8815, 'grad_norm': 14.400370597839355, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.08it/s] 10%|█         | 4/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.7624, 'grad_norm': 14.97284984588623, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.03it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.5991, 'grad_norm': 14.940475463867188, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.5517, 'grad_norm': 19.539663314819336, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.9222, 'grad_norm': 11.815947532653809, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 2.7682, 'grad_norm': 6.2440595626831055, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s]                                              {'loss': 1.1715, 'grad_norm': 15.380526542663574, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 1.8316, 'grad_norm': 24.92222023010254, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 0.4266, 'grad_norm': 10.952524185180664, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.31it/s]                                               {'loss': 0.8401, 'grad_norm': 15.757966995239258, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.31it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s]                                               {'loss': 0.7381, 'grad_norm': 9.085810661315918, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.21it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.8523, 'grad_norm': 8.347867012023926, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.3327, 'grad_norm': 5.270163059234619, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 1.1775, 'grad_norm': 29.390687942504883, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s]                                               {'loss': 0.4111, 'grad_norm': 5.036375045776367, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.85it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s]                                               {'loss': 0.4152, 'grad_norm': 6.082974910736084, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.60it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.5219, 'grad_norm': 8.43106746673584, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.29it/s]                                               {'loss': 0.3471, 'grad_norm': 4.453547477722168, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.29it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.366, 'grad_norm': 8.157999992370605, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.1367, 'grad_norm': 7.228172302246094, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.4132, 'grad_norm': 6.877716541290283, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0772, 'grad_norm': 5.427639484405518, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.2414, 'grad_norm': 3.7617828845977783, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.134, 'grad_norm': 5.257123947143555, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.6649, 'grad_norm': 10.882935523986816, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.32it/s]                                               {'loss': 0.256, 'grad_norm': 7.023768424987793, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.32it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.2068, 'grad_norm': 4.526600360870361, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.0767, 'grad_norm': 1.7062166929244995, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.1522, 'grad_norm': 2.9726359844207764, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0565, 'grad_norm': 3.990168809890747, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s]                                               {'loss': 0.1001, 'grad_norm': 2.4113237857818604, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.80it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.1063, 'grad_norm': 2.6905107498168945, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s]                                               {'loss': 0.0395, 'grad_norm': 1.0214043855667114, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.37it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.2227, 'grad_norm': 3.4828927516937256, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s]                                               {'loss': 0.0625, 'grad_norm': 1.5051182508468628, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.20it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0238, 'grad_norm': 0.7353003621101379, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0955, 'grad_norm': 2.416430950164795, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0093, 'grad_norm': 0.49898141622543335, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.074, 'train_samples_per_second': 46.795, 'train_steps_per_second': 3.313, 'train_loss': 0.6453145245090127, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.31it/s]
CLIENT:96
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  save_steps = sys.maxsize
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.9799, 'grad_norm': 9.018085479736328, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 2.2949, 'grad_norm': 19.99488639831543, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:11,  3.09it/s]                                              {'loss': 1.8379, 'grad_norm': 16.905189514160156, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.09it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 0.973, 'grad_norm': 20.625951766967773, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.5757, 'grad_norm': 20.318157196044922, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.8395, 'grad_norm': 17.421646118164062, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 0.9118, 'grad_norm': 10.753752708435059, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.02it/s]                                              {'loss': 4.9279, 'grad_norm': 67.78327178955078, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.02it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 0.4937, 'grad_norm': 9.47824764251709, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s]                                               {'loss': 1.0664, 'grad_norm': 14.790328979492188, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.56it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 0.9272, 'grad_norm': 6.438653469085693, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.29it/s]                                               {'loss': 1.266, 'grad_norm': 13.475240707397461, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.29it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.6751, 'grad_norm': 9.245797157287598, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.18it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.3912, 'grad_norm': 6.551154613494873, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.472, 'grad_norm': 9.120920181274414, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.0363, 'grad_norm': 1.8788400888442993, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.08it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.4865, 'grad_norm': 6.6995320320129395, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.28, 'grad_norm': 11.451617240905762, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s]                                               {'loss': 0.8359, 'grad_norm': 8.286845207214355, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.39it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.3305, 'grad_norm': 5.366678237915039, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.1055, 'grad_norm': 3.0248491764068604, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.18it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s]                                               {'loss': 0.2798, 'grad_norm': 9.031975746154785, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.13it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.6128, 'grad_norm': 7.060707092285156, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0267, 'grad_norm': 1.9899471998214722, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s]                                               {'loss': 0.0469, 'grad_norm': 1.0974668264389038, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s]                                               {'loss': 0.0495, 'grad_norm': 1.2686760425567627, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.60it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s]                                               {'loss': 0.1344, 'grad_norm': 3.036614179611206, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.44it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.053, 'grad_norm': 1.4759782552719116, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.7762, 'grad_norm': 2.1826844215393066, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s]                                               {'loss': 0.0546, 'grad_norm': 1.0619035959243774, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.17it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0916, 'grad_norm': 3.3850619792938232, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0002, 'grad_norm': 0.01566310226917267, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.0422, 'grad_norm': 1.1454542875289917, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s]                                               {'loss': 0.0354, 'grad_norm': 2.1187329292297363, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.60it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.0339, 'grad_norm': 1.2000669240951538, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0279, 'grad_norm': 0.8262677788734436, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.3171, 'grad_norm': 4.289420127868652, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.3932, 'grad_norm': 0.3873850405216217, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.1112, 'grad_norm': 36.94577407836914, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.081, 'grad_norm': 5.581958293914795, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.0596, 'train_samples_per_second': 46.851, 'train_steps_per_second': 3.317, 'train_loss': 0.6718622679192776, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:29
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  train_data = Subset(data["train"], data_indices)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.1319, 'grad_norm': 8.215337753295898, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.04it/s]  5%|▌         | 2/40 [00:00<00:12,  3.15it/s]                                              {'loss': 1.5262, 'grad_norm': 14.50454330444336, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.15it/s]  8%|▊         | 3/40 [00:00<00:11,  3.10it/s]                                              {'loss': 2.6166, 'grad_norm': 18.22285270690918, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:11,  3.10it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.8081, 'grad_norm': 21.51350975036621, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 2.4997, 'grad_norm': 21.1967716217041, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.8057, 'grad_norm': 21.41794776916504, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 2.7459, 'grad_norm': 17.583019256591797, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  3.00it/s]                                              {'loss': 0.0252, 'grad_norm': 2.5156989097595215, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s]                                              {'loss': 1.1027, 'grad_norm': 12.360892295837402, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.60it/s]                                               {'loss': 1.0695, 'grad_norm': 9.565330505371094, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.60it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 1.0997, 'grad_norm': 13.833494186401367, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 0.7416, 'grad_norm': 9.343981742858887, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.2462, 'grad_norm': 13.704235076904297, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.6856, 'grad_norm': 9.884546279907227, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.8854, 'grad_norm': 8.245965003967285, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 2.0311, 'grad_norm': 249.80006408691406, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.72it/s]                                               {'loss': 0.3356, 'grad_norm': 6.419248104095459, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.72it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s]                                               {'loss': 0.1928, 'grad_norm': 3.4098010063171387, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.51it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s]                                               {'loss': 0.8328, 'grad_norm': 6.718445301055908, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.38it/s] 50%|█████     | 20/40 [00:06<00:06,  3.26it/s]                                               {'loss': 0.6088, 'grad_norm': 14.936209678649902, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.26it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.2184, 'grad_norm': 5.034549713134766, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.17it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.462, 'grad_norm': 7.070247650146484, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.8165, 'grad_norm': 32.5782585144043, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.08it/s]                                               {'loss': 0.0171, 'grad_norm': 1.3874449729919434, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.08it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s]                                               {'loss': 0.4245, 'grad_norm': 3.3492188453674316, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s]                                               {'loss': 0.4081, 'grad_norm': 3.403247356414795, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.54it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s]                                               {'loss': 0.1215, 'grad_norm': 5.381677627563477, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s] 70%|███████   | 28/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.5678, 'grad_norm': 13.348567008972168, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.23it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s]                                               {'loss': 0.2198, 'grad_norm': 2.8321378231048584, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s]                                               {'loss': 0.2738, 'grad_norm': 9.18835735321045, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.09it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.1521, 'grad_norm': 3.2794852256774902, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.05it/s]                                               {'loss': 0.1049, 'grad_norm': 6.509781360626221, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.05it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s]                                               {'loss': 0.3806, 'grad_norm': 3.5800564289093018, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.74it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s]                                               {'loss': 0.0423, 'grad_norm': 1.6710658073425293, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s]                                               {'loss': 0.3086, 'grad_norm': 1.3866751194000244, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.36it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s]                                               {'loss': 0.147, 'grad_norm': 5.718561172485352, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.23it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.449, 'grad_norm': 27.6167049407959, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.1689, 'grad_norm': 5.9446940422058105, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.11it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.3986, 'grad_norm': 14.02079963684082, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.116, 'grad_norm': 15.994030952453613, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.2044, 'train_samples_per_second': 46.295, 'train_steps_per_second': 3.277, 'train_loss': 0.7697197061032057, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.28it/s]
CLIENT:86
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  train_data = Subset(data["train"], data_indices)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]                                              {'loss': 1.4147, 'grad_norm': 8.259997367858887, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  3.00it/s]  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.3718, 'grad_norm': 12.107730865478516, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.03it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 0.9903, 'grad_norm': 16.170879364013672, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.08it/s]                                              {'loss': 1.7428, 'grad_norm': 14.087594032287598, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.08it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.0065, 'grad_norm': 17.64537811279297, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.7157, 'grad_norm': 23.67975616455078, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 2.5737, 'grad_norm': 16.413705825805664, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 6.0714, 'grad_norm': 91.42906951904297, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 0.5741, 'grad_norm': 6.593475818634033, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s]                                               {'loss': 0.6598, 'grad_norm': 9.764138221740723, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.55it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 0.5651, 'grad_norm': 9.991267204284668, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.23it/s]                                               {'loss': 0.2671, 'grad_norm': 5.830219745635986, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.23it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.7234, 'grad_norm': 7.071809768676758, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.14it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.6397, 'grad_norm': 8.962881088256836, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.07it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 0.9176, 'grad_norm': 10.546334266662598, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.04it/s]                                               {'loss': 1.2534, 'grad_norm': 40.54832077026367, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.04it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.1147, 'grad_norm': 2.9630250930786133, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s]                                               {'loss': 0.0889, 'grad_norm': 2.37693190574646, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.55it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.6252, 'grad_norm': 3.64616060256958, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.27it/s]                                               {'loss': 0.2073, 'grad_norm': 2.297886848449707, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.27it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s]                                               {'loss': 0.096, 'grad_norm': 2.912896156311035, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.15it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.1023, 'grad_norm': 5.343310832977295, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.1937, 'grad_norm': 4.40434455871582, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.0903, 'grad_norm': 6.348537445068359, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s]                                               {'loss': 0.0668, 'grad_norm': 3.85133957862854, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.78it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.4236, 'grad_norm': 1.704047441482544, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.0518, 'grad_norm': 1.3102705478668213, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.098, 'grad_norm': 2.5115838050842285, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s]                                               {'loss': 0.1455, 'grad_norm': 3.288195848464966, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.18it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.1789, 'grad_norm': 2.194335699081421, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0711, 'grad_norm': 2.970546245574951, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.07it/s]                                               {'loss': 0.0131, 'grad_norm': 0.795326292514801, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.07it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.0844, 'grad_norm': 5.990573883056641, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s]                                               {'loss': 0.4683, 'grad_norm': 7.54477071762085, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.55it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s]                                               {'loss': 0.1328, 'grad_norm': 0.7844831943511963, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.38it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.0257, 'grad_norm': 1.3261173963546753, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0317, 'grad_norm': 0.869979202747345, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0201, 'grad_norm': 0.4942043423652649, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.10it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.03it/s]                                               {'loss': 0.0268, 'grad_norm': 1.6979165077209473, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.03it/s]                                               {'loss': 0.1196, 'grad_norm': 7.1645426750183105, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.03it/s]                                               {'train_runtime': 12.2298, 'train_samples_per_second': 46.199, 'train_steps_per_second': 3.271, 'train_loss': 0.6990883357822895, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.03it/s]100%|██████████| 40/40 [00:12<00:00,  3.27it/s]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  train_data = Subset(data["train"], data_indices)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.18it/s]                                              {'loss': 2.0909, 'grad_norm': 10.517016410827637, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.18it/s]  5%|▌         | 2/40 [00:00<00:12,  3.11it/s]                                              {'loss': 2.0287, 'grad_norm': 13.01733684539795, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.11it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 0.9637, 'grad_norm': 10.563910484313965, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.14it/s]                                              {'loss': 1.9282, 'grad_norm': 14.088607788085938, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.14it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.10it/s]                                              {'loss': 1.7362, 'grad_norm': 15.224015235900879, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.10it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.6394, 'grad_norm': 28.846206665039062, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.06it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 1.206, 'grad_norm': 15.747041702270508, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.05it/s]                                              {'loss': 9.0375, 'grad_norm': 76.32544708251953, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.05it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 0.2976, 'grad_norm': 8.834761619567871, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.61it/s]                                               {'loss': 0.856, 'grad_norm': 10.865545272827148, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.61it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s]                                               {'loss': 0.834, 'grad_norm': 13.837939262390137, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.42it/s] 30%|███       | 12/40 [00:03<00:08,  3.30it/s]                                               {'loss': 0.7502, 'grad_norm': 13.307764053344727, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.30it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.5976, 'grad_norm': 5.0119476318359375, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.25it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.20it/s]                                               {'loss': 0.6752, 'grad_norm': 8.864093780517578, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.20it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 0.3866, 'grad_norm': 6.3358025550842285, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 0.9173, 'grad_norm': 35.635196685791016, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.14it/s] 42%|████▎     | 17/40 [00:04<00:05,  3.90it/s]                                               {'loss': 0.4174, 'grad_norm': 5.619193077087402, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:04<00:05,  3.90it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.65it/s]                                               {'loss': 0.3806, 'grad_norm': 10.002933502197266, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.65it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s]                                               {'loss': 0.0903, 'grad_norm': 2.108593702316284, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s] 50%|█████     | 20/40 [00:05<00:06,  3.32it/s]                                               {'loss': 0.2578, 'grad_norm': 6.023738861083984, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:05<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s]                                               {'loss': 0.3477, 'grad_norm': 5.708120822906494, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.361, 'grad_norm': 6.09081506729126, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.2289, 'grad_norm': 5.210541248321533, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.2989, 'grad_norm': 16.156145095825195, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s]                                               {'loss': 0.1768, 'grad_norm': 5.371872425079346, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.79it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s]                                               {'loss': 0.224, 'grad_norm': 3.3260385990142822, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.58it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s]                                               {'loss': 0.0756, 'grad_norm': 2.3188552856445312, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.41it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.2472, 'grad_norm': 7.231564044952393, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1019, 'grad_norm': 4.369473934173584, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s]                                               {'loss': 0.1247, 'grad_norm': 4.597141742706299, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.15it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.2513, 'grad_norm': 5.5415239334106445, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0153, 'grad_norm': 1.1167081594467163, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.0622, 'grad_norm': 2.186004400253296, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.66it/s]                                               {'loss': 0.035, 'grad_norm': 0.7358769178390503, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.66it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.47it/s]                                               {'loss': 0.2376, 'grad_norm': 3.1359522342681885, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.47it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.1745, 'grad_norm': 7.7782769203186035, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.0647, 'grad_norm': 1.708958387374878, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0639, 'grad_norm': 1.8642282485961914, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0764, 'grad_norm': 2.441826105117798, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.1079, 'grad_norm': 4.645077705383301, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.0607, 'train_samples_per_second': 46.846, 'train_steps_per_second': 3.317, 'train_loss': 0.7591680137207731, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  train_dataset=train_data,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:43, 10.87it/s]  1%|          | 4/471 [00:00<01:08,  6.85it/s]  1%|          | 5/471 [00:00<01:13,  6.33it/s]  1%|▏         | 6/471 [00:00<01:17,  5.99it/s]  1%|▏         | 7/471 [00:01<01:20,  5.79it/s]  2%|▏         | 8/471 [00:01<01:21,  5.66it/s]  2%|▏         | 9/471 [00:01<01:22,  5.60it/s]  2%|▏         | 10/471 [00:01<01:23,  5.53it/s]  2%|▏         | 11/471 [00:01<01:23,  5.49it/s]  3%|▎         | 12/471 [00:02<01:24,  5.44it/s]  3%|▎         | 13/471 [00:02<01:24,  5.41it/s]  3%|▎         | 14/471 [00:02<01:24,  5.41it/s]  3%|▎         | 15/471 [00:02<01:24,  5.41it/s]  3%|▎         | 16/471 [00:02<01:24,  5.39it/s]  4%|▎         | 17/471 [00:02<01:24,  5.39it/s]  4%|▍         | 18/471 [00:03<01:24,  5.37it/s]  4%|▍         | 19/471 [00:03<01:24,  5.38it/s]  4%|▍         | 20/471 [00:03<01:24,  5.37it/s]  4%|▍         | 21/471 [00:03<01:23,  5.37it/s]  5%|▍         | 22/471 [00:03<01:23,  5.37it/s]  5%|▍         | 23/471 [00:04<01:23,  5.37it/s]  5%|▌         | 24/471 [00:04<01:23,  5.37it/s]  5%|▌         | 25/471 [00:04<01:22,  5.38it/s]  6%|▌         | 26/471 [00:04<01:22,  5.37it/s]  6%|▌         | 27/471 [00:04<01:22,  5.37it/s]  6%|▌         | 28/471 [00:05<01:22,  5.36it/s]  6%|▌         | 29/471 [00:05<01:22,  5.36it/s]  6%|▋         | 30/471 [00:05<01:22,  5.36it/s]  7%|▋         | 31/471 [00:05<01:22,  5.35it/s]  7%|▋         | 32/471 [00:05<01:21,  5.36it/s]  7%|▋         | 33/471 [00:05<01:21,  5.40it/s]  7%|▋         | 34/471 [00:06<01:20,  5.40it/s]  7%|▋         | 35/471 [00:06<01:20,  5.39it/s]  8%|▊         | 36/471 [00:06<01:20,  5.38it/s]  8%|▊         | 37/471 [00:06<01:21,  5.35it/s]  8%|▊         | 38/471 [00:06<01:21,  5.34it/s]  8%|▊         | 39/471 [00:07<01:20,  5.36it/s]  8%|▊         | 40/471 [00:07<01:20,  5.35it/s]  9%|▊         | 41/471 [00:07<01:20,  5.35it/s]  9%|▉         | 42/471 [00:07<01:20,  5.35it/s]  9%|▉         | 43/471 [00:07<01:20,  5.34it/s]  9%|▉         | 44/471 [00:08<01:19,  5.35it/s] 10%|▉         | 45/471 [00:08<01:19,  5.36it/s] 10%|▉         | 46/471 [00:08<01:19,  5.35it/s] 10%|▉         | 47/471 [00:08<01:19,  5.35it/s] 10%|█         | 48/471 [00:08<01:18,  5.37it/s] 10%|█         | 49/471 [00:08<01:18,  5.36it/s] 11%|█         | 50/471 [00:09<01:18,  5.35it/s] 11%|█         | 51/471 [00:09<01:18,  5.35it/s] 11%|█         | 52/471 [00:09<01:18,  5.35it/s] 11%|█▏        | 53/471 [00:09<01:18,  5.34it/s] 11%|█▏        | 54/471 [00:09<01:18,  5.33it/s] 12%|█▏        | 55/471 [00:10<01:18,  5.33it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.33it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.33it/s] 12%|█▏        | 58/471 [00:10<01:17,  5.32it/s] 13%|█▎        | 59/471 [00:10<01:17,  5.32it/s] 13%|█▎        | 60/471 [00:11<01:16,  5.34it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.34it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.32it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.32it/s] 14%|█▎        | 64/471 [00:11<01:16,  5.32it/s] 14%|█▍        | 65/471 [00:11<01:16,  5.33it/s] 14%|█▍        | 66/471 [00:12<01:16,  5.33it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.32it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.32it/s] 15%|█▍        | 69/471 [00:12<01:15,  5.32it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.32it/s] 15%|█▌        | 71/471 [00:13<01:15,  5.32it/s] 15%|█▌        | 72/471 [00:13<01:15,  5.31it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.31it/s] 16%|█▌        | 74/471 [00:13<01:14,  5.32it/s] 16%|█▌        | 75/471 [00:13<01:14,  5.35it/s] 16%|█▌        | 76/471 [00:14<01:13,  5.35it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.33it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.32it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.31it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.30it/s] 17%|█▋        | 81/471 [00:14<01:13,  5.33it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.33it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.34it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.32it/s] 18%|█▊        | 86/471 [00:15<01:12,  5.32it/s] 18%|█▊        | 87/471 [00:16<01:12,  5.32it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.34it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.34it/s] 19%|█▉        | 90/471 [00:16<01:11,  5.31it/s] 19%|█▉        | 91/471 [00:16<01:11,  5.33it/s] 20%|█▉        | 92/471 [00:17<01:11,  5.33it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.33it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.33it/s] 20%|██        | 95/471 [00:17<01:10,  5.34it/s] 20%|██        | 96/471 [00:17<01:10,  5.35it/s] 21%|██        | 97/471 [00:17<01:10,  5.33it/s] 21%|██        | 98/471 [00:18<01:10,  5.33it/s] 21%|██        | 99/471 [00:18<01:09,  5.33it/s] 21%|██        | 100/471 [00:18<01:09,  5.36it/s] 21%|██▏       | 101/471 [00:18<01:09,  5.35it/s] 22%|██▏       | 102/471 [00:18<01:09,  5.34it/s] 22%|██▏       | 103/471 [00:19<01:09,  5.33it/s] 22%|██▏       | 104/471 [00:19<01:09,  5.31it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.31it/s] 23%|██▎       | 106/471 [00:19<01:08,  5.34it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.35it/s] 23%|██▎       | 108/471 [00:20<01:07,  5.34it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.34it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.35it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.34it/s] 24%|██▍       | 112/471 [00:20<01:07,  5.33it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.36it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.35it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.34it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.34it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.32it/s] 25%|██▌       | 118/471 [00:21<01:06,  5.31it/s] 25%|██▌       | 119/471 [00:22<01:06,  5.31it/s] 25%|██▌       | 120/471 [00:22<01:06,  5.31it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.32it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.31it/s] 26%|██▌       | 123/471 [00:22<01:05,  5.31it/s] 26%|██▋       | 124/471 [00:23<01:05,  5.30it/s] 27%|██▋       | 125/471 [00:23<01:05,  5.29it/s] 27%|██▋       | 126/471 [00:23<01:05,  5.30it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.30it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.29it/s] 27%|██▋       | 129/471 [00:23<01:04,  5.31it/s] 28%|██▊       | 130/471 [00:24<01:04,  5.31it/s] 28%|██▊       | 131/471 [00:24<01:04,  5.30it/s] 28%|██▊       | 132/471 [00:24<01:04,  5.29it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.29it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.28it/s] 29%|██▊       | 135/471 [00:25<01:03,  5.28it/s] 29%|██▉       | 136/471 [00:25<01:03,  5.29it/s] 29%|██▉       | 137/471 [00:25<01:03,  5.28it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.30it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.31it/s] 30%|██▉       | 140/471 [00:26<01:02,  5.30it/s] 30%|██▉       | 141/471 [00:26<01:02,  5.31it/s] 30%|███       | 142/471 [00:26<01:02,  5.30it/s] 30%|███       | 143/471 [00:26<01:01,  5.30it/s] 31%|███       | 144/471 [00:26<01:01,  5.29it/s] 31%|███       | 145/471 [00:26<01:01,  5.32it/s] 31%|███       | 146/471 [00:27<01:01,  5.32it/s] 31%|███       | 147/471 [00:27<01:01,  5.30it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.30it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.28it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.27it/s] 32%|███▏      | 151/471 [00:28<01:00,  5.27it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.27it/s] 32%|███▏      | 153/471 [00:28<01:00,  5.27it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.29it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.28it/s] 33%|███▎      | 156/471 [00:29<00:59,  5.29it/s] 33%|███▎      | 157/471 [00:29<00:59,  5.29it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.31it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.31it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.30it/s] 34%|███▍      | 161/471 [00:30<00:58,  5.29it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.28it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.28it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.30it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.29it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.27it/s] 35%|███▌      | 167/471 [00:31<00:57,  5.27it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.26it/s] 36%|███▌      | 169/471 [00:31<00:57,  5.26it/s] 36%|███▌      | 170/471 [00:31<00:57,  5.27it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.28it/s] 37%|███▋      | 172/471 [00:32<00:56,  5.28it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.27it/s] 37%|███▋      | 174/471 [00:32<00:56,  5.26it/s] 37%|███▋      | 175/471 [00:32<00:56,  5.26it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.28it/s] 38%|███▊      | 177/471 [00:33<00:55,  5.29it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.29it/s] 38%|███▊      | 179/471 [00:33<00:55,  5.30it/s] 38%|███▊      | 180/471 [00:33<00:55,  5.28it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.28it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.28it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.28it/s] 39%|███▉      | 184/471 [00:34<00:54,  5.28it/s] 39%|███▉      | 185/471 [00:34<00:54,  5.28it/s] 39%|███▉      | 186/471 [00:34<00:54,  5.27it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.28it/s] 40%|███▉      | 188/471 [00:35<00:53,  5.25it/s] 40%|████      | 189/471 [00:35<00:53,  5.27it/s] 40%|████      | 190/471 [00:35<00:53,  5.26it/s] 41%|████      | 191/471 [00:35<00:53,  5.26it/s] 41%|████      | 192/471 [00:35<00:53,  5.26it/s] 41%|████      | 193/471 [00:36<00:52,  5.29it/s] 41%|████      | 194/471 [00:36<00:52,  5.28it/s] 41%|████▏     | 195/471 [00:36<00:52,  5.27it/s] 42%|████▏     | 196/471 [00:36<00:52,  5.28it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.30it/s] 42%|████▏     | 198/471 [00:37<00:51,  5.30it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.29it/s] 42%|████▏     | 200/471 [00:37<00:51,  5.28it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.30it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.29it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.27it/s] 43%|████▎     | 204/471 [00:38<00:50,  5.28it/s] 44%|████▎     | 205/471 [00:38<00:50,  5.29it/s] 44%|████▎     | 206/471 [00:38<00:50,  5.28it/s] 44%|████▍     | 207/471 [00:38<00:50,  5.28it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.30it/s] 44%|████▍     | 209/471 [00:39<00:49,  5.32it/s] 45%|████▍     | 210/471 [00:39<00:48,  5.33it/s] 45%|████▍     | 211/471 [00:39<00:49,  5.30it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.29it/s] 45%|████▌     | 213/471 [00:39<00:49,  5.26it/s] 45%|████▌     | 214/471 [00:40<00:48,  5.27it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.28it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.26it/s] 46%|████▌     | 217/471 [00:40<00:48,  5.27it/s] 46%|████▋     | 218/471 [00:40<00:48,  5.26it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.26it/s] 47%|████▋     | 220/471 [00:41<00:47,  5.26it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.26it/s] 47%|████▋     | 222/471 [00:41<00:47,  5.28it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.28it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.28it/s] 48%|████▊     | 225/471 [00:42<00:46,  5.27it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.26it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.26it/s] 48%|████▊     | 228/471 [00:42<00:46,  5.26it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.27it/s] 49%|████▉     | 230/471 [00:43<00:45,  5.26it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.27it/s] 49%|████▉     | 232/471 [00:43<00:45,  5.28it/s] 49%|████▉     | 233/471 [00:43<00:45,  5.28it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.27it/s] 50%|████▉     | 235/471 [00:44<00:44,  5.26it/s] 50%|█████     | 236/471 [00:44<00:44,  5.28it/s] 50%|█████     | 237/471 [00:44<00:44,  5.27it/s] 51%|█████     | 238/471 [00:44<00:44,  5.27it/s] 51%|█████     | 239/471 [00:44<00:43,  5.27it/s] 51%|█████     | 240/471 [00:44<00:43,  5.27it/s] 51%|█████     | 241/471 [00:45<00:43,  5.26it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.28it/s] 52%|█████▏    | 243/471 [00:45<00:43,  5.27it/s] 52%|█████▏    | 244/471 [00:45<00:43,  5.26it/s] 52%|█████▏    | 245/471 [00:45<00:43,  5.26it/s] 52%|█████▏    | 246/471 [00:46<00:42,  5.26it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.29it/s] 53%|█████▎    | 248/471 [00:46<00:42,  5.29it/s] 53%|█████▎    | 249/471 [00:46<00:42,  5.28it/s] 53%|█████▎    | 250/471 [00:46<00:41,  5.27it/s] 53%|█████▎    | 251/471 [00:47<00:41,  5.26it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.26it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.25it/s] 54%|█████▍    | 254/471 [00:47<00:41,  5.24it/s] 54%|█████▍    | 255/471 [00:47<00:41,  5.25it/s] 54%|█████▍    | 256/471 [00:48<00:40,  5.25it/s] 55%|█████▍    | 257/471 [00:48<00:40,  5.25it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.25it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.25it/s] 55%|█████▌    | 260/471 [00:48<00:40,  5.25it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.26it/s] 56%|█████▌    | 262/471 [00:49<00:39,  5.26it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.26it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.26it/s] 56%|█████▋    | 265/471 [00:49<00:39,  5.26it/s] 56%|█████▋    | 266/471 [00:49<00:38,  5.26it/s] 57%|█████▋    | 267/471 [00:50<00:38,  5.26it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.26it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.26it/s] 57%|█████▋    | 270/471 [00:50<00:38,  5.26it/s] 58%|█████▊    | 271/471 [00:50<00:37,  5.26it/s] 58%|█████▊    | 272/471 [00:51<00:37,  5.29it/s] 58%|█████▊    | 273/471 [00:51<00:37,  5.29it/s] 58%|█████▊    | 274/471 [00:51<00:37,  5.30it/s] 58%|█████▊    | 275/471 [00:51<00:36,  5.30it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.28it/s] 59%|█████▉    | 277/471 [00:52<00:36,  5.28it/s] 59%|█████▉    | 278/471 [00:52<00:36,  5.27it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.28it/s] 59%|█████▉    | 280/471 [00:52<00:36,  5.28it/s] 60%|█████▉    | 281/471 [00:52<00:36,  5.27it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.27it/s] 60%|██████    | 283/471 [00:53<00:35,  5.26it/s] 60%|██████    | 284/471 [00:53<00:35,  5.27it/s] 61%|██████    | 285/471 [00:53<00:35,  5.26it/s] 61%|██████    | 286/471 [00:53<00:35,  5.26it/s] 61%|██████    | 287/471 [00:53<00:35,  5.25it/s] 61%|██████    | 288/471 [00:54<00:34,  5.24it/s] 61%|██████▏   | 289/471 [00:54<00:34,  5.26it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.27it/s] 62%|██████▏   | 291/471 [00:54<00:34,  5.27it/s] 62%|██████▏   | 292/471 [00:54<00:33,  5.27it/s] 62%|██████▏   | 293/471 [00:55<00:33,  5.28it/s] 62%|██████▏   | 294/471 [00:55<00:33,  5.28it/s] 63%|██████▎   | 295/471 [00:55<00:33,  5.29it/s] 63%|██████▎   | 296/471 [00:55<00:33,  5.30it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.30it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.27it/s] 63%|██████▎   | 299/471 [00:56<00:32,  5.28it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.28it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.26it/s] 64%|██████▍   | 302/471 [00:56<00:32,  5.27it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.27it/s] 65%|██████▍   | 304/471 [00:57<00:31,  5.28it/s] 65%|██████▍   | 305/471 [00:57<00:31,  5.27it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.25it/s] 65%|██████▌   | 307/471 [00:57<00:31,  5.26it/s] 65%|██████▌   | 308/471 [00:57<00:31,  5.25it/s] 66%|██████▌   | 309/471 [00:58<00:30,  5.26it/s] 66%|██████▌   | 310/471 [00:58<00:30,  5.27it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.26it/s] 66%|██████▌   | 312/471 [00:58<00:30,  5.28it/s] 66%|██████▋   | 313/471 [00:58<00:29,  5.28it/s] 67%|██████▋   | 314/471 [00:59<00:29,  5.28it/s] 67%|██████▋   | 315/471 [00:59<00:29,  5.27it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.28it/s] 67%|██████▋   | 317/471 [00:59<00:29,  5.29it/s] 68%|██████▊   | 318/471 [00:59<00:28,  5.28it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.28it/s] 68%|██████▊   | 320/471 [01:00<00:28,  5.26it/s] 68%|██████▊   | 321/471 [01:00<00:28,  5.25it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.25it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.24it/s] 69%|██████▉   | 324/471 [01:00<00:28,  5.25it/s] 69%|██████▉   | 325/471 [01:01<00:27,  5.25it/s] 69%|██████▉   | 326/471 [01:01<00:27,  5.26it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.27it/s] 70%|██████▉   | 328/471 [01:01<00:27,  5.26it/s] 70%|██████▉   | 329/471 [01:01<00:27,  5.26it/s] 70%|███████   | 330/471 [01:02<00:26,  5.29it/s] 70%|███████   | 331/471 [01:02<00:26,  5.28it/s] 70%|███████   | 332/471 [01:02<00:26,  5.26it/s] 71%|███████   | 333/471 [01:02<00:26,  5.27it/s] 71%|███████   | 334/471 [01:02<00:26,  5.26it/s] 71%|███████   | 335/471 [01:03<00:25,  5.26it/s] 71%|███████▏  | 336/471 [01:03<00:25,  5.27it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.29it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.28it/s] 72%|███████▏  | 339/471 [01:03<00:25,  5.26it/s] 72%|███████▏  | 340/471 [01:03<00:24,  5.27it/s] 72%|███████▏  | 341/471 [01:04<00:24,  5.27it/s] 73%|███████▎  | 342/471 [01:04<00:24,  5.28it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.27it/s] 73%|███████▎  | 344/471 [01:04<00:24,  5.28it/s] 73%|███████▎  | 345/471 [01:04<00:23,  5.28it/s] 73%|███████▎  | 346/471 [01:05<00:23,  5.27it/s] 74%|███████▎  | 347/471 [01:05<00:23,  5.30it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.30it/s] 74%|███████▍  | 349/471 [01:05<00:23,  5.29it/s] 74%|███████▍  | 350/471 [01:05<00:22,  5.27it/s] 75%|███████▍  | 351/471 [01:06<00:22,  5.29it/s] 75%|███████▍  | 352/471 [01:06<00:22,  5.28it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.27it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.27it/s] 75%|███████▌  | 355/471 [01:06<00:22,  5.26it/s] 76%|███████▌  | 356/471 [01:06<00:21,  5.26it/s] 76%|███████▌  | 357/471 [01:07<00:21,  5.26it/s] 76%|███████▌  | 358/471 [01:07<00:21,  5.26it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.27it/s] 76%|███████▋  | 360/471 [01:07<00:21,  5.26it/s] 77%|███████▋  | 361/471 [01:07<00:20,  5.27it/s] 77%|███████▋  | 362/471 [01:08<00:20,  5.28it/s] 77%|███████▋  | 363/471 [01:08<00:20,  5.27it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.27it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.27it/s] 78%|███████▊  | 366/471 [01:08<00:19,  5.26it/s] 78%|███████▊  | 367/471 [01:09<00:19,  5.27it/s] 78%|███████▊  | 368/471 [01:09<00:19,  5.26it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.28it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.27it/s] 79%|███████▉  | 371/471 [01:09<00:18,  5.27it/s] 79%|███████▉  | 372/471 [01:10<00:18,  5.28it/s] 79%|███████▉  | 373/471 [01:10<00:18,  5.26it/s] 79%|███████▉  | 374/471 [01:10<00:18,  5.28it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.28it/s] 80%|███████▉  | 376/471 [01:10<00:17,  5.29it/s] 80%|████████  | 377/471 [01:10<00:17,  5.30it/s] 80%|████████  | 378/471 [01:11<00:17,  5.32it/s] 80%|████████  | 379/471 [01:11<00:17,  5.28it/s] 81%|████████  | 380/471 [01:11<00:17,  5.28it/s] 81%|████████  | 381/471 [01:11<00:17,  5.29it/s] 81%|████████  | 382/471 [01:11<00:16,  5.28it/s] 81%|████████▏ | 383/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 384/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.26it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.27it/s] 82%|████████▏ | 387/471 [01:12<00:15,  5.26it/s] 82%|████████▏ | 388/471 [01:13<00:15,  5.26it/s] 83%|████████▎ | 389/471 [01:13<00:15,  5.26it/s] 83%|████████▎ | 390/471 [01:13<00:15,  5.27it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.27it/s] 83%|████████▎ | 392/471 [01:13<00:14,  5.27it/s] 83%|████████▎ | 393/471 [01:14<00:14,  5.28it/s] 84%|████████▎ | 394/471 [01:14<00:14,  5.26it/s] 84%|████████▍ | 395/471 [01:14<00:14,  5.25it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.27it/s] 84%|████████▍ | 397/471 [01:14<00:14,  5.28it/s] 85%|████████▍ | 398/471 [01:14<00:13,  5.28it/s] 85%|████████▍ | 399/471 [01:15<00:13,  5.25it/s] 85%|████████▍ | 400/471 [01:15<00:13,  5.26it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.28it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.28it/s] 86%|████████▌ | 403/471 [01:15<00:12,  5.28it/s] 86%|████████▌ | 404/471 [01:16<00:12,  5.27it/s] 86%|████████▌ | 405/471 [01:16<00:12,  5.25it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.27it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.28it/s] 87%|████████▋ | 408/471 [01:16<00:11,  5.28it/s] 87%|████████▋ | 409/471 [01:17<00:11,  5.27it/s] 87%|████████▋ | 410/471 [01:17<00:11,  5.28it/s] 87%|████████▋ | 411/471 [01:17<00:11,  5.30it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.29it/s] 88%|████████▊ | 413/471 [01:17<00:10,  5.30it/s] 88%|████████▊ | 414/471 [01:17<00:10,  5.28it/s] 88%|████████▊ | 415/471 [01:18<00:10,  5.29it/s] 88%|████████▊ | 416/471 [01:18<00:10,  5.27it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.29it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.28it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.28it/s] 89%|████████▉ | 420/471 [01:19<00:09,  5.30it/s] 89%|████████▉ | 421/471 [01:19<00:09,  5.29it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.29it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.30it/s] 90%|█████████ | 424/471 [01:19<00:08,  5.29it/s] 90%|█████████ | 425/471 [01:20<00:08,  5.31it/s] 90%|█████████ | 426/471 [01:20<00:08,  5.28it/s] 91%|█████████ | 427/471 [01:20<00:08,  5.28it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.27it/s] 91%|█████████ | 429/471 [01:20<00:07,  5.27it/s] 91%|█████████▏| 430/471 [01:21<00:07,  5.28it/s] 92%|█████████▏| 431/471 [01:21<00:07,  5.25it/s] 92%|█████████▏| 432/471 [01:21<00:07,  5.27it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.26it/s] 92%|█████████▏| 434/471 [01:21<00:07,  5.27it/s] 92%|█████████▏| 435/471 [01:21<00:06,  5.26it/s] 93%|█████████▎| 436/471 [01:22<00:06,  5.28it/s] 93%|█████████▎| 437/471 [01:22<00:06,  5.25it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.27it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.27it/s] 93%|█████████▎| 440/471 [01:22<00:05,  5.28it/s] 94%|█████████▎| 441/471 [01:23<00:05,  5.28it/s] 94%|█████████▍| 442/471 [01:23<00:05,  5.29it/s] 94%|█████████▍| 443/471 [01:23<00:05,  5.29it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.27it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.26it/s] 95%|█████████▍| 446/471 [01:24<00:04,  5.25it/s] 95%|█████████▍| 447/471 [01:24<00:04,  5.26it/s] 95%|█████████▌| 448/471 [01:24<00:04,  5.28it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.27it/s] 96%|█████████▌| 450/471 [01:24<00:03,  5.26it/s] 96%|█████████▌| 451/471 [01:25<00:03,  5.27it/s] 96%|█████████▌| 452/471 [01:25<00:03,  5.26it/s] 96%|█████████▌| 453/471 [01:25<00:03,  5.25it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.25it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.25it/s] 97%|█████████▋| 456/471 [01:25<00:02,  5.27it/s] 97%|█████████▋| 457/471 [01:26<00:02,  5.26it/s] 97%|█████████▋| 458/471 [01:26<00:02,  5.27it/s] 97%|█████████▋| 459/471 [01:26<00:02,  5.29it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.29it/s] 98%|█████████▊| 461/471 [01:26<00:01,  5.28it/s] 98%|█████████▊| 462/471 [01:27<00:01,  5.26it/s] 98%|█████████▊| 463/471 [01:27<00:01,  5.27it/s] 99%|█████████▊| 464/471 [01:27<00:01,  5.27it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.28it/s] 99%|█████████▉| 466/471 [01:27<00:00,  5.27it/s] 99%|█████████▉| 467/471 [01:28<00:00,  5.26it/s] 99%|█████████▉| 468/471 [01:28<00:00,  5.25it/s]100%|█████████▉| 469/471 [01:28<00:00,  5.25it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.25it/s]100%|██████████| 471/471 [01:28<00:00,  5.62it/s]100%|██████████| 471/471 [01:28<00:00,  5.31it/s]
{'eval_loss': 1.845204472541809, 'eval_model_preparation_time': 0.0053, 'eval_acc': 0.5033191715347849, 'eval_runtime': 88.9358, 'eval_samples_per_second': 84.69, 'eval_steps_per_second': 5.296}
ROUND:19
CLIENT:83
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  # with open('./save/cov_72.txt', 'w') as file:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.0899, 'grad_norm': 12.043916702270508, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.01it/s]  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]                                              {'loss': 1.3392, 'grad_norm': 9.542104721069336, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  2.97it/s]  8%|▊         | 3/40 [00:01<00:12,  2.97it/s]                                              {'loss': 1.0084, 'grad_norm': 10.552656173706055, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:01<00:12,  2.97it/s] 10%|█         | 4/40 [00:01<00:12,  2.97it/s]                                              {'loss': 1.658, 'grad_norm': 16.213016510009766, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:12,  2.97it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s]                                              {'loss': 2.7077, 'grad_norm': 14.726058006286621, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.97it/s] 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s]                                              {'loss': 1.2812, 'grad_norm': 11.413104057312012, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:02<00:11,  2.97it/s] 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 2.6629, 'grad_norm': 16.796409606933594, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:11,  2.97it/s]                                              {'loss': 0.2555, 'grad_norm': 15.68707275390625, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  2.97it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s]                                              {'loss': 0.4142, 'grad_norm': 5.97102165222168, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.73it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s]                                               {'loss': 0.4216, 'grad_norm': 6.160075664520264, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.50it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s]                                               {'loss': 1.0339, 'grad_norm': 9.252090454101562, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.32it/s] 30%|███       | 12/40 [00:03<00:08,  3.21it/s]                                               {'loss': 0.4419, 'grad_norm': 6.767535209655762, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.21it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.4549, 'grad_norm': 6.434848308563232, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.15it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s]                                               {'loss': 0.6771, 'grad_norm': 8.072922706604004, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.08it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s]                                               {'loss': 0.2046, 'grad_norm': 4.399210453033447, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.03it/s]                                               {'loss': 0.0138, 'grad_norm': 0.6525732278823853, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.03it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s]                                               {'loss': 0.1261, 'grad_norm': 2.7398362159729004, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.74it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s]                                               {'loss': 0.2212, 'grad_norm': 2.4896202087402344, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.52it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.34it/s]                                               {'loss': 0.3321, 'grad_norm': 8.75854206085205, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.34it/s] 50%|█████     | 20/40 [00:06<00:06,  3.24it/s]                                               {'loss': 0.4289, 'grad_norm': 9.8560791015625, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.24it/s] 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s]                                               {'loss': 0.1845, 'grad_norm': 5.617844581604004, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:06,  3.14it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s]                                               {'loss': 0.1442, 'grad_norm': 2.514643907546997, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.09it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.2607, 'grad_norm': 4.108565330505371, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.05it/s]                                               {'loss': 0.0749, 'grad_norm': 3.651449680328369, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.05it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s]                                               {'loss': 0.042, 'grad_norm': 0.9850815534591675, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.76it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s]                                               {'loss': 0.1133, 'grad_norm': 3.2053959369659424, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.51it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s]                                               {'loss': 0.1369, 'grad_norm': 4.322726726531982, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.34it/s] 70%|███████   | 28/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.2268, 'grad_norm': 3.5498273372650146, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.23it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s]                                               {'loss': 0.0638, 'grad_norm': 1.4387986660003662, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.15it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s]                                               {'loss': 0.0816, 'grad_norm': 3.002967596054077, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.10it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.0532, 'grad_norm': 1.3853880167007446, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.06it/s]                                               {'loss': 0.191, 'grad_norm': 21.476957321166992, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.06it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s]                                               {'loss': 0.0215, 'grad_norm': 0.45744696259498596, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.76it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s]                                               {'loss': 0.0224, 'grad_norm': 0.5743259191513062, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.52it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s]                                               {'loss': 0.024, 'grad_norm': 0.9293933510780334, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s] 90%|█████████ | 36/40 [00:11<00:01,  3.21it/s]                                               {'loss': 0.0393, 'grad_norm': 1.2468256950378418, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:11<00:01,  3.21it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.0228, 'grad_norm': 0.9719815850257874, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.15it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0608, 'grad_norm': 2.3822500705718994, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.09it/s] 98%|█████████▊| 39/40 [00:12<00:00,  3.03it/s]                                               {'loss': 0.0199, 'grad_norm': 0.5182342529296875, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:12<00:00,  3.03it/s]                                               {'loss': 2.0693, 'grad_norm': 5.382467746734619, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.03it/s]                                               {'train_runtime': 12.3203, 'train_samples_per_second': 45.859, 'train_steps_per_second': 3.247, 'train_loss': 0.5156451176619157, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.03it/s]100%|██████████| 40/40 [00:12<00:00,  3.25it/s]
CLIENT:1
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  #         file.write(str(item) + '\n')
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.6713, 'grad_norm': 8.87541389465332, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]                                              {'loss': 1.8714, 'grad_norm': 10.603236198425293, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 2.17, 'grad_norm': 20.34817123413086, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 2.3257, 'grad_norm': 20.845685958862305, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s]                                              {'loss': 2.0936, 'grad_norm': 26.122970581054688, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  2.99it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 3.2958, 'grad_norm': 20.551610946655273, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 3.0319, 'grad_norm': 19.66954231262207, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.00it/s]                                              {'loss': 0.1004, 'grad_norm': 7.247396945953369, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.00it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 0.7657, 'grad_norm': 9.725101470947266, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 1.1688, 'grad_norm': 14.422035217285156, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 1.048, 'grad_norm': 17.921268463134766, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 1.0339, 'grad_norm': 9.876886367797852, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 0.799, 'grad_norm': 9.364385604858398, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.8525, 'grad_norm': 7.898398399353027, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.16it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.646, 'grad_norm': 9.937161445617676, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.11it/s]                                               {'loss': 2.0379, 'grad_norm': 56.00718688964844, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.11it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s]                                               {'loss': 0.4615, 'grad_norm': 10.711325645446777, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.83it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s]                                               {'loss': 0.7005, 'grad_norm': 4.0029215812683105, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.58it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s]                                               {'loss': 0.4952, 'grad_norm': 4.535582542419434, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.43it/s] 50%|█████     | 20/40 [00:06<00:06,  3.30it/s]                                               {'loss': 0.6589, 'grad_norm': 8.38545036315918, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.30it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.3846, 'grad_norm': 6.944745063781738, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.6514, 'grad_norm': 8.875584602355957, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.3499, 'grad_norm': 7.443758487701416, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.10it/s]                                               {'loss': 0.0061, 'grad_norm': 0.4470927119255066, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.10it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.31, 'grad_norm': 5.939217567443848, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.164, 'grad_norm': 4.731532096862793, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.1828, 'grad_norm': 4.721697807312012, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.29it/s]                                               {'loss': 0.3638, 'grad_norm': 2.8001503944396973, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.29it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.5691, 'grad_norm': 6.86065673828125, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.1394, 'grad_norm': 3.2009928226470947, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0896, 'grad_norm': 2.108372211456299, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0172, 'grad_norm': 1.1992244720458984, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.72it/s]                                               {'loss': 0.0743, 'grad_norm': 1.6951817274093628, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.72it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.49it/s]                                               {'loss': 0.1003, 'grad_norm': 17.059900283813477, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.49it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s]                                               {'loss': 0.0549, 'grad_norm': 1.9216479063034058, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.35it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s]                                               {'loss': 0.3003, 'grad_norm': 1.435934066772461, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.25it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.076, 'grad_norm': 3.1907498836517334, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.17it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.5571, 'grad_norm': 4.07034158706665, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.06, 'grad_norm': 1.855301856994629, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.09it/s]                                               {'loss': 0.0573, 'grad_norm': 4.518184185028076, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.09it/s]                                               {'train_runtime': 12.1493, 'train_samples_per_second': 46.505, 'train_steps_per_second': 3.292, 'train_loss': 0.7934075556579046, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.09it/s]100%|██████████| 40/40 [00:12<00:00,  3.29it/s]
CLIENT:55
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  #     for item in coefficient_of_variation:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.4773, 'grad_norm': 9.56664752960205, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]                                              {'loss': 1.4568, 'grad_norm': 10.825738906860352, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.01it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 2.0311, 'grad_norm': 15.601420402526855, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.00it/s]                                              {'loss': 1.6055, 'grad_norm': 10.707435607910156, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.00it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 2.0556, 'grad_norm': 16.17296028137207, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.0088, 'grad_norm': 10.929606437683105, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.01it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.982, 'grad_norm': 16.418561935424805, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.0301, 'grad_norm': 2.127915859222412, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s]                                              {'loss': 0.362, 'grad_norm': 6.955910682678223, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.78it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s]                                               {'loss': 0.5001, 'grad_norm': 7.7030768394470215, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.54it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.803, 'grad_norm': 9.806111335754395, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.27it/s]                                               {'loss': 0.9761, 'grad_norm': 28.408689498901367, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.27it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.4138, 'grad_norm': 5.059671401977539, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.5274, 'grad_norm': 4.4409589767456055, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.12it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.1716, 'grad_norm': 3.157104969024658, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.5434, 'grad_norm': 34.081912994384766, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.2242, 'grad_norm': 4.003937721252441, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.3836, 'grad_norm': 5.868508338928223, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s]                                               {'loss': 0.0823, 'grad_norm': 1.5087554454803467, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.40it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.0581, 'grad_norm': 1.1229771375656128, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.1115, 'grad_norm': 2.5307323932647705, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.1228, 'grad_norm': 5.903787612915039, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.2121, 'grad_norm': 5.634392738342285, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0016, 'grad_norm': 0.11610400676727295, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.0408, 'grad_norm': 1.3753371238708496, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.0307, 'grad_norm': 1.0009387731552124, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.0319, 'grad_norm': 1.343990445137024, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.1185, 'grad_norm': 4.535741329193115, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s]                                               {'loss': 0.0208, 'grad_norm': 0.6546249389648438, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.19it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s]                                               {'loss': 0.0418, 'grad_norm': 1.708729863166809, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.12it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.198, 'grad_norm': 4.815678119659424, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0009, 'grad_norm': 0.048493921756744385, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.043, 'grad_norm': 0.8870580196380615, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.0303, 'grad_norm': 1.3306483030319214, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.1107, 'grad_norm': 5.204282760620117, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.0579, 'grad_norm': 3.1980886459350586, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s]                                               {'loss': 0.036, 'grad_norm': 1.6665853261947632, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.19it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.05, 'grad_norm': 4.487427234649658, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.13it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.1202, 'grad_norm': 4.522505283355713, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.08it/s]                                               {'loss': 0.0556, 'grad_norm': 4.131760120391846, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.08it/s]                                               {'train_runtime': 12.1251, 'train_samples_per_second': 46.597, 'train_steps_per_second': 3.299, 'train_loss': 0.45319639734370865, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.08it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:9
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  #     for item in coefficient_of_variation:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.10it/s]                                              {'loss': 1.6656, 'grad_norm': 9.299426078796387, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.10it/s]  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]                                              {'loss': 1.5898, 'grad_norm': 19.046226501464844, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.06it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 0.4026, 'grad_norm': 7.267253875732422, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.437, 'grad_norm': 13.954300880432129, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.3427, 'grad_norm': 17.21062660217285, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.05it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.7307, 'grad_norm': 19.957233428955078, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.4036, 'grad_norm': 22.74462890625, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.5364, 'grad_norm': 47.3375129699707, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s]                                              {'loss': 1.2104, 'grad_norm': 26.6782169342041, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.81it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s]                                               {'loss': 0.3822, 'grad_norm': 12.12850570678711, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.59it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 0.3956, 'grad_norm': 9.927041053771973, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.29it/s]                                               {'loss': 0.4791, 'grad_norm': 15.191364288330078, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.29it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.2062, 'grad_norm': 5.651034355163574, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s]                                               {'loss': 0.3832, 'grad_norm': 7.5267109870910645, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.15it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 0.464, 'grad_norm': 7.717500686645508, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.14it/s]                                               {'loss': 0.4791, 'grad_norm': 17.839895248413086, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.14it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.91it/s]                                               {'loss': 0.7556, 'grad_norm': 7.951886177062988, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.91it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.64it/s]                                               {'loss': 0.1755, 'grad_norm': 5.044119358062744, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.64it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s]                                               {'loss': 0.0886, 'grad_norm': 2.302941083908081, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s] 50%|█████     | 20/40 [00:06<00:06,  3.33it/s]                                               {'loss': 0.1536, 'grad_norm': 4.01509952545166, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.33it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s]                                               {'loss': 0.3111, 'grad_norm': 6.130533695220947, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.22it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.0963, 'grad_norm': 3.264467716217041, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.464, 'grad_norm': 7.460040092468262, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.1419, 'grad_norm': 11.879484176635742, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.12it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s]                                               {'loss': 0.0762, 'grad_norm': 3.610687732696533, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.83it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s]                                               {'loss': 0.1455, 'grad_norm': 5.21467924118042, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.57it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s]                                               {'loss': 0.079, 'grad_norm': 2.3687541484832764, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.40it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.2142, 'grad_norm': 1.9757143259048462, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s]                                               {'loss': 0.0474, 'grad_norm': 1.711696982383728, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.21it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.1102, 'grad_norm': 3.8033010959625244, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.2348, 'grad_norm': 8.800236701965332, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.12it/s]                                               {'loss': 0.0115, 'grad_norm': 0.7432397603988647, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.12it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s]                                               {'loss': 0.1141, 'grad_norm': 3.7337629795074463, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.82it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.1734, 'grad_norm': 0.7744593024253845, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s]                                               {'loss': 0.0789, 'grad_norm': 2.469972610473633, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.43it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.0261, 'grad_norm': 0.7135815024375916, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.0304, 'grad_norm': 1.447869062423706, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s]                                               {'loss': 0.0306, 'grad_norm': 0.9474561214447021, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.14it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.1087, 'grad_norm': 3.494459867477417, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.10it/s]                                               {'loss': 0.0086, 'grad_norm': 0.5948823094367981, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.10it/s]                                               {'train_runtime': 12.0275, 'train_samples_per_second': 46.976, 'train_steps_per_second': 3.326, 'train_loss': 0.4446140093263239, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.10it/s]100%|██████████| 40/40 [00:12<00:00,  3.33it/s]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  #     for item in coefficient_of_variation:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.6243, 'grad_norm': 8.214461326599121, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.8206, 'grad_norm': 12.242591857910156, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.02it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.0242, 'grad_norm': 8.938586235046387, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.01it/s]                                              {'loss': 1.338, 'grad_norm': 11.871526718139648, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.01it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.9421, 'grad_norm': 22.695295333862305, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.06it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.4829, 'grad_norm': 13.910978317260742, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 1.7019, 'grad_norm': 14.346780776977539, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.01it/s]                                              {'loss': 0.049, 'grad_norm': 2.8806824684143066, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.01it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 0.3664, 'grad_norm': 6.9571003913879395, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s]                                               {'loss': 0.3756, 'grad_norm': 5.864259243011475, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.53it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s]                                               {'loss': 0.5635, 'grad_norm': 7.734288215637207, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.36it/s] 30%|███       | 12/40 [00:03<00:08,  3.25it/s]                                               {'loss': 0.6, 'grad_norm': 4.758230209350586, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.25it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s]                                               {'loss': 0.3269, 'grad_norm': 6.7645673751831055, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.16it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s]                                               {'loss': 0.3638, 'grad_norm': 7.463254928588867, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.11it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.2071, 'grad_norm': 6.269181251525879, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.1422, 'grad_norm': 12.949079513549805, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s]                                               {'loss': 0.0787, 'grad_norm': 2.5973362922668457, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.80it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s]                                               {'loss': 0.0745, 'grad_norm': 3.67409348487854, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.56it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 0.1711, 'grad_norm': 5.759092807769775, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.0761, 'grad_norm': 1.5758103132247925, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s]                                               {'loss': 0.3822, 'grad_norm': 8.086953163146973, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.19it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s]                                               {'loss': 0.3315, 'grad_norm': 6.945078372955322, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.12it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.3973, 'grad_norm': 2.5338587760925293, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0079, 'grad_norm': 0.603685200214386, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s]                                               {'loss': 0.1357, 'grad_norm': 4.030235290527344, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.80it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s]                                               {'loss': 0.0603, 'grad_norm': 1.393129587173462, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.56it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s]                                               {'loss': 0.0351, 'grad_norm': 1.0719053745269775, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.39it/s] 70%|███████   | 28/40 [00:08<00:03,  3.28it/s]                                               {'loss': 0.354, 'grad_norm': 2.397416830062866, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.28it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0183, 'grad_norm': 0.5235593318939209, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.0793, 'grad_norm': 2.986318588256836, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.023, 'grad_norm': 1.0380290746688843, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.09it/s]                                               {'loss': 0.0524, 'grad_norm': 6.565026760101318, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.09it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s]                                               {'loss': 0.0169, 'grad_norm': 0.632610559463501, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.81it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.3257, 'grad_norm': 6.853754997253418, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s]                                               {'loss': 0.035, 'grad_norm': 1.1706511974334717, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.41it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s]                                               {'loss': 0.0218, 'grad_norm': 0.6795186400413513, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.28it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s]                                               {'loss': 0.024, 'grad_norm': 0.7762858271598816, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.18it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0166, 'grad_norm': 0.5203278660774231, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.12it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.0109, 'grad_norm': 0.44049379229545593, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.07it/s]                                               {'loss': 0.1767, 'grad_norm': 11.246447563171387, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.07it/s]                                               {'train_runtime': 12.1288, 'train_samples_per_second': 46.583, 'train_steps_per_second': 3.298, 'train_loss': 0.4208303748164326, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.07it/s]100%|██████████| 40/40 [00:12<00:00,  3.30it/s]
CLIENT:28
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  #     for item in coefficient_of_variation:
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]                                              {'loss': 1.7204, 'grad_norm': 8.875008583068848, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:13,  2.98it/s]  5%|▌         | 2/40 [00:00<00:12,  3.10it/s]                                              {'loss': 0.8757, 'grad_norm': 10.071816444396973, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.10it/s]  8%|▊         | 3/40 [00:00<00:12,  3.07it/s]                                              {'loss': 1.7172, 'grad_norm': 14.231413841247559, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.07it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.6239, 'grad_norm': 14.716665267944336, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.11it/s]                                              {'loss': 1.4639, 'grad_norm': 14.675298690795898, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.11it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.08it/s]                                              {'loss': 1.4055, 'grad_norm': 23.7876033782959, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.08it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 0.8911, 'grad_norm': 13.209216117858887, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.06it/s]                                              {'loss': 2.6946, 'grad_norm': 6.441689491271973, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.06it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s]                                              {'loss': 1.2978, 'grad_norm': 19.110984802246094, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.82it/s] 25%|██▌       | 10/40 [00:02<00:08,  3.59it/s]                                               {'loss': 1.7801, 'grad_norm': 27.424341201782227, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:02<00:08,  3.59it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.45it/s]                                               {'loss': 0.5391, 'grad_norm': 14.083916664123535, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.45it/s] 30%|███       | 12/40 [00:03<00:08,  3.32it/s]                                               {'loss': 0.5866, 'grad_norm': 11.861924171447754, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.32it/s] 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s]                                               {'loss': 0.7955, 'grad_norm': 10.028343200683594, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:03<00:08,  3.22it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s]                                               {'loss': 0.707, 'grad_norm': 8.581491470336914, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.17it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.2551, 'grad_norm': 5.40545654296875, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 1.1321, 'grad_norm': 31.386001586914062, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.12it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s]                                               {'loss': 0.2602, 'grad_norm': 3.6217052936553955, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.87it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s]                                               {'loss': 0.4488, 'grad_norm': 7.562959671020508, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s]                                               {'loss': 0.4072, 'grad_norm': 7.110726356506348, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.44it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.3633, 'grad_norm': 5.050583839416504, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s]                                               {'loss': 0.2661, 'grad_norm': 6.562154293060303, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.0937, 'grad_norm': 6.587904930114746, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s] 57%|█████▊    | 23/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.4944, 'grad_norm': 10.18619155883789, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:06<00:05,  3.11it/s]                                               {'loss': 0.0801, 'grad_norm': 8.85762882232666, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s]                                               {'loss': 0.2811, 'grad_norm': 4.556478023529053, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.85it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s]                                               {'loss': 0.0563, 'grad_norm': 1.8055140972137451, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.61it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.6082, 'grad_norm': 11.97848129272461, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.31it/s]                                               {'loss': 0.1492, 'grad_norm': 4.561135768890381, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.31it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1386, 'grad_norm': 3.48846435546875, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.0562, 'grad_norm': 1.33585524559021, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.1484, 'grad_norm': 3.0035531520843506, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.316, 'grad_norm': 23.349803924560547, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s]                                               {'loss': 0.0964, 'grad_norm': 2.5432772636413574, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.83it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s]                                               {'loss': 0.1086, 'grad_norm': 3.1692802906036377, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.57it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s]                                               {'loss': 0.0533, 'grad_norm': 1.4945313930511475, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.40it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s]                                               {'loss': 0.3071, 'grad_norm': 5.78936243057251, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.31it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s]                                               {'loss': 0.0656, 'grad_norm': 1.637341856956482, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.23it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0389, 'grad_norm': 2.310849905014038, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0888, 'grad_norm': 2.7965667247772217, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0149, 'grad_norm': 0.6740881204605103, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 11.99, 'train_samples_per_second': 47.123, 'train_steps_per_second': 3.336, 'train_loss': 0.6106747937155887, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]100%|██████████| 40/40 [00:11<00:00,  3.34it/s]
CLIENT:96
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  #     # 遍历列表中的每个元素，并将其转换为字符串后写入文件
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]                                              {'loss': 1.8206, 'grad_norm': 9.072000503540039, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.09it/s]  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]                                              {'loss': 2.0324, 'grad_norm': 19.873308181762695, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.07it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 1.6652, 'grad_norm': 16.636798858642578, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.04it/s]                                              {'loss': 0.764, 'grad_norm': 19.8961238861084, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.04it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.6136, 'grad_norm': 21.82868194580078, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.03it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s]                                              {'loss': 1.811, 'grad_norm': 19.7199764251709, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.03it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.8526, 'grad_norm': 10.067294120788574, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 5.0164, 'grad_norm': 66.42677307128906, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s]                                              {'loss': 0.4952, 'grad_norm': 9.925042152404785, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.84it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s]                                               {'loss': 0.836, 'grad_norm': 14.458351135253906, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.58it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s]                                               {'loss': 0.9182, 'grad_norm': 7.2025885581970215, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.39it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 1.0953, 'grad_norm': 14.682586669921875, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s]                                               {'loss': 0.5176, 'grad_norm': 9.880054473876953, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.20it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s]                                               {'loss': 0.3061, 'grad_norm': 5.973902702331543, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.14it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.3906, 'grad_norm': 8.312292098999023, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.12it/s]                                               {'loss': 0.0383, 'grad_norm': 2.3632800579071045, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.12it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.89it/s]                                               {'loss': 0.3943, 'grad_norm': 6.913399696350098, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.89it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s]                                               {'loss': 0.2972, 'grad_norm': 13.29654598236084, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.63it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.47it/s]                                               {'loss': 0.7638, 'grad_norm': 7.938903331756592, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.47it/s] 50%|█████     | 20/40 [00:06<00:06,  3.32it/s]                                               {'loss': 0.3127, 'grad_norm': 5.852730751037598, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.32it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s]                                               {'loss': 0.1046, 'grad_norm': 2.962578773498535, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.23it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.18it/s]                                               {'loss': 0.1785, 'grad_norm': 5.332152843475342, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.18it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.15it/s]                                               {'loss': 0.4938, 'grad_norm': 5.274497985839844, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.15it/s]                                               {'loss': 0.0395, 'grad_norm': 2.7534842491149902, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.15it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.88it/s]                                               {'loss': 0.0375, 'grad_norm': 0.9893966913223267, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.88it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s]                                               {'loss': 0.0349, 'grad_norm': 0.8369338512420654, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.46it/s]                                               {'loss': 0.1198, 'grad_norm': 4.626952171325684, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.46it/s] 70%|███████   | 28/40 [00:08<00:03,  3.33it/s]                                               {'loss': 0.0749, 'grad_norm': 2.3188397884368896, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.33it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s]                                               {'loss': 0.7042, 'grad_norm': 1.8497827053070068, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.23it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.18it/s]                                               {'loss': 0.0763, 'grad_norm': 2.112518787384033, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.18it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.0755, 'grad_norm': 13.413190841674805, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.14it/s]                                               {'loss': 0.0002, 'grad_norm': 0.03524250537157059, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.14it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.88it/s]                                               {'loss': 0.0242, 'grad_norm': 1.3674505949020386, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.88it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s]                                               {'loss': 0.0256, 'grad_norm': 1.3993704319000244, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.62it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s]                                               {'loss': 0.0258, 'grad_norm': 1.0520933866500854, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0247, 'grad_norm': 0.9559066295623779, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.2423, 'grad_norm': 0.7267695069313049, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.3869, 'grad_norm': 0.3981076776981354, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0528, 'grad_norm': 2.2990801334381104, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.13it/s]                                               {'loss': 0.0888, 'grad_norm': 5.96136474609375, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]                                               {'train_runtime': 11.9721, 'train_samples_per_second': 47.193, 'train_steps_per_second': 3.341, 'train_loss': 0.6187919541789597, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.13it/s]100%|██████████| 40/40 [00:11<00:00,  3.34it/s]
CLIENT:29
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  #     # 遍历列表中的每个元素，并将其转换为字符串后写入文件
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.08it/s]                                              {'loss': 0.9744, 'grad_norm': 7.919212818145752, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.08it/s]  5%|▌         | 2/40 [00:00<00:12,  3.13it/s]                                              {'loss': 1.3152, 'grad_norm': 14.827672958374023, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.13it/s]  8%|▊         | 3/40 [00:00<00:12,  3.08it/s]                                              {'loss': 2.6112, 'grad_norm': 20.08293342590332, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.08it/s] 10%|█         | 4/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.5732, 'grad_norm': 21.645851135253906, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.05it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s]                                              {'loss': 2.2184, 'grad_norm': 21.928749084472656, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.07it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s]                                              {'loss': 1.7793, 'grad_norm': 26.034154891967773, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.05it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 2.6907, 'grad_norm': 22.375192642211914, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 0.0122, 'grad_norm': 1.2585300207138062, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s]                                              {'loss': 1.5216, 'grad_norm': 22.359294891357422, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.79it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 1.1333, 'grad_norm': 11.3720064163208, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s]                                               {'loss': 1.1506, 'grad_norm': 21.51523780822754, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.40it/s] 30%|███       | 12/40 [00:03<00:08,  3.26it/s]                                               {'loss': 0.4917, 'grad_norm': 9.74036693572998, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.26it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s]                                               {'loss': 1.262, 'grad_norm': 33.587440490722656, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.17it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.6864, 'grad_norm': 15.619038581848145, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.10it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 0.7325, 'grad_norm': 8.606364250183105, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.07it/s]                                               {'loss': 1.1764, 'grad_norm': 103.94664764404297, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.07it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s]                                               {'loss': 0.4298, 'grad_norm': 9.980792045593262, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.79it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.1922, 'grad_norm': 4.162539482116699, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s]                                               {'loss': 1.1624, 'grad_norm': 9.30855941772461, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.41it/s] 50%|█████     | 20/40 [00:06<00:06,  3.28it/s]                                               {'loss': 0.7124, 'grad_norm': 24.591638565063477, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.28it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s]                                               {'loss': 0.5672, 'grad_norm': 11.021136283874512, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.20it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s]                                               {'loss': 0.525, 'grad_norm': 8.38437557220459, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.14it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.2602, 'grad_norm': 5.792393684387207, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.12it/s]                                               {'loss': 0.0564, 'grad_norm': 6.605206489562988, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.12it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s]                                               {'loss': 0.4675, 'grad_norm': 5.221036911010742, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.87it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s]                                               {'loss': 0.5449, 'grad_norm': 9.855445861816406, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.62it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s]                                               {'loss': 0.1691, 'grad_norm': 7.812802314758301, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.43it/s] 70%|███████   | 28/40 [00:08<00:03,  3.30it/s]                                               {'loss': 0.4765, 'grad_norm': 11.088674545288086, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.30it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.0511, 'grad_norm': 1.814352035522461, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.2221, 'grad_norm': 5.291070938110352, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0869, 'grad_norm': 2.6326324939727783, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0166, 'grad_norm': 1.091244101524353, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s]                                               {'loss': 0.3443, 'grad_norm': 2.636225938796997, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.84it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s]                                               {'loss': 0.0768, 'grad_norm': 2.531024217605591, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.59it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.3244, 'grad_norm': 6.053203582763672, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s]                                               {'loss': 0.1536, 'grad_norm': 6.283242702484131, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.29it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s]                                               {'loss': 0.5276, 'grad_norm': 14.139532089233398, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.21it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s]                                               {'loss': 0.1129, 'grad_norm': 4.89381742477417, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.15it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.3755, 'grad_norm': 11.651349067687988, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0344, 'grad_norm': 5.60714054107666, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.0494, 'train_samples_per_second': 46.89, 'train_steps_per_second': 3.32, 'train_loss': 0.7304731362266466, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:86
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  #     # 遍历列表中的每个元素，并将其转换为字符串后写入文件
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]                                              {'loss': 1.2332, 'grad_norm': 8.243809700012207, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.05it/s]  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]                                              {'loss': 1.2125, 'grad_norm': 12.150602340698242, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.04it/s]  8%|▊         | 3/40 [00:00<00:12,  3.03it/s]                                              {'loss': 0.846, 'grad_norm': 16.062421798706055, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.03it/s] 10%|█         | 4/40 [00:01<00:11,  3.02it/s]                                              {'loss': 1.6368, 'grad_norm': 12.952312469482422, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.02it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.8089, 'grad_norm': 18.740571975708008, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s]                                              {'loss': 2.4755, 'grad_norm': 26.888723373413086, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.00it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 2.3889, 'grad_norm': 17.48557472229004, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.04it/s]                                              {'loss': 4.6473, 'grad_norm': 135.8813934326172, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.04it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s]                                              {'loss': 0.4864, 'grad_norm': 7.355518817901611, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.80it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s]                                               {'loss': 0.7167, 'grad_norm': 12.30847454071045, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.57it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s]                                               {'loss': 0.585, 'grad_norm': 11.909601211547852, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.41it/s] 30%|███       | 12/40 [00:03<00:08,  3.29it/s]                                               {'loss': 0.2615, 'grad_norm': 5.864091396331787, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.29it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s]                                               {'loss': 0.6166, 'grad_norm': 6.6775946617126465, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.19it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s]                                               {'loss': 0.7654, 'grad_norm': 10.408285140991211, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.13it/s] 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.745, 'grad_norm': 7.197287559509277, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:08,  3.10it/s]                                               {'loss': 0.8635, 'grad_norm': 33.2083625793457, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.10it/s] 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s]                                               {'loss': 0.0668, 'grad_norm': 1.6057878732681274, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:06,  3.82it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s]                                               {'loss': 0.063, 'grad_norm': 1.6948010921478271, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.57it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s]                                               {'loss': 0.6539, 'grad_norm': 4.267770290374756, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.45it/s] 50%|█████     | 20/40 [00:06<00:06,  3.31it/s]                                               {'loss': 0.2347, 'grad_norm': 2.997182846069336, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:06,  3.31it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s]                                               {'loss': 0.1344, 'grad_norm': 4.641911029815674, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.21it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s]                                               {'loss': 0.1153, 'grad_norm': 4.3971757888793945, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.15it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.1905, 'grad_norm': 4.486823558807373, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.09it/s]                                               {'loss': 0.0267, 'grad_norm': 1.9787148237228394, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.09it/s] 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s]                                               {'loss': 0.0409, 'grad_norm': 1.40579092502594, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:03,  3.81it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s]                                               {'loss': 0.4043, 'grad_norm': 1.0715579986572266, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.59it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s]                                               {'loss': 0.0462, 'grad_norm': 1.3812657594680786, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.42it/s] 70%|███████   | 28/40 [00:08<00:03,  3.32it/s]                                               {'loss': 0.1235, 'grad_norm': 4.199184417724609, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.32it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s]                                               {'loss': 0.1091, 'grad_norm': 2.7939491271972656, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.22it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s]                                               {'loss': 0.1629, 'grad_norm': 2.5207581520080566, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.16it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.2081, 'grad_norm': 16.746719360351562, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.11it/s]                                               {'loss': 0.0083, 'grad_norm': 0.48659899830818176, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.11it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s]                                               {'loss': 0.1325, 'grad_norm': 19.49027442932129, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.85it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s]                                               {'loss': 0.3895, 'grad_norm': 6.143599510192871, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.61it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s]                                               {'loss': 0.1632, 'grad_norm': 3.047163963317871, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.44it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.0424, 'grad_norm': 1.5798536539077759, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.2594, 'grad_norm': 11.624616622924805, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s]                                               {'loss': 0.0261, 'grad_norm': 1.195652961730957, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.17it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0176, 'grad_norm': 1.8613170385360718, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.11it/s]                                               {'loss': 0.0597, 'grad_norm': 5.24791955947876, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.11it/s]                                               {'train_runtime': 12.046, 'train_samples_per_second': 46.904, 'train_steps_per_second': 3.321, 'train_loss': 0.624200982437469, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.11it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:350: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  #     # 遍历列表中的每个元素，并将其转换为字符串后写入文件
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]                                              {'loss': 1.9385, 'grad_norm': 10.720553398132324, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:00<00:12,  3.02it/s]  5%|▌         | 2/40 [00:00<00:12,  3.12it/s]                                              {'loss': 1.8826, 'grad_norm': 12.547090530395508, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:00<00:12,  3.12it/s]  8%|▊         | 3/40 [00:00<00:12,  3.02it/s]                                              {'loss': 0.9089, 'grad_norm': 11.150094985961914, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:00<00:12,  3.02it/s] 10%|█         | 4/40 [00:01<00:11,  3.06it/s]                                              {'loss': 1.8755, 'grad_norm': 14.254192352294922, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:01<00:11,  3.06it/s] 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.6277, 'grad_norm': 15.838312149047852, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:01<00:11,  3.04it/s] 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s]                                              {'loss': 1.4697, 'grad_norm': 30.640945434570312, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:01<00:11,  3.04it/s] 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 1.1605, 'grad_norm': 19.303722381591797, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:02<00:10,  3.03it/s]                                              {'loss': 7.7256, 'grad_norm': 87.93144226074219, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:02<00:10,  3.03it/s] 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s]                                              {'loss': 0.2007, 'grad_norm': 8.040220260620117, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:02<00:08,  3.76it/s] 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s]                                               {'loss': 0.7507, 'grad_norm': 11.408478736877441, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:03<00:08,  3.52it/s] 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s]                                               {'loss': 0.8728, 'grad_norm': 15.552457809448242, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:03<00:08,  3.38it/s] 30%|███       | 12/40 [00:03<00:08,  3.28it/s]                                               {'loss': 0.3687, 'grad_norm': 7.486102104187012, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:03<00:08,  3.28it/s] 32%|███▎      | 13/40 [00:04<00:08,  3.23it/s]                                               {'loss': 0.527, 'grad_norm': 6.1248064041137695, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:04<00:08,  3.23it/s] 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s]                                               {'loss': 0.6858, 'grad_norm': 11.112202644348145, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:04<00:08,  3.18it/s] 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 0.3543, 'grad_norm': 8.668034553527832, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:04<00:07,  3.13it/s]                                               {'loss': 0.8108, 'grad_norm': 32.11419677734375, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:04<00:07,  3.13it/s] 42%|████▎     | 17/40 [00:05<00:05,  3.88it/s]                                               {'loss': 0.4383, 'grad_norm': 5.701257705688477, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:05<00:05,  3.88it/s] 45%|████▌     | 18/40 [00:05<00:06,  3.65it/s]                                               {'loss': 0.2203, 'grad_norm': 10.432124137878418, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:05<00:06,  3.65it/s] 48%|████▊     | 19/40 [00:05<00:06,  3.47it/s]                                               {'loss': 0.1545, 'grad_norm': 3.2878220081329346, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:05<00:06,  3.47it/s] 50%|█████     | 20/40 [00:06<00:05,  3.34it/s]                                               {'loss': 0.2123, 'grad_norm': 5.279365062713623, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:06<00:05,  3.34it/s] 52%|█████▎    | 21/40 [00:06<00:05,  3.25it/s]                                               {'loss': 0.3594, 'grad_norm': 5.7229156494140625, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:06<00:05,  3.25it/s] 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s]                                               {'loss': 0.4067, 'grad_norm': 8.62289047241211, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:06<00:05,  3.17it/s] 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.3212, 'grad_norm': 6.968952655792236, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:07<00:05,  3.11it/s]                                               {'loss': 0.3384, 'grad_norm': 16.5855655670166, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:07<00:05,  3.11it/s] 62%|██████▎   | 25/40 [00:07<00:04,  3.69it/s]                                               {'loss': 0.1596, 'grad_norm': 5.425759792327881, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:07<00:04,  3.69it/s] 65%|██████▌   | 26/40 [00:07<00:03,  3.50it/s]                                               {'loss': 0.2709, 'grad_norm': 5.211484909057617, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:07<00:03,  3.50it/s] 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s]                                               {'loss': 0.0892, 'grad_norm': 1.6088447570800781, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:08<00:03,  3.37it/s] 70%|███████   | 28/40 [00:08<00:03,  3.27it/s]                                               {'loss': 0.2587, 'grad_norm': 6.944679260253906, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:08<00:03,  3.27it/s] 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s]                                               {'loss': 0.0733, 'grad_norm': 2.8345065116882324, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:08<00:03,  3.20it/s] 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s]                                               {'loss': 0.1329, 'grad_norm': 4.779144287109375, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:09<00:03,  3.14it/s] 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.1808, 'grad_norm': 3.932016611099243, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [00:09<00:02,  3.10it/s]                                               {'loss': 0.0092, 'grad_norm': 0.6361371278762817, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [00:09<00:02,  3.10it/s] 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s]                                               {'loss': 0.0457, 'grad_norm': 1.4366494417190552, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [00:09<00:01,  3.79it/s] 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s]                                               {'loss': 0.0331, 'grad_norm': 0.7969298362731934, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [00:10<00:01,  3.58it/s] 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s]                                               {'loss': 0.1802, 'grad_norm': 0.9513288140296936, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [00:10<00:01,  3.42it/s] 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s]                                               {'loss': 0.2179, 'grad_norm': 9.247400283813477, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [00:10<00:01,  3.30it/s] 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s]                                               {'loss': 0.0987, 'grad_norm': 3.9248244762420654, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [00:11<00:00,  3.22it/s] 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s]                                               {'loss': 0.0523, 'grad_norm': 1.602158784866333, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [00:11<00:00,  3.16it/s] 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0427, 'grad_norm': 1.1303094625473022, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [00:11<00:00,  3.12it/s]                                               {'loss': 0.0582, 'grad_norm': 2.617058515548706, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [00:11<00:00,  3.12it/s]                                               {'train_runtime': 12.0484, 'train_samples_per_second': 46.894, 'train_steps_per_second': 3.32, 'train_loss': 0.687854491127655, 'epoch': 5.0}
100%|██████████| 40/40 [00:12<00:00,  3.12it/s]100%|██████████| 40/40 [00:12<00:00,  3.32it/s]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:385: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  learning_rate=self.args.lr,
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:00<00:43, 10.90it/s]  1%|          | 4/471 [00:00<01:07,  6.88it/s]  1%|          | 5/471 [00:00<01:13,  6.37it/s]  1%|▏         | 6/471 [00:00<01:17,  6.03it/s]  1%|▏         | 7/471 [00:01<01:19,  5.82it/s]  2%|▏         | 8/471 [00:01<01:21,  5.68it/s]  2%|▏         | 9/471 [00:01<01:22,  5.62it/s]  2%|▏         | 10/471 [00:01<01:22,  5.57it/s]  2%|▏         | 11/471 [00:01<01:23,  5.52it/s]  3%|▎         | 12/471 [00:02<01:23,  5.48it/s]  3%|▎         | 13/471 [00:02<01:24,  5.44it/s]  3%|▎         | 14/471 [00:02<01:24,  5.42it/s]  3%|▎         | 15/471 [00:02<01:23,  5.44it/s]  3%|▎         | 16/471 [00:02<01:23,  5.43it/s]  4%|▎         | 17/471 [00:02<01:23,  5.42it/s]  4%|▍         | 18/471 [00:03<01:23,  5.40it/s]  4%|▍         | 19/471 [00:03<01:23,  5.40it/s]  4%|▍         | 20/471 [00:03<01:23,  5.38it/s]  4%|▍         | 21/471 [00:03<01:23,  5.39it/s]  5%|▍         | 22/471 [00:03<01:23,  5.39it/s]  5%|▍         | 23/471 [00:04<01:23,  5.38it/s]  5%|▌         | 24/471 [00:04<01:22,  5.39it/s]  5%|▌         | 25/471 [00:04<01:22,  5.39it/s]  6%|▌         | 26/471 [00:04<01:22,  5.40it/s]  6%|▌         | 27/471 [00:04<01:22,  5.38it/s]  6%|▌         | 28/471 [00:04<01:22,  5.38it/s]  6%|▌         | 29/471 [00:05<01:22,  5.38it/s]  6%|▋         | 30/471 [00:05<01:22,  5.37it/s]  7%|▋         | 31/471 [00:05<01:21,  5.38it/s]  7%|▋         | 32/471 [00:05<01:21,  5.38it/s]  7%|▋         | 33/471 [00:05<01:20,  5.43it/s]  7%|▋         | 34/471 [00:06<01:20,  5.43it/s]  7%|▋         | 35/471 [00:06<01:20,  5.41it/s]  8%|▊         | 36/471 [00:06<01:20,  5.39it/s]  8%|▊         | 37/471 [00:06<01:20,  5.39it/s]  8%|▊         | 38/471 [00:06<01:20,  5.37it/s]  8%|▊         | 39/471 [00:07<01:20,  5.37it/s]  8%|▊         | 40/471 [00:07<01:20,  5.39it/s]  9%|▊         | 41/471 [00:07<01:19,  5.38it/s]  9%|▉         | 42/471 [00:07<01:19,  5.38it/s]  9%|▉         | 43/471 [00:07<01:19,  5.38it/s]  9%|▉         | 44/471 [00:07<01:19,  5.39it/s] 10%|▉         | 45/471 [00:08<01:19,  5.38it/s] 10%|▉         | 46/471 [00:08<01:18,  5.38it/s] 10%|▉         | 47/471 [00:08<01:18,  5.41it/s] 10%|█         | 48/471 [00:08<01:18,  5.40it/s] 10%|█         | 49/471 [00:08<01:18,  5.39it/s] 11%|█         | 50/471 [00:09<01:18,  5.36it/s] 11%|█         | 51/471 [00:09<01:18,  5.36it/s] 11%|█         | 52/471 [00:09<01:17,  5.37it/s] 11%|█▏        | 53/471 [00:09<01:17,  5.36it/s] 11%|█▏        | 54/471 [00:09<01:18,  5.34it/s] 12%|█▏        | 55/471 [00:10<01:17,  5.34it/s] 12%|█▏        | 56/471 [00:10<01:17,  5.34it/s] 12%|█▏        | 57/471 [00:10<01:17,  5.35it/s] 12%|█▏        | 58/471 [00:10<01:17,  5.34it/s] 13%|█▎        | 59/471 [00:10<01:17,  5.35it/s] 13%|█▎        | 60/471 [00:10<01:16,  5.36it/s] 13%|█▎        | 61/471 [00:11<01:16,  5.35it/s] 13%|█▎        | 62/471 [00:11<01:16,  5.35it/s] 13%|█▎        | 63/471 [00:11<01:16,  5.36it/s] 14%|█▎        | 64/471 [00:11<01:16,  5.35it/s] 14%|█▍        | 65/471 [00:11<01:15,  5.35it/s] 14%|█▍        | 66/471 [00:12<01:15,  5.35it/s] 14%|█▍        | 67/471 [00:12<01:15,  5.35it/s] 14%|█▍        | 68/471 [00:12<01:15,  5.36it/s] 15%|█▍        | 69/471 [00:12<01:14,  5.36it/s] 15%|█▍        | 70/471 [00:12<01:15,  5.33it/s] 15%|█▌        | 71/471 [00:13<01:15,  5.33it/s] 15%|█▌        | 72/471 [00:13<01:14,  5.34it/s] 15%|█▌        | 73/471 [00:13<01:14,  5.33it/s] 16%|█▌        | 74/471 [00:13<01:14,  5.36it/s] 16%|█▌        | 75/471 [00:13<01:14,  5.34it/s] 16%|█▌        | 76/471 [00:13<01:13,  5.36it/s] 16%|█▋        | 77/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 78/471 [00:14<01:13,  5.36it/s] 17%|█▋        | 79/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 80/471 [00:14<01:13,  5.35it/s] 17%|█▋        | 81/471 [00:14<01:12,  5.36it/s] 17%|█▋        | 82/471 [00:15<01:12,  5.37it/s] 18%|█▊        | 83/471 [00:15<01:12,  5.36it/s] 18%|█▊        | 84/471 [00:15<01:12,  5.35it/s] 18%|█▊        | 85/471 [00:15<01:12,  5.36it/s] 18%|█▊        | 86/471 [00:15<01:11,  5.35it/s] 18%|█▊        | 87/471 [00:15<01:11,  5.36it/s] 19%|█▊        | 88/471 [00:16<01:11,  5.38it/s] 19%|█▉        | 89/471 [00:16<01:11,  5.37it/s] 19%|█▉        | 90/471 [00:16<01:10,  5.37it/s] 19%|█▉        | 91/471 [00:16<01:10,  5.38it/s] 20%|█▉        | 92/471 [00:16<01:10,  5.36it/s] 20%|█▉        | 93/471 [00:17<01:10,  5.36it/s] 20%|█▉        | 94/471 [00:17<01:10,  5.37it/s] 20%|██        | 95/471 [00:17<01:09,  5.38it/s] 20%|██        | 96/471 [00:17<01:09,  5.38it/s] 21%|██        | 97/471 [00:17<01:09,  5.36it/s] 21%|██        | 98/471 [00:18<01:09,  5.36it/s] 21%|██        | 99/471 [00:18<01:09,  5.38it/s] 21%|██        | 100/471 [00:18<01:08,  5.39it/s] 21%|██▏       | 101/471 [00:18<01:08,  5.40it/s] 22%|██▏       | 102/471 [00:18<01:08,  5.37it/s] 22%|██▏       | 103/471 [00:18<01:08,  5.36it/s] 22%|██▏       | 104/471 [00:19<01:08,  5.35it/s] 22%|██▏       | 105/471 [00:19<01:08,  5.33it/s] 23%|██▎       | 106/471 [00:19<01:08,  5.36it/s] 23%|██▎       | 107/471 [00:19<01:07,  5.38it/s] 23%|██▎       | 108/471 [00:19<01:07,  5.37it/s] 23%|██▎       | 109/471 [00:20<01:07,  5.38it/s] 23%|██▎       | 110/471 [00:20<01:07,  5.38it/s] 24%|██▎       | 111/471 [00:20<01:07,  5.36it/s] 24%|██▍       | 112/471 [00:20<01:06,  5.36it/s] 24%|██▍       | 113/471 [00:20<01:06,  5.38it/s] 24%|██▍       | 114/471 [00:21<01:06,  5.38it/s] 24%|██▍       | 115/471 [00:21<01:06,  5.36it/s] 25%|██▍       | 116/471 [00:21<01:06,  5.35it/s] 25%|██▍       | 117/471 [00:21<01:06,  5.33it/s] 25%|██▌       | 118/471 [00:21<01:06,  5.33it/s] 25%|██▌       | 119/471 [00:21<01:05,  5.34it/s] 25%|██▌       | 120/471 [00:22<01:05,  5.34it/s] 26%|██▌       | 121/471 [00:22<01:05,  5.33it/s] 26%|██▌       | 122/471 [00:22<01:05,  5.33it/s] 26%|██▌       | 123/471 [00:22<01:05,  5.34it/s] 26%|██▋       | 124/471 [00:22<01:05,  5.33it/s] 27%|██▋       | 125/471 [00:23<01:05,  5.32it/s] 27%|██▋       | 126/471 [00:23<01:04,  5.32it/s] 27%|██▋       | 127/471 [00:23<01:04,  5.32it/s] 27%|██▋       | 128/471 [00:23<01:04,  5.33it/s] 27%|██▋       | 129/471 [00:23<01:04,  5.34it/s] 28%|██▊       | 130/471 [00:24<01:04,  5.33it/s] 28%|██▊       | 131/471 [00:24<01:03,  5.31it/s] 28%|██▊       | 132/471 [00:24<01:03,  5.31it/s] 28%|██▊       | 133/471 [00:24<01:03,  5.32it/s] 28%|██▊       | 134/471 [00:24<01:03,  5.31it/s] 29%|██▊       | 135/471 [00:24<01:03,  5.31it/s] 29%|██▉       | 136/471 [00:25<01:03,  5.31it/s] 29%|██▉       | 137/471 [00:25<01:02,  5.30it/s] 29%|██▉       | 138/471 [00:25<01:02,  5.30it/s] 30%|██▉       | 139/471 [00:25<01:02,  5.32it/s] 30%|██▉       | 140/471 [00:25<01:02,  5.31it/s] 30%|██▉       | 141/471 [00:26<01:01,  5.32it/s] 30%|███       | 142/471 [00:26<01:01,  5.32it/s] 30%|███       | 143/471 [00:26<01:01,  5.32it/s] 31%|███       | 144/471 [00:26<01:01,  5.31it/s] 31%|███       | 145/471 [00:26<01:01,  5.34it/s] 31%|███       | 146/471 [00:27<01:01,  5.32it/s] 31%|███       | 147/471 [00:27<01:00,  5.31it/s] 31%|███▏      | 148/471 [00:27<01:00,  5.31it/s] 32%|███▏      | 149/471 [00:27<01:00,  5.31it/s] 32%|███▏      | 150/471 [00:27<01:00,  5.30it/s] 32%|███▏      | 151/471 [00:27<01:00,  5.31it/s] 32%|███▏      | 152/471 [00:28<01:00,  5.31it/s] 32%|███▏      | 153/471 [00:28<01:00,  5.30it/s] 33%|███▎      | 154/471 [00:28<00:59,  5.33it/s] 33%|███▎      | 155/471 [00:28<00:59,  5.33it/s] 33%|███▎      | 156/471 [00:28<00:59,  5.33it/s] 33%|███▎      | 157/471 [00:29<00:58,  5.33it/s] 34%|███▎      | 158/471 [00:29<00:58,  5.33it/s] 34%|███▍      | 159/471 [00:29<00:58,  5.36it/s] 34%|███▍      | 160/471 [00:29<00:58,  5.34it/s] 34%|███▍      | 161/471 [00:29<00:58,  5.33it/s] 34%|███▍      | 162/471 [00:30<00:58,  5.32it/s] 35%|███▍      | 163/471 [00:30<00:58,  5.29it/s] 35%|███▍      | 164/471 [00:30<00:57,  5.32it/s] 35%|███▌      | 165/471 [00:30<00:57,  5.34it/s] 35%|███▌      | 166/471 [00:30<00:57,  5.32it/s] 35%|███▌      | 167/471 [00:30<00:57,  5.31it/s] 36%|███▌      | 168/471 [00:31<00:57,  5.28it/s] 36%|███▌      | 169/471 [00:31<00:56,  5.32it/s] 36%|███▌      | 170/471 [00:31<00:56,  5.33it/s] 36%|███▋      | 171/471 [00:31<00:56,  5.32it/s] 37%|███▋      | 172/471 [00:31<00:56,  5.32it/s] 37%|███▋      | 173/471 [00:32<00:56,  5.30it/s] 37%|███▋      | 174/471 [00:32<00:56,  5.30it/s] 37%|███▋      | 175/471 [00:32<00:55,  5.30it/s] 37%|███▋      | 176/471 [00:32<00:55,  5.32it/s] 38%|███▊      | 177/471 [00:32<00:55,  5.32it/s] 38%|███▊      | 178/471 [00:33<00:55,  5.30it/s] 38%|███▊      | 179/471 [00:33<00:54,  5.31it/s] 38%|███▊      | 180/471 [00:33<00:54,  5.30it/s] 38%|███▊      | 181/471 [00:33<00:54,  5.30it/s] 39%|███▊      | 182/471 [00:33<00:54,  5.30it/s] 39%|███▉      | 183/471 [00:34<00:54,  5.30it/s] 39%|███▉      | 184/471 [00:34<00:54,  5.31it/s] 39%|███▉      | 185/471 [00:34<00:53,  5.30it/s] 39%|███▉      | 186/471 [00:34<00:53,  5.29it/s] 40%|███▉      | 187/471 [00:34<00:53,  5.29it/s] 40%|███▉      | 188/471 [00:34<00:53,  5.28it/s] 40%|████      | 189/471 [00:35<00:53,  5.30it/s] 40%|████      | 190/471 [00:35<00:52,  5.30it/s] 41%|████      | 191/471 [00:35<00:52,  5.29it/s] 41%|████      | 192/471 [00:35<00:52,  5.30it/s] 41%|████      | 193/471 [00:35<00:52,  5.34it/s] 41%|████      | 194/471 [00:36<00:52,  5.31it/s] 41%|████▏     | 195/471 [00:36<00:52,  5.31it/s] 42%|████▏     | 196/471 [00:36<00:51,  5.30it/s] 42%|████▏     | 197/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 198/471 [00:36<00:51,  5.32it/s] 42%|████▏     | 199/471 [00:37<00:51,  5.31it/s] 42%|████▏     | 200/471 [00:37<00:51,  5.30it/s] 43%|████▎     | 201/471 [00:37<00:50,  5.31it/s] 43%|████▎     | 202/471 [00:37<00:50,  5.30it/s] 43%|████▎     | 203/471 [00:37<00:50,  5.29it/s] 43%|████▎     | 204/471 [00:37<00:50,  5.29it/s] 44%|████▎     | 205/471 [00:38<00:50,  5.30it/s] 44%|████▎     | 206/471 [00:38<00:49,  5.30it/s] 44%|████▍     | 207/471 [00:38<00:49,  5.29it/s] 44%|████▍     | 208/471 [00:38<00:49,  5.32it/s] 44%|████▍     | 209/471 [00:38<00:49,  5.32it/s] 45%|████▍     | 210/471 [00:39<00:49,  5.32it/s] 45%|████▍     | 211/471 [00:39<00:48,  5.31it/s] 45%|████▌     | 212/471 [00:39<00:48,  5.31it/s] 45%|████▌     | 213/471 [00:39<00:48,  5.30it/s] 45%|████▌     | 214/471 [00:39<00:48,  5.29it/s] 46%|████▌     | 215/471 [00:40<00:48,  5.29it/s] 46%|████▌     | 216/471 [00:40<00:48,  5.27it/s] 46%|████▌     | 217/471 [00:40<00:48,  5.27it/s] 46%|████▋     | 218/471 [00:40<00:48,  5.27it/s] 46%|████▋     | 219/471 [00:40<00:47,  5.27it/s] 47%|████▋     | 220/471 [00:40<00:47,  5.26it/s] 47%|████▋     | 221/471 [00:41<00:47,  5.25it/s] 47%|████▋     | 222/471 [00:41<00:47,  5.29it/s] 47%|████▋     | 223/471 [00:41<00:46,  5.30it/s] 48%|████▊     | 224/471 [00:41<00:46,  5.30it/s] 48%|████▊     | 225/471 [00:41<00:46,  5.26it/s] 48%|████▊     | 226/471 [00:42<00:46,  5.27it/s] 48%|████▊     | 227/471 [00:42<00:46,  5.27it/s] 48%|████▊     | 228/471 [00:42<00:46,  5.28it/s] 49%|████▊     | 229/471 [00:42<00:45,  5.28it/s] 49%|████▉     | 230/471 [00:42<00:45,  5.27it/s] 49%|████▉     | 231/471 [00:43<00:45,  5.26it/s] 49%|████▉     | 232/471 [00:43<00:45,  5.29it/s] 49%|████▉     | 233/471 [00:43<00:44,  5.30it/s] 50%|████▉     | 234/471 [00:43<00:44,  5.29it/s] 50%|████▉     | 235/471 [00:43<00:44,  5.28it/s] 50%|█████     | 236/471 [00:44<00:44,  5.28it/s] 50%|█████     | 237/471 [00:44<00:44,  5.28it/s] 51%|█████     | 238/471 [00:44<00:44,  5.28it/s] 51%|█████     | 239/471 [00:44<00:43,  5.28it/s] 51%|█████     | 240/471 [00:44<00:43,  5.27it/s] 51%|█████     | 241/471 [00:44<00:43,  5.26it/s] 51%|█████▏    | 242/471 [00:45<00:43,  5.28it/s] 52%|█████▏    | 243/471 [00:45<00:43,  5.28it/s] 52%|█████▏    | 244/471 [00:45<00:43,  5.27it/s] 52%|█████▏    | 245/471 [00:45<00:43,  5.25it/s] 52%|█████▏    | 246/471 [00:45<00:42,  5.27it/s] 52%|█████▏    | 247/471 [00:46<00:42,  5.29it/s] 53%|█████▎    | 248/471 [00:46<00:42,  5.28it/s] 53%|█████▎    | 249/471 [00:46<00:42,  5.27it/s] 53%|█████▎    | 250/471 [00:46<00:42,  5.26it/s] 53%|█████▎    | 251/471 [00:46<00:41,  5.26it/s] 54%|█████▎    | 252/471 [00:47<00:41,  5.26it/s] 54%|█████▎    | 253/471 [00:47<00:41,  5.25it/s] 54%|█████▍    | 254/471 [00:47<00:41,  5.26it/s] 54%|█████▍    | 255/471 [00:47<00:41,  5.25it/s] 54%|█████▍    | 256/471 [00:47<00:40,  5.25it/s] 55%|█████▍    | 257/471 [00:48<00:40,  5.26it/s] 55%|█████▍    | 258/471 [00:48<00:40,  5.26it/s] 55%|█████▍    | 259/471 [00:48<00:40,  5.26it/s] 55%|█████▌    | 260/471 [00:48<00:40,  5.26it/s] 55%|█████▌    | 261/471 [00:48<00:39,  5.26it/s] 56%|█████▌    | 262/471 [00:48<00:39,  5.28it/s] 56%|█████▌    | 263/471 [00:49<00:39,  5.26it/s] 56%|█████▌    | 264/471 [00:49<00:39,  5.26it/s] 56%|█████▋    | 265/471 [00:49<00:39,  5.26it/s] 56%|█████▋    | 266/471 [00:49<00:39,  5.25it/s] 57%|█████▋    | 267/471 [00:49<00:38,  5.25it/s] 57%|█████▋    | 268/471 [00:50<00:38,  5.25it/s] 57%|█████▋    | 269/471 [00:50<00:38,  5.26it/s] 57%|█████▋    | 270/471 [00:50<00:38,  5.26it/s] 58%|█████▊    | 271/471 [00:50<00:38,  5.26it/s] 58%|█████▊    | 272/471 [00:50<00:37,  5.28it/s] 58%|█████▊    | 273/471 [00:51<00:37,  5.28it/s] 58%|█████▊    | 274/471 [00:51<00:37,  5.30it/s] 58%|█████▊    | 275/471 [00:51<00:37,  5.29it/s] 59%|█████▊    | 276/471 [00:51<00:36,  5.27it/s] 59%|█████▉    | 277/471 [00:51<00:36,  5.26it/s] 59%|█████▉    | 278/471 [00:51<00:36,  5.25it/s] 59%|█████▉    | 279/471 [00:52<00:36,  5.27it/s] 59%|█████▉    | 280/471 [00:52<00:36,  5.27it/s] 60%|█████▉    | 281/471 [00:52<00:36,  5.25it/s] 60%|█████▉    | 282/471 [00:52<00:35,  5.25it/s] 60%|██████    | 283/471 [00:52<00:35,  5.25it/s] 60%|██████    | 284/471 [00:53<00:35,  5.26it/s] 61%|██████    | 285/471 [00:53<00:35,  5.25it/s] 61%|██████    | 286/471 [00:53<00:35,  5.24it/s] 61%|██████    | 287/471 [00:53<00:35,  5.24it/s] 61%|██████    | 288/471 [00:53<00:34,  5.24it/s] 61%|██████▏   | 289/471 [00:54<00:34,  5.26it/s] 62%|██████▏   | 290/471 [00:54<00:34,  5.27it/s] 62%|██████▏   | 291/471 [00:54<00:34,  5.26it/s] 62%|██████▏   | 292/471 [00:54<00:34,  5.26it/s] 62%|██████▏   | 293/471 [00:54<00:33,  5.27it/s] 62%|██████▏   | 294/471 [00:55<00:33,  5.28it/s] 63%|██████▎   | 295/471 [00:55<00:33,  5.28it/s] 63%|██████▎   | 296/471 [00:55<00:33,  5.29it/s] 63%|██████▎   | 297/471 [00:55<00:32,  5.29it/s] 63%|██████▎   | 298/471 [00:55<00:32,  5.26it/s] 63%|██████▎   | 299/471 [00:55<00:32,  5.27it/s] 64%|██████▎   | 300/471 [00:56<00:32,  5.26it/s] 64%|██████▍   | 301/471 [00:56<00:32,  5.27it/s] 64%|██████▍   | 302/471 [00:56<00:32,  5.26it/s] 64%|██████▍   | 303/471 [00:56<00:31,  5.26it/s] 65%|██████▍   | 304/471 [00:56<00:31,  5.27it/s] 65%|██████▍   | 305/471 [00:57<00:31,  5.27it/s] 65%|██████▍   | 306/471 [00:57<00:31,  5.25it/s] 65%|██████▌   | 307/471 [00:57<00:31,  5.25it/s] 65%|██████▌   | 308/471 [00:57<00:31,  5.24it/s] 66%|██████▌   | 309/471 [00:57<00:30,  5.23it/s] 66%|██████▌   | 310/471 [00:58<00:30,  5.22it/s] 66%|██████▌   | 311/471 [00:58<00:30,  5.23it/s] 66%|██████▌   | 312/471 [00:58<00:30,  5.25it/s] 66%|██████▋   | 313/471 [00:58<00:30,  5.26it/s] 67%|██████▋   | 314/471 [00:58<00:29,  5.25it/s] 67%|██████▋   | 315/471 [00:59<00:29,  5.24it/s] 67%|██████▋   | 316/471 [00:59<00:29,  5.25it/s] 67%|██████▋   | 317/471 [00:59<00:29,  5.26it/s] 68%|██████▊   | 318/471 [00:59<00:29,  5.25it/s] 68%|██████▊   | 319/471 [00:59<00:28,  5.25it/s] 68%|██████▊   | 320/471 [00:59<00:28,  5.22it/s] 68%|██████▊   | 321/471 [01:00<00:28,  5.20it/s] 68%|██████▊   | 322/471 [01:00<00:28,  5.22it/s] 69%|██████▊   | 323/471 [01:00<00:28,  5.22it/s] 69%|██████▉   | 324/471 [01:00<00:28,  5.22it/s] 69%|██████▉   | 325/471 [01:00<00:27,  5.22it/s] 69%|██████▉   | 326/471 [01:01<00:27,  5.22it/s] 69%|██████▉   | 327/471 [01:01<00:27,  5.23it/s] 70%|██████▉   | 328/471 [01:01<00:27,  5.22it/s] 70%|██████▉   | 329/471 [01:01<00:27,  5.23it/s] 70%|███████   | 330/471 [01:01<00:26,  5.25it/s] 70%|███████   | 331/471 [01:02<00:26,  5.23it/s] 70%|███████   | 332/471 [01:02<00:26,  5.21it/s] 71%|███████   | 333/471 [01:02<00:26,  5.22it/s] 71%|███████   | 334/471 [01:02<00:26,  5.22it/s] 71%|███████   | 335/471 [01:02<00:26,  5.22it/s] 71%|███████▏  | 336/471 [01:03<00:25,  5.23it/s] 72%|███████▏  | 337/471 [01:03<00:25,  5.24it/s] 72%|███████▏  | 338/471 [01:03<00:25,  5.24it/s] 72%|███████▏  | 339/471 [01:03<00:25,  5.23it/s] 72%|███████▏  | 340/471 [01:03<00:25,  5.23it/s] 72%|███████▏  | 341/471 [01:04<00:24,  5.22it/s] 73%|███████▎  | 342/471 [01:04<00:24,  5.22it/s] 73%|███████▎  | 343/471 [01:04<00:24,  5.22it/s] 73%|███████▎  | 344/471 [01:04<00:24,  5.24it/s] 73%|███████▎  | 345/471 [01:04<00:24,  5.24it/s] 73%|███████▎  | 346/471 [01:04<00:23,  5.22it/s] 74%|███████▎  | 347/471 [01:05<00:23,  5.24it/s] 74%|███████▍  | 348/471 [01:05<00:23,  5.22it/s] 74%|███████▍  | 349/471 [01:05<00:23,  5.21it/s] 74%|███████▍  | 350/471 [01:05<00:23,  5.22it/s] 75%|███████▍  | 351/471 [01:05<00:22,  5.24it/s] 75%|███████▍  | 352/471 [01:06<00:22,  5.23it/s] 75%|███████▍  | 353/471 [01:06<00:22,  5.21it/s] 75%|███████▌  | 354/471 [01:06<00:22,  5.20it/s] 75%|███████▌  | 355/471 [01:06<00:22,  5.20it/s] 76%|███████▌  | 356/471 [01:06<00:22,  5.21it/s] 76%|███████▌  | 357/471 [01:07<00:21,  5.21it/s] 76%|███████▌  | 358/471 [01:07<00:21,  5.21it/s] 76%|███████▌  | 359/471 [01:07<00:21,  5.20it/s] 76%|███████▋  | 360/471 [01:07<00:21,  5.21it/s] 77%|███████▋  | 361/471 [01:07<00:21,  5.22it/s] 77%|███████▋  | 362/471 [01:08<00:20,  5.23it/s] 77%|███████▋  | 363/471 [01:08<00:20,  5.23it/s] 77%|███████▋  | 364/471 [01:08<00:20,  5.22it/s] 77%|███████▋  | 365/471 [01:08<00:20,  5.22it/s] 78%|███████▊  | 366/471 [01:08<00:20,  5.21it/s] 78%|███████▊  | 367/471 [01:08<00:19,  5.22it/s] 78%|███████▊  | 368/471 [01:09<00:19,  5.22it/s] 78%|███████▊  | 369/471 [01:09<00:19,  5.22it/s] 79%|███████▊  | 370/471 [01:09<00:19,  5.20it/s] 79%|███████▉  | 371/471 [01:09<00:19,  5.21it/s] 79%|███████▉  | 372/471 [01:09<00:18,  5.22it/s] 79%|███████▉  | 373/471 [01:10<00:18,  5.22it/s] 79%|███████▉  | 374/471 [01:10<00:18,  5.23it/s] 80%|███████▉  | 375/471 [01:10<00:18,  5.23it/s] 80%|███████▉  | 376/471 [01:10<00:18,  5.22it/s] 80%|████████  | 377/471 [01:10<00:17,  5.23it/s] 80%|████████  | 378/471 [01:11<00:17,  5.26it/s] 80%|████████  | 379/471 [01:11<00:17,  5.24it/s] 81%|████████  | 380/471 [01:11<00:17,  5.22it/s] 81%|████████  | 381/471 [01:11<00:17,  5.23it/s] 81%|████████  | 382/471 [01:11<00:17,  5.22it/s] 81%|████████▏ | 383/471 [01:12<00:16,  5.21it/s] 82%|████████▏ | 384/471 [01:12<00:16,  5.20it/s] 82%|████████▏ | 385/471 [01:12<00:16,  5.20it/s] 82%|████████▏ | 386/471 [01:12<00:16,  5.20it/s] 82%|████████▏ | 387/471 [01:12<00:16,  5.20it/s] 82%|████████▏ | 388/471 [01:13<00:15,  5.20it/s] 83%|████████▎ | 389/471 [01:13<00:15,  5.22it/s] 83%|████████▎ | 390/471 [01:13<00:15,  5.21it/s] 83%|████████▎ | 391/471 [01:13<00:15,  5.21it/s] 83%|████████▎ | 392/471 [01:13<00:15,  5.20it/s] 83%|████████▎ | 393/471 [01:13<00:14,  5.20it/s] 84%|████████▎ | 394/471 [01:14<00:14,  5.20it/s] 84%|████████▍ | 395/471 [01:14<00:14,  5.19it/s] 84%|████████▍ | 396/471 [01:14<00:14,  5.18it/s] 84%|████████▍ | 397/471 [01:14<00:14,  5.20it/s] 85%|████████▍ | 398/471 [01:14<00:14,  5.20it/s] 85%|████████▍ | 399/471 [01:15<00:13,  5.19it/s] 85%|████████▍ | 400/471 [01:15<00:13,  5.18it/s] 85%|████████▌ | 401/471 [01:15<00:13,  5.19it/s] 85%|████████▌ | 402/471 [01:15<00:13,  5.19it/s] 86%|████████▌ | 403/471 [01:15<00:13,  5.20it/s] 86%|████████▌ | 404/471 [01:16<00:12,  5.19it/s] 86%|████████▌ | 405/471 [01:16<00:12,  5.20it/s] 86%|████████▌ | 406/471 [01:16<00:12,  5.21it/s] 86%|████████▋ | 407/471 [01:16<00:12,  5.21it/s] 87%|████████▋ | 408/471 [01:16<00:12,  5.20it/s] 87%|████████▋ | 409/471 [01:17<00:11,  5.18it/s] 87%|████████▋ | 410/471 [01:17<00:11,  5.20it/s] 87%|████████▋ | 411/471 [01:17<00:11,  5.22it/s] 87%|████████▋ | 412/471 [01:17<00:11,  5.20it/s] 88%|████████▊ | 413/471 [01:17<00:11,  5.20it/s] 88%|████████▊ | 414/471 [01:18<00:10,  5.19it/s] 88%|████████▊ | 415/471 [01:18<00:10,  5.20it/s] 88%|████████▊ | 416/471 [01:18<00:10,  5.19it/s] 89%|████████▊ | 417/471 [01:18<00:10,  5.20it/s] 89%|████████▊ | 418/471 [01:18<00:10,  5.20it/s] 89%|████████▉ | 419/471 [01:18<00:09,  5.20it/s] 89%|████████▉ | 420/471 [01:19<00:09,  5.23it/s] 89%|████████▉ | 421/471 [01:19<00:09,  5.20it/s] 90%|████████▉ | 422/471 [01:19<00:09,  5.21it/s] 90%|████████▉ | 423/471 [01:19<00:09,  5.22it/s] 90%|█████████ | 424/471 [01:19<00:09,  5.21it/s] 90%|█████████ | 425/471 [01:20<00:08,  5.21it/s] 90%|█████████ | 426/471 [01:20<00:08,  5.19it/s] 91%|█████████ | 427/471 [01:20<00:08,  5.19it/s] 91%|█████████ | 428/471 [01:20<00:08,  5.20it/s] 91%|█████████ | 429/471 [01:20<00:08,  5.19it/s] 91%|█████████▏| 430/471 [01:21<00:07,  5.19it/s] 92%|█████████▏| 431/471 [01:21<00:07,  5.18it/s] 92%|█████████▏| 432/471 [01:21<00:07,  5.18it/s] 92%|█████████▏| 433/471 [01:21<00:07,  5.19it/s] 92%|█████████▏| 434/471 [01:21<00:07,  5.19it/s] 92%|█████████▏| 435/471 [01:22<00:06,  5.19it/s] 93%|█████████▎| 436/471 [01:22<00:06,  5.19it/s] 93%|█████████▎| 437/471 [01:22<00:06,  5.25it/s] 93%|█████████▎| 438/471 [01:22<00:06,  5.22it/s] 93%|█████████▎| 439/471 [01:22<00:06,  5.21it/s] 93%|█████████▎| 440/471 [01:23<00:05,  5.22it/s] 94%|█████████▎| 441/471 [01:23<00:05,  5.21it/s] 94%|█████████▍| 442/471 [01:23<00:05,  5.23it/s] 94%|█████████▍| 443/471 [01:23<00:05,  5.22it/s] 94%|█████████▍| 444/471 [01:23<00:05,  5.21it/s] 94%|█████████▍| 445/471 [01:23<00:04,  5.20it/s] 95%|█████████▍| 446/471 [01:24<00:04,  5.20it/s] 95%|█████████▍| 447/471 [01:24<00:04,  5.19it/s] 95%|█████████▌| 448/471 [01:24<00:04,  5.20it/s] 95%|█████████▌| 449/471 [01:24<00:04,  5.20it/s] 96%|█████████▌| 450/471 [01:24<00:04,  5.20it/s] 96%|█████████▌| 451/471 [01:25<00:03,  5.19it/s] 96%|█████████▌| 452/471 [01:25<00:03,  5.19it/s] 96%|█████████▌| 453/471 [01:25<00:03,  5.19it/s] 96%|█████████▋| 454/471 [01:25<00:03,  5.18it/s] 97%|█████████▋| 455/471 [01:25<00:03,  5.18it/s] 97%|█████████▋| 456/471 [01:26<00:02,  5.19it/s] 97%|█████████▋| 457/471 [01:26<00:02,  5.20it/s] 97%|█████████▋| 458/471 [01:26<00:02,  5.19it/s] 97%|█████████▋| 459/471 [01:26<00:02,  5.21it/s] 98%|█████████▊| 460/471 [01:26<00:02,  5.19it/s] 98%|█████████▊| 461/471 [01:27<00:01,  5.19it/s] 98%|█████████▊| 462/471 [01:27<00:01,  5.20it/s] 98%|█████████▊| 463/471 [01:27<00:01,  5.19it/s] 99%|█████████▊| 464/471 [01:27<00:01,  5.20it/s] 99%|█████████▊| 465/471 [01:27<00:01,  5.22it/s] 99%|█████████▉| 466/471 [01:28<00:00,  5.21it/s] 99%|█████████▉| 467/471 [01:28<00:00,  5.19it/s] 99%|█████████▉| 468/471 [01:28<00:00,  5.18it/s]100%|█████████▉| 469/471 [01:28<00:00,  5.19it/s]100%|█████████▉| 470/471 [01:28<00:00,  5.20it/s]100%|██████████| 471/471 [01:28<00:00,  5.56it/s]100%|██████████| 471/471 [01:28<00:00,  5.30it/s]
{'eval_loss': 1.8047758340835571, 'eval_model_preparation_time': 0.0051, 'eval_acc': 0.5169941582580988, 'eval_runtime': 89.1108, 'eval_samples_per_second': 84.524, 'eval_steps_per_second': 5.286}
