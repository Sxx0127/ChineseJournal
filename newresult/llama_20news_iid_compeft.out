nohup: ignoring input
Map:   0%|          | 0/11314 [00:00<?, ? examples/s]Map:   9%|▉         | 1000/11314 [00:00<00:01, 7987.28 examples/s]Map:  18%|█▊        | 2000/11314 [00:00<00:01, 8897.78 examples/s]Map:  27%|██▋       | 3000/11314 [00:00<00:00, 9132.24 examples/s]Map:  35%|███▌      | 4000/11314 [00:00<00:00, 8823.36 examples/s]Map:  44%|████▍     | 5000/11314 [00:00<00:00, 8057.06 examples/s]Map:  53%|█████▎    | 6000/11314 [00:00<00:00, 8230.42 examples/s]Map:  62%|██████▏   | 7000/11314 [00:00<00:00, 8618.69 examples/s]Map:  71%|███████   | 8000/11314 [00:00<00:00, 8986.20 examples/s]Map:  80%|███████▉  | 9000/11314 [00:01<00:00, 8828.46 examples/s]Map:  88%|████████▊ | 10000/11314 [00:01<00:00, 8445.16 examples/s]Map:  97%|█████████▋| 11000/11314 [00:01<00:00, 8780.52 examples/s]Map: 100%|██████████| 11314/11314 [00:01<00:00, 8562.76 examples/s]
Map:   0%|          | 0/7532 [00:00<?, ? examples/s]Map:  13%|█▎        | 1000/7532 [00:00<00:00, 9210.40 examples/s]Map:  27%|██▋       | 2000/7532 [00:00<00:00, 9579.55 examples/s]Map:  40%|███▉      | 3000/7532 [00:00<00:00, 6658.83 examples/s]Map:  66%|██████▋   | 5000/7532 [00:00<00:00, 8397.21 examples/s]Map:  80%|███████▉  | 6000/7532 [00:00<00:00, 6382.23 examples/s]Map:  93%|█████████▎| 7000/7532 [00:00<00:00, 6773.59 examples/s]Map: 100%|██████████| 7532/7532 [00:01<00:00, 7123.05 examples/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:07<00:14,  7.29s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:21<00:11, 11.48s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:31<00:00, 10.56s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:31<00:00, 10.39s/it]
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at ./model/models--llama-2-7b-hf/ and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
trainable params: 8,388,608 || all params: 6,615,814,144 || trainable%: 0.1268
the model architecture is 
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): LlamaForSequenceClassification(
      (model): LlamaModel(
        (embed_tokens): Embedding(32000, 4096)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaAttention(
              (q_proj): lora.Linear(
                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
              (v_proj): lora.Linear(
                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
              (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
              (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
              (act_fn): SiLU()
            )
            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
          )
        )
        (norm): LlamaRMSNorm((4096,), eps=1e-05)
        (rotary_emb): LlamaRotaryEmbedding()
      )
      (score): Linear(in_features=4096, out_features=20, bias=False)
    )
  )
)
the number of packet is  782
ROUND:0
CLIENT:85
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:04<02:51,  4.39s/it]                                              {'loss': 5.5007, 'grad_norm': 35.699607849121094, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:04<02:51,  4.39s/it]  5%|▌         | 2/40 [00:06<01:55,  3.04s/it]                                              {'loss': 4.8454, 'grad_norm': 35.2910270690918, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:06<01:55,  3.04s/it]  8%|▊         | 3/40 [00:08<01:36,  2.61s/it]                                              {'loss': 5.8726, 'grad_norm': 46.65425491333008, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:08<01:36,  2.61s/it] 10%|█         | 4/40 [00:10<01:26,  2.41s/it]                                              {'loss': 6.2843, 'grad_norm': 41.752532958984375, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:10<01:26,  2.41s/it] 12%|█▎        | 5/40 [00:12<01:20,  2.31s/it]                                              {'loss': 4.3943, 'grad_norm': 34.57638168334961, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:12<01:20,  2.31s/it] 15%|█▌        | 6/40 [00:14<01:16,  2.25s/it]                                              {'loss': 4.4782, 'grad_norm': 39.77699279785156, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:14<01:16,  2.25s/it] 18%|█▊        | 7/40 [00:17<01:12,  2.20s/it]                                              {'loss': 5.5904, 'grad_norm': 36.636844635009766, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:17<01:12,  2.20s/it] 20%|██        | 8/40 [00:17<00:49,  1.56s/it]                                              {'loss': 6.2732, 'grad_norm': 140.22007751464844, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:17<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:19<00:53,  1.73s/it]                                              {'loss': 1.8755, 'grad_norm': 21.628509521484375, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:19<00:53,  1.73s/it] 25%|██▌       | 10/40 [00:21<00:55,  1.86s/it]                                               {'loss': 1.4367, 'grad_norm': 23.65162467956543, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:21<00:55,  1.86s/it] 28%|██▊       | 11/40 [00:23<00:56,  1.95s/it]                                               {'loss': 1.171, 'grad_norm': 21.935794830322266, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:56,  1.95s/it] 30%|███       | 12/40 [00:25<00:55,  1.98s/it]                                               {'loss': 1.3802, 'grad_norm': 24.637964248657227, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:55,  1.98s/it] 32%|███▎      | 13/40 [00:27<00:55,  2.04s/it]                                               {'loss': 1.0368, 'grad_norm': 21.50191307067871, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:55,  2.04s/it] 35%|███▌      | 14/40 [00:30<00:53,  2.07s/it]                                               {'loss': 1.4869, 'grad_norm': 18.683195114135742, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:30<00:53,  2.07s/it] 38%|███▊      | 15/40 [00:32<00:52,  2.10s/it]                                               {'loss': 1.3302, 'grad_norm': 21.99294662475586, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:52,  2.10s/it] 40%|████      | 16/40 [00:32<00:36,  1.52s/it]                                               {'loss': 0.282, 'grad_norm': 34.359737396240234, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:36,  1.52s/it] 42%|████▎     | 17/40 [00:34<00:39,  1.71s/it]                                               {'loss': 0.2647, 'grad_norm': 9.463595390319824, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:39,  1.71s/it] 45%|████▌     | 18/40 [00:36<00:40,  1.86s/it]                                               {'loss': 0.1998, 'grad_norm': 9.790050506591797, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:40,  1.86s/it] 48%|████▊     | 19/40 [00:38<00:41,  1.96s/it]                                               {'loss': 0.325, 'grad_norm': 13.205451965332031, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  1.96s/it] 50%|█████     | 20/40 [00:41<00:40,  2.02s/it]                                               {'loss': 0.4335, 'grad_norm': 14.545297622680664, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:40,  2.02s/it] 52%|█████▎    | 21/40 [00:43<00:38,  2.05s/it]                                               {'loss': 0.381, 'grad_norm': 11.650986671447754, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:38,  2.05s/it] 55%|█████▌    | 22/40 [00:45<00:37,  2.08s/it]                                               {'loss': 1.2172, 'grad_norm': 19.372303009033203, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:37,  2.08s/it] 57%|█████▊    | 23/40 [00:47<00:35,  2.11s/it]                                               {'loss': 1.0714, 'grad_norm': 18.636184692382812, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:35,  2.11s/it] 60%|██████    | 24/40 [00:47<00:24,  1.53s/it]                                               {'loss': 0.3559, 'grad_norm': 39.957984924316406, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:24,  1.53s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.74s/it]                                               {'loss': 0.3606, 'grad_norm': 33.165245056152344, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.74s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.87s/it]                                               {'loss': 0.9383, 'grad_norm': 124.98271942138672, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.87s/it] 68%|██████▊   | 27/40 [00:54<00:25,  1.97s/it]                                               {'loss': 1.0389, 'grad_norm': 43.37029266357422, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:25,  1.97s/it] 70%|███████   | 28/40 [00:56<00:24,  2.03s/it]                                               {'loss': 0.2964, 'grad_norm': 7.980676174163818, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.03s/it] 72%|███████▎  | 29/40 [00:58<00:22,  2.08s/it]                                               {'loss': 0.1547, 'grad_norm': 8.29322338104248, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:22,  2.08s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.11s/it]                                               {'loss': 0.071, 'grad_norm': 4.926584243774414, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.11s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.14s/it]                                               {'loss': 0.9655, 'grad_norm': 19.46712875366211, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.14s/it] 80%|████████  | 32/40 [01:03<00:12,  1.55s/it]                                               {'loss': 0.0002, 'grad_norm': 0.02899949625134468, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.55s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.76s/it]                                               {'loss': 0.2862, 'grad_norm': 12.100931167602539, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.76s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.87s/it]                                               {'loss': 0.3469, 'grad_norm': 12.349433898925781, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.87s/it] 88%|████████▊ | 35/40 [01:09<00:09,  1.96s/it]                                               {'loss': 0.7132, 'grad_norm': 15.432636260986328, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:09,  1.96s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.04s/it]                                               {'loss': 0.1726, 'grad_norm': 8.519793510437012, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.04s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.09s/it]                                               {'loss': 0.2758, 'grad_norm': 7.639098644256592, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.09s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it]                                               {'loss': 0.0204, 'grad_norm': 1.7474148273468018, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.18s/it]                                               {'loss': 0.2576, 'grad_norm': 7.6989617347717285, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.18s/it]100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'loss': 0.0096, 'grad_norm': 1.4168986082077026, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'train_runtime': 79.2481, 'train_samples_per_second': 7.13, 'train_steps_per_second': 0.505, 'train_loss': 1.584876303459896, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.58s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:64
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.20s/it]                                              {'loss': 4.6374, 'grad_norm': 2.9995369911193848, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.20s/it]  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]                                              {'loss': 5.5367, 'grad_norm': 2.615645408630371, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]  8%|▊         | 3/40 [00:06<01:19,  2.16s/it]                                              {'loss': 4.1484, 'grad_norm': 4.644571304321289, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.16s/it] 10%|█         | 4/40 [00:08<01:18,  2.17s/it]                                              {'loss': 4.4793, 'grad_norm': 3.845005989074707, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.17s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it]                                              {'loss': 4.0402, 'grad_norm': 3.698268175125122, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 3.3753, 'grad_norm': 4.0529866218566895, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 3.9132, 'grad_norm': 8.152078628540039, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 0.3682, 'grad_norm': 5.4325270652771, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 1.9528, 'grad_norm': 17.214170455932617, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.90s/it]                                               {'loss': 1.858, 'grad_norm': 6.283308506011963, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 2.1315, 'grad_norm': 7.404751777648926, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.492, 'grad_norm': 3.310770034790039, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it]                                               {'loss': 1.4939, 'grad_norm': 6.215404510498047, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it]                                               {'loss': 1.6646, 'grad_norm': 9.008403778076172, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:30<00:54,  2.16s/it]                                               {'loss': 2.7342, 'grad_norm': 7.823966026306152, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 1.8118, 'grad_norm': 33.024658203125, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.6459, 'grad_norm': 4.686238765716553, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.7941, 'grad_norm': 6.8985700607299805, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it]                                               {'loss': 1.2313, 'grad_norm': 7.814154624938965, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 1.9993, 'grad_norm': 8.042366981506348, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.6906, 'grad_norm': 5.235284328460693, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 1.0225, 'grad_norm': 7.667457103729248, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it]                                               {'loss': 1.5222, 'grad_norm': 6.4332451820373535, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it] 60%|██████    | 24/40 [00:46<00:25,  1.58s/it]                                               {'loss': 0.0133, 'grad_norm': 0.25858134031295776, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.469, 'grad_norm': 3.7825849056243896, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.4666, 'grad_norm': 5.557157516479492, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 1.0635, 'grad_norm': 8.4688720703125, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:55<00:24,  2.08s/it]                                               {'loss': 0.7595, 'grad_norm': 4.220010757446289, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it]                                               {'loss': 0.2651, 'grad_norm': 2.816865921020508, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.6687, 'grad_norm': 2.8186659812927246, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.7069, 'grad_norm': 4.922449111938477, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:02<00:12,  1.59s/it]                                               {'loss': 0.8779, 'grad_norm': 23.269100189208984, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.2718, 'grad_norm': 2.511256456375122, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.12, 'grad_norm': 2.2812728881835938, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.6663, 'grad_norm': 9.359580039978027, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it]                                               {'loss': 0.1521, 'grad_norm': 2.176584005355835, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.087, 'grad_norm': 1.0061205625534058, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.4065, 'grad_norm': 4.759432792663574, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]                                               {'loss': 0.7989, 'grad_norm': 4.396721839904785, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 1.0932, 'grad_norm': 18.97679901123047, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 79.156, 'train_samples_per_second': 7.138, 'train_steps_per_second': 0.505, 'train_loss': 1.5607378232525662, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.16s/it]                                              {'loss': 4.8382, 'grad_norm': 6.356035232543945, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.16s/it]  5%|▌         | 2/40 [00:04<01:21,  2.13s/it]                                              {'loss': 3.3704, 'grad_norm': 2.4121763706207275, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:21,  2.13s/it]  8%|▊         | 3/40 [00:06<01:19,  2.14s/it]                                              {'loss': 3.57, 'grad_norm': 2.987017869949341, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.14s/it] 10%|█         | 4/40 [00:08<01:16,  2.13s/it]                                              {'loss': 4.752, 'grad_norm': 4.448099136352539, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:16,  2.13s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.14s/it]                                              {'loss': 2.2705, 'grad_norm': 3.585453987121582, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.14s/it] 15%|█▌        | 6/40 [00:12<01:13,  2.15s/it]                                              {'loss': 4.5543, 'grad_norm': 7.094880104064941, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:12<01:13,  2.15s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it]                                              {'loss': 3.5328, 'grad_norm': 4.1487507820129395, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 6.5629, 'grad_norm': 13.546975135803223, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 1.6695, 'grad_norm': 3.995671510696411, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.90s/it]                                               {'loss': 2.2492, 'grad_norm': 3.2564609050750732, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it]                                               {'loss': 1.3949, 'grad_norm': 132.732666015625, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 1.823, 'grad_norm': 3.5042777061462402, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:55,  2.06s/it]                                               {'loss': 2.4254, 'grad_norm': 22.3302001953125, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:55,  2.06s/it] 35%|███▌      | 14/40 [00:28<00:54,  2.09s/it]                                               {'loss': 2.3778, 'grad_norm': 8.962172508239746, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:54,  2.09s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.13s/it]                                               {'loss': 1.5231, 'grad_norm': 6.87653112411499, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.13s/it] 40%|████      | 16/40 [00:30<00:37,  1.54s/it]                                               {'loss': 10.4289, 'grad_norm': 20.155498504638672, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.54s/it] 42%|████▎     | 17/40 [00:32<00:39,  1.73s/it]                                               {'loss': 1.0747, 'grad_norm': 4.641282558441162, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:32<00:39,  1.73s/it] 45%|████▌     | 18/40 [00:35<00:40,  1.86s/it]                                               {'loss': 1.7104, 'grad_norm': 8.588227272033691, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:40,  1.86s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.97s/it]                                               {'loss': 1.206, 'grad_norm': 10.848115921020508, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.97s/it] 50%|█████     | 20/40 [00:39<00:40,  2.04s/it]                                               {'loss': 0.8078, 'grad_norm': 3.700972318649292, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:40,  2.04s/it] 52%|█████▎    | 21/40 [00:41<00:39,  2.08s/it]                                               {'loss': 1.3669, 'grad_norm': 7.881504535675049, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:41<00:39,  2.08s/it] 55%|█████▌    | 22/40 [00:43<00:38,  2.14s/it]                                               {'loss': 0.6905, 'grad_norm': 2.8526721000671387, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:43<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it]                                               {'loss': 1.6223, 'grad_norm': 6.777237415313721, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 3.151, 'grad_norm': 30.946853637695312, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it]                                               {'loss': 0.735, 'grad_norm': 6.740455150604248, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it] 65%|██████▌   | 26/40 [00:50<00:26,  1.89s/it]                                               {'loss': 0.8224, 'grad_norm': 3.8463430404663086, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:50<00:26,  1.89s/it] 68%|██████▊   | 27/40 [00:52<00:25,  1.98s/it]                                               {'loss': 0.8351, 'grad_norm': 6.052786827087402, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:52<00:25,  1.98s/it] 70%|███████   | 28/40 [00:55<00:24,  2.05s/it]                                               {'loss': 0.7307, 'grad_norm': 7.229855537414551, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.05s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.10s/it]                                               {'loss': 0.4155, 'grad_norm': 4.201075077056885, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.10s/it] 75%|███████▌  | 30/40 [00:59<00:21,  2.14s/it]                                               {'loss': 0.2607, 'grad_norm': 6.68511962890625, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:59<00:21,  2.14s/it] 78%|███████▊  | 31/40 [01:01<00:19,  2.18s/it]                                               {'loss': 0.5265, 'grad_norm': 5.758908748626709, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:01<00:19,  2.18s/it] 80%|████████  | 32/40 [01:02<00:12,  1.58s/it]                                               {'loss': 0.1441, 'grad_norm': 11.112038612365723, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.76s/it]                                               {'loss': 0.2043, 'grad_norm': 3.5155746936798096, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.76s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.89s/it]                                               {'loss': 0.3581, 'grad_norm': 5.575412273406982, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.89s/it] 88%|████████▊ | 35/40 [01:08<00:10,  2.00s/it]                                               {'loss': 0.2355, 'grad_norm': 10.244531631469727, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:08<00:10,  2.00s/it] 90%|█████████ | 36/40 [01:10<00:08,  2.07s/it]                                               {'loss': 0.6538, 'grad_norm': 13.565486907958984, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:10<00:08,  2.07s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.12s/it]                                               {'loss': 0.3551, 'grad_norm': 3.465763568878174, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.12s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.15s/it]                                               {'loss': 0.4015, 'grad_norm': 3.9515974521636963, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.15s/it] 98%|█████████▊| 39/40 [01:17<00:02,  2.18s/it]                                               {'loss': 0.3666, 'grad_norm': 8.664177894592285, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:17<00:02,  2.18s/it]100%|██████████| 40/40 [01:17<00:00,  1.58s/it]                                               {'loss': 0.6919, 'grad_norm': 42.19877624511719, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:17<00:00,  1.58s/it]                                               {'train_runtime': 78.0507, 'train_samples_per_second': 7.239, 'train_steps_per_second': 0.512, 'train_loss': 1.9177241917699575, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]100%|██████████| 40/40 [01:18<00:00,  1.95s/it]
CLIENT:80
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:23,  2.14s/it]                                              {'loss': 5.9576, 'grad_norm': 2.9376115798950195, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:23,  2.14s/it]  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]                                              {'loss': 5.6567, 'grad_norm': 2.844036817550659, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]  8%|▊         | 3/40 [00:06<01:19,  2.15s/it]                                              {'loss': 4.3782, 'grad_norm': 4.042764186859131, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.15s/it] 10%|█         | 4/40 [00:08<01:17,  2.16s/it]                                              {'loss': 4.7145, 'grad_norm': 2.7741925716400146, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.16s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.16s/it]                                              {'loss': 5.0068, 'grad_norm': 3.6687052249908447, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.16s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 3.1867, 'grad_norm': 3.15928053855896, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 4.1896, 'grad_norm': 4.025552749633789, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 1.8577, 'grad_norm': 12.3161039352417, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 2.3485, 'grad_norm': 4.906413555145264, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it]                                               {'loss': 2.6465, 'grad_norm': 4.958210468292236, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 1.5414, 'grad_norm': 3.3393197059631348, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:58,  2.07s/it]                                               {'loss': 2.1767, 'grad_norm': 4.3800506591796875, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 1.1008, 'grad_norm': 22.652122497558594, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 1.8049, 'grad_norm': 8.534175872802734, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:30<00:54,  2.16s/it]                                               {'loss': 2.1936, 'grad_norm': 10.134122848510742, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 0.013, 'grad_norm': 0.6832192540168762, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.7417, 'grad_norm': 2.8116047382354736, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it]                                               {'loss': 0.8588, 'grad_norm': 6.995296955108643, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it]                                               {'loss': 0.7114, 'grad_norm': 6.773273468017578, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it] 50%|█████     | 20/40 [00:39<00:41,  2.06s/it]                                               {'loss': 1.1247, 'grad_norm': 8.4657564163208, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.5111, 'grad_norm': 6.953996181488037, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.4665, 'grad_norm': 8.14005184173584, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.20s/it]                                               {'loss': 0.3064, 'grad_norm': 2.7784881591796875, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.20s/it] 60%|██████    | 24/40 [00:46<00:25,  1.59s/it]                                               {'loss': 0.0433, 'grad_norm': 1.3972645998001099, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.566, 'grad_norm': 2.1233346462249756, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.033, 'grad_norm': 0.6464819312095642, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.2097, 'grad_norm': 2.056433916091919, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:55<00:25,  2.08s/it]                                               {'loss': 0.321, 'grad_norm': 1.4054689407348633, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:25,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.2441, 'grad_norm': 4.309719085693359, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.1655, 'grad_norm': 5.005366325378418, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.3348, 'grad_norm': 4.349488258361816, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:02<00:12,  1.60s/it]                                               {'loss': 3.8538, 'grad_norm': 40.15251159667969, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0619, 'grad_norm': 0.8704134225845337, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.1197, 'grad_norm': 1.518689751625061, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.1941, 'grad_norm': 2.827969551086426, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it]                                               {'loss': 0.9232, 'grad_norm': 7.722167015075684, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.2534, 'grad_norm': 4.869864463806152, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.1995, 'grad_norm': 4.708036422729492, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]                                               {'loss': 0.4728, 'grad_norm': 1.6057440042495728, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 0.2763, 'grad_norm': 11.143757820129395, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 79.2005, 'train_samples_per_second': 7.134, 'train_steps_per_second': 0.505, 'train_loss': 1.5441511414479465, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:6
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.16s/it]                                              {'loss': 3.3491, 'grad_norm': 4.340394020080566, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.16s/it]  5%|▌         | 2/40 [00:04<01:20,  2.12s/it]                                              {'loss': 6.9246, 'grad_norm': 2.743384838104248, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:20,  2.12s/it]  8%|▊         | 3/40 [00:06<01:19,  2.15s/it]                                              {'loss': 4.3237, 'grad_norm': 4.860828399658203, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.15s/it] 10%|█         | 4/40 [00:08<01:17,  2.16s/it]                                              {'loss': 5.0551, 'grad_norm': 6.324195384979248, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.16s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.17s/it]                                              {'loss': 3.7224, 'grad_norm': 4.345726490020752, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.17s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 3.4307, 'grad_norm': 4.55136775970459, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 4.245, 'grad_norm': 6.346025466918945, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 4.7627, 'grad_norm': 35.74348449707031, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 1.9937, 'grad_norm': 6.502841472625732, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it]                                               {'loss': 2.7035, 'grad_norm': 5.990269184112549, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it]                                               {'loss': 2.724, 'grad_norm': 8.840666770935059, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 1.941, 'grad_norm': 3.5524961948394775, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 1.6425, 'grad_norm': 5.386899948120117, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it]                                               {'loss': 1.4483, 'grad_norm': 5.884629726409912, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:30<00:54,  2.16s/it]                                               {'loss': 1.1707, 'grad_norm': 5.261624336242676, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 4.198, 'grad_norm': 37.41929626464844, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 1.0094, 'grad_norm': 8.054098129272461, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it]                                               {'loss': 0.5814, 'grad_norm': 6.684582233428955, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it] 48%|████▊     | 19/40 [00:37<00:41,  2.00s/it]                                               {'loss': 0.3579, 'grad_norm': 2.888350486755371, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  2.00s/it] 50%|█████     | 20/40 [00:39<00:41,  2.07s/it]                                               {'loss': 0.9323, 'grad_norm': 6.5416765213012695, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.6514, 'grad_norm': 10.505718231201172, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.3511, 'grad_norm': 1.9368406534194946, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 0.9541, 'grad_norm': 5.561738014221191, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.0272, 'grad_norm': 0.8501790761947632, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.77s/it]                                               {'loss': 0.3504, 'grad_norm': 5.175696849822998, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.091, 'grad_norm': 1.5096827745437622, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:25,  2.00s/it]                                               {'loss': 0.6622, 'grad_norm': 9.91569995880127, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  2.00s/it] 70%|███████   | 28/40 [00:55<00:24,  2.08s/it]                                               {'loss': 0.0542, 'grad_norm': 1.655537486076355, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.13s/it]                                               {'loss': 0.2832, 'grad_norm': 2.8203887939453125, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.0902, 'grad_norm': 2.5250792503356934, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it]                                               {'loss': 0.4701, 'grad_norm': 3.3312807083129883, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it] 80%|████████  | 32/40 [01:02<00:12,  1.58s/it]                                               {'loss': 0.2037, 'grad_norm': 6.55843448638916, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it]                                               {'loss': 0.0553, 'grad_norm': 1.4040369987487793, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.0504, 'grad_norm': 1.2271074056625366, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.01s/it]                                               {'loss': 0.2325, 'grad_norm': 3.4789276123046875, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.01s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it]                                               {'loss': 0.0329, 'grad_norm': 0.6596488952636719, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.14s/it]                                               {'loss': 0.1281, 'grad_norm': 1.8301951885223389, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 0.6284, 'grad_norm': 2.6161797046661377, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]                                               {'loss': 0.1151, 'grad_norm': 1.9044065475463867, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'loss': 0.0019, 'grad_norm': 0.07806981354951859, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'train_runtime': 78.8251, 'train_samples_per_second': 7.168, 'train_steps_per_second': 0.507, 'train_loss': 1.548735359427519, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]100%|██████████| 40/40 [01:18<00:00,  1.97s/it]
CLIENT:12
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.18s/it]                                              {'loss': 4.4859, 'grad_norm': 3.0617518424987793, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.18s/it]  5%|▌         | 2/40 [00:04<01:20,  2.13s/it]                                              {'loss': 7.4268, 'grad_norm': 3.73299241065979, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:20,  2.13s/it]  8%|▊         | 3/40 [00:06<01:19,  2.16s/it]                                              {'loss': 4.9017, 'grad_norm': 2.8338348865509033, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.16s/it] 10%|█         | 4/40 [00:08<01:18,  2.18s/it]                                              {'loss': 4.1453, 'grad_norm': 2.8614187240600586, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.18s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it]                                              {'loss': 3.1744, 'grad_norm': 3.364478588104248, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 4.5103, 'grad_norm': 6.935163974761963, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 4.8748, 'grad_norm': 7.418041229248047, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 7.4852, 'grad_norm': 9.219364166259766, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 2.6311, 'grad_norm': 3.5304598808288574, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it]                                               {'loss': 3.1559, 'grad_norm': 3.6797573566436768, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 1.6333, 'grad_norm': 3.8101508617401123, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 1.4005, 'grad_norm': 4.127768516540527, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it]                                               {'loss': 2.6256, 'grad_norm': 4.884982585906982, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 1.7419, 'grad_norm': 6.556241989135742, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:30<00:54,  2.16s/it]                                               {'loss': 0.9257, 'grad_norm': 4.669012069702148, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 2.7209, 'grad_norm': 35.94133758544922, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.8183, 'grad_norm': 2.9221043586730957, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it]                                               {'loss': 0.2373, 'grad_norm': 2.9301223754882812, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it] 48%|████▊     | 19/40 [00:37<00:41,  2.00s/it]                                               {'loss': 0.3594, 'grad_norm': 3.3492753505706787, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  2.00s/it] 50%|█████     | 20/40 [00:39<00:41,  2.05s/it]                                               {'loss': 0.3052, 'grad_norm': 5.899666786193848, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.05s/it] 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it]                                               {'loss': 0.3451, 'grad_norm': 3.9606523513793945, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 0.5378, 'grad_norm': 4.749412536621094, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.18s/it]                                               {'loss': 0.9055, 'grad_norm': 4.988255500793457, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.18s/it] 60%|██████    | 24/40 [00:46<00:25,  1.58s/it]                                               {'loss': 0.0846, 'grad_norm': 2.989301919937134, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0391, 'grad_norm': 0.5395153164863586, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.0697, 'grad_norm': 1.21378493309021, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it]                                               {'loss': 0.6096, 'grad_norm': 23.029830932617188, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it] 70%|███████   | 28/40 [00:55<00:24,  2.08s/it]                                               {'loss': 0.1867, 'grad_norm': 2.5221242904663086, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.12s/it]                                               {'loss': 0.4445, 'grad_norm': 4.274506568908691, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.12s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.14s/it]                                               {'loss': 0.2887, 'grad_norm': 6.98137092590332, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.14s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it]                                               {'loss': 0.306, 'grad_norm': 5.610891342163086, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it] 80%|████████  | 32/40 [01:02<00:12,  1.59s/it]                                               {'loss': 0.0053, 'grad_norm': 0.32629892230033875, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it]                                               {'loss': 0.2067, 'grad_norm': 2.3671658039093018, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.0274, 'grad_norm': 0.5585659742355347, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.0547, 'grad_norm': 0.9888425469398499, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it]                                               {'loss': 0.0303, 'grad_norm': 0.8912482261657715, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.15s/it]                                               {'loss': 0.2311, 'grad_norm': 1.3852826356887817, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 0.2023, 'grad_norm': 1.8812921047210693, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.2496, 'grad_norm': 3.1032660007476807, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'loss': 0.118, 'grad_norm': 5.835831165313721, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'train_runtime': 78.8668, 'train_samples_per_second': 7.164, 'train_steps_per_second': 0.507, 'train_loss': 1.6125596166122704, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]100%|██████████| 40/40 [01:18<00:00,  1.97s/it]
CLIENT:43
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]                                              {'loss': 5.1058, 'grad_norm': 3.545525312423706, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]                                              {'loss': 4.8174, 'grad_norm': 3.232832193374634, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]  8%|▊         | 3/40 [00:06<01:20,  2.18s/it]                                              {'loss': 4.9241, 'grad_norm': 3.6105661392211914, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.18s/it] 10%|█         | 4/40 [00:08<01:18,  2.18s/it]                                              {'loss': 4.8199, 'grad_norm': 9.519346237182617, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.18s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it]                                              {'loss': 3.1524, 'grad_norm': 5.366383075714111, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 3.106, 'grad_norm': 4.8061323165893555, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 3.1589, 'grad_norm': 4.764090538024902, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.4617, 'grad_norm': 4.7117390632629395, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.79s/it]                                              {'loss': 2.1548, 'grad_norm': 4.194357872009277, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 2.0014, 'grad_norm': 7.8533430099487305, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 1.9336, 'grad_norm': 6.095668315887451, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 3.0502, 'grad_norm': 6.390511512756348, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 1.7416, 'grad_norm': 6.140339374542236, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 1.2496, 'grad_norm': 4.206071376800537, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 1.2671, 'grad_norm': 4.454864501953125, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0261, 'grad_norm': 0.7263128757476807, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.5143, 'grad_norm': 3.6164095401763916, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.2543, 'grad_norm': 2.1618402004241943, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.9266, 'grad_norm': 4.282162189483643, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.4499, 'grad_norm': 2.932518482208252, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.3994, 'grad_norm': 4.923641204833984, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it]                                               {'loss': 0.7686, 'grad_norm': 4.298666954040527, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.5928, 'grad_norm': 4.381503582000732, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 1.14, 'grad_norm': 17.751853942871094, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.2555, 'grad_norm': 1.6940511465072632, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.18, 'grad_norm': 1.9593311548233032, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.4371, 'grad_norm': 2.793243885040283, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.2598, 'grad_norm': 2.091325044631958, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.5493, 'grad_norm': 6.402447700500488, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.0653, 'grad_norm': 1.637740135192871, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.1385, 'grad_norm': 3.440317153930664, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0177, 'grad_norm': 0.9148516654968262, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.3557, 'grad_norm': 5.920254230499268, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.0234, 'grad_norm': 0.5036295056343079, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it]                                               {'loss': 0.1116, 'grad_norm': 2.841963291168213, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.3404, 'grad_norm': 2.9160735607147217, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.0966, 'grad_norm': 1.7734252214431763, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.1582, 'grad_norm': 2.978304862976074, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.2923, 'grad_norm': 1.9519816637039185, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.3783, 'grad_norm': 12.486055374145508, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.5712, 'train_samples_per_second': 7.101, 'train_steps_per_second': 0.503, 'train_loss': 1.2919054887723178, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:17
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]                                              {'loss': 5.0047, 'grad_norm': 4.751118183135986, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]                                              {'loss': 5.7734, 'grad_norm': 4.287298202514648, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]  8%|▊         | 3/40 [00:06<01:20,  2.19s/it]                                              {'loss': 4.4551, 'grad_norm': 3.2600834369659424, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.19s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 4.3655, 'grad_norm': 3.414252281188965, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it]                                              {'loss': 3.2832, 'grad_norm': 4.061037063598633, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:13<01:13,  2.18s/it]                                              {'loss': 5.6437, 'grad_norm': 3.9460017681121826, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:13,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 3.6272, 'grad_norm': 3.282910108566284, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 9.1488, 'grad_norm': 23.664438247680664, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.72s/it]                                              {'loss': 3.3591, 'grad_norm': 5.3002028465271, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.72s/it] 25%|██▌       | 10/40 [00:19<00:55,  1.86s/it]                                               {'loss': 1.2769, 'grad_norm': 4.112964630126953, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:55,  1.86s/it] 28%|██▊       | 11/40 [00:21<00:56,  1.95s/it]                                               {'loss': 2.1748, 'grad_norm': 4.67779016494751, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:56,  1.95s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 1.6321, 'grad_norm': 5.059694290161133, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it]                                               {'loss': 1.8468, 'grad_norm': 5.410943984985352, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it]                                               {'loss': 1.5304, 'grad_norm': 8.552419662475586, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:30<00:54,  2.17s/it]                                               {'loss': 2.8581, 'grad_norm': 14.52966022491455, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.4632, 'grad_norm': 18.011287689208984, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 1.0212, 'grad_norm': 5.083123207092285, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.7654, 'grad_norm': 4.2773518562316895, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it]                                               {'loss': 1.2257, 'grad_norm': 45.95613098144531, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it] 50%|█████     | 20/40 [00:39<00:41,  2.07s/it]                                               {'loss': 1.3428, 'grad_norm': 6.450647830963135, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.8622, 'grad_norm': 6.348485946655273, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 0.9375, 'grad_norm': 5.382528781890869, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 0.9657, 'grad_norm': 4.1290388107299805, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.0493, 'grad_norm': 1.3043553829193115, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.7451, 'grad_norm': 5.431276321411133, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it]                                               {'loss': 0.4676, 'grad_norm': 2.946638345718384, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it]                                               {'loss': 0.591, 'grad_norm': 5.943915843963623, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it] 70%|███████   | 28/40 [00:55<00:24,  2.07s/it]                                               {'loss': 1.1656, 'grad_norm': 43.83681106567383, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.13s/it]                                               {'loss': 0.7557, 'grad_norm': 3.236877918243408, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.6943, 'grad_norm': 3.97221302986145, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it]                                               {'loss': 0.7929, 'grad_norm': 3.8600683212280273, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it] 80%|████████  | 32/40 [01:02<00:12,  1.59s/it]                                               {'loss': 0.0837, 'grad_norm': 2.2762579917907715, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.79s/it]                                               {'loss': 0.2316, 'grad_norm': 2.7093517780303955, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.4427, 'grad_norm': 4.465551376342773, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.2997, 'grad_norm': 10.511857032775879, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it]                                               {'loss': 0.7938, 'grad_norm': 4.533006191253662, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.15s/it]                                               {'loss': 0.4999, 'grad_norm': 5.245370864868164, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 0.1173, 'grad_norm': 1.2768551111221313, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]                                               {'loss': 0.3467, 'grad_norm': 2.9913523197174072, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'loss': 0.0911, 'grad_norm': 4.4969563484191895, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'train_runtime': 78.9364, 'train_samples_per_second': 7.158, 'train_steps_per_second': 0.507, 'train_loss': 1.7932827148586512, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]100%|██████████| 40/40 [01:18<00:00,  1.97s/it]
CLIENT:7
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]                                              {'loss': 5.0381, 'grad_norm': 2.9790456295013428, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]                                              {'loss': 4.9306, 'grad_norm': 3.107264757156372, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]  8%|▊         | 3/40 [00:06<01:20,  2.16s/it]                                              {'loss': 4.8424, 'grad_norm': 3.1881983280181885, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.16s/it] 10%|█         | 4/40 [00:08<01:17,  2.17s/it]                                              {'loss': 5.2238, 'grad_norm': 5.27199125289917, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.17s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it]                                              {'loss': 5.0877, 'grad_norm': 3.714296817779541, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 2.6532, 'grad_norm': 5.171139717102051, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.16s/it]                                              {'loss': 5.1541, 'grad_norm': 9.25484848022461, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.16s/it] 20%|██        | 8/40 [00:15<00:49,  1.53s/it]                                              {'loss': 4.1571, 'grad_norm': 17.71735191345215, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.53s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it]                                              {'loss': 2.0113, 'grad_norm': 3.208024501800537, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it] 25%|██▌       | 10/40 [00:19<00:55,  1.87s/it]                                               {'loss': 1.5433, 'grad_norm': 3.4561920166015625, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:55,  1.87s/it] 28%|██▊       | 11/40 [00:21<00:56,  1.96s/it]                                               {'loss': 2.7837, 'grad_norm': 4.2618889808654785, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:56,  1.96s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 1.8416, 'grad_norm': 7.635200500488281, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 2.4501, 'grad_norm': 6.886404514312744, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 2.7301, 'grad_norm': 9.070636749267578, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.14s/it]                                               {'loss': 2.7443, 'grad_norm': 11.914850234985352, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.14s/it] 40%|████      | 16/40 [00:30<00:37,  1.55s/it]                                               {'loss': 1.4441, 'grad_norm': 20.095455169677734, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.55s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.9722, 'grad_norm': 5.964736461639404, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.2565, 'grad_norm': 4.993561267852783, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it]                                               {'loss': 1.2991, 'grad_norm': 4.871367931365967, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it] 50%|█████     | 20/40 [00:39<00:40,  2.04s/it]                                               {'loss': 1.0008, 'grad_norm': 6.9951581954956055, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:40,  2.04s/it] 52%|█████▎    | 21/40 [00:41<00:39,  2.09s/it]                                               {'loss': 1.1021, 'grad_norm': 13.89365291595459, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:41<00:39,  2.09s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 1.0321, 'grad_norm': 7.117236614227295, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 0.4003, 'grad_norm': 3.00490403175354, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.0042, 'grad_norm': 0.20859280228614807, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it]                                               {'loss': 0.2209, 'grad_norm': 3.109706163406372, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it] 65%|██████▌   | 26/40 [00:50<00:26,  1.89s/it]                                               {'loss': 0.3621, 'grad_norm': 10.735450744628906, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:50<00:26,  1.89s/it] 68%|██████▊   | 27/40 [00:53<00:25,  2.00s/it]                                               {'loss': 0.3233, 'grad_norm': 5.340734481811523, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  2.00s/it] 70%|███████   | 28/40 [00:55<00:24,  2.07s/it]                                               {'loss': 0.9999, 'grad_norm': 6.851484775543213, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.12s/it]                                               {'loss': 0.1454, 'grad_norm': 2.600628137588501, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.12s/it] 75%|███████▌  | 30/40 [00:59<00:21,  2.15s/it]                                               {'loss': 0.2207, 'grad_norm': 1.7878814935684204, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:59<00:21,  2.15s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.17s/it]                                               {'loss': 0.3146, 'grad_norm': 32.40522003173828, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.17s/it] 80%|████████  | 32/40 [01:02<00:12,  1.58s/it]                                               {'loss': 0.009, 'grad_norm': 0.3530043959617615, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.77s/it]                                               {'loss': 0.1826, 'grad_norm': 3.3299639225006104, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.77s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.90s/it]                                               {'loss': 0.4833, 'grad_norm': 5.206221103668213, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.90s/it] 88%|████████▊ | 35/40 [01:08<00:10,  2.00s/it]                                               {'loss': 0.3464, 'grad_norm': 22.750675201416016, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:08<00:10,  2.00s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it]                                               {'loss': 0.5092, 'grad_norm': 4.3570942878723145, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.13s/it]                                               {'loss': 0.1743, 'grad_norm': 1.350087285041809, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.13s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.16s/it]                                               {'loss': 0.2512, 'grad_norm': 9.046109199523926, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.16s/it] 98%|█████████▊| 39/40 [01:17<00:02,  2.18s/it]                                               {'loss': 0.1304, 'grad_norm': 3.9929537773132324, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:17<00:02,  2.18s/it]100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'loss': 0.3665, 'grad_norm': 12.244133949279785, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'train_runtime': 78.4616, 'train_samples_per_second': 7.201, 'train_steps_per_second': 0.51, 'train_loss': 1.6435654301312752, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]100%|██████████| 40/40 [01:18<00:00,  1.96s/it]
CLIENT:8
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:23,  2.15s/it]                                              {'loss': 3.0708, 'grad_norm': 2.71870756149292, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:23,  2.15s/it]  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]                                              {'loss': 4.5617, 'grad_norm': 3.8026347160339355, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]  8%|▊         | 3/40 [00:06<01:19,  2.16s/it]                                              {'loss': 3.624, 'grad_norm': 3.022650957107544, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.16s/it] 10%|█         | 4/40 [00:08<01:16,  2.14s/it]                                              {'loss': 6.0945, 'grad_norm': 4.971972942352295, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:16,  2.14s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.15s/it]                                              {'loss': 4.74, 'grad_norm': 7.4112443923950195, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.15s/it] 15%|█▌        | 6/40 [00:12<01:13,  2.15s/it]                                              {'loss': 3.6462, 'grad_norm': 5.374606132507324, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:12<01:13,  2.15s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 3.4697, 'grad_norm': 5.809826850891113, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 4.4027, 'grad_norm': 14.867506980895996, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 1.7848, 'grad_norm': 9.955828666687012, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it]                                               {'loss': 2.6475, 'grad_norm': 9.990373611450195, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it]                                               {'loss': 1.9528, 'grad_norm': 8.224038124084473, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 2.4472, 'grad_norm': 6.292572975158691, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 2.0624, 'grad_norm': 5.018811225891113, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it]                                               {'loss': 3.338, 'grad_norm': 11.402066230773926, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it]                                               {'loss': 1.9076, 'grad_norm': 5.229182720184326, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it] 40%|████      | 16/40 [00:30<00:37,  1.56s/it]                                               {'loss': 1.9455, 'grad_norm': 17.25943374633789, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.995, 'grad_norm': 3.1626651287078857, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.9182, 'grad_norm': 3.359212636947632, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it]                                               {'loss': 1.1726, 'grad_norm': 4.964609622955322, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it] 50%|█████     | 20/40 [00:39<00:41,  2.05s/it]                                               {'loss': 0.6659, 'grad_norm': 4.820939064025879, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.05s/it] 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it]                                               {'loss': 0.8673, 'grad_norm': 6.357660293579102, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 1.2556, 'grad_norm': 7.5096940994262695, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it]                                               {'loss': 1.3138, 'grad_norm': 8.682860374450684, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.5143, 'grad_norm': 7.053102016448975, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it]                                               {'loss': 0.4105, 'grad_norm': 5.054109573364258, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it] 65%|██████▌   | 26/40 [00:50<00:26,  1.89s/it]                                               {'loss': 0.3563, 'grad_norm': 4.824624538421631, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:50<00:26,  1.89s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it]                                               {'loss': 0.3816, 'grad_norm': 5.903965950012207, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it] 70%|███████   | 28/40 [00:55<00:24,  2.07s/it]                                               {'loss': 0.4598, 'grad_norm': 8.457107543945312, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.12s/it]                                               {'loss': 0.534, 'grad_norm': 4.5376105308532715, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.12s/it] 75%|███████▌  | 30/40 [00:59<00:21,  2.15s/it]                                               {'loss': 0.4012, 'grad_norm': 8.336862564086914, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:59<00:21,  2.15s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.17s/it]                                               {'loss': 0.3299, 'grad_norm': 4.046020984649658, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.17s/it] 80%|████████  | 32/40 [01:02<00:12,  1.58s/it]                                               {'loss': 0.0087, 'grad_norm': 0.4076761305332184, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.77s/it]                                               {'loss': 0.1647, 'grad_norm': 2.07047700881958, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.77s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.91s/it]                                               {'loss': 0.1356, 'grad_norm': 2.262791872024536, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.91s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.01s/it]                                               {'loss': 0.1148, 'grad_norm': 1.0881513357162476, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.01s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it]                                               {'loss': 0.0457, 'grad_norm': 0.8456557393074036, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.14s/it]                                               {'loss': 0.0837, 'grad_norm': 2.6220149993896484, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.16s/it]                                               {'loss': 0.3835, 'grad_norm': 7.342264652252197, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.16s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.18s/it]                                               {'loss': 0.2079, 'grad_norm': 2.409052848815918, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.18s/it]100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'loss': 0.0348, 'grad_norm': 2.4470343589782715, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'train_runtime': 78.4768, 'train_samples_per_second': 7.2, 'train_steps_per_second': 0.51, 'train_loss': 1.5862690161447972, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]100%|██████████| 40/40 [01:18<00:00,  1.96s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:53,  1.60it/s]  1%|          | 3/471 [00:02<06:55,  1.13it/s]  1%|          | 4/471 [00:03<08:00,  1.03s/it]  1%|          | 5/471 [00:05<08:37,  1.11s/it]  1%|▏         | 6/471 [00:06<08:59,  1.16s/it]  1%|▏         | 7/471 [00:07<09:14,  1.20s/it]  2%|▏         | 8/471 [00:08<09:24,  1.22s/it]  2%|▏         | 9/471 [00:10<09:30,  1.23s/it]  2%|▏         | 10/471 [00:11<09:34,  1.25s/it]  2%|▏         | 11/471 [00:12<09:37,  1.25s/it]  3%|▎         | 12/471 [00:13<09:38,  1.26s/it]  3%|▎         | 13/471 [00:15<09:40,  1.27s/it]  3%|▎         | 14/471 [00:16<09:41,  1.27s/it]  3%|▎         | 15/471 [00:17<09:40,  1.27s/it]  3%|▎         | 16/471 [00:19<09:40,  1.28s/it]  4%|▎         | 17/471 [00:20<09:40,  1.28s/it]  4%|▍         | 18/471 [00:21<09:40,  1.28s/it]  4%|▍         | 19/471 [00:22<09:39,  1.28s/it]  4%|▍         | 20/471 [00:24<09:38,  1.28s/it]  4%|▍         | 21/471 [00:25<09:38,  1.28s/it]  5%|▍         | 22/471 [00:26<09:37,  1.29s/it]  5%|▍         | 23/471 [00:28<09:36,  1.29s/it]  5%|▌         | 24/471 [00:29<09:36,  1.29s/it]  5%|▌         | 25/471 [00:30<09:35,  1.29s/it]  6%|▌         | 26/471 [00:31<09:34,  1.29s/it]  6%|▌         | 27/471 [00:33<09:33,  1.29s/it]  6%|▌         | 28/471 [00:34<09:32,  1.29s/it]  6%|▌         | 29/471 [00:35<09:31,  1.29s/it]  6%|▋         | 30/471 [00:37<09:31,  1.30s/it]  7%|▋         | 31/471 [00:38<09:30,  1.30s/it]  7%|▋         | 32/471 [00:39<09:28,  1.30s/it]  7%|▋         | 33/471 [00:40<09:26,  1.29s/it]  7%|▋         | 34/471 [00:42<09:25,  1.29s/it]  7%|▋         | 35/471 [00:43<09:25,  1.30s/it]  8%|▊         | 36/471 [00:44<09:24,  1.30s/it]  8%|▊         | 37/471 [00:46<09:23,  1.30s/it]  8%|▊         | 38/471 [00:47<09:22,  1.30s/it]  8%|▊         | 39/471 [00:48<09:20,  1.30s/it]  8%|▊         | 40/471 [00:50<09:19,  1.30s/it]  9%|▊         | 41/471 [00:51<09:18,  1.30s/it]  9%|▉         | 42/471 [00:52<09:18,  1.30s/it]  9%|▉         | 43/471 [00:53<09:16,  1.30s/it]  9%|▉         | 44/471 [00:55<09:14,  1.30s/it] 10%|▉         | 45/471 [00:56<09:14,  1.30s/it] 10%|▉         | 46/471 [00:57<09:13,  1.30s/it] 10%|▉         | 47/471 [00:59<09:11,  1.30s/it] 10%|█         | 48/471 [01:00<09:10,  1.30s/it] 10%|█         | 49/471 [01:01<09:09,  1.30s/it] 11%|█         | 50/471 [01:03<09:08,  1.30s/it] 11%|█         | 51/471 [01:04<09:07,  1.30s/it] 11%|█         | 52/471 [01:05<09:06,  1.30s/it] 11%|█▏        | 53/471 [01:07<09:05,  1.31s/it] 11%|█▏        | 54/471 [01:08<09:04,  1.30s/it] 12%|█▏        | 55/471 [01:09<09:02,  1.31s/it] 12%|█▏        | 56/471 [01:10<09:02,  1.31s/it] 12%|█▏        | 57/471 [01:12<09:00,  1.31s/it] 12%|█▏        | 58/471 [01:13<08:59,  1.31s/it] 13%|█▎        | 59/471 [01:14<08:58,  1.31s/it] 13%|█▎        | 60/471 [01:16<08:56,  1.31s/it] 13%|█▎        | 61/471 [01:17<08:55,  1.31s/it] 13%|█▎        | 62/471 [01:18<08:54,  1.31s/it] 13%|█▎        | 63/471 [01:20<08:52,  1.31s/it] 14%|█▎        | 64/471 [01:21<08:51,  1.31s/it] 14%|█▍        | 65/471 [01:22<08:49,  1.31s/it] 14%|█▍        | 66/471 [01:24<08:48,  1.31s/it] 14%|█▍        | 67/471 [01:25<08:48,  1.31s/it] 14%|█▍        | 68/471 [01:26<08:46,  1.31s/it] 15%|█▍        | 69/471 [01:27<08:45,  1.31s/it] 15%|█▍        | 70/471 [01:29<08:45,  1.31s/it] 15%|█▌        | 71/471 [01:30<08:44,  1.31s/it] 15%|█▌        | 72/471 [01:31<08:42,  1.31s/it] 15%|█▌        | 73/471 [01:33<08:41,  1.31s/it] 16%|█▌        | 74/471 [01:34<08:38,  1.31s/it] 16%|█▌        | 75/471 [01:35<08:38,  1.31s/it] 16%|█▌        | 76/471 [01:37<08:37,  1.31s/it] 16%|█▋        | 77/471 [01:38<08:35,  1.31s/it] 17%|█▋        | 78/471 [01:39<08:34,  1.31s/it] 17%|█▋        | 79/471 [01:41<08:34,  1.31s/it] 17%|█▋        | 80/471 [01:42<08:33,  1.31s/it] 17%|█▋        | 81/471 [01:43<08:31,  1.31s/it] 17%|█▋        | 82/471 [01:44<08:29,  1.31s/it] 18%|█▊        | 83/471 [01:46<08:28,  1.31s/it] 18%|█▊        | 84/471 [01:47<08:27,  1.31s/it] 18%|█▊        | 85/471 [01:48<08:25,  1.31s/it] 18%|█▊        | 86/471 [01:50<08:24,  1.31s/it] 18%|█▊        | 87/471 [01:51<08:23,  1.31s/it] 19%|█▊        | 88/471 [01:52<08:21,  1.31s/it] 19%|█▉        | 89/471 [01:54<08:20,  1.31s/it] 19%|█▉        | 90/471 [01:55<08:19,  1.31s/it] 19%|█▉        | 91/471 [01:56<08:18,  1.31s/it] 20%|█▉        | 92/471 [01:58<08:16,  1.31s/it] 20%|█▉        | 93/471 [01:59<08:15,  1.31s/it] 20%|█▉        | 94/471 [02:00<08:14,  1.31s/it] 20%|██        | 95/471 [02:02<08:13,  1.31s/it] 20%|██        | 96/471 [02:03<08:11,  1.31s/it] 21%|██        | 97/471 [02:04<08:11,  1.31s/it] 21%|██        | 98/471 [02:05<08:09,  1.31s/it] 21%|██        | 99/471 [02:07<08:08,  1.31s/it] 21%|██        | 100/471 [02:08<08:07,  1.31s/it] 21%|██▏       | 101/471 [02:09<08:06,  1.31s/it] 22%|██▏       | 102/471 [02:11<08:05,  1.31s/it] 22%|██▏       | 103/471 [02:12<08:04,  1.32s/it] 22%|██▏       | 104/471 [02:13<08:03,  1.32s/it] 22%|██▏       | 105/471 [02:15<08:03,  1.32s/it] 23%|██▎       | 106/471 [02:16<08:01,  1.32s/it] 23%|██▎       | 107/471 [02:17<07:59,  1.32s/it] 23%|██▎       | 108/471 [02:19<07:57,  1.32s/it] 23%|██▎       | 109/471 [02:20<07:55,  1.31s/it] 23%|██▎       | 110/471 [02:21<07:53,  1.31s/it] 24%|██▎       | 111/471 [02:23<07:53,  1.32s/it] 24%|██▍       | 112/471 [02:24<07:52,  1.32s/it] 24%|██▍       | 113/471 [02:25<07:50,  1.31s/it] 24%|██▍       | 114/471 [02:27<07:50,  1.32s/it] 24%|██▍       | 115/471 [02:28<07:48,  1.32s/it] 25%|██▍       | 116/471 [02:29<07:47,  1.32s/it] 25%|██▍       | 117/471 [02:30<07:46,  1.32s/it] 25%|██▌       | 118/471 [02:32<07:45,  1.32s/it] 25%|██▌       | 119/471 [02:33<07:44,  1.32s/it] 25%|██▌       | 120/471 [02:34<07:43,  1.32s/it] 26%|██▌       | 121/471 [02:36<07:42,  1.32s/it] 26%|██▌       | 122/471 [02:37<07:40,  1.32s/it] 26%|██▌       | 123/471 [02:38<07:39,  1.32s/it] 26%|██▋       | 124/471 [02:40<07:38,  1.32s/it] 27%|██▋       | 125/471 [02:41<07:37,  1.32s/it] 27%|██▋       | 126/471 [02:42<07:36,  1.32s/it] 27%|██▋       | 127/471 [02:44<07:34,  1.32s/it] 27%|██▋       | 128/471 [02:45<07:33,  1.32s/it] 27%|██▋       | 129/471 [02:46<07:31,  1.32s/it] 28%|██▊       | 130/471 [02:48<07:30,  1.32s/it] 28%|██▊       | 131/471 [02:49<07:29,  1.32s/it] 28%|██▊       | 132/471 [02:50<07:28,  1.32s/it] 28%|██▊       | 133/471 [02:52<07:26,  1.32s/it] 28%|██▊       | 134/471 [02:53<07:26,  1.32s/it] 29%|██▊       | 135/471 [02:54<07:24,  1.32s/it] 29%|██▉       | 136/471 [02:56<07:23,  1.32s/it] 29%|██▉       | 137/471 [02:57<07:22,  1.32s/it] 29%|██▉       | 138/471 [02:58<07:20,  1.32s/it] 30%|██▉       | 139/471 [03:00<07:19,  1.32s/it] 30%|██▉       | 140/471 [03:01<07:17,  1.32s/it] 30%|██▉       | 141/471 [03:02<07:16,  1.32s/it] 30%|███       | 142/471 [03:04<07:14,  1.32s/it] 30%|███       | 143/471 [03:05<07:13,  1.32s/it] 31%|███       | 144/471 [03:06<07:12,  1.32s/it] 31%|███       | 145/471 [03:07<07:10,  1.32s/it] 31%|███       | 146/471 [03:09<07:09,  1.32s/it] 31%|███       | 147/471 [03:10<07:08,  1.32s/it] 31%|███▏      | 148/471 [03:11<07:06,  1.32s/it] 32%|███▏      | 149/471 [03:13<07:05,  1.32s/it] 32%|███▏      | 150/471 [03:14<07:04,  1.32s/it] 32%|███▏      | 151/471 [03:15<07:03,  1.32s/it] 32%|███▏      | 152/471 [03:17<07:01,  1.32s/it] 32%|███▏      | 153/471 [03:18<07:00,  1.32s/it] 33%|███▎      | 154/471 [03:19<06:58,  1.32s/it] 33%|███▎      | 155/471 [03:21<06:57,  1.32s/it] 33%|███▎      | 156/471 [03:22<06:55,  1.32s/it] 33%|███▎      | 157/471 [03:23<06:54,  1.32s/it] 34%|███▎      | 158/471 [03:25<06:52,  1.32s/it] 34%|███▍      | 159/471 [03:26<06:51,  1.32s/it] 34%|███▍      | 160/471 [03:27<06:50,  1.32s/it] 34%|███▍      | 161/471 [03:29<06:48,  1.32s/it] 34%|███▍      | 162/471 [03:30<06:47,  1.32s/it] 35%|███▍      | 163/471 [03:31<06:46,  1.32s/it] 35%|███▍      | 164/471 [03:33<06:44,  1.32s/it] 35%|███▌      | 165/471 [03:34<06:43,  1.32s/it] 35%|███▌      | 166/471 [03:35<06:42,  1.32s/it] 35%|███▌      | 167/471 [03:37<06:40,  1.32s/it] 36%|███▌      | 168/471 [03:38<06:39,  1.32s/it] 36%|███▌      | 169/471 [03:39<06:38,  1.32s/it] 36%|███▌      | 170/471 [03:40<06:37,  1.32s/it] 36%|███▋      | 171/471 [03:42<06:35,  1.32s/it] 37%|███▋      | 172/471 [03:43<06:33,  1.32s/it] 37%|███▋      | 173/471 [03:44<06:32,  1.32s/it] 37%|███▋      | 174/471 [03:46<06:31,  1.32s/it] 37%|███▋      | 175/471 [03:47<06:30,  1.32s/it] 37%|███▋      | 176/471 [03:48<06:28,  1.32s/it] 38%|███▊      | 177/471 [03:50<06:27,  1.32s/it] 38%|███▊      | 178/471 [03:51<06:26,  1.32s/it] 38%|███▊      | 179/471 [03:52<06:24,  1.32s/it] 38%|███▊      | 180/471 [03:54<06:23,  1.32s/it] 38%|███▊      | 181/471 [03:55<06:22,  1.32s/it] 39%|███▊      | 182/471 [03:56<06:21,  1.32s/it] 39%|███▉      | 183/471 [03:58<06:19,  1.32s/it] 39%|███▉      | 184/471 [03:59<06:18,  1.32s/it] 39%|███▉      | 185/471 [04:00<06:17,  1.32s/it] 39%|███▉      | 186/471 [04:02<06:16,  1.32s/it] 40%|███▉      | 187/471 [04:03<06:15,  1.32s/it] 40%|███▉      | 188/471 [04:04<06:14,  1.32s/it] 40%|████      | 189/471 [04:06<06:11,  1.32s/it] 40%|████      | 190/471 [04:07<06:10,  1.32s/it] 41%|████      | 191/471 [04:08<06:10,  1.32s/it] 41%|████      | 192/471 [04:10<06:08,  1.32s/it] 41%|████      | 193/471 [04:11<06:06,  1.32s/it] 41%|████      | 194/471 [04:12<06:06,  1.32s/it] 41%|████▏     | 195/471 [04:13<06:05,  1.32s/it] 42%|████▏     | 196/471 [04:15<06:03,  1.32s/it] 42%|████▏     | 197/471 [04:16<06:01,  1.32s/it] 42%|████▏     | 198/471 [04:17<06:00,  1.32s/it] 42%|████▏     | 199/471 [04:19<05:59,  1.32s/it] 42%|████▏     | 200/471 [04:20<05:57,  1.32s/it] 43%|████▎     | 201/471 [04:21<05:55,  1.32s/it] 43%|████▎     | 202/471 [04:23<05:54,  1.32s/it] 43%|████▎     | 203/471 [04:24<05:53,  1.32s/it] 43%|████▎     | 204/471 [04:25<05:52,  1.32s/it] 44%|████▎     | 205/471 [04:27<05:51,  1.32s/it] 44%|████▎     | 206/471 [04:28<05:49,  1.32s/it] 44%|████▍     | 207/471 [04:29<05:48,  1.32s/it] 44%|████▍     | 208/471 [04:31<05:47,  1.32s/it] 44%|████▍     | 209/471 [04:32<05:46,  1.32s/it] 45%|████▍     | 210/471 [04:33<05:44,  1.32s/it] 45%|████▍     | 211/471 [04:35<05:43,  1.32s/it] 45%|████▌     | 212/471 [04:36<05:42,  1.32s/it] 45%|████▌     | 213/471 [04:37<05:41,  1.32s/it] 45%|████▌     | 214/471 [04:39<05:40,  1.32s/it] 46%|████▌     | 215/471 [04:40<05:38,  1.32s/it] 46%|████▌     | 216/471 [04:41<05:37,  1.32s/it] 46%|████▌     | 217/471 [04:43<05:36,  1.33s/it] 46%|████▋     | 218/471 [04:44<05:35,  1.33s/it] 46%|████▋     | 219/471 [04:45<05:33,  1.33s/it] 47%|████▋     | 220/471 [04:47<05:32,  1.33s/it] 47%|████▋     | 221/471 [04:48<05:31,  1.33s/it] 47%|████▋     | 222/471 [04:49<05:29,  1.32s/it] 47%|████▋     | 223/471 [04:51<05:28,  1.32s/it] 48%|████▊     | 224/471 [04:52<05:27,  1.32s/it] 48%|████▊     | 225/471 [04:53<05:25,  1.32s/it] 48%|████▊     | 226/471 [04:54<05:24,  1.32s/it] 48%|████▊     | 227/471 [04:56<05:23,  1.32s/it] 48%|████▊     | 228/471 [04:57<05:22,  1.33s/it] 49%|████▊     | 229/471 [04:58<05:21,  1.33s/it] 49%|████▉     | 230/471 [05:00<05:20,  1.33s/it] 49%|████▉     | 231/471 [05:01<05:18,  1.33s/it] 49%|████▉     | 232/471 [05:02<05:16,  1.32s/it] 49%|████▉     | 233/471 [05:04<05:15,  1.32s/it] 50%|████▉     | 234/471 [05:05<05:14,  1.33s/it] 50%|████▉     | 235/471 [05:06<05:13,  1.33s/it] 50%|█████     | 236/471 [05:08<05:11,  1.33s/it] 50%|█████     | 237/471 [05:09<05:10,  1.33s/it] 51%|█████     | 238/471 [05:10<05:09,  1.33s/it] 51%|█████     | 239/471 [05:12<05:07,  1.33s/it] 51%|█████     | 240/471 [05:13<05:06,  1.33s/it] 51%|█████     | 241/471 [05:14<05:05,  1.33s/it] 51%|█████▏    | 242/471 [05:16<05:03,  1.33s/it] 52%|█████▏    | 243/471 [05:17<05:02,  1.33s/it] 52%|█████▏    | 244/471 [05:18<05:01,  1.33s/it] 52%|█████▏    | 245/471 [05:20<04:59,  1.33s/it] 52%|█████▏    | 246/471 [05:21<04:58,  1.33s/it] 52%|█████▏    | 247/471 [05:22<04:56,  1.33s/it] 53%|█████▎    | 248/471 [05:24<04:55,  1.33s/it] 53%|█████▎    | 249/471 [05:25<04:54,  1.33s/it] 53%|█████▎    | 250/471 [05:26<04:53,  1.33s/it] 53%|█████▎    | 251/471 [05:28<04:51,  1.33s/it] 54%|█████▎    | 252/471 [05:29<04:50,  1.33s/it] 54%|█████▎    | 253/471 [05:30<04:49,  1.33s/it] 54%|█████▍    | 254/471 [05:32<04:48,  1.33s/it] 54%|█████▍    | 255/471 [05:33<04:46,  1.33s/it] 54%|█████▍    | 256/471 [05:34<04:45,  1.33s/it] 55%|█████▍    | 257/471 [05:36<04:44,  1.33s/it] 55%|█████▍    | 258/471 [05:37<04:43,  1.33s/it] 55%|█████▍    | 259/471 [05:38<04:42,  1.33s/it] 55%|█████▌    | 260/471 [05:40<04:41,  1.33s/it] 55%|█████▌    | 261/471 [05:41<04:39,  1.33s/it] 56%|█████▌    | 262/471 [05:42<04:37,  1.33s/it] 56%|█████▌    | 263/471 [05:44<04:36,  1.33s/it] 56%|█████▌    | 264/471 [05:45<04:35,  1.33s/it] 56%|█████▋    | 265/471 [05:46<04:33,  1.33s/it] 56%|█████▋    | 266/471 [05:48<04:32,  1.33s/it] 57%|█████▋    | 267/471 [05:49<04:31,  1.33s/it] 57%|█████▋    | 268/471 [05:50<04:30,  1.33s/it] 57%|█████▋    | 269/471 [05:52<04:28,  1.33s/it] 57%|█████▋    | 270/471 [05:53<04:27,  1.33s/it] 58%|█████▊    | 271/471 [05:54<04:25,  1.33s/it] 58%|█████▊    | 272/471 [05:56<04:24,  1.33s/it] 58%|█████▊    | 273/471 [05:57<04:22,  1.33s/it] 58%|█████▊    | 274/471 [05:58<04:21,  1.33s/it] 58%|█████▊    | 275/471 [06:00<04:19,  1.33s/it] 59%|█████▊    | 276/471 [06:01<04:18,  1.33s/it] 59%|█████▉    | 277/471 [06:02<04:17,  1.33s/it] 59%|█████▉    | 278/471 [06:04<04:16,  1.33s/it] 59%|█████▉    | 279/471 [06:05<04:14,  1.33s/it] 59%|█████▉    | 280/471 [06:06<04:13,  1.33s/it] 60%|█████▉    | 281/471 [06:08<04:12,  1.33s/it] 60%|█████▉    | 282/471 [06:09<04:10,  1.33s/it] 60%|██████    | 283/471 [06:10<04:09,  1.33s/it] 60%|██████    | 284/471 [06:11<04:08,  1.33s/it] 61%|██████    | 285/471 [06:13<04:06,  1.33s/it] 61%|██████    | 286/471 [06:14<04:05,  1.33s/it] 61%|██████    | 287/471 [06:15<04:04,  1.33s/it] 61%|██████    | 288/471 [06:17<04:02,  1.33s/it] 61%|██████▏   | 289/471 [06:18<04:01,  1.33s/it] 62%|██████▏   | 290/471 [06:19<04:00,  1.33s/it] 62%|██████▏   | 291/471 [06:21<03:58,  1.33s/it] 62%|██████▏   | 292/471 [06:22<03:57,  1.33s/it] 62%|██████▏   | 293/471 [06:23<03:55,  1.32s/it] 62%|██████▏   | 294/471 [06:25<03:54,  1.33s/it] 63%|██████▎   | 295/471 [06:26<03:53,  1.33s/it] 63%|██████▎   | 296/471 [06:27<03:51,  1.32s/it] 63%|██████▎   | 297/471 [06:29<03:50,  1.33s/it] 63%|██████▎   | 298/471 [06:30<03:49,  1.33s/it] 63%|██████▎   | 299/471 [06:31<03:48,  1.33s/it] 64%|██████▎   | 300/471 [06:33<03:47,  1.33s/it] 64%|██████▍   | 301/471 [06:34<03:45,  1.33s/it] 64%|██████▍   | 302/471 [06:35<03:44,  1.33s/it] 64%|██████▍   | 303/471 [06:37<03:42,  1.33s/it] 65%|██████▍   | 304/471 [06:38<03:41,  1.33s/it] 65%|██████▍   | 305/471 [06:39<03:40,  1.33s/it] 65%|██████▍   | 306/471 [06:41<03:39,  1.33s/it] 65%|██████▌   | 307/471 [06:42<03:38,  1.33s/it] 65%|██████▌   | 308/471 [06:43<03:37,  1.33s/it] 66%|██████▌   | 309/471 [06:45<03:35,  1.33s/it] 66%|██████▌   | 310/471 [06:46<03:34,  1.33s/it] 66%|██████▌   | 311/471 [06:47<03:32,  1.33s/it] 66%|██████▌   | 312/471 [06:49<03:31,  1.33s/it] 66%|██████▋   | 313/471 [06:50<03:30,  1.33s/it] 67%|██████▋   | 314/471 [06:51<03:28,  1.33s/it] 67%|██████▋   | 315/471 [06:53<03:27,  1.33s/it] 67%|██████▋   | 316/471 [06:54<03:26,  1.33s/it] 67%|██████▋   | 317/471 [06:55<03:25,  1.33s/it] 68%|██████▊   | 318/471 [06:57<03:24,  1.33s/it] 68%|██████▊   | 319/471 [06:58<03:22,  1.34s/it] 68%|██████▊   | 320/471 [06:59<03:21,  1.34s/it] 68%|██████▊   | 321/471 [07:01<03:20,  1.34s/it] 68%|██████▊   | 322/471 [07:02<03:19,  1.34s/it] 69%|██████▊   | 323/471 [07:03<03:18,  1.34s/it] 69%|██████▉   | 324/471 [07:05<03:16,  1.34s/it] 69%|██████▉   | 325/471 [07:06<03:15,  1.34s/it] 69%|██████▉   | 326/471 [07:07<03:14,  1.34s/it] 69%|██████▉   | 327/471 [07:09<03:12,  1.34s/it] 70%|██████▉   | 328/471 [07:10<03:11,  1.34s/it] 70%|██████▉   | 329/471 [07:11<03:10,  1.34s/it] 70%|███████   | 330/471 [07:13<03:08,  1.34s/it] 70%|███████   | 331/471 [07:14<03:07,  1.34s/it] 70%|███████   | 332/471 [07:15<03:06,  1.34s/it] 71%|███████   | 333/471 [07:17<03:04,  1.34s/it] 71%|███████   | 334/471 [07:18<03:03,  1.34s/it] 71%|███████   | 335/471 [07:19<03:02,  1.34s/it] 71%|███████▏  | 336/471 [07:21<03:01,  1.34s/it] 72%|███████▏  | 337/471 [07:22<02:59,  1.34s/it] 72%|███████▏  | 338/471 [07:23<02:58,  1.34s/it] 72%|███████▏  | 339/471 [07:25<02:57,  1.34s/it] 72%|███████▏  | 340/471 [07:26<02:55,  1.34s/it] 72%|███████▏  | 341/471 [07:27<02:54,  1.34s/it] 73%|███████▎  | 342/471 [07:29<02:52,  1.34s/it] 73%|███████▎  | 343/471 [07:30<02:51,  1.34s/it] 73%|███████▎  | 344/471 [07:31<02:49,  1.34s/it] 73%|███████▎  | 345/471 [07:33<02:48,  1.34s/it] 73%|███████▎  | 346/471 [07:34<02:47,  1.34s/it] 74%|███████▎  | 347/471 [07:36<02:46,  1.34s/it] 74%|███████▍  | 348/471 [07:37<02:45,  1.34s/it] 74%|███████▍  | 349/471 [07:38<02:43,  1.34s/it] 74%|███████▍  | 350/471 [07:40<02:42,  1.34s/it] 75%|███████▍  | 351/471 [07:41<02:40,  1.34s/it] 75%|███████▍  | 352/471 [07:42<02:39,  1.34s/it] 75%|███████▍  | 353/471 [07:44<02:38,  1.34s/it] 75%|███████▌  | 354/471 [07:45<02:37,  1.34s/it] 75%|███████▌  | 355/471 [07:46<02:35,  1.34s/it] 76%|███████▌  | 356/471 [07:48<02:34,  1.34s/it] 76%|███████▌  | 357/471 [07:49<02:33,  1.35s/it] 76%|███████▌  | 358/471 [07:50<02:31,  1.34s/it] 76%|███████▌  | 359/471 [07:52<02:30,  1.34s/it] 76%|███████▋  | 360/471 [07:53<02:29,  1.34s/it] 77%|███████▋  | 361/471 [07:54<02:27,  1.34s/it] 77%|███████▋  | 362/471 [07:56<02:26,  1.35s/it] 77%|███████▋  | 363/471 [07:57<02:25,  1.34s/it] 77%|███████▋  | 364/471 [07:58<02:23,  1.35s/it] 77%|███████▋  | 365/471 [08:00<02:22,  1.35s/it] 78%|███████▊  | 366/471 [08:01<02:21,  1.35s/it] 78%|███████▊  | 367/471 [08:02<02:20,  1.35s/it] 78%|███████▊  | 368/471 [08:04<02:18,  1.35s/it] 78%|███████▊  | 369/471 [08:05<02:17,  1.34s/it] 79%|███████▊  | 370/471 [08:06<02:15,  1.35s/it] 79%|███████▉  | 371/471 [08:08<02:14,  1.35s/it] 79%|███████▉  | 372/471 [08:09<02:13,  1.35s/it] 79%|███████▉  | 373/471 [08:10<02:11,  1.35s/it] 79%|███████▉  | 374/471 [08:12<02:10,  1.34s/it] 80%|███████▉  | 375/471 [08:13<02:08,  1.34s/it] 80%|███████▉  | 376/471 [08:15<02:07,  1.34s/it] 80%|████████  | 377/471 [08:16<02:06,  1.34s/it] 80%|████████  | 378/471 [08:17<02:04,  1.34s/it] 80%|████████  | 379/471 [08:19<02:03,  1.34s/it] 81%|████████  | 380/471 [08:20<02:02,  1.35s/it] 81%|████████  | 381/471 [08:21<02:01,  1.34s/it] 81%|████████  | 382/471 [08:23<01:59,  1.34s/it] 81%|████████▏ | 383/471 [08:24<01:58,  1.35s/it] 82%|████████▏ | 384/471 [08:25<01:57,  1.35s/it] 82%|████████▏ | 385/471 [08:27<01:55,  1.35s/it] 82%|████████▏ | 386/471 [08:28<01:54,  1.34s/it] 82%|████████▏ | 387/471 [08:29<01:52,  1.34s/it] 82%|████████▏ | 388/471 [08:31<01:51,  1.35s/it] 83%|████████▎ | 389/471 [08:32<01:50,  1.34s/it] 83%|████████▎ | 390/471 [08:33<01:48,  1.34s/it] 83%|████████▎ | 391/471 [08:35<01:47,  1.34s/it] 83%|████████▎ | 392/471 [08:36<01:46,  1.34s/it] 83%|████████▎ | 393/471 [08:37<01:44,  1.34s/it] 84%|████████▎ | 394/471 [08:39<01:43,  1.34s/it] 84%|████████▍ | 395/471 [08:40<01:42,  1.34s/it] 84%|████████▍ | 396/471 [08:41<01:40,  1.34s/it] 84%|████████▍ | 397/471 [08:43<01:39,  1.34s/it] 85%|████████▍ | 398/471 [08:44<01:37,  1.34s/it] 85%|████████▍ | 399/471 [08:45<01:36,  1.34s/it] 85%|████████▍ | 400/471 [08:47<01:35,  1.34s/it] 85%|████████▌ | 401/471 [08:48<01:33,  1.34s/it] 85%|████████▌ | 402/471 [08:49<01:32,  1.34s/it] 86%|████████▌ | 403/471 [08:51<01:31,  1.34s/it] 86%|████████▌ | 404/471 [08:52<01:29,  1.34s/it] 86%|████████▌ | 405/471 [08:53<01:28,  1.34s/it] 86%|████████▌ | 406/471 [08:55<01:27,  1.34s/it] 86%|████████▋ | 407/471 [08:56<01:25,  1.34s/it] 87%|████████▋ | 408/471 [08:57<01:24,  1.34s/it] 87%|████████▋ | 409/471 [08:59<01:23,  1.34s/it] 87%|████████▋ | 410/471 [09:00<01:21,  1.34s/it] 87%|████████▋ | 411/471 [09:01<01:20,  1.34s/it] 87%|████████▋ | 412/471 [09:03<01:19,  1.34s/it] 88%|████████▊ | 413/471 [09:04<01:17,  1.34s/it] 88%|████████▊ | 414/471 [09:06<01:16,  1.34s/it] 88%|████████▊ | 415/471 [09:07<01:14,  1.34s/it] 88%|████████▊ | 416/471 [09:08<01:13,  1.34s/it] 89%|████████▊ | 417/471 [09:10<01:12,  1.34s/it] 89%|████████▊ | 418/471 [09:11<01:10,  1.34s/it] 89%|████████▉ | 419/471 [09:12<01:09,  1.34s/it] 89%|████████▉ | 420/471 [09:14<01:08,  1.34s/it] 89%|████████▉ | 421/471 [09:15<01:06,  1.34s/it] 90%|████████▉ | 422/471 [09:16<01:05,  1.34s/it] 90%|████████▉ | 423/471 [09:18<01:04,  1.34s/it] 90%|█████████ | 424/471 [09:19<01:02,  1.34s/it] 90%|█████████ | 425/471 [09:20<01:01,  1.34s/it] 90%|█████████ | 426/471 [09:22<01:00,  1.34s/it] 91%|█████████ | 427/471 [09:23<00:58,  1.34s/it] 91%|█████████ | 428/471 [09:24<00:57,  1.34s/it] 91%|█████████ | 429/471 [09:26<00:56,  1.34s/it] 91%|█████████▏| 430/471 [09:27<00:54,  1.34s/it] 92%|█████████▏| 431/471 [09:28<00:53,  1.34s/it] 92%|█████████▏| 432/471 [09:30<00:52,  1.34s/it] 92%|█████████▏| 433/471 [09:31<00:50,  1.34s/it] 92%|█████████▏| 434/471 [09:32<00:49,  1.34s/it] 92%|█████████▏| 435/471 [09:34<00:48,  1.34s/it] 93%|█████████▎| 436/471 [09:35<00:46,  1.34s/it] 93%|█████████▎| 437/471 [09:36<00:45,  1.34s/it] 93%|█████████▎| 438/471 [09:38<00:44,  1.34s/it] 93%|█████████▎| 439/471 [09:39<00:42,  1.34s/it] 93%|█████████▎| 440/471 [09:40<00:41,  1.34s/it] 94%|█████████▎| 441/471 [09:42<00:40,  1.34s/it] 94%|█████████▍| 442/471 [09:43<00:38,  1.34s/it] 94%|█████████▍| 443/471 [09:44<00:37,  1.34s/it] 94%|█████████▍| 444/471 [09:46<00:36,  1.34s/it] 94%|█████████▍| 445/471 [09:47<00:34,  1.34s/it] 95%|█████████▍| 446/471 [09:48<00:33,  1.34s/it] 95%|█████████▍| 447/471 [09:50<00:32,  1.34s/it] 95%|█████████▌| 448/471 [09:51<00:30,  1.34s/it] 95%|█████████▌| 449/471 [09:52<00:29,  1.34s/it] 96%|█████████▌| 450/471 [09:54<00:28,  1.34s/it] 96%|█████████▌| 451/471 [09:55<00:26,  1.34s/it] 96%|█████████▌| 452/471 [09:56<00:25,  1.34s/it] 96%|█████████▌| 453/471 [09:58<00:24,  1.34s/it] 96%|█████████▋| 454/471 [09:59<00:22,  1.34s/it] 97%|█████████▋| 455/471 [10:00<00:21,  1.34s/it] 97%|█████████▋| 456/471 [10:02<00:20,  1.34s/it] 97%|█████████▋| 457/471 [10:03<00:18,  1.34s/it] 97%|█████████▋| 458/471 [10:04<00:17,  1.34s/it] 97%|█████████▋| 459/471 [10:06<00:16,  1.34s/it] 98%|█████████▊| 460/471 [10:07<00:14,  1.34s/it] 98%|█████████▊| 461/471 [10:08<00:13,  1.34s/it] 98%|█████████▊| 462/471 [10:10<00:12,  1.34s/it] 98%|█████████▊| 463/471 [10:11<00:10,  1.33s/it] 99%|█████████▊| 464/471 [10:12<00:09,  1.34s/it] 99%|█████████▊| 465/471 [10:14<00:08,  1.33s/it] 99%|█████████▉| 466/471 [10:15<00:06,  1.34s/it] 99%|█████████▉| 467/471 [10:16<00:05,  1.34s/it] 99%|█████████▉| 468/471 [10:18<00:04,  1.34s/it]100%|█████████▉| 469/471 [10:19<00:02,  1.34s/it]100%|█████████▉| 470/471 [10:20<00:01,  1.34s/it]100%|██████████| 471/471 [10:21<00:00,  1.22s/it]100%|██████████| 471/471 [10:21<00:00,  1.32s/it]
{'eval_loss': 5.0413079261779785, 'eval_model_preparation_time': 0.0102, 'eval_acc': 0.12387148167817313, 'eval_runtime': 623.1718, 'eval_samples_per_second': 12.087, 'eval_steps_per_second': 0.756}
ROUND:1
CLIENT:26
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:27,  2.24s/it]                                              {'loss': 4.4339, 'grad_norm': 2.432481288909912, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:27,  2.24s/it]  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]                                              {'loss': 5.5998, 'grad_norm': 2.989990472793579, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]  8%|▊         | 3/40 [00:06<01:20,  2.17s/it]                                              {'loss': 5.6545, 'grad_norm': 3.532998561859131, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.17s/it] 10%|█         | 4/40 [00:08<01:17,  2.16s/it]                                              {'loss': 3.2445, 'grad_norm': 3.8158414363861084, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.16s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it]                                              {'loss': 4.2347, 'grad_norm': 10.313010215759277, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 3.6711, 'grad_norm': 3.632174491882324, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 4.0704, 'grad_norm': 6.0675129890441895, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 5.2039, 'grad_norm': 11.63781452178955, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 2.0151, 'grad_norm': 4.230676651000977, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it]                                               {'loss': 2.1462, 'grad_norm': 4.420362949371338, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 2.7716, 'grad_norm': 4.541746616363525, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.3517, 'grad_norm': 10.56989860534668, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 1.608, 'grad_norm': 5.893828868865967, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 1.8976, 'grad_norm': 31.660905838012695, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.16s/it]                                               {'loss': 2.6723, 'grad_norm': 12.321990013122559, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 0.3391, 'grad_norm': 12.171984672546387, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.3277, 'grad_norm': 4.0977783203125, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.5912, 'grad_norm': 5.339401721954346, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it]                                               {'loss': 0.8863, 'grad_norm': 7.155275821685791, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it] 50%|█████     | 20/40 [00:39<00:41,  2.06s/it]                                               {'loss': 0.8348, 'grad_norm': 7.268821716308594, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.7877, 'grad_norm': 8.238870620727539, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.6964, 'grad_norm': 11.603856086730957, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it]                                               {'loss': 0.5929, 'grad_norm': 4.381070613861084, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it] 60%|██████    | 24/40 [00:46<00:25,  1.59s/it]                                               {'loss': 0.493, 'grad_norm': 8.705242156982422, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.2383, 'grad_norm': 3.0101304054260254, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.94s/it]                                               {'loss': 0.2216, 'grad_norm': 3.16428279876709, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.03s/it]                                               {'loss': 0.246, 'grad_norm': 5.348052978515625, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.03s/it] 70%|███████   | 28/40 [00:55<00:25,  2.09s/it]                                               {'loss': 0.656, 'grad_norm': 21.407928466796875, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.11s/it]                                               {'loss': 0.5919, 'grad_norm': 8.772003173828125, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.11s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.1574, 'grad_norm': 3.1281745433807373, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.413, 'grad_norm': 5.374109268188477, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:02<00:12,  1.59s/it]                                               {'loss': 0.1959, 'grad_norm': 6.1491475105285645, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.4941, 'grad_norm': 8.75388240814209, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.2873, 'grad_norm': 4.45590353012085, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.1035, 'grad_norm': 2.0871243476867676, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it]                                               {'loss': 0.3017, 'grad_norm': 5.0595526695251465, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.5165, 'grad_norm': 22.055681228637695, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.20s/it]                                               {'loss': 0.3933, 'grad_norm': 6.20261287689209, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.26s/it]                                               {'loss': 0.1097, 'grad_norm': 3.174346446990967, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.26s/it]100%|██████████| 40/40 [01:19<00:00,  1.69s/it]                                               {'loss': 0.0575, 'grad_norm': 4.98280668258667, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.69s/it]                                               {'train_runtime': 79.7461, 'train_samples_per_second': 7.085, 'train_steps_per_second': 0.502, 'train_loss': 1.5277048023417592, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.69s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:80
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:21,  2.10s/it]                                              {'loss': 5.9503, 'grad_norm': 3.136672258377075, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:21,  2.10s/it]  5%|▌         | 2/40 [00:04<01:20,  2.13s/it]                                              {'loss': 5.6204, 'grad_norm': 3.4092864990234375, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:20,  2.13s/it]  8%|▊         | 3/40 [00:06<01:18,  2.12s/it]                                              {'loss': 4.2509, 'grad_norm': 4.557123184204102, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:18,  2.12s/it] 10%|█         | 4/40 [00:08<01:16,  2.13s/it]                                              {'loss': 4.6112, 'grad_norm': 3.273627996444702, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:16,  2.13s/it] 12%|█▎        | 5/40 [00:10<01:14,  2.12s/it]                                              {'loss': 4.9022, 'grad_norm': 4.280514717102051, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:14,  2.12s/it] 15%|█▌        | 6/40 [00:12<01:13,  2.15s/it]                                              {'loss': 3.129, 'grad_norm': 3.682476282119751, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:12<01:13,  2.15s/it] 18%|█▊        | 7/40 [00:14<01:11,  2.16s/it]                                              {'loss': 4.1096, 'grad_norm': 5.122483730316162, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:14<01:11,  2.16s/it] 20%|██        | 8/40 [00:15<00:48,  1.53s/it]                                              {'loss': 1.9531, 'grad_norm': 16.108625411987305, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:48,  1.53s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it]                                              {'loss': 2.0305, 'grad_norm': 5.729284763336182, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.87s/it]                                               {'loss': 2.3475, 'grad_norm': 6.551408290863037, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.87s/it] 28%|██▊       | 11/40 [00:21<00:57,  1.97s/it]                                               {'loss': 1.2719, 'grad_norm': 5.904659748077393, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:57,  1.97s/it] 30%|███       | 12/40 [00:23<00:57,  2.05s/it]                                               {'loss': 1.8719, 'grad_norm': 5.5304107666015625, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:23<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it]                                               {'loss': 1.2163, 'grad_norm': 9.401252746582031, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it] 35%|███▌      | 14/40 [00:28<00:54,  2.10s/it]                                               {'loss': 1.6906, 'grad_norm': 8.196399688720703, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:54,  2.10s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.14s/it]                                               {'loss': 2.0985, 'grad_norm': 8.070213317871094, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.14s/it] 40%|████      | 16/40 [00:30<00:37,  1.55s/it]                                               {'loss': 0.0087, 'grad_norm': 0.4670669436454773, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.55s/it] 42%|████▎     | 17/40 [00:32<00:39,  1.74s/it]                                               {'loss': 0.6258, 'grad_norm': 2.069770574569702, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:32<00:39,  1.74s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.87s/it]                                               {'loss': 0.724, 'grad_norm': 5.0782623291015625, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.87s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.96s/it]                                               {'loss': 0.7689, 'grad_norm': 6.243204593658447, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.96s/it] 50%|█████     | 20/40 [00:39<00:40,  2.04s/it]                                               {'loss': 0.9206, 'grad_norm': 7.162635326385498, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:40,  2.04s/it] 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it]                                               {'loss': 0.3884, 'grad_norm': 3.2175276279449463, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:43<00:38,  2.13s/it]                                               {'loss': 0.419, 'grad_norm': 4.227061748504639, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:43<00:38,  2.13s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 0.183, 'grad_norm': 2.047952651977539, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.0579, 'grad_norm': 1.942044973373413, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.77s/it]                                               {'loss': 0.4345, 'grad_norm': 1.8702419996261597, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:50<00:26,  1.91s/it]                                               {'loss': 0.0169, 'grad_norm': 0.35332244634628296, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:50<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:52<00:26,  2.01s/it]                                               {'loss': 0.1275, 'grad_norm': 1.3076415061950684, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:52<00:26,  2.01s/it] 70%|███████   | 28/40 [00:55<00:24,  2.06s/it]                                               {'loss': 0.2842, 'grad_norm': 2.197248935699463, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.06s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.11s/it]                                               {'loss': 0.1568, 'grad_norm': 3.393972873687744, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.11s/it] 75%|███████▌  | 30/40 [00:59<00:21,  2.15s/it]                                               {'loss': 0.0491, 'grad_norm': 0.8586541414260864, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:59<00:21,  2.15s/it] 78%|███████▊  | 31/40 [01:01<00:19,  2.19s/it]                                               {'loss': 0.1487, 'grad_norm': 1.5560733079910278, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:01<00:19,  2.19s/it] 80%|████████  | 32/40 [01:02<00:12,  1.58s/it]                                               {'loss': 3.2691, 'grad_norm': 12.360995292663574, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it]                                               {'loss': 0.0493, 'grad_norm': 1.2334901094436646, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.91s/it]                                               {'loss': 0.2341, 'grad_norm': 5.114397048950195, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.91s/it] 88%|████████▊ | 35/40 [01:08<00:09,  2.00s/it]                                               {'loss': 0.0923, 'grad_norm': 2.2839787006378174, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:08<00:09,  2.00s/it] 90%|█████████ | 36/40 [01:10<00:08,  2.07s/it]                                               {'loss': 0.3389, 'grad_norm': 1.351751446723938, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:10<00:08,  2.07s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.13s/it]                                               {'loss': 0.1349, 'grad_norm': 3.1448581218719482, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.13s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.17s/it]                                               {'loss': 0.0615, 'grad_norm': 1.6257784366607666, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:17<00:02,  2.21s/it]                                               {'loss': 0.4126, 'grad_norm': 1.1956636905670166, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:17<00:02,  2.21s/it]100%|██████████| 40/40 [01:18<00:00,  1.63s/it]                                               {'loss': 0.0643, 'grad_norm': 3.8067450523376465, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.63s/it]                                               {'train_runtime': 78.489, 'train_samples_per_second': 7.198, 'train_steps_per_second': 0.51, 'train_loss': 1.425624636048451, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.63s/it]100%|██████████| 40/40 [01:18<00:00,  1.96s/it]
CLIENT:82
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:22,  2.11s/it]                                              {'loss': 6.4269, 'grad_norm': 3.0350308418273926, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:22,  2.11s/it]  5%|▌         | 2/40 [00:04<01:20,  2.12s/it]                                              {'loss': 5.3822, 'grad_norm': 3.539881944656372, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:20,  2.12s/it]  8%|▊         | 3/40 [00:06<01:18,  2.12s/it]                                              {'loss': 3.7534, 'grad_norm': 9.744104385375977, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:18,  2.12s/it] 10%|█         | 4/40 [00:08<01:17,  2.15s/it]                                              {'loss': 5.3624, 'grad_norm': 4.4572062492370605, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.15s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it]                                              {'loss': 4.2575, 'grad_norm': 4.779872894287109, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:12<01:13,  2.16s/it]                                              {'loss': 4.1876, 'grad_norm': 7.076384544372559, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:12<01:13,  2.16s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 2.5845, 'grad_norm': 5.098919868469238, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 3.6983, 'grad_norm': 26.291547775268555, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.74s/it]                                              {'loss': 2.1386, 'grad_norm': 6.22166109085083, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.74s/it] 25%|██▌       | 10/40 [00:19<00:55,  1.86s/it]                                               {'loss': 0.9853, 'grad_norm': 3.5380609035491943, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:55,  1.86s/it] 28%|██▊       | 11/40 [00:21<00:57,  1.97s/it]                                               {'loss': 0.9942, 'grad_norm': 4.093852519989014, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:57,  1.97s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 2.914, 'grad_norm': 6.841796398162842, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it]                                               {'loss': 3.0056, 'grad_norm': 7.8842453956604, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 2.4448, 'grad_norm': 7.146053314208984, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:30<00:54,  2.17s/it]                                               {'loss': 1.8537, 'grad_norm': 4.12551736831665, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:54,  2.17s/it] 40%|████      | 16/40 [00:30<00:37,  1.57s/it]                                               {'loss': 3.9939, 'grad_norm': 8.228269577026367, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.3552, 'grad_norm': 2.9297657012939453, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it]                                               {'loss': 0.9323, 'grad_norm': 5.227296829223633, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it]                                               {'loss': 1.1432, 'grad_norm': 12.595914840698242, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it] 50%|█████     | 20/40 [00:39<00:41,  2.06s/it]                                               {'loss': 0.8388, 'grad_norm': 12.666983604431152, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it]                                               {'loss': 0.8634, 'grad_norm': 4.4817376136779785, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.5608, 'grad_norm': 3.889465093612671, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it]                                               {'loss': 0.6502, 'grad_norm': 2.892224073410034, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.0085, 'grad_norm': 0.4137627184391022, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.75s/it]                                               {'loss': 0.4745, 'grad_norm': 2.219093084335327, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.75s/it] 65%|██████▌   | 26/40 [00:50<00:26,  1.89s/it]                                               {'loss': 0.0489, 'grad_norm': 0.5764773488044739, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:50<00:26,  1.89s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it]                                               {'loss': 0.1882, 'grad_norm': 5.080493450164795, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it] 70%|███████   | 28/40 [00:55<00:24,  2.08s/it]                                               {'loss': 0.1328, 'grad_norm': 2.0976197719573975, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.14s/it]                                               {'loss': 0.4703, 'grad_norm': 3.4450788497924805, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.14s/it] 75%|███████▌  | 30/40 [00:59<00:21,  2.16s/it]                                               {'loss': 0.4934, 'grad_norm': 2.580977201461792, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:59<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it]                                               {'loss': 0.1459, 'grad_norm': 1.9897654056549072, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it] 80%|████████  | 32/40 [01:02<00:12,  1.58s/it]                                               {'loss': 0.5527, 'grad_norm': 17.54144287109375, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it]                                               {'loss': 0.161, 'grad_norm': 6.89357328414917, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.93s/it]                                               {'loss': 0.2892, 'grad_norm': 6.966073513031006, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.3782, 'grad_norm': 7.698211193084717, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it]                                               {'loss': 0.7935, 'grad_norm': 10.019413948059082, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.14s/it]                                               {'loss': 0.6899, 'grad_norm': 19.817466735839844, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.18s/it]                                               {'loss': 0.8042, 'grad_norm': 15.598821640014648, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.7408, 'grad_norm': 7.942622184753418, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 0.0159, 'grad_norm': 1.236527442932129, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 78.6915, 'train_samples_per_second': 7.18, 'train_steps_per_second': 0.508, 'train_loss': 1.6428623440675438, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]100%|██████████| 40/40 [01:18<00:00,  1.97s/it]
CLIENT:68
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.18s/it]                                              {'loss': 3.9955, 'grad_norm': 3.8920557498931885, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.18s/it]  5%|▌         | 2/40 [00:04<01:22,  2.17s/it]                                              {'loss': 4.4499, 'grad_norm': 4.063035011291504, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.17s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 4.5448, 'grad_norm': 6.89508056640625, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:18,  2.19s/it]                                              {'loss': 5.0378, 'grad_norm': 4.372419834136963, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.19s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it]                                              {'loss': 3.4206, 'grad_norm': 4.580291271209717, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 4.34, 'grad_norm': 8.602946281433105, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 4.2569, 'grad_norm': 7.234140396118164, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 0.7816, 'grad_norm': 27.818384170532227, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it]                                              {'loss': 2.2299, 'grad_norm': 6.647862434387207, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.4614, 'grad_norm': 3.881671667098999, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 2.0634, 'grad_norm': 10.587920188903809, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.5606, 'grad_norm': 10.43134593963623, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it]                                               {'loss': 1.4575, 'grad_norm': 22.87801742553711, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it]                                               {'loss': 2.7418, 'grad_norm': 9.576478958129883, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.91, 'grad_norm': 4.754689693450928, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0569, 'grad_norm': 1.4469444751739502, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 1.1531, 'grad_norm': 5.598150730133057, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 1.5079, 'grad_norm': 6.905928134918213, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.4656, 'grad_norm': 3.1997880935668945, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.8501, 'grad_norm': 5.973031044006348, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.6997, 'grad_norm': 5.456740856170654, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it]                                               {'loss': 0.337, 'grad_norm': 2.9442226886749268, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.9115, 'grad_norm': 12.840690612792969, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.9363, 'grad_norm': 33.99797058105469, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.4277, 'grad_norm': 4.268383979797363, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it]                                               {'loss': 0.2105, 'grad_norm': 2.7209420204162598, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.5368, 'grad_norm': 3.620887041091919, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.2629, 'grad_norm': 4.578710556030273, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.2995, 'grad_norm': 3.5021023750305176, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.2148, 'grad_norm': 3.6418204307556152, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.3693, 'grad_norm': 5.453154563903809, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.1179, 'grad_norm': 4.471124649047852, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.1262, 'grad_norm': 1.5946340560913086, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.96s/it]                                               {'loss': 0.0433, 'grad_norm': 0.8895454406738281, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.0619, 'grad_norm': 1.211631417274475, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.2051, 'grad_norm': 110.18971252441406, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.0814, 'grad_norm': 1.198264479637146, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.0332, 'grad_norm': 0.4602196514606476, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.1272, 'grad_norm': 2.1215593814849854, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.7922, 'grad_norm': 19.172395706176758, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.7317, 'train_samples_per_second': 7.086, 'train_steps_per_second': 0.502, 'train_loss': 1.3519942447543145, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:77
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.18s/it]                                              {'loss': 6.132, 'grad_norm': 4.69735050201416, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.18s/it]  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]                                              {'loss': 4.2478, 'grad_norm': 2.5983235836029053, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]  8%|▊         | 3/40 [00:06<01:20,  2.17s/it]                                              {'loss': 3.7594, 'grad_norm': 4.747675895690918, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.17s/it] 10%|█         | 4/40 [00:08<01:17,  2.16s/it]                                              {'loss': 4.7333, 'grad_norm': 4.536302089691162, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.16s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.16s/it]                                              {'loss': 3.4851, 'grad_norm': 5.01674747467041, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.16s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 3.1281, 'grad_norm': 4.967982769012451, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 3.0399, 'grad_norm': 8.028660774230957, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 0.8587, 'grad_norm': 13.941878318786621, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it]                                              {'loss': 1.9325, 'grad_norm': 7.930859565734863, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.90s/it]                                               {'loss': 1.4554, 'grad_norm': 8.761638641357422, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 1.6067, 'grad_norm': 5.61714506149292, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 1.7388, 'grad_norm': 7.8443121910095215, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 2.1456, 'grad_norm': 37.17850112915039, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it]                                               {'loss': 1.6423, 'grad_norm': 6.498044013977051, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.16s/it]                                               {'loss': 1.4243, 'grad_norm': 8.965096473693848, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 3.7245, 'grad_norm': 28.51780128479004, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 1.0696, 'grad_norm': 7.2752885818481445, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it]                                               {'loss': 0.5773, 'grad_norm': 8.10239028930664, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it]                                               {'loss': 0.9641, 'grad_norm': 8.027741432189941, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.95, 'grad_norm': 7.659652233123779, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.6051, 'grad_norm': 8.879057884216309, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.5925, 'grad_norm': 24.8067626953125, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 1.6649, 'grad_norm': 20.61836051940918, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:46<00:25,  1.58s/it]                                               {'loss': 0.009, 'grad_norm': 0.2876286804676056, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.5653, 'grad_norm': 6.521512031555176, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.2614, 'grad_norm': 4.653585910797119, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it]                                               {'loss': 0.9672, 'grad_norm': 4.145374298095703, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it] 70%|███████   | 28/40 [00:55<00:24,  2.06s/it]                                               {'loss': 0.3946, 'grad_norm': 28.58466148376465, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.06s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.6712, 'grad_norm': 5.590486526489258, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.5793, 'grad_norm': 3.7322421073913574, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it]                                               {'loss': 1.3095, 'grad_norm': 48.1980094909668, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it] 80%|████████  | 32/40 [01:02<00:12,  1.60s/it]                                               {'loss': 1.238, 'grad_norm': 78.85675048828125, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it]                                               {'loss': 1.8522, 'grad_norm': 108.57980346679688, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 1.6963, 'grad_norm': 27.1096134185791, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.975, 'grad_norm': 26.38739585876465, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it]                                               {'loss': 0.5072, 'grad_norm': 10.536890029907227, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.5356, 'grad_norm': 4.860790252685547, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.1109, 'grad_norm': 1.271268606185913, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]                                               {'loss': 0.665, 'grad_norm': 6.059145927429199, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]100%|██████████| 40/40 [01:18<00:00,  1.61s/it]                                               {'loss': 0.3003, 'grad_norm': 10.389492988586426, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.61s/it]                                               {'train_runtime': 79.164, 'train_samples_per_second': 7.137, 'train_steps_per_second': 0.505, 'train_loss': 1.6029015659121797, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:23,  2.13s/it]                                              {'loss': 5.5706, 'grad_norm': 3.946197748184204, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:23,  2.13s/it]  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]                                              {'loss': 5.5595, 'grad_norm': 3.583897829055786, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]  8%|▊         | 3/40 [00:06<01:19,  2.16s/it]                                              {'loss': 3.4242, 'grad_norm': 5.009420871734619, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.16s/it] 10%|█         | 4/40 [00:08<01:17,  2.15s/it]                                              {'loss': 3.7718, 'grad_norm': 5.331167221069336, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.15s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.16s/it]                                              {'loss': 3.0762, 'grad_norm': 3.304884195327759, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.16s/it] 15%|█▌        | 6/40 [00:12<01:13,  2.15s/it]                                              {'loss': 4.5583, 'grad_norm': 9.19760799407959, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:12<01:13,  2.15s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.15s/it]                                              {'loss': 4.345, 'grad_norm': 7.426366806030273, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.15s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 0.963, 'grad_norm': 45.29091262817383, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 2.1359, 'grad_norm': 3.685154676437378, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it]                                               {'loss': 0.9512, 'grad_norm': 2.363872528076172, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:21<00:57,  1.99s/it]                                               {'loss': 2.14, 'grad_norm': 5.585461139678955, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.4649, 'grad_norm': 16.119516372680664, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it]                                               {'loss': 2.7677, 'grad_norm': 10.496356964111328, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it]                                               {'loss': 1.6167, 'grad_norm': 18.62548065185547, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.13s/it]                                               {'loss': 1.443, 'grad_norm': 7.8133745193481445, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.13s/it] 40%|████      | 16/40 [00:30<00:37,  1.55s/it]                                               {'loss': 0.0697, 'grad_norm': 2.537050247192383, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.55s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.74s/it]                                               {'loss': 0.5455, 'grad_norm': 4.20672607421875, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.74s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it]                                               {'loss': 0.3491, 'grad_norm': 5.525900840759277, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it]                                               {'loss': 0.7386, 'grad_norm': 4.683870315551758, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it] 50%|█████     | 20/40 [00:39<00:40,  2.05s/it]                                               {'loss': 0.5015, 'grad_norm': 3.7378406524658203, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:40,  2.05s/it] 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it]                                               {'loss': 0.6149, 'grad_norm': 3.023726463317871, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.13s/it]                                               {'loss': 0.7233, 'grad_norm': 4.651156902313232, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.13s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 1.3783, 'grad_norm': 8.120292663574219, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.7239, 'grad_norm': 47.420753479003906, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it]                                               {'loss': 0.6504, 'grad_norm': 5.539163589477539, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it] 65%|██████▌   | 26/40 [00:50<00:26,  1.90s/it]                                               {'loss': 0.0966, 'grad_norm': 2.1185901165008545, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:50<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it]                                               {'loss': 0.485, 'grad_norm': 16.384164810180664, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it] 70%|███████   | 28/40 [00:55<00:24,  2.06s/it]                                               {'loss': 0.2981, 'grad_norm': 4.6384687423706055, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.06s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.11s/it]                                               {'loss': 0.6979, 'grad_norm': 113.4498291015625, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.11s/it] 75%|███████▌  | 30/40 [00:59<00:21,  2.16s/it]                                               {'loss': 0.6288, 'grad_norm': 4.812195301055908, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:59<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it]                                               {'loss': 0.4378, 'grad_norm': 4.472235679626465, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it] 80%|████████  | 32/40 [01:02<00:12,  1.58s/it]                                               {'loss': 0.0712, 'grad_norm': 2.17838978767395, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.77s/it]                                               {'loss': 0.077, 'grad_norm': 4.109668254852295, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.77s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.92s/it]                                               {'loss': 0.0605, 'grad_norm': 1.9330085515975952, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:08<00:10,  2.01s/it]                                               {'loss': 0.2381, 'grad_norm': 5.7611985206604, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:08<00:10,  2.01s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it]                                               {'loss': 0.0834, 'grad_norm': 1.539459466934204, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.13s/it]                                               {'loss': 0.1724, 'grad_norm': 4.216398239135742, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.13s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.16s/it]                                               {'loss': 0.667, 'grad_norm': 5.385922431945801, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.16s/it] 98%|█████████▊| 39/40 [01:17<00:02,  2.18s/it]                                               {'loss': 0.9849, 'grad_norm': 4.732108116149902, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:17<00:02,  2.18s/it]100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'loss': 0.0039, 'grad_norm': 0.14488749206066132, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'train_runtime': 78.3983, 'train_samples_per_second': 7.207, 'train_steps_per_second': 0.51, 'train_loss': 1.3771463622746523, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]100%|██████████| 40/40 [01:18<00:00,  1.96s/it]
CLIENT:3
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.17s/it]                                              {'loss': 4.6361, 'grad_norm': 7.449802398681641, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.17s/it]  5%|▌         | 2/40 [00:04<01:22,  2.17s/it]                                              {'loss': 3.6858, 'grad_norm': 2.5981836318969727, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.17s/it]  8%|▊         | 3/40 [00:06<01:19,  2.14s/it]                                              {'loss': 4.8762, 'grad_norm': 3.680774450302124, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.14s/it] 10%|█         | 4/40 [00:08<01:17,  2.16s/it]                                              {'loss': 5.101, 'grad_norm': 4.409592151641846, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.16s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.15s/it]                                              {'loss': 4.956, 'grad_norm': 5.306143283843994, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.15s/it] 15%|█▌        | 6/40 [00:12<01:13,  2.17s/it]                                              {'loss': 4.1992, 'grad_norm': 4.595423698425293, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:12<01:13,  2.17s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.16s/it]                                              {'loss': 4.7261, 'grad_norm': 8.807827949523926, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.16s/it] 20%|██        | 8/40 [00:15<00:49,  1.53s/it]                                              {'loss': 6.2797, 'grad_norm': 12.72949504852295, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.53s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it]                                              {'loss': 2.9867, 'grad_norm': 13.214478492736816, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it]                                               {'loss': 1.933, 'grad_norm': 4.7825703620910645, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it]                                               {'loss': 2.2548, 'grad_norm': 4.777889728546143, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 1.1348, 'grad_norm': 5.339808940887451, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it]                                               {'loss': 1.859, 'grad_norm': 4.46807861328125, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it] 35%|███▌      | 14/40 [00:28<00:54,  2.11s/it]                                               {'loss': 1.7046, 'grad_norm': 6.715682029724121, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:54,  2.11s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.13s/it]                                               {'loss': 2.1163, 'grad_norm': 10.01831340789795, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.13s/it] 40%|████      | 16/40 [00:30<00:37,  1.54s/it]                                               {'loss': 5.0181, 'grad_norm': 34.390167236328125, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.54s/it] 42%|████▎     | 17/40 [00:32<00:39,  1.74s/it]                                               {'loss': 1.0449, 'grad_norm': 4.5853590965271, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:32<00:39,  1.74s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.87s/it]                                               {'loss': 0.8548, 'grad_norm': 7.570555686950684, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.87s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.97s/it]                                               {'loss': 0.8578, 'grad_norm': 3.7166264057159424, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.97s/it] 50%|█████     | 20/40 [00:39<00:40,  2.04s/it]                                               {'loss': 1.2271, 'grad_norm': 8.788378715515137, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:40,  2.04s/it] 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it]                                               {'loss': 0.3866, 'grad_norm': 3.105105400085449, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 0.6708, 'grad_norm': 4.136980056762695, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it]                                               {'loss': 0.8813, 'grad_norm': 19.62484359741211, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.0176, 'grad_norm': 0.6248576045036316, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it]                                               {'loss': 0.4998, 'grad_norm': 9.474082946777344, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it] 65%|██████▌   | 26/40 [00:50<00:26,  1.91s/it]                                               {'loss': 0.2668, 'grad_norm': 10.766863822937012, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:50<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:25,  2.00s/it]                                               {'loss': 0.1572, 'grad_norm': 3.0156099796295166, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  2.00s/it] 70%|███████   | 28/40 [00:55<00:24,  2.06s/it]                                               {'loss': 0.7012, 'grad_norm': 3.7644970417022705, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.06s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.11s/it]                                               {'loss': 0.4613, 'grad_norm': 6.012416839599609, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.11s/it] 75%|███████▌  | 30/40 [00:59<00:21,  2.13s/it]                                               {'loss': 0.5146, 'grad_norm': 6.354379653930664, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:59<00:21,  2.13s/it] 78%|███████▊  | 31/40 [01:01<00:19,  2.15s/it]                                               {'loss': 0.4172, 'grad_norm': 4.5325446128845215, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:01<00:19,  2.15s/it] 80%|████████  | 32/40 [01:02<00:12,  1.56s/it]                                               {'loss': 0.0905, 'grad_norm': 4.085367679595947, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.56s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.76s/it]                                               {'loss': 0.0634, 'grad_norm': 1.0883302688598633, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.76s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.90s/it]                                               {'loss': 0.0891, 'grad_norm': 1.8069548606872559, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.90s/it] 88%|████████▊ | 35/40 [01:08<00:09,  2.00s/it]                                               {'loss': 0.2519, 'grad_norm': 4.521964073181152, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:08<00:09,  2.00s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.07s/it]                                               {'loss': 0.0497, 'grad_norm': 0.856252908706665, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.07s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.12s/it]                                               {'loss': 0.8748, 'grad_norm': 15.1563720703125, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.12s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.14s/it]                                               {'loss': 0.614, 'grad_norm': 6.890153884887695, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.14s/it] 98%|█████████▊| 39/40 [01:17<00:02,  2.16s/it]                                               {'loss': 0.1868, 'grad_norm': 1.9586269855499268, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:17<00:02,  2.16s/it]100%|██████████| 40/40 [01:17<00:00,  1.57s/it]                                               {'loss': 0.0571, 'grad_norm': 2.3642120361328125, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:17<00:00,  1.57s/it]                                               {'train_runtime': 78.1357, 'train_samples_per_second': 7.231, 'train_steps_per_second': 0.512, 'train_loss': 1.7175977983046322, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.57s/it]100%|██████████| 40/40 [01:18<00:00,  1.95s/it]
CLIENT:55
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.18s/it]                                              {'loss': 5.3543, 'grad_norm': 3.750589609146118, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.18s/it]  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]                                              {'loss': 5.4786, 'grad_norm': 6.1565093994140625, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]  8%|▊         | 3/40 [00:06<01:19,  2.14s/it]                                              {'loss': 4.2887, 'grad_norm': 6.211050510406494, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.14s/it] 10%|█         | 4/40 [00:08<01:17,  2.15s/it]                                              {'loss': 3.7696, 'grad_norm': 5.979415416717529, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.15s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.15s/it]                                              {'loss': 4.3831, 'grad_norm': 20.776277542114258, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.15s/it] 15%|█▌        | 6/40 [00:12<01:13,  2.17s/it]                                              {'loss': 3.2426, 'grad_norm': 28.37470054626465, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:12<01:13,  2.17s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it]                                              {'loss': 3.4908, 'grad_norm': 50.828102111816406, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 5.0944, 'grad_norm': 25.29429817199707, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it]                                              {'loss': 2.4703, 'grad_norm': 6.849598407745361, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.87s/it]                                               {'loss': 1.4929, 'grad_norm': 8.978531837463379, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.87s/it] 28%|██▊       | 11/40 [00:21<00:56,  1.96s/it]                                               {'loss': 3.042, 'grad_norm': 51.67637634277344, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:56,  1.96s/it] 30%|███       | 12/40 [00:24<00:56,  2.03s/it]                                               {'loss': 3.0699, 'grad_norm': 434.3051452636719, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:56,  2.03s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it]                                               {'loss': 2.6249, 'grad_norm': 7.264222621917725, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it]                                               {'loss': 2.02, 'grad_norm': 8.588932991027832, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it]                                               {'loss': 1.9434, 'grad_norm': 13.994169235229492, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it] 40%|████      | 16/40 [00:30<00:37,  1.56s/it]                                               {'loss': 1.8747, 'grad_norm': 161.1563262939453, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 1.4321, 'grad_norm': 9.168227195739746, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it]                                               {'loss': 1.0786, 'grad_norm': 12.039155960083008, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it]                                               {'loss': 1.5044, 'grad_norm': 4.5835418701171875, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it] 50%|█████     | 20/40 [00:39<00:40,  2.05s/it]                                               {'loss': 1.8087, 'grad_norm': 8.370777130126953, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:40,  2.05s/it] 52%|█████▎    | 21/40 [00:41<00:39,  2.09s/it]                                               {'loss': 1.8076, 'grad_norm': 13.58928394317627, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:41<00:39,  2.09s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.13s/it]                                               {'loss': 1.3423, 'grad_norm': 6.0493340492248535, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.13s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 1.4921, 'grad_norm': 9.150742530822754, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.3657, 'grad_norm': 16.116437911987305, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it]                                               {'loss': 0.6488, 'grad_norm': 2.9500083923339844, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it] 65%|██████▌   | 26/40 [00:50<00:26,  1.90s/it]                                               {'loss': 0.9781, 'grad_norm': 4.808376312255859, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:50<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it]                                               {'loss': 0.6916, 'grad_norm': 27.832687377929688, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it] 70%|███████   | 28/40 [00:55<00:24,  2.08s/it]                                               {'loss': 1.0191, 'grad_norm': 37.06614303588867, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.14s/it]                                               {'loss': 0.954, 'grad_norm': 7.535677909851074, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.14s/it] 75%|███████▌  | 30/40 [00:59<00:21,  2.17s/it]                                               {'loss': 0.4345, 'grad_norm': 4.205051422119141, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:59<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it]                                               {'loss': 0.7403, 'grad_norm': 10.410099983215332, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it] 80%|████████  | 32/40 [01:02<00:12,  1.58s/it]                                               {'loss': 0.0417, 'grad_norm': 2.1815080642700195, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it]                                               {'loss': 0.9094, 'grad_norm': 9.289295196533203, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.91s/it]                                               {'loss': 0.5903, 'grad_norm': 11.160701751708984, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.91s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.01s/it]                                               {'loss': 0.5481, 'grad_norm': 4.431241035461426, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.01s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it]                                               {'loss': 0.5617, 'grad_norm': 5.968177795410156, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.14s/it]                                               {'loss': 0.2327, 'grad_norm': 2.29543137550354, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.18s/it]                                               {'loss': 0.1739, 'grad_norm': 3.3152916431427, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.1554, 'grad_norm': 1.8149285316467285, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 0.1819, 'grad_norm': 8.784619331359863, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 78.7387, 'train_samples_per_second': 7.176, 'train_steps_per_second': 0.508, 'train_loss': 1.8333301916718483, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]100%|██████████| 40/40 [01:18<00:00,  1.97s/it]
CLIENT:20
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:23,  2.15s/it]                                              {'loss': 4.0115, 'grad_norm': 3.1787049770355225, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:23,  2.15s/it]  5%|▌         | 2/40 [00:04<01:19,  2.10s/it]                                              {'loss': 5.25, 'grad_norm': 3.0672924518585205, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:19,  2.10s/it]  8%|▊         | 3/40 [00:06<01:18,  2.11s/it]                                              {'loss': 5.1939, 'grad_norm': 7.072494983673096, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:18,  2.11s/it] 10%|█         | 4/40 [00:08<01:17,  2.15s/it]                                              {'loss': 5.532, 'grad_norm': 4.086864471435547, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.15s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it]                                              {'loss': 4.0782, 'grad_norm': 3.961686849594116, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it] 15%|█▌        | 6/40 [00:12<01:13,  2.16s/it]                                              {'loss': 3.5341, 'grad_norm': 6.127115726470947, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:12<01:13,  2.16s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 2.0393, 'grad_norm': 3.345510959625244, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 0.017, 'grad_norm': 0.35695314407348633, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it]                                              {'loss': 3.7432, 'grad_norm': 7.455913543701172, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.87s/it]                                               {'loss': 2.0974, 'grad_norm': 4.515045642852783, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.87s/it] 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it]                                               {'loss': 1.0524, 'grad_norm': 2.2236242294311523, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 2.0141, 'grad_norm': 5.600619792938232, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.07s/it]                                               {'loss': 2.3761, 'grad_norm': 10.65584659576416, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.07s/it] 35%|███▌      | 14/40 [00:28<00:54,  2.11s/it]                                               {'loss': 1.4332, 'grad_norm': 4.5088791847229, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:54,  2.11s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it]                                               {'loss': 1.3779, 'grad_norm': 6.135712146759033, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it] 40%|████      | 16/40 [00:30<00:37,  1.56s/it]                                               {'loss': 0.5137, 'grad_norm': 23.015108108520508, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:32<00:39,  1.73s/it]                                               {'loss': 1.2814, 'grad_norm': 4.433757781982422, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:32<00:39,  1.73s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it]                                               {'loss': 0.687, 'grad_norm': 3.020228147506714, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.97s/it]                                               {'loss': 0.7675, 'grad_norm': 5.0813069343566895, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.97s/it] 50%|█████     | 20/40 [00:39<00:40,  2.04s/it]                                               {'loss': 0.8518, 'grad_norm': 3.433833122253418, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:40,  2.04s/it] 52%|█████▎    | 21/40 [00:41<00:39,  2.09s/it]                                               {'loss': 0.2023, 'grad_norm': 1.7795753479003906, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:41<00:39,  2.09s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.6136, 'grad_norm': 4.297544002532959, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it]                                               {'loss': 1.0326, 'grad_norm': 5.832523822784424, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it] 60%|██████    | 24/40 [00:46<00:25,  1.58s/it]                                               {'loss': 0.0612, 'grad_norm': 2.1206142902374268, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.78s/it]                                               {'loss': 0.0554, 'grad_norm': 1.2266628742218018, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:50<00:26,  1.92s/it]                                               {'loss': 0.2789, 'grad_norm': 12.205571174621582, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:50<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it]                                               {'loss': 0.4942, 'grad_norm': 9.700400352478027, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it] 70%|███████   | 28/40 [00:55<00:24,  2.07s/it]                                               {'loss': 0.8571, 'grad_norm': 4.612106800079346, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.10s/it]                                               {'loss': 0.3737, 'grad_norm': 4.1634202003479, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.10s/it] 75%|███████▌  | 30/40 [00:59<00:21,  2.16s/it]                                               {'loss': 0.3329, 'grad_norm': 2.4540889263153076, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:59<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.21s/it]                                               {'loss': 0.0875, 'grad_norm': 1.327219843864441, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.21s/it] 80%|████████  | 32/40 [01:02<00:12,  1.60s/it]                                               {'loss': 0.0015, 'grad_norm': 0.07521267235279083, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it]                                               {'loss': 0.2786, 'grad_norm': 5.158817768096924, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.93s/it]                                               {'loss': 0.0608, 'grad_norm': 0.942970335483551, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.0309, 'grad_norm': 0.7190943956375122, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it]                                               {'loss': 0.607, 'grad_norm': 17.430936813354492, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.14s/it]                                               {'loss': 0.3576, 'grad_norm': 8.288030624389648, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.15s/it]                                               {'loss': 0.4855, 'grad_norm': 3.8541970252990723, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.15s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.18s/it]                                               {'loss': 0.2648, 'grad_norm': 3.6171445846557617, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.18s/it]100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'loss': 0.0862, 'grad_norm': 2.945007085800171, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'train_runtime': 78.4774, 'train_samples_per_second': 7.2, 'train_steps_per_second': 0.51, 'train_loss': 1.3603514116955921, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]100%|██████████| 40/40 [01:18<00:00,  1.96s/it]
CLIENT:17
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.16s/it]                                              {'loss': 4.999, 'grad_norm': 5.080719947814941, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.16s/it]  5%|▌         | 2/40 [00:04<01:20,  2.13s/it]                                              {'loss': 5.6934, 'grad_norm': 4.796481132507324, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:20,  2.13s/it]  8%|▊         | 3/40 [00:06<01:19,  2.16s/it]                                              {'loss': 4.3987, 'grad_norm': 3.468515157699585, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.16s/it] 10%|█         | 4/40 [00:08<01:17,  2.16s/it]                                              {'loss': 4.2309, 'grad_norm': 4.032663345336914, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.16s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.15s/it]                                              {'loss': 3.1597, 'grad_norm': 7.2150702476501465, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.15s/it] 15%|█▌        | 6/40 [00:12<01:12,  2.14s/it]                                              {'loss': 5.4407, 'grad_norm': 4.327081680297852, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:12<01:12,  2.14s/it] 18%|█▊        | 7/40 [00:15<01:10,  2.15s/it]                                              {'loss': 3.5882, 'grad_norm': 9.88162899017334, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:10,  2.15s/it] 20%|██        | 8/40 [00:15<00:48,  1.52s/it]                                              {'loss': 8.8056, 'grad_norm': 27.204275131225586, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:48,  1.52s/it] 22%|██▎       | 9/40 [00:17<00:52,  1.70s/it]                                              {'loss': 3.336, 'grad_norm': 5.400435447692871, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:52,  1.70s/it] 25%|██▌       | 10/40 [00:19<00:55,  1.85s/it]                                               {'loss': 1.1069, 'grad_norm': 4.205681324005127, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:55,  1.85s/it] 28%|██▊       | 11/40 [00:21<00:56,  1.94s/it]                                               {'loss': 2.2551, 'grad_norm': 5.44048547744751, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:56,  1.94s/it] 30%|███       | 12/40 [00:23<00:56,  2.02s/it]                                               {'loss': 1.4084, 'grad_norm': 5.555009365081787, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:23<00:56,  2.02s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it]                                               {'loss': 1.8565, 'grad_norm': 6.260904312133789, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 1.7518, 'grad_norm': 11.856364250183105, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it]                                               {'loss': 2.7378, 'grad_norm': 18.24481773376465, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it] 40%|████      | 16/40 [00:30<00:37,  1.55s/it]                                               {'loss': 0.0556, 'grad_norm': 4.320603847503662, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.55s/it] 42%|████▎     | 17/40 [00:32<00:40,  1.75s/it]                                               {'loss': 0.9736, 'grad_norm': 4.674079895019531, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:32<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.641, 'grad_norm': 4.1372599601745605, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it]                                               {'loss': 1.0014, 'grad_norm': 5.654599666595459, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it] 50%|█████     | 20/40 [00:39<00:40,  2.05s/it]                                               {'loss': 1.2381, 'grad_norm': 4.994692325592041, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:40,  2.05s/it] 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it]                                               {'loss': 0.5913, 'grad_norm': 3.5995514392852783, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:43<00:38,  2.12s/it]                                               {'loss': 0.69, 'grad_norm': 3.1253793239593506, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:43<00:38,  2.12s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.14s/it]                                               {'loss': 0.9273, 'grad_norm': 5.3559112548828125, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.14s/it] 60%|██████    | 24/40 [00:46<00:24,  1.55s/it]                                               {'loss': 0.016, 'grad_norm': 0.4789559841156006, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:24,  1.55s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.74s/it]                                               {'loss': 0.2852, 'grad_norm': 2.7995944023132324, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.74s/it] 65%|██████▌   | 26/40 [00:50<00:26,  1.87s/it]                                               {'loss': 0.3361, 'grad_norm': 3.0906243324279785, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:50<00:26,  1.87s/it] 68%|██████▊   | 27/40 [00:52<00:25,  1.98s/it]                                               {'loss': 0.4072, 'grad_norm': 4.70668363571167, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:52<00:25,  1.98s/it] 70%|███████   | 28/40 [00:55<00:24,  2.04s/it]                                               {'loss': 1.1473, 'grad_norm': 4.645684242248535, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.04s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.10s/it]                                               {'loss': 0.3778, 'grad_norm': 4.087879657745361, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.10s/it] 75%|███████▌  | 30/40 [00:59<00:21,  2.13s/it]                                               {'loss': 0.3687, 'grad_norm': 2.39961838722229, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:59<00:21,  2.13s/it] 78%|███████▊  | 31/40 [01:01<00:19,  2.17s/it]                                               {'loss': 0.4239, 'grad_norm': 3.1702334880828857, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:01<00:19,  2.17s/it] 80%|████████  | 32/40 [01:01<00:12,  1.57s/it]                                               {'loss': 0.1616, 'grad_norm': 4.730870246887207, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:01<00:12,  1.57s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.77s/it]                                               {'loss': 0.0558, 'grad_norm': 0.7252524495124817, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.77s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.90s/it]                                               {'loss': 0.0446, 'grad_norm': 0.6674585938453674, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.90s/it] 88%|████████▊ | 35/40 [01:08<00:10,  2.01s/it]                                               {'loss': 0.0632, 'grad_norm': 1.674316167831421, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:08<00:10,  2.01s/it] 90%|█████████ | 36/40 [01:10<00:08,  2.06s/it]                                               {'loss': 0.8705, 'grad_norm': 5.014937400817871, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:10<00:08,  2.06s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.12s/it]                                               {'loss': 0.9158, 'grad_norm': 6.29440975189209, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.12s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.15s/it]                                               {'loss': 0.2311, 'grad_norm': 5.293673038482666, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.15s/it] 98%|█████████▊| 39/40 [01:17<00:02,  2.17s/it]                                               {'loss': 0.071, 'grad_norm': 1.2888137102127075, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:17<00:02,  2.17s/it]100%|██████████| 40/40 [01:17<00:00,  1.58s/it]                                               {'loss': 0.0158, 'grad_norm': 0.6624605059623718, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:17<00:00,  1.58s/it]                                               {'train_runtime': 77.9749, 'train_samples_per_second': 7.246, 'train_steps_per_second': 0.513, 'train_loss': 1.666963338572532, 'epoch': 5.0}
100%|██████████| 40/40 [01:17<00:00,  1.58s/it]100%|██████████| 40/40 [01:17<00:00,  1.95s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:51,  1.61it/s]  1%|          | 3/471 [00:02<06:52,  1.13it/s]  1%|          | 4/471 [00:03<07:57,  1.02s/it]  1%|          | 5/471 [00:05<08:33,  1.10s/it]  1%|▏         | 6/471 [00:06<08:55,  1.15s/it]  1%|▏         | 7/471 [00:07<09:10,  1.19s/it]  2%|▏         | 8/471 [00:08<09:20,  1.21s/it]  2%|▏         | 9/471 [00:10<09:27,  1.23s/it]  2%|▏         | 10/471 [00:11<09:30,  1.24s/it]  2%|▏         | 11/471 [00:12<09:32,  1.25s/it]  3%|▎         | 12/471 [00:13<09:35,  1.25s/it]  3%|▎         | 13/471 [00:15<09:36,  1.26s/it]  3%|▎         | 14/471 [00:16<09:36,  1.26s/it]  3%|▎         | 15/471 [00:17<09:36,  1.26s/it]  3%|▎         | 16/471 [00:18<09:37,  1.27s/it]  4%|▎         | 17/471 [00:20<09:36,  1.27s/it]  4%|▍         | 18/471 [00:21<09:37,  1.27s/it]  4%|▍         | 19/471 [00:22<09:36,  1.28s/it]  4%|▍         | 20/471 [00:24<09:35,  1.28s/it]  4%|▍         | 21/471 [00:25<09:35,  1.28s/it]  5%|▍         | 22/471 [00:26<09:35,  1.28s/it]  5%|▍         | 23/471 [00:27<09:34,  1.28s/it]  5%|▌         | 24/471 [00:29<09:34,  1.28s/it]  5%|▌         | 25/471 [00:30<09:32,  1.28s/it]  6%|▌         | 26/471 [00:31<09:32,  1.29s/it]  6%|▌         | 27/471 [00:33<09:31,  1.29s/it]  6%|▌         | 28/471 [00:34<09:29,  1.29s/it]  6%|▌         | 29/471 [00:35<09:29,  1.29s/it]  6%|▋         | 30/471 [00:36<09:28,  1.29s/it]  7%|▋         | 31/471 [00:38<09:28,  1.29s/it]  7%|▋         | 32/471 [00:39<09:27,  1.29s/it]  7%|▋         | 33/471 [00:40<09:24,  1.29s/it]  7%|▋         | 34/471 [00:42<09:23,  1.29s/it]  7%|▋         | 35/471 [00:43<09:24,  1.29s/it]  8%|▊         | 36/471 [00:44<09:22,  1.29s/it]  8%|▊         | 37/471 [00:45<09:22,  1.30s/it]  8%|▊         | 38/471 [00:47<09:21,  1.30s/it]  8%|▊         | 39/471 [00:48<09:19,  1.30s/it]  8%|▊         | 40/471 [00:49<09:18,  1.30s/it]  9%|▊         | 41/471 [00:51<09:18,  1.30s/it]  9%|▉         | 42/471 [00:52<09:17,  1.30s/it]  9%|▉         | 43/471 [00:53<09:15,  1.30s/it]  9%|▉         | 44/471 [00:55<09:14,  1.30s/it] 10%|▉         | 45/471 [00:56<09:14,  1.30s/it] 10%|▉         | 46/471 [00:57<09:12,  1.30s/it] 10%|▉         | 47/471 [00:58<09:11,  1.30s/it] 10%|█         | 48/471 [01:00<09:10,  1.30s/it] 10%|█         | 49/471 [01:01<09:09,  1.30s/it] 11%|█         | 50/471 [01:02<09:08,  1.30s/it] 11%|█         | 51/471 [01:04<09:07,  1.30s/it] 11%|█         | 52/471 [01:05<09:05,  1.30s/it] 11%|█▏        | 53/471 [01:06<09:04,  1.30s/it] 11%|█▏        | 54/471 [01:08<09:03,  1.30s/it] 12%|█▏        | 55/471 [01:09<09:02,  1.30s/it] 12%|█▏        | 56/471 [01:10<09:01,  1.31s/it] 12%|█▏        | 57/471 [01:12<09:00,  1.31s/it] 12%|█▏        | 58/471 [01:13<08:59,  1.31s/it] 13%|█▎        | 59/471 [01:14<08:58,  1.31s/it] 13%|█▎        | 60/471 [01:15<08:57,  1.31s/it] 13%|█▎        | 61/471 [01:17<08:56,  1.31s/it] 13%|█▎        | 62/471 [01:18<08:54,  1.31s/it] 13%|█▎        | 63/471 [01:19<08:53,  1.31s/it] 14%|█▎        | 64/471 [01:21<08:52,  1.31s/it] 14%|█▍        | 65/471 [01:22<08:50,  1.31s/it] 14%|█▍        | 66/471 [01:23<08:49,  1.31s/it] 14%|█▍        | 67/471 [01:25<08:48,  1.31s/it] 14%|█▍        | 68/471 [01:26<08:47,  1.31s/it] 15%|█▍        | 69/471 [01:27<08:45,  1.31s/it] 15%|█▍        | 70/471 [01:29<08:45,  1.31s/it] 15%|█▌        | 71/471 [01:30<08:44,  1.31s/it] 15%|█▌        | 72/471 [01:31<08:42,  1.31s/it] 15%|█▌        | 73/471 [01:32<08:40,  1.31s/it] 16%|█▌        | 74/471 [01:34<08:38,  1.31s/it] 16%|█▌        | 75/471 [01:35<08:38,  1.31s/it] 16%|█▌        | 76/471 [01:36<08:36,  1.31s/it] 16%|█▋        | 77/471 [01:38<08:35,  1.31s/it] 17%|█▋        | 78/471 [01:39<08:34,  1.31s/it] 17%|█▋        | 79/471 [01:40<08:33,  1.31s/it] 17%|█▋        | 80/471 [01:42<08:32,  1.31s/it] 17%|█▋        | 81/471 [01:43<08:30,  1.31s/it] 17%|█▋        | 82/471 [01:44<08:29,  1.31s/it] 18%|█▊        | 83/471 [01:46<08:28,  1.31s/it] 18%|█▊        | 84/471 [01:47<08:26,  1.31s/it] 18%|█▊        | 85/471 [01:48<08:25,  1.31s/it] 18%|█▊        | 86/471 [01:49<08:24,  1.31s/it] 18%|█▊        | 87/471 [01:51<08:22,  1.31s/it] 19%|█▊        | 88/471 [01:52<08:21,  1.31s/it] 19%|█▉        | 89/471 [01:53<08:19,  1.31s/it] 19%|█▉        | 90/471 [01:55<08:19,  1.31s/it] 19%|█▉        | 91/471 [01:56<08:17,  1.31s/it] 20%|█▉        | 92/471 [01:57<08:16,  1.31s/it] 20%|█▉        | 93/471 [01:59<08:15,  1.31s/it] 20%|█▉        | 94/471 [02:00<08:14,  1.31s/it] 20%|██        | 95/471 [02:01<08:13,  1.31s/it] 20%|██        | 96/471 [02:03<08:11,  1.31s/it] 21%|██        | 97/471 [02:04<08:10,  1.31s/it] 21%|██        | 98/471 [02:05<08:08,  1.31s/it] 21%|██        | 99/471 [02:07<08:07,  1.31s/it] 21%|██        | 100/471 [02:08<08:06,  1.31s/it] 21%|██▏       | 101/471 [02:09<08:05,  1.31s/it] 22%|██▏       | 102/471 [02:10<08:04,  1.31s/it] 22%|██▏       | 103/471 [02:12<08:03,  1.31s/it] 22%|██▏       | 104/471 [02:13<08:02,  1.31s/it] 22%|██▏       | 105/471 [02:14<08:01,  1.32s/it] 23%|██▎       | 106/471 [02:16<07:59,  1.31s/it] 23%|██▎       | 107/471 [02:17<07:57,  1.31s/it] 23%|██▎       | 108/471 [02:18<07:56,  1.31s/it] 23%|██▎       | 109/471 [02:20<07:54,  1.31s/it] 23%|██▎       | 110/471 [02:21<07:52,  1.31s/it] 24%|██▎       | 111/471 [02:22<07:52,  1.31s/it] 24%|██▍       | 112/471 [02:24<07:51,  1.31s/it] 24%|██▍       | 113/471 [02:25<07:49,  1.31s/it] 24%|██▍       | 114/471 [02:26<07:48,  1.31s/it] 24%|██▍       | 115/471 [02:28<07:47,  1.31s/it] 25%|██▍       | 116/471 [02:29<07:46,  1.31s/it] 25%|██▍       | 117/471 [02:30<07:44,  1.31s/it] 25%|██▌       | 118/471 [02:31<07:43,  1.31s/it] 25%|██▌       | 119/471 [02:33<07:42,  1.31s/it] 25%|██▌       | 120/471 [02:34<07:41,  1.32s/it] 26%|██▌       | 121/471 [02:35<07:40,  1.32s/it] 26%|██▌       | 122/471 [02:37<07:39,  1.32s/it] 26%|██▌       | 123/471 [02:38<07:37,  1.32s/it] 26%|██▋       | 124/471 [02:39<07:36,  1.32s/it] 27%|██▋       | 125/471 [02:41<07:35,  1.32s/it] 27%|██▋       | 126/471 [02:42<07:34,  1.32s/it] 27%|██▋       | 127/471 [02:43<07:33,  1.32s/it] 27%|██▋       | 128/471 [02:45<07:32,  1.32s/it] 27%|██▋       | 129/471 [02:46<07:29,  1.32s/it] 28%|██▊       | 130/471 [02:47<07:28,  1.32s/it] 28%|██▊       | 131/471 [02:49<07:27,  1.32s/it] 28%|██▊       | 132/471 [02:50<07:26,  1.32s/it] 28%|██▊       | 133/471 [02:51<07:25,  1.32s/it] 28%|██▊       | 134/471 [02:53<07:24,  1.32s/it] 29%|██▊       | 135/471 [02:54<07:22,  1.32s/it] 29%|██▉       | 136/471 [02:55<07:21,  1.32s/it] 29%|██▉       | 137/471 [02:57<07:20,  1.32s/it] 29%|██▉       | 138/471 [02:58<07:18,  1.32s/it] 30%|██▉       | 139/471 [02:59<07:16,  1.32s/it] 30%|██▉       | 140/471 [03:00<07:15,  1.32s/it] 30%|██▉       | 141/471 [03:02<07:14,  1.32s/it] 30%|███       | 142/471 [03:03<07:12,  1.32s/it] 30%|███       | 143/471 [03:04<07:11,  1.31s/it] 31%|███       | 144/471 [03:06<07:10,  1.32s/it] 31%|███       | 145/471 [03:07<07:08,  1.31s/it] 31%|███       | 146/471 [03:08<07:07,  1.32s/it] 31%|███       | 147/471 [03:10<07:06,  1.32s/it] 31%|███▏      | 148/471 [03:11<07:05,  1.32s/it] 32%|███▏      | 149/471 [03:12<07:04,  1.32s/it] 32%|███▏      | 150/471 [03:14<07:03,  1.32s/it] 32%|███▏      | 151/471 [03:15<07:01,  1.32s/it] 32%|███▏      | 152/471 [03:16<07:00,  1.32s/it] 32%|███▏      | 153/471 [03:18<06:59,  1.32s/it] 33%|███▎      | 154/471 [03:19<06:57,  1.32s/it] 33%|███▎      | 155/471 [03:20<06:56,  1.32s/it] 33%|███▎      | 156/471 [03:22<06:54,  1.32s/it] 33%|███▎      | 157/471 [03:23<06:52,  1.31s/it] 34%|███▎      | 158/471 [03:24<06:51,  1.31s/it] 34%|███▍      | 159/471 [03:25<06:49,  1.31s/it] 34%|███▍      | 160/471 [03:27<06:49,  1.32s/it] 34%|███▍      | 161/471 [03:28<06:48,  1.32s/it] 34%|███▍      | 162/471 [03:29<06:47,  1.32s/it] 35%|███▍      | 163/471 [03:31<06:46,  1.32s/it] 35%|███▍      | 164/471 [03:32<06:44,  1.32s/it] 35%|███▌      | 165/471 [03:33<06:43,  1.32s/it] 35%|███▌      | 166/471 [03:35<06:42,  1.32s/it] 35%|███▌      | 167/471 [03:36<06:41,  1.32s/it] 36%|███▌      | 168/471 [03:37<06:39,  1.32s/it] 36%|███▌      | 169/471 [03:39<06:38,  1.32s/it] 36%|███▌      | 170/471 [03:40<06:36,  1.32s/it] 36%|███▋      | 171/471 [03:41<06:35,  1.32s/it] 37%|███▋      | 172/471 [03:43<06:33,  1.32s/it] 37%|███▋      | 173/471 [03:44<06:32,  1.32s/it] 37%|███▋      | 174/471 [03:45<06:31,  1.32s/it] 37%|███▋      | 175/471 [03:47<06:30,  1.32s/it] 37%|███▋      | 176/471 [03:48<06:28,  1.32s/it] 38%|███▊      | 177/471 [03:49<06:26,  1.32s/it] 38%|███▊      | 178/471 [03:50<06:25,  1.32s/it] 38%|███▊      | 179/471 [03:52<06:23,  1.32s/it] 38%|███▊      | 180/471 [03:53<06:22,  1.32s/it] 38%|███▊      | 181/471 [03:54<06:21,  1.32s/it] 39%|███▊      | 182/471 [03:56<06:20,  1.32s/it] 39%|███▉      | 183/471 [03:57<06:19,  1.32s/it] 39%|███▉      | 184/471 [03:58<06:18,  1.32s/it] 39%|███▉      | 185/471 [04:00<06:16,  1.32s/it] 39%|███▉      | 186/471 [04:01<06:16,  1.32s/it] 40%|███▉      | 187/471 [04:02<06:15,  1.32s/it] 40%|███▉      | 188/471 [04:04<06:13,  1.32s/it] 40%|████      | 189/471 [04:05<06:11,  1.32s/it] 40%|████      | 190/471 [04:06<06:10,  1.32s/it] 41%|████      | 191/471 [04:08<06:09,  1.32s/it] 41%|████      | 192/471 [04:09<06:08,  1.32s/it] 41%|████      | 193/471 [04:10<06:06,  1.32s/it] 41%|████      | 194/471 [04:12<06:05,  1.32s/it] 41%|████▏     | 195/471 [04:13<06:04,  1.32s/it] 42%|████▏     | 196/471 [04:14<06:02,  1.32s/it] 42%|████▏     | 197/471 [04:16<06:00,  1.32s/it] 42%|████▏     | 198/471 [04:17<05:59,  1.32s/it] 42%|████▏     | 199/471 [04:18<05:58,  1.32s/it] 42%|████▏     | 200/471 [04:20<05:57,  1.32s/it] 43%|████▎     | 201/471 [04:21<05:55,  1.32s/it] 43%|████▎     | 202/471 [04:22<05:54,  1.32s/it] 43%|████▎     | 203/471 [04:23<05:53,  1.32s/it] 43%|████▎     | 204/471 [04:25<05:51,  1.32s/it] 44%|████▎     | 205/471 [04:26<05:50,  1.32s/it] 44%|████▎     | 206/471 [04:27<05:48,  1.32s/it] 44%|████▍     | 207/471 [04:29<05:48,  1.32s/it] 44%|████▍     | 208/471 [04:30<05:46,  1.32s/it] 44%|████▍     | 209/471 [04:31<05:44,  1.32s/it] 45%|████▍     | 210/471 [04:33<05:43,  1.32s/it] 45%|████▍     | 211/471 [04:34<05:42,  1.32s/it] 45%|████▌     | 212/471 [04:35<05:41,  1.32s/it] 45%|████▌     | 213/471 [04:37<05:39,  1.32s/it] 45%|████▌     | 214/471 [04:38<05:38,  1.32s/it] 46%|████▌     | 215/471 [04:39<05:37,  1.32s/it] 46%|████▌     | 216/471 [04:41<05:36,  1.32s/it] 46%|████▌     | 217/471 [04:42<05:35,  1.32s/it] 46%|████▋     | 218/471 [04:43<05:34,  1.32s/it] 46%|████▋     | 219/471 [04:45<05:32,  1.32s/it] 47%|████▋     | 220/471 [04:46<05:31,  1.32s/it] 47%|████▋     | 221/471 [04:47<05:30,  1.32s/it] 47%|████▋     | 222/471 [04:49<05:28,  1.32s/it] 47%|████▋     | 223/471 [04:50<05:26,  1.32s/it] 48%|████▊     | 224/471 [04:51<05:25,  1.32s/it] 48%|████▊     | 225/471 [04:52<05:24,  1.32s/it] 48%|████▊     | 226/471 [04:54<05:23,  1.32s/it] 48%|████▊     | 227/471 [04:55<05:22,  1.32s/it] 48%|████▊     | 228/471 [04:56<05:21,  1.32s/it] 49%|████▊     | 229/471 [04:58<05:19,  1.32s/it] 49%|████▉     | 230/471 [04:59<05:18,  1.32s/it] 49%|████▉     | 231/471 [05:00<05:17,  1.32s/it] 49%|████▉     | 232/471 [05:02<05:15,  1.32s/it] 49%|████▉     | 233/471 [05:03<05:14,  1.32s/it] 50%|████▉     | 234/471 [05:04<05:13,  1.32s/it] 50%|████▉     | 235/471 [05:06<05:12,  1.33s/it] 50%|█████     | 236/471 [05:07<05:10,  1.32s/it] 50%|█████     | 237/471 [05:08<05:09,  1.32s/it] 51%|█████     | 238/471 [05:10<05:08,  1.33s/it] 51%|█████     | 239/471 [05:11<05:07,  1.33s/it] 51%|█████     | 240/471 [05:12<05:06,  1.33s/it] 51%|█████     | 241/471 [05:14<05:05,  1.33s/it] 51%|█████▏    | 242/471 [05:15<05:03,  1.33s/it] 52%|█████▏    | 243/471 [05:16<05:02,  1.33s/it] 52%|█████▏    | 244/471 [05:18<05:01,  1.33s/it] 52%|█████▏    | 245/471 [05:19<05:00,  1.33s/it] 52%|█████▏    | 246/471 [05:20<04:58,  1.33s/it] 52%|█████▏    | 247/471 [05:22<04:57,  1.33s/it] 53%|█████▎    | 248/471 [05:23<04:55,  1.33s/it] 53%|█████▎    | 249/471 [05:24<04:55,  1.33s/it] 53%|█████▎    | 250/471 [05:26<04:53,  1.33s/it] 53%|█████▎    | 251/471 [05:27<04:52,  1.33s/it] 54%|█████▎    | 252/471 [05:28<04:50,  1.33s/it] 54%|█████▎    | 253/471 [05:30<04:49,  1.33s/it] 54%|█████▍    | 254/471 [05:31<04:48,  1.33s/it] 54%|█████▍    | 255/471 [05:32<04:47,  1.33s/it] 54%|█████▍    | 256/471 [05:34<04:46,  1.33s/it] 55%|█████▍    | 257/471 [05:35<04:45,  1.33s/it] 55%|█████▍    | 258/471 [05:36<04:44,  1.33s/it] 55%|█████▍    | 259/471 [05:38<04:42,  1.33s/it] 55%|█████▌    | 260/471 [05:39<04:41,  1.33s/it] 55%|█████▌    | 261/471 [05:40<04:39,  1.33s/it] 56%|█████▌    | 262/471 [05:42<04:38,  1.33s/it] 56%|█████▌    | 263/471 [05:43<04:37,  1.33s/it] 56%|█████▌    | 264/471 [05:44<04:35,  1.33s/it] 56%|█████▋    | 265/471 [05:46<04:34,  1.33s/it] 56%|█████▋    | 266/471 [05:47<04:33,  1.34s/it] 57%|█████▋    | 267/471 [05:48<04:32,  1.34s/it] 57%|█████▋    | 268/471 [05:50<04:31,  1.34s/it] 57%|█████▋    | 269/471 [05:51<04:29,  1.34s/it] 57%|█████▋    | 270/471 [05:52<04:28,  1.34s/it] 58%|█████▊    | 271/471 [05:54<04:27,  1.34s/it] 58%|█████▊    | 272/471 [05:55<04:25,  1.33s/it] 58%|█████▊    | 273/471 [05:56<04:24,  1.33s/it] 58%|█████▊    | 274/471 [05:58<04:22,  1.33s/it] 58%|█████▊    | 275/471 [05:59<04:21,  1.33s/it] 59%|█████▊    | 276/471 [06:00<04:20,  1.33s/it] 59%|█████▉    | 277/471 [06:02<04:19,  1.34s/it] 59%|█████▉    | 278/471 [06:03<04:18,  1.34s/it] 59%|█████▉    | 279/471 [06:04<04:16,  1.34s/it] 59%|█████▉    | 280/471 [06:06<04:14,  1.33s/it] 60%|█████▉    | 281/471 [06:07<04:13,  1.33s/it] 60%|█████▉    | 282/471 [06:08<04:12,  1.33s/it] 60%|██████    | 283/471 [06:10<04:10,  1.33s/it] 60%|██████    | 284/471 [06:11<04:09,  1.33s/it] 61%|██████    | 285/471 [06:12<04:08,  1.34s/it] 61%|██████    | 286/471 [06:14<04:07,  1.34s/it] 61%|██████    | 287/471 [06:15<04:05,  1.34s/it] 61%|██████    | 288/471 [06:16<04:04,  1.34s/it] 61%|██████▏   | 289/471 [06:18<04:02,  1.33s/it] 62%|██████▏   | 290/471 [06:19<04:01,  1.33s/it] 62%|██████▏   | 291/471 [06:20<04:00,  1.33s/it] 62%|██████▏   | 292/471 [06:22<03:58,  1.33s/it] 62%|██████▏   | 293/471 [06:23<03:57,  1.33s/it] 62%|██████▏   | 294/471 [06:24<03:56,  1.33s/it] 63%|██████▎   | 295/471 [06:26<03:54,  1.33s/it] 63%|██████▎   | 296/471 [06:27<03:53,  1.34s/it] 63%|██████▎   | 297/471 [06:28<03:52,  1.33s/it] 63%|██████▎   | 298/471 [06:30<03:51,  1.34s/it] 63%|██████▎   | 299/471 [06:31<03:49,  1.34s/it] 64%|██████▎   | 300/471 [06:32<03:48,  1.34s/it] 64%|██████▍   | 301/471 [06:34<03:47,  1.34s/it] 64%|██████▍   | 302/471 [06:35<03:45,  1.33s/it] 64%|██████▍   | 303/471 [06:36<03:43,  1.33s/it] 65%|██████▍   | 304/471 [06:38<03:42,  1.33s/it] 65%|██████▍   | 305/471 [06:39<03:40,  1.33s/it] 65%|██████▍   | 306/471 [06:40<03:39,  1.33s/it] 65%|██████▌   | 307/471 [06:42<03:38,  1.33s/it] 65%|██████▌   | 308/471 [06:43<03:37,  1.33s/it] 66%|██████▌   | 309/471 [06:44<03:35,  1.33s/it] 66%|██████▌   | 310/471 [06:46<03:34,  1.33s/it] 66%|██████▌   | 311/471 [06:47<03:32,  1.33s/it] 66%|██████▌   | 312/471 [06:48<03:31,  1.33s/it] 66%|██████▋   | 313/471 [06:50<03:30,  1.33s/it] 67%|██████▋   | 314/471 [06:51<03:28,  1.33s/it] 67%|██████▋   | 315/471 [06:52<03:27,  1.33s/it] 67%|██████▋   | 316/471 [06:54<03:25,  1.33s/it] 67%|██████▋   | 317/471 [06:55<03:24,  1.33s/it] 68%|██████▊   | 318/471 [06:56<03:23,  1.33s/it] 68%|██████▊   | 319/471 [06:58<03:21,  1.33s/it] 68%|██████▊   | 320/471 [06:59<03:20,  1.33s/it] 68%|██████▊   | 321/471 [07:00<03:19,  1.33s/it] 68%|██████▊   | 322/471 [07:02<03:17,  1.33s/it] 69%|██████▊   | 323/471 [07:03<03:16,  1.33s/it] 69%|██████▉   | 324/471 [07:04<03:15,  1.33s/it] 69%|██████▉   | 325/471 [07:06<03:14,  1.33s/it] 69%|██████▉   | 326/471 [07:07<03:12,  1.33s/it] 69%|██████▉   | 327/471 [07:08<03:10,  1.33s/it] 70%|██████▉   | 328/471 [07:10<03:09,  1.33s/it] 70%|██████▉   | 329/471 [07:11<03:08,  1.33s/it] 70%|███████   | 330/471 [07:12<03:06,  1.32s/it] 70%|███████   | 331/471 [07:14<03:05,  1.32s/it] 70%|███████   | 332/471 [07:15<03:04,  1.33s/it] 71%|███████   | 333/471 [07:16<03:03,  1.33s/it] 71%|███████   | 334/471 [07:18<03:01,  1.33s/it] 71%|███████   | 335/471 [07:19<03:00,  1.33s/it] 71%|███████▏  | 336/471 [07:20<02:59,  1.33s/it] 72%|███████▏  | 337/471 [07:21<02:57,  1.32s/it] 72%|███████▏  | 338/471 [07:23<02:56,  1.33s/it] 72%|███████▏  | 339/471 [07:24<02:54,  1.32s/it] 72%|███████▏  | 340/471 [07:25<02:53,  1.33s/it] 72%|███████▏  | 341/471 [07:27<02:51,  1.32s/it] 73%|███████▎  | 342/471 [07:28<02:50,  1.32s/it] 73%|███████▎  | 343/471 [07:29<02:49,  1.32s/it] 73%|███████▎  | 344/471 [07:31<02:47,  1.32s/it] 73%|███████▎  | 345/471 [07:32<02:46,  1.32s/it] 73%|███████▎  | 346/471 [07:33<02:45,  1.32s/it] 74%|███████▎  | 347/471 [07:35<02:43,  1.32s/it] 74%|███████▍  | 348/471 [07:36<02:42,  1.32s/it] 74%|███████▍  | 349/471 [07:37<02:41,  1.32s/it] 74%|███████▍  | 350/471 [07:39<02:40,  1.32s/it] 75%|███████▍  | 351/471 [07:40<02:38,  1.32s/it] 75%|███████▍  | 352/471 [07:41<02:37,  1.32s/it] 75%|███████▍  | 353/471 [07:43<02:36,  1.32s/it] 75%|███████▌  | 354/471 [07:44<02:34,  1.32s/it] 75%|███████▌  | 355/471 [07:45<02:33,  1.32s/it] 76%|███████▌  | 356/471 [07:47<02:31,  1.32s/it] 76%|███████▌  | 357/471 [07:48<02:30,  1.32s/it] 76%|███████▌  | 358/471 [07:49<02:29,  1.32s/it] 76%|███████▌  | 359/471 [07:51<02:27,  1.32s/it] 76%|███████▋  | 360/471 [07:52<02:26,  1.32s/it] 77%|███████▋  | 361/471 [07:53<02:25,  1.32s/it] 77%|███████▋  | 362/471 [07:55<02:23,  1.32s/it] 77%|███████▋  | 363/471 [07:56<02:22,  1.32s/it] 77%|███████▋  | 364/471 [07:57<02:21,  1.32s/it] 77%|███████▋  | 365/471 [07:58<02:20,  1.32s/it] 78%|███████▊  | 366/471 [08:00<02:18,  1.32s/it] 78%|███████▊  | 367/471 [08:01<02:17,  1.32s/it] 78%|███████▊  | 368/471 [08:02<02:15,  1.32s/it] 78%|███████▊  | 369/471 [08:04<02:14,  1.32s/it] 79%|███████▊  | 370/471 [08:05<02:13,  1.32s/it] 79%|███████▉  | 371/471 [08:06<02:12,  1.33s/it] 79%|███████▉  | 372/471 [08:08<02:10,  1.32s/it] 79%|███████▉  | 373/471 [08:09<02:09,  1.32s/it] 79%|███████▉  | 374/471 [08:10<02:08,  1.32s/it] 80%|███████▉  | 375/471 [08:12<02:06,  1.32s/it] 80%|███████▉  | 376/471 [08:13<02:05,  1.32s/it] 80%|████████  | 377/471 [08:14<02:04,  1.32s/it] 80%|████████  | 378/471 [08:16<02:02,  1.32s/it] 80%|████████  | 379/471 [08:17<02:01,  1.32s/it] 81%|████████  | 380/471 [08:18<02:00,  1.32s/it] 81%|████████  | 381/471 [08:20<01:59,  1.32s/it] 81%|████████  | 382/471 [08:21<01:57,  1.32s/it] 81%|████████▏ | 383/471 [08:22<01:56,  1.33s/it] 82%|████████▏ | 384/471 [08:24<01:55,  1.33s/it] 82%|████████▏ | 385/471 [08:25<01:54,  1.33s/it] 82%|████████▏ | 386/471 [08:26<01:52,  1.32s/it] 82%|████████▏ | 387/471 [08:28<01:51,  1.33s/it] 82%|████████▏ | 388/471 [08:29<01:49,  1.33s/it] 83%|████████▎ | 389/471 [08:30<01:48,  1.32s/it] 83%|████████▎ | 390/471 [08:32<01:47,  1.33s/it] 83%|████████▎ | 391/471 [08:33<01:45,  1.32s/it] 83%|████████▎ | 392/471 [08:34<01:44,  1.33s/it] 83%|████████▎ | 393/471 [08:36<01:43,  1.33s/it] 84%|████████▎ | 394/471 [08:37<01:42,  1.33s/it] 84%|████████▍ | 395/471 [08:38<01:40,  1.33s/it] 84%|████████▍ | 396/471 [08:40<01:39,  1.33s/it] 84%|████████▍ | 397/471 [08:41<01:38,  1.33s/it] 85%|████████▍ | 398/471 [08:42<01:36,  1.32s/it] 85%|████████▍ | 399/471 [08:44<01:35,  1.33s/it] 85%|████████▍ | 400/471 [08:45<01:34,  1.33s/it] 85%|████████▌ | 401/471 [08:46<01:32,  1.32s/it] 85%|████████▌ | 402/471 [08:47<01:31,  1.32s/it] 86%|████████▌ | 403/471 [08:49<01:29,  1.32s/it] 86%|████████▌ | 404/471 [08:50<01:28,  1.32s/it] 86%|████████▌ | 405/471 [08:51<01:27,  1.32s/it] 86%|████████▌ | 406/471 [08:53<01:25,  1.32s/it] 86%|████████▋ | 407/471 [08:54<01:24,  1.32s/it] 87%|████████▋ | 408/471 [08:55<01:23,  1.32s/it] 87%|████████▋ | 409/471 [08:57<01:22,  1.32s/it] 87%|████████▋ | 410/471 [08:58<01:20,  1.32s/it] 87%|████████▋ | 411/471 [08:59<01:19,  1.32s/it] 87%|████████▋ | 412/471 [09:01<01:18,  1.33s/it] 88%|████████▊ | 413/471 [09:02<01:17,  1.33s/it] 88%|████████▊ | 414/471 [09:03<01:15,  1.33s/it] 88%|████████▊ | 415/471 [09:05<01:14,  1.32s/it] 88%|████████▊ | 416/471 [09:06<01:12,  1.33s/it] 89%|████████▊ | 417/471 [09:07<01:11,  1.32s/it] 89%|████████▊ | 418/471 [09:09<01:10,  1.32s/it] 89%|████████▉ | 419/471 [09:10<01:08,  1.32s/it] 89%|████████▉ | 420/471 [09:11<01:07,  1.32s/it] 89%|████████▉ | 421/471 [09:13<01:06,  1.32s/it] 90%|████████▉ | 422/471 [09:14<01:04,  1.32s/it] 90%|████████▉ | 423/471 [09:15<01:03,  1.32s/it] 90%|█████████ | 424/471 [09:17<01:02,  1.32s/it] 90%|█████████ | 425/471 [09:18<01:00,  1.32s/it] 90%|█████████ | 426/471 [09:19<00:59,  1.32s/it] 91%|█████████ | 427/471 [09:21<00:58,  1.32s/it] 91%|█████████ | 428/471 [09:22<00:56,  1.32s/it] 91%|█████████ | 429/471 [09:23<00:55,  1.32s/it] 91%|█████████▏| 430/471 [09:24<00:54,  1.32s/it] 92%|█████████▏| 431/471 [09:26<00:52,  1.32s/it] 92%|█████████▏| 432/471 [09:27<00:51,  1.32s/it] 92%|█████████▏| 433/471 [09:28<00:50,  1.32s/it] 92%|█████████▏| 434/471 [09:30<00:48,  1.32s/it] 92%|█████████▏| 435/471 [09:31<00:47,  1.32s/it] 93%|█████████▎| 436/471 [09:32<00:46,  1.32s/it] 93%|█████████▎| 437/471 [09:34<00:44,  1.32s/it] 93%|█████████▎| 438/471 [09:35<00:43,  1.32s/it] 93%|█████████▎| 439/471 [09:36<00:42,  1.32s/it] 93%|█████████▎| 440/471 [09:38<00:40,  1.32s/it] 94%|█████████▎| 441/471 [09:39<00:39,  1.32s/it] 94%|█████████▍| 442/471 [09:40<00:38,  1.32s/it] 94%|█████████▍| 443/471 [09:42<00:36,  1.32s/it] 94%|█████████▍| 444/471 [09:43<00:35,  1.32s/it] 94%|█████████▍| 445/471 [09:44<00:34,  1.32s/it] 95%|█████████▍| 446/471 [09:46<00:33,  1.32s/it] 95%|█████████▍| 447/471 [09:47<00:31,  1.32s/it] 95%|█████████▌| 448/471 [09:48<00:30,  1.32s/it] 95%|█████████▌| 449/471 [09:50<00:29,  1.32s/it] 96%|█████████▌| 450/471 [09:51<00:27,  1.32s/it] 96%|█████████▌| 451/471 [09:52<00:26,  1.32s/it] 96%|█████████▌| 452/471 [09:54<00:25,  1.32s/it] 96%|█████████▌| 453/471 [09:55<00:23,  1.33s/it] 96%|█████████▋| 454/471 [09:56<00:22,  1.33s/it] 97%|█████████▋| 455/471 [09:58<00:21,  1.33s/it] 97%|█████████▋| 456/471 [09:59<00:19,  1.33s/it] 97%|█████████▋| 457/471 [10:00<00:18,  1.33s/it] 97%|█████████▋| 458/471 [10:02<00:17,  1.33s/it] 97%|█████████▋| 459/471 [10:03<00:15,  1.33s/it] 98%|█████████▊| 460/471 [10:04<00:14,  1.33s/it] 98%|█████████▊| 461/471 [10:06<00:13,  1.33s/it] 98%|█████████▊| 462/471 [10:07<00:11,  1.33s/it] 98%|█████████▊| 463/471 [10:08<00:10,  1.33s/it] 99%|█████████▊| 464/471 [10:10<00:09,  1.33s/it] 99%|█████████▊| 465/471 [10:11<00:07,  1.33s/it] 99%|█████████▉| 466/471 [10:12<00:06,  1.33s/it] 99%|█████████▉| 467/471 [10:14<00:05,  1.33s/it] 99%|█████████▉| 468/471 [10:15<00:04,  1.33s/it]100%|█████████▉| 469/471 [10:16<00:02,  1.33s/it]100%|█████████▉| 470/471 [10:18<00:01,  1.33s/it]100%|██████████| 471/471 [10:18<00:00,  1.22s/it]100%|██████████| 471/471 [10:18<00:00,  1.31s/it]
{'eval_loss': 5.021449565887451, 'eval_model_preparation_time': 0.0151, 'eval_acc': 0.1249336165693043, 'eval_runtime': 620.1873, 'eval_samples_per_second': 12.145, 'eval_steps_per_second': 0.759}
ROUND:2
CLIENT:75
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.68s/it]                                              {'loss': 5.8225, 'grad_norm': 3.4202682971954346, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.68s/it]  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]                                              {'loss': 4.7969, 'grad_norm': 3.926450729370117, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]  8%|▊         | 3/40 [00:07<01:24,  2.29s/it]                                              {'loss': 3.2918, 'grad_norm': 4.275871753692627, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 3.2826, 'grad_norm': 16.163185119628906, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 3.3761, 'grad_norm': 4.397063255310059, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 3.5738, 'grad_norm': 6.374983787536621, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 3.7985, 'grad_norm': 14.73492431640625, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 3.8765, 'grad_norm': 46.19431686401367, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 1.4294, 'grad_norm': 5.081188678741455, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it]                                               {'loss': 1.6951, 'grad_norm': 11.469947814941406, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 2.3318, 'grad_norm': 6.285063743591309, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 1.6159, 'grad_norm': 9.810664176940918, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it]                                               {'loss': 2.8295, 'grad_norm': 11.799356460571289, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it]                                               {'loss': 1.9624, 'grad_norm': 6.8499956130981445, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it]                                               {'loss': 2.4363, 'grad_norm': 6.752622127532959, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it] 40%|████      | 16/40 [00:31<00:38,  1.60s/it]                                               {'loss': 1.9077, 'grad_norm': 18.929271697998047, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.81s/it]                                               {'loss': 0.4679, 'grad_norm': 7.565552711486816, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 0.9017, 'grad_norm': 9.176838874816895, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 1.3385, 'grad_norm': 9.354002952575684, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 1.1, 'grad_norm': 5.86283016204834, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 1.0127, 'grad_norm': 5.085842609405518, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.15s/it]                                               {'loss': 0.5423, 'grad_norm': 3.970034122467041, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:47<00:36,  2.17s/it]                                               {'loss': 0.5711, 'grad_norm': 5.555942058563232, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:36,  2.17s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 2.8963, 'grad_norm': 26.936813354492188, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.5219, 'grad_norm': 7.020179271697998, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.2549, 'grad_norm': 3.4231982231140137, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:25,  1.99s/it]                                               {'loss': 0.6915, 'grad_norm': 6.8850417137146, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:25,  1.99s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.5616, 'grad_norm': 5.138942241668701, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it]                                               {'loss': 0.5715, 'grad_norm': 4.888757228851318, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.1143, 'grad_norm': 1.9089007377624512, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.5296, 'grad_norm': 5.251804351806641, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0265, 'grad_norm': 1.823561429977417, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0988, 'grad_norm': 2.401975154876709, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.3724, 'grad_norm': 7.929721355438232, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.3833, 'grad_norm': 5.65327787399292, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.1789, 'grad_norm': 4.1650590896606445, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.2493, 'grad_norm': 2.355879545211792, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 0.8306, 'grad_norm': 7.282026290893555, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.2383, 'grad_norm': 3.2846951484680176, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0258, 'grad_norm': 0.8833634257316589, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.6272, 'train_samples_per_second': 7.096, 'train_steps_per_second': 0.502, 'train_loss': 1.5626656628213822, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:34,  2.42s/it]                                              {'loss': 4.2709, 'grad_norm': 8.086320877075195, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:34,  2.42s/it]  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]                                              {'loss': 4.5146, 'grad_norm': 3.6532623767852783, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 3.1654, 'grad_norm': 3.068610668182373, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:18,  2.18s/it]                                              {'loss': 5.6988, 'grad_norm': 4.088371753692627, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.18s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it]                                              {'loss': 3.0395, 'grad_norm': 3.6728765964508057, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 4.1951, 'grad_norm': 5.0655670166015625, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 3.7026, 'grad_norm': 5.980938911437988, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 4.6084, 'grad_norm': 21.924129486083984, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 2.05, 'grad_norm': 3.8000059127807617, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it]                                               {'loss': 1.7166, 'grad_norm': 4.3762712478637695, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 1.4282, 'grad_norm': 44.399662017822266, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.7169, 'grad_norm': 5.665530681610107, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it]                                               {'loss': 1.7791, 'grad_norm': 5.073411464691162, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it] 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it]                                               {'loss': 0.7191, 'grad_norm': 3.7159571647644043, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 2.1879, 'grad_norm': 7.5940752029418945, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 3.0647, 'grad_norm': 26.081735610961914, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.5731, 'grad_norm': 2.439793825149536, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it]                                               {'loss': 0.3371, 'grad_norm': 2.6071348190307617, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it]                                               {'loss': 0.2522, 'grad_norm': 2.9340322017669678, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.5451, 'grad_norm': 3.482311725616455, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.4914, 'grad_norm': 4.812809944152832, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.5617, 'grad_norm': 3.7901721000671387, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.20s/it]                                               {'loss': 0.5605, 'grad_norm': 3.3451952934265137, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0473, 'grad_norm': 0.9999698996543884, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.1977, 'grad_norm': 2.9544835090637207, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it]                                               {'loss': 0.3986, 'grad_norm': 1.0766957998275757, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.1818, 'grad_norm': 2.4781486988067627, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.1334, 'grad_norm': 2.5132977962493896, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.057, 'grad_norm': 1.0933363437652588, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.076, 'grad_norm': 1.1818815469741821, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.0999, 'grad_norm': 1.5695405006408691, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0018, 'grad_norm': 0.07707221060991287, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.034, 'grad_norm': 1.182924747467041, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.4389, 'grad_norm': 2.3780300617218018, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.0242, 'grad_norm': 0.3625309467315674, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.1124, 'grad_norm': 2.522516965866089, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.0629, 'grad_norm': 2.1211016178131104, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.2051, 'grad_norm': 2.6786062717437744, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]                                               {'loss': 0.2313, 'grad_norm': 4.444458484649658, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0279, 'grad_norm': 1.4069344997406006, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.3006, 'train_samples_per_second': 7.125, 'train_steps_per_second': 0.504, 'train_loss': 1.3377258640859508, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:46
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.68s/it]                                              {'loss': 4.424, 'grad_norm': 3.402968406677246, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.68s/it]  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]                                              {'loss': 4.7465, 'grad_norm': 4.351111888885498, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]  8%|▊         | 3/40 [00:07<01:24,  2.28s/it]                                              {'loss': 4.7736, 'grad_norm': 4.539181232452393, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 3.5947, 'grad_norm': 4.756665229797363, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 4.8582, 'grad_norm': 7.828068733215332, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 4.2232, 'grad_norm': 19.93032455444336, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 3.3489, 'grad_norm': 26.642404556274414, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 5.2506, 'grad_norm': 265.3493957519531, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 4.0959, 'grad_norm': 75.01420593261719, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 4.5305, 'grad_norm': 17.94673728942871, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.97s/it]                                               {'loss': 4.3668, 'grad_norm': 47.201812744140625, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.97s/it] 30%|███       | 12/40 [00:24<00:56,  2.02s/it]                                               {'loss': 4.6838, 'grad_norm': 30.89002227783203, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:56,  2.02s/it] 32%|███▎      | 13/40 [00:26<00:55,  2.06s/it]                                               {'loss': 3.7632, 'grad_norm': 14.272268295288086, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:55,  2.06s/it] 35%|███▌      | 14/40 [00:28<00:54,  2.09s/it]                                               {'loss': 3.5313, 'grad_norm': 65.11935424804688, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:54,  2.09s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.13s/it]                                               {'loss': 3.6415, 'grad_norm': 25.540817260742188, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.13s/it] 40%|████      | 16/40 [00:31<00:36,  1.54s/it]                                               {'loss': 3.5153, 'grad_norm': 27.305715560913086, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:36,  1.54s/it] 42%|████▎     | 17/40 [00:33<00:39,  1.73s/it]                                               {'loss': 3.5083, 'grad_norm': 16.939342498779297, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:39,  1.73s/it] 45%|████▌     | 18/40 [00:35<00:40,  1.86s/it]                                               {'loss': 3.4767, 'grad_norm': 36.966800689697266, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:40,  1.86s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.95s/it]                                               {'loss': 3.3774, 'grad_norm': 18.15659523010254, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.95s/it] 50%|█████     | 20/40 [00:40<00:40,  2.02s/it]                                               {'loss': 3.1213, 'grad_norm': 6.797824382781982, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:40,  2.02s/it] 52%|█████▎    | 21/40 [00:42<00:39,  2.08s/it]                                               {'loss': 3.7634, 'grad_norm': 30.985857009887695, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:39,  2.08s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.12s/it]                                               {'loss': 3.126, 'grad_norm': 16.42738151550293, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.12s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.14s/it]                                               {'loss': 4.2605, 'grad_norm': 34.81135559082031, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.14s/it] 60%|██████    | 24/40 [00:46<00:24,  1.55s/it]                                               {'loss': 2.8209, 'grad_norm': 99.26774597167969, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:24,  1.55s/it] 62%|██████▎   | 25/40 [00:48<00:25,  1.73s/it]                                               {'loss': 3.4245, 'grad_norm': 60.19914627075195, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:25,  1.73s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.87s/it]                                               {'loss': 3.5211, 'grad_norm': 13.620964050292969, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.87s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it]                                               {'loss': 4.2976, 'grad_norm': 10.628536224365234, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it] 70%|███████   | 28/40 [00:55<00:24,  2.05s/it]                                               {'loss': 3.0506, 'grad_norm': 39.490787506103516, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.05s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.10s/it]                                               {'loss': 3.1148, 'grad_norm': 11.337638854980469, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.10s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.13s/it]                                               {'loss': 3.0736, 'grad_norm': 18.375030517578125, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.13s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.15s/it]                                               {'loss': 3.5797, 'grad_norm': 27.168224334716797, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.15s/it] 80%|████████  | 32/40 [01:02<00:12,  1.56s/it]                                               {'loss': 2.9504, 'grad_norm': 30.378707885742188, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.56s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.75s/it]                                               {'loss': 3.3671, 'grad_norm': 7.954432964324951, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.75s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.89s/it]                                               {'loss': 3.384, 'grad_norm': 38.10532760620117, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.89s/it] 88%|████████▊ | 35/40 [01:09<00:09,  1.99s/it]                                               {'loss': 4.2447, 'grad_norm': 18.022382736206055, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:09,  1.99s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.05s/it]                                               {'loss': 3.1655, 'grad_norm': 9.209166526794434, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.05s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.11s/it]                                               {'loss': 3.0093, 'grad_norm': 12.179868698120117, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.11s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.14s/it]                                               {'loss': 3.3693, 'grad_norm': 24.334917068481445, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.14s/it] 98%|█████████▊| 39/40 [01:17<00:02,  2.17s/it]                                               {'loss': 3.0543, 'grad_norm': 21.459732055664062, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:17<00:02,  2.17s/it]100%|██████████| 40/40 [01:18<00:00,  1.57s/it]                                               {'loss': 2.0476, 'grad_norm': 19.73184585571289, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.57s/it]                                               {'train_runtime': 78.3712, 'train_samples_per_second': 7.209, 'train_steps_per_second': 0.51, 'train_loss': 3.6864239096641542, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.57s/it]100%|██████████| 40/40 [01:18<00:00,  1.96s/it]
CLIENT:68
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:26,  2.22s/it]                                              {'loss': 3.9597, 'grad_norm': 4.128132343292236, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:26,  2.22s/it]  5%|▌         | 2/40 [00:04<01:23,  2.18s/it]                                              {'loss': 4.3253, 'grad_norm': 4.806013584136963, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.18s/it]  8%|▊         | 3/40 [00:06<01:21,  2.20s/it]                                              {'loss': 4.3803, 'grad_norm': 7.364060401916504, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.20s/it] 10%|█         | 4/40 [00:08<01:18,  2.19s/it]                                              {'loss': 4.9229, 'grad_norm': 5.218976974487305, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.19s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it]                                              {'loss': 3.3027, 'grad_norm': 5.4203362464904785, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 4.3364, 'grad_norm': 9.200640678405762, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 4.2668, 'grad_norm': 8.761543273925781, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 0.6044, 'grad_norm': 20.626182556152344, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 2.0845, 'grad_norm': 14.466947555541992, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.3962, 'grad_norm': 13.58045768737793, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.9216, 'grad_norm': 10.087800979614258, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.4132, 'grad_norm': 15.686033248901367, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it]                                               {'loss': 0.9573, 'grad_norm': 9.624216079711914, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it]                                               {'loss': 2.4338, 'grad_norm': 9.1954984664917, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 1.0429, 'grad_norm': 6.790004730224609, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.0216, 'grad_norm': 0.5969627499580383, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 1.0049, 'grad_norm': 4.753378868103027, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.91s/it]                                               {'loss': 1.0133, 'grad_norm': 6.810895919799805, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it]                                               {'loss': 0.4407, 'grad_norm': 4.9989333152771, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it] 50%|█████     | 20/40 [00:40<00:42,  2.10s/it]                                               {'loss': 0.8095, 'grad_norm': 6.125293254852295, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.16s/it]                                               {'loss': 0.5571, 'grad_norm': 3.6077051162719727, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.16s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it]                                               {'loss': 0.5281, 'grad_norm': 10.702553749084473, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 1.0013, 'grad_norm': 9.115372657775879, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 4.7049, 'grad_norm': 22.274208068847656, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.3909, 'grad_norm': 4.585794925689697, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.2181, 'grad_norm': 2.3245513439178467, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.5777, 'grad_norm': 6.03757905960083, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.1438, 'grad_norm': 2.1740646362304688, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.2465, 'grad_norm': 3.381657600402832, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it]                                               {'loss': 0.4327, 'grad_norm': 8.027862548828125, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.484, 'grad_norm': 8.165755271911621, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0631, 'grad_norm': 2.964876890182495, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0896, 'grad_norm': 1.3498997688293457, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.96s/it]                                               {'loss': 0.0571, 'grad_norm': 1.1569772958755493, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it]                                               {'loss': 0.0473, 'grad_norm': 0.8575515747070312, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it]                                               {'loss': 0.0331, 'grad_norm': 0.5983312726020813, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it]                                               {'loss': 0.0874, 'grad_norm': 1.6958492994308472, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.079, 'grad_norm': 1.185225009918213, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.1505, 'grad_norm': 1.9290043115615845, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0215, 'grad_norm': 0.6779791116714478, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.7218, 'train_samples_per_second': 7.087, 'train_steps_per_second': 0.502, 'train_loss': 1.3637907369527966, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:3
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:54,  2.94s/it]                                              {'loss': 4.6102, 'grad_norm': 7.86510705947876, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:54,  2.94s/it]  5%|▌         | 2/40 [00:05<01:34,  2.48s/it]                                              {'loss': 3.6413, 'grad_norm': 2.8835291862487793, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:34,  2.48s/it]  8%|▊         | 3/40 [00:07<01:25,  2.32s/it]                                              {'loss': 4.8009, 'grad_norm': 4.079161643981934, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.32s/it] 10%|█         | 4/40 [00:09<01:21,  2.27s/it]                                              {'loss': 4.9568, 'grad_norm': 4.264682292938232, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.27s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it]                                              {'loss': 4.8263, 'grad_norm': 5.3109564781188965, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 4.2608, 'grad_norm': 5.014837741851807, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 4.4872, 'grad_norm': 6.742992401123047, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:16<00:50,  1.56s/it]                                              {'loss': 6.1125, 'grad_norm': 13.7910795211792, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 2.5491, 'grad_norm': 10.509438514709473, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.6015, 'grad_norm': 5.945157527923584, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 1.9852, 'grad_norm': 4.76596736907959, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:25<00:57,  2.07s/it]                                               {'loss': 1.166, 'grad_norm': 8.006494522094727, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it]                                               {'loss': 1.9047, 'grad_norm': 5.676634311676025, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it]                                               {'loss': 1.4919, 'grad_norm': 7.0961995124816895, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 2.0059, 'grad_norm': 7.2151923179626465, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 4.2895, 'grad_norm': 38.55736541748047, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.76s/it]                                               {'loss': 1.0104, 'grad_norm': 4.224198818206787, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it]                                               {'loss': 0.7377, 'grad_norm': 11.801800727844238, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it]                                               {'loss': 0.5852, 'grad_norm': 3.5036888122558594, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.8316, 'grad_norm': 5.558083534240723, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.2867, 'grad_norm': 3.9370455741882324, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.5029, 'grad_norm': 4.862430095672607, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.6587, 'grad_norm': 5.370749473571777, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0253, 'grad_norm': 0.737194836139679, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.199, 'grad_norm': 2.873426675796509, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.0951, 'grad_norm': 2.2913217544555664, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.0832, 'grad_norm': 1.36110520362854, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.6186, 'grad_norm': 3.7635703086853027, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it]                                               {'loss': 0.4392, 'grad_norm': 7.56663179397583, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.2946, 'grad_norm': 5.755053520202637, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.275, 'grad_norm': 3.8113150596618652, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0178, 'grad_norm': 0.8059434294700623, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it]                                               {'loss': 0.1059, 'grad_norm': 1.225339651107788, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.0897, 'grad_norm': 1.9538140296936035, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.2019, 'grad_norm': 3.760707139968872, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.1048, 'grad_norm': 2.189692974090576, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.3443, 'grad_norm': 2.1106159687042236, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.4875, 'grad_norm': 1.4900065660476685, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.2032, 'grad_norm': 3.481762647628784, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.3814, 'grad_norm': 12.736739158630371, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.1148, 'train_samples_per_second': 7.052, 'train_steps_per_second': 0.499, 'train_loss': 1.5817375319078564, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:39
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.17s/it]                                              {'loss': 4.7948, 'grad_norm': 3.645188093185425, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.17s/it]  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]                                              {'loss': 4.4171, 'grad_norm': 5.478105068206787, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]  8%|▊         | 3/40 [00:06<01:20,  2.17s/it]                                              {'loss': 5.1006, 'grad_norm': 12.001859664916992, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.17s/it] 10%|█         | 4/40 [00:08<01:17,  2.16s/it]                                              {'loss': 4.0146, 'grad_norm': 13.373595237731934, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.16s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it]                                              {'loss': 6.0176, 'grad_norm': 14.793380737304688, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 2.1994, 'grad_norm': 4.646072864532471, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 3.9404, 'grad_norm': 6.685696125030518, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 4.6176, 'grad_norm': 49.535667419433594, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 2.6471, 'grad_norm': 6.204367637634277, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.90s/it]                                               {'loss': 2.1169, 'grad_norm': 7.65703010559082, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 2.5739, 'grad_norm': 5.695686340332031, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 2.1873, 'grad_norm': 5.052212238311768, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 1.6413, 'grad_norm': 22.528045654296875, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it]                                               {'loss': 2.0022, 'grad_norm': 8.680298805236816, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it]                                               {'loss': 2.1179, 'grad_norm': 24.822839736938477, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 7.2095, 'grad_norm': 33.348472595214844, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 1.2168, 'grad_norm': 6.119807720184326, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it]                                               {'loss': 1.2455, 'grad_norm': 8.791610717773438, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it]                                               {'loss': 1.0401, 'grad_norm': 7.590745449066162, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it] 50%|█████     | 20/40 [00:39<00:41,  2.08s/it]                                               {'loss': 0.9384, 'grad_norm': 7.917142868041992, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.7713, 'grad_norm': 5.121269702911377, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.9402, 'grad_norm': 4.498504161834717, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it]                                               {'loss': 0.544, 'grad_norm': 3.8625357151031494, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it] 60%|██████    | 24/40 [00:46<00:25,  1.61s/it]                                               {'loss': 0.2671, 'grad_norm': 16.509014129638672, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it]                                               {'loss': 0.3308, 'grad_norm': 3.590542793273926, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.413, 'grad_norm': 1.9519670009613037, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.04s/it]                                               {'loss': 0.5994, 'grad_norm': 8.529793739318848, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.04s/it] 70%|███████   | 28/40 [00:55<00:25,  2.09s/it]                                               {'loss': 0.3335, 'grad_norm': 5.418697357177734, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.284, 'grad_norm': 2.8930206298828125, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.4339, 'grad_norm': 4.185569763183594, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.4837, 'grad_norm': 7.860854625701904, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:02<00:12,  1.60s/it]                                               {'loss': 0.5129, 'grad_norm': 11.111614227294922, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it]                                               {'loss': 0.8102, 'grad_norm': 8.540618896484375, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.6454, 'grad_norm': 5.559035301208496, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.00s/it]                                               {'loss': 0.0879, 'grad_norm': 1.31718111038208, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.00s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it]                                               {'loss': 0.9482, 'grad_norm': 3.7285611629486084, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.3861, 'grad_norm': 4.932878494262695, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.0757, 'grad_norm': 1.2318243980407715, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]                                               {'loss': 0.3478, 'grad_norm': 4.4052252769470215, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 0.0341, 'grad_norm': 2.106499671936035, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 79.1151, 'train_samples_per_second': 7.141, 'train_steps_per_second': 0.506, 'train_loss': 1.7821973215788602, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:23
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]                                              {'loss': 4.2491, 'grad_norm': 3.7664639949798584, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]                                              {'loss': 3.4525, 'grad_norm': 2.7968456745147705, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]  8%|▊         | 3/40 [00:06<01:19,  2.15s/it]                                              {'loss': 5.7464, 'grad_norm': 4.921359539031982, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.15s/it] 10%|█         | 4/40 [00:08<01:17,  2.15s/it]                                              {'loss': 3.14, 'grad_norm': 4.893911838531494, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.15s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.16s/it]                                              {'loss': 4.1089, 'grad_norm': 7.42515754699707, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.16s/it] 15%|█▌        | 6/40 [00:12<01:13,  2.15s/it]                                              {'loss': 3.1217, 'grad_norm': 5.464513301849365, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:12<01:13,  2.15s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.16s/it]                                              {'loss': 4.486, 'grad_norm': 24.63882064819336, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.16s/it] 20%|██        | 8/40 [00:15<00:48,  1.53s/it]                                              {'loss': 5.8054, 'grad_norm': 33.360107421875, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:48,  1.53s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it]                                              {'loss': 3.5372, 'grad_norm': 12.991851806640625, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it] 25%|██▌       | 10/40 [00:19<00:55,  1.84s/it]                                               {'loss': 3.0, 'grad_norm': 92.29045104980469, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:55,  1.84s/it] 28%|██▊       | 11/40 [00:21<00:56,  1.94s/it]                                               {'loss': 2.5908, 'grad_norm': 13.909412384033203, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:56,  1.94s/it] 30%|███       | 12/40 [00:23<00:56,  2.03s/it]                                               {'loss': 2.8345, 'grad_norm': 12.375937461853027, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:23<00:56,  2.03s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it]                                               {'loss': 2.6958, 'grad_norm': 15.696743965148926, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 2.0908, 'grad_norm': 14.15882682800293, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it]                                               {'loss': 2.1192, 'grad_norm': 11.7753267288208, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it] 40%|████      | 16/40 [00:30<00:37,  1.56s/it]                                               {'loss': 0.0165, 'grad_norm': 0.7169162034988403, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:32<00:40,  1.75s/it]                                               {'loss': 1.8817, 'grad_norm': 5.658361911773682, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:32<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it]                                               {'loss': 0.931, 'grad_norm': 5.227298736572266, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.97s/it]                                               {'loss': 1.9406, 'grad_norm': 11.577069282531738, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.97s/it] 50%|█████     | 20/40 [00:39<00:40,  2.03s/it]                                               {'loss': 1.3097, 'grad_norm': 8.95133113861084, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:40,  2.03s/it] 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it]                                               {'loss': 1.7873, 'grad_norm': 6.540430545806885, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:41<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:43<00:38,  2.13s/it]                                               {'loss': 1.0682, 'grad_norm': 7.903636932373047, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:43<00:38,  2.13s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it]                                               {'loss': 1.4669, 'grad_norm': 7.486384868621826, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.2836, 'grad_norm': 7.001059532165527, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it]                                               {'loss': 1.2276, 'grad_norm': 5.2177252769470215, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.76s/it] 65%|██████▌   | 26/40 [00:50<00:26,  1.91s/it]                                               {'loss': 0.9233, 'grad_norm': 12.58768081665039, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:50<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.99s/it]                                               {'loss': 2.2661, 'grad_norm': 9.894403457641602, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.99s/it] 70%|███████   | 28/40 [00:55<00:24,  2.06s/it]                                               {'loss': 1.4401, 'grad_norm': 77.83514404296875, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.06s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.12s/it]                                               {'loss': 1.3171, 'grad_norm': 28.267498016357422, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.12s/it] 75%|███████▌  | 30/40 [00:59<00:21,  2.15s/it]                                               {'loss': 0.9869, 'grad_norm': 21.625171661376953, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [00:59<00:21,  2.15s/it] 78%|███████▊  | 31/40 [01:01<00:19,  2.16s/it]                                               {'loss': 2.6628, 'grad_norm': 19.560279846191406, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:01<00:19,  2.16s/it] 80%|████████  | 32/40 [01:02<00:12,  1.57s/it]                                               {'loss': 0.6183, 'grad_norm': 20.206281661987305, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.57s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.79s/it]                                               {'loss': 0.8934, 'grad_norm': 5.542159080505371, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:06<00:11,  1.92s/it]                                               {'loss': 0.75, 'grad_norm': 4.587062358856201, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:06<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:08<00:10,  2.01s/it]                                               {'loss': 0.8704, 'grad_norm': 34.057552337646484, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:08<00:10,  2.01s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.07s/it]                                               {'loss': 1.3229, 'grad_norm': 7.153585910797119, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.07s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.12s/it]                                               {'loss': 0.9538, 'grad_norm': 17.104036331176758, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.12s/it] 95%|█████████▌| 38/40 [01:15<00:04,  2.16s/it]                                               {'loss': 1.2036, 'grad_norm': 18.055767059326172, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:15<00:04,  2.16s/it] 98%|█████████▊| 39/40 [01:17<00:02,  2.17s/it]                                               {'loss': 1.5925, 'grad_norm': 16.887453079223633, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:17<00:02,  2.17s/it]100%|██████████| 40/40 [01:17<00:00,  1.58s/it]                                               {'loss': 0.2066, 'grad_norm': 9.94614028930664, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:17<00:00,  1.58s/it]                                               {'train_runtime': 78.2068, 'train_samples_per_second': 7.224, 'train_steps_per_second': 0.511, 'train_loss': 2.072476621111855, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]100%|██████████| 40/40 [01:18<00:00,  1.96s/it]
CLIENT:20
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.69s/it]                                              {'loss': 3.9892, 'grad_norm': 3.473992109298706, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.69s/it]  5%|▌         | 2/40 [00:04<01:29,  2.37s/it]                                              {'loss': 5.1922, 'grad_norm': 3.6210429668426514, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.37s/it]  8%|▊         | 3/40 [00:06<01:23,  2.27s/it]                                              {'loss': 5.0293, 'grad_norm': 7.585702419281006, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.27s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 5.4055, 'grad_norm': 4.477350234985352, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 4.0265, 'grad_norm': 4.024774074554443, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 3.3523, 'grad_norm': 4.867414951324463, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.994, 'grad_norm': 3.5642764568328857, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 0.0188, 'grad_norm': 0.3950918912887573, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 3.2141, 'grad_norm': 7.489801406860352, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it]                                               {'loss': 1.9621, 'grad_norm': 5.434435844421387, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.0501, 'grad_norm': 2.6859476566314697, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 1.8517, 'grad_norm': 6.999346733093262, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it]                                               {'loss': 1.7426, 'grad_norm': 7.404107093811035, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.12s/it]                                               {'loss': 1.3756, 'grad_norm': 5.234162330627441, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it]                                               {'loss': 1.1584, 'grad_norm': 5.619055271148682, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.1151, 'grad_norm': 6.994790077209473, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.9622, 'grad_norm': 9.901405334472656, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it]                                               {'loss': 0.9062, 'grad_norm': 19.37708854675293, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it]                                               {'loss': 0.8758, 'grad_norm': 21.933332443237305, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.8551, 'grad_norm': 15.33389949798584, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it]                                               {'loss': 0.2107, 'grad_norm': 1.979659914970398, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 0.6727, 'grad_norm': 9.288168907165527, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.8609, 'grad_norm': 3.4969520568847656, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.068, 'grad_norm': 2.006920099258423, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0977, 'grad_norm': 1.9028544425964355, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.6475, 'grad_norm': 5.792537689208984, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it]                                               {'loss': 0.2784, 'grad_norm': 1.8894553184509277, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it] 70%|███████   | 28/40 [00:56<00:24,  2.07s/it]                                               {'loss': 0.3534, 'grad_norm': 1.64310622215271, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.11s/it]                                               {'loss': 0.8976, 'grad_norm': 7.357773780822754, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.11s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.13s/it]                                               {'loss': 0.6003, 'grad_norm': 2.866600275039673, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.13s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it]                                               {'loss': 0.2304, 'grad_norm': 2.553260326385498, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it] 80%|████████  | 32/40 [01:02<00:12,  1.58s/it]                                               {'loss': 0.4192, 'grad_norm': 28.10021209716797, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.77s/it]                                               {'loss': 0.2553, 'grad_norm': 1.8940186500549316, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.77s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.0768, 'grad_norm': 2.291093349456787, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.01s/it]                                               {'loss': 0.0218, 'grad_norm': 0.3616006076335907, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.01s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it]                                               {'loss': 0.9167, 'grad_norm': 31.882232666015625, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.12s/it]                                               {'loss': 0.5165, 'grad_norm': 3.7196829319000244, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.12s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it]                                               {'loss': 1.0922, 'grad_norm': 16.795495986938477, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.17s/it]                                               {'loss': 1.3157, 'grad_norm': 55.45705032348633, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.17s/it]100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'loss': 0.0166, 'grad_norm': 0.7005847692489624, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'train_runtime': 79.0695, 'train_samples_per_second': 7.146, 'train_steps_per_second': 0.506, 'train_loss': 1.3656328502111137, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.58s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:70
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:31,  2.35s/it]                                              {'loss': 5.2224, 'grad_norm': 3.0595383644104004, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:31,  2.35s/it]  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]                                              {'loss': 6.162, 'grad_norm': 3.507514476776123, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 3.1127, 'grad_norm': 9.761468887329102, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:18,  2.19s/it]                                              {'loss': 5.2418, 'grad_norm': 5.659778594970703, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.19s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it]                                              {'loss': 3.5461, 'grad_norm': 4.8887739181518555, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 4.706, 'grad_norm': 38.67073059082031, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 3.7806, 'grad_norm': 20.75371551513672, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 2.2915, 'grad_norm': 80.0035171508789, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 2.7545, 'grad_norm': 7.511970520019531, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 2.371, 'grad_norm': 12.582186698913574, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.9195, 'grad_norm': 7.973843097686768, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 2.489, 'grad_norm': 10.54832935333252, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 2.2428, 'grad_norm': 11.922562599182129, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 2.6095, 'grad_norm': 22.401920318603516, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 2.2974, 'grad_norm': 10.650129318237305, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 1.866, 'grad_norm': 41.36555480957031, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.819, 'grad_norm': 7.755485534667969, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:44,  2.05s/it]                                               {'loss': 1.0253, 'grad_norm': 45.070804595947266, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:44,  2.05s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.10s/it]                                               {'loss': 0.9532, 'grad_norm': 6.371988296508789, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.10s/it] 50%|█████     | 20/40 [00:40<00:42,  2.13s/it]                                               {'loss': 0.6814, 'grad_norm': 4.219795227050781, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.13s/it] 52%|█████▎    | 21/40 [00:42<00:41,  2.16s/it]                                               {'loss': 1.1456, 'grad_norm': 6.354920864105225, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:41,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.5233, 'grad_norm': 6.298458576202393, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.7493, 'grad_norm': 5.227275848388672, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 1.3043, 'grad_norm': 94.8357162475586, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.573, 'grad_norm': 84.7279281616211, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it]                                               {'loss': 0.4449, 'grad_norm': 4.530314922332764, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.1313, 'grad_norm': 2.1712467670440674, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.3086, 'grad_norm': 7.034670829772949, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.4738, 'grad_norm': 12.259342193603516, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.3356, 'grad_norm': 6.754671096801758, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.2036, 'grad_norm': 5.330258846282959, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.3152, 'grad_norm': 15.72665023803711, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it]                                               {'loss': 0.3452, 'grad_norm': 5.335577011108398, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.0733, 'grad_norm': 1.2381221055984497, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.1392, 'grad_norm': 3.0760772228240967, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.0952, 'grad_norm': 1.7319179773330688, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.3446, 'grad_norm': 8.490541458129883, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.4528, 'grad_norm': 6.712787628173828, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]                                               {'loss': 0.08, 'grad_norm': 1.4401237964630127, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.7696, 'grad_norm': 23.62830924987793, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.7027, 'train_samples_per_second': 7.089, 'train_steps_per_second': 0.502, 'train_loss': 1.622498287819326, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:73
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.17s/it]                                              {'loss': 5.8751, 'grad_norm': 3.0026395320892334, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.17s/it]  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]                                              {'loss': 4.2942, 'grad_norm': 10.09887409210205, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]  8%|▊         | 3/40 [00:06<01:19,  2.15s/it]                                              {'loss': 2.9662, 'grad_norm': 3.442077159881592, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.15s/it] 10%|█         | 4/40 [00:08<01:17,  2.16s/it]                                              {'loss': 4.7939, 'grad_norm': 4.3054351806640625, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.16s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it]                                              {'loss': 4.195, 'grad_norm': 5.623859405517578, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it] 15%|█▌        | 6/40 [00:13<01:13,  2.18s/it]                                              {'loss': 3.7697, 'grad_norm': 16.15245246887207, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:13,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 3.6045, 'grad_norm': 5.869319915771484, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 7.9828, 'grad_norm': 59.977779388427734, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 2.6454, 'grad_norm': 8.797148704528809, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it]                                               {'loss': 1.8575, 'grad_norm': 23.75297737121582, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:21<00:57,  1.97s/it]                                               {'loss': 1.6673, 'grad_norm': 24.783239364624023, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:57,  1.97s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 2.5551, 'grad_norm': 150.61483764648438, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it]                                               {'loss': 1.1752, 'grad_norm': 6.850749492645264, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it]                                               {'loss': 1.907, 'grad_norm': 7.609830379486084, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:30<00:54,  2.17s/it]                                               {'loss': 1.9303, 'grad_norm': 5.173887252807617, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 1.655, 'grad_norm': 38.04924774169922, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:42,  1.85s/it]                                               {'loss': 1.4615, 'grad_norm': 21.34375, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:42,  1.85s/it] 45%|████▌     | 18/40 [00:35<00:43,  1.97s/it]                                               {'loss': 0.857, 'grad_norm': 5.727662086486816, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:43,  1.97s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it]                                               {'loss': 0.5221, 'grad_norm': 4.114030838012695, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.8609, 'grad_norm': 10.665851593017578, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.9018, 'grad_norm': 4.263609409332275, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it]                                               {'loss': 1.0681, 'grad_norm': 5.558816432952881, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it]                                               {'loss': 0.9744, 'grad_norm': 7.003978729248047, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.127, 'grad_norm': 6.382025718688965, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.419, 'grad_norm': 4.5734992027282715, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.3321, 'grad_norm': 2.7405107021331787, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.09, 'grad_norm': 1.0024608373641968, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.1306, 'grad_norm': 1.9134349822998047, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.2785, 'grad_norm': 5.606233596801758, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.5604, 'grad_norm': 11.52595329284668, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it]                                               {'loss': 0.2769, 'grad_norm': 4.671093463897705, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0091, 'grad_norm': 0.370539128780365, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0463, 'grad_norm': 0.7313311100006104, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.0291, 'grad_norm': 0.7742217183113098, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.0718, 'grad_norm': 1.4316624402999878, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.0538, 'grad_norm': 1.2422817945480347, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.0576, 'grad_norm': 2.0024378299713135, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.0917, 'grad_norm': 1.8178048133850098, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.1818, 'grad_norm': 4.693533420562744, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0193, 'grad_norm': 1.4450433254241943, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.2764, 'train_samples_per_second': 7.127, 'train_steps_per_second': 0.505, 'train_loss': 1.5573766246205196, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:54,  1.59it/s]  1%|          | 3/471 [00:02<06:57,  1.12it/s]  1%|          | 4/471 [00:03<08:02,  1.03s/it]  1%|          | 5/471 [00:05<08:39,  1.11s/it]  1%|▏         | 6/471 [00:06<09:01,  1.16s/it]  1%|▏         | 7/471 [00:07<09:16,  1.20s/it]  2%|▏         | 8/471 [00:08<09:26,  1.22s/it]  2%|▏         | 9/471 [00:10<09:32,  1.24s/it]  2%|▏         | 10/471 [00:11<09:36,  1.25s/it]  2%|▏         | 11/471 [00:12<09:37,  1.26s/it]  3%|▎         | 12/471 [00:13<09:39,  1.26s/it]  3%|▎         | 13/471 [00:15<09:41,  1.27s/it]  3%|▎         | 14/471 [00:16<09:41,  1.27s/it]  3%|▎         | 15/471 [00:17<09:40,  1.27s/it]  3%|▎         | 16/471 [00:19<09:40,  1.28s/it]  4%|▎         | 17/471 [00:20<09:40,  1.28s/it]  4%|▍         | 18/471 [00:21<09:39,  1.28s/it]  4%|▍         | 19/471 [00:22<09:38,  1.28s/it]  4%|▍         | 20/471 [00:24<09:38,  1.28s/it]  4%|▍         | 21/471 [00:25<09:37,  1.28s/it]  5%|▍         | 22/471 [00:26<09:37,  1.29s/it]  5%|▍         | 23/471 [00:28<09:36,  1.29s/it]  5%|▌         | 24/471 [00:29<09:36,  1.29s/it]  5%|▌         | 25/471 [00:30<09:35,  1.29s/it]  6%|▌         | 26/471 [00:31<09:34,  1.29s/it]  6%|▌         | 27/471 [00:33<09:33,  1.29s/it]  6%|▌         | 28/471 [00:34<09:32,  1.29s/it]  6%|▌         | 29/471 [00:35<09:32,  1.29s/it]  6%|▋         | 30/471 [00:37<09:31,  1.30s/it]  7%|▋         | 31/471 [00:38<09:30,  1.30s/it]  7%|▋         | 32/471 [00:39<09:28,  1.30s/it]  7%|▋         | 33/471 [00:41<09:25,  1.29s/it]  7%|▋         | 34/471 [00:42<09:25,  1.29s/it]  7%|▋         | 35/471 [00:43<09:25,  1.30s/it]  8%|▊         | 36/471 [00:44<09:24,  1.30s/it]  8%|▊         | 37/471 [00:46<09:24,  1.30s/it]  8%|▊         | 38/471 [00:47<09:23,  1.30s/it]  8%|▊         | 39/471 [00:48<09:22,  1.30s/it]  8%|▊         | 40/471 [00:50<09:21,  1.30s/it]  9%|▊         | 41/471 [00:51<09:20,  1.30s/it]  9%|▉         | 42/471 [00:52<09:20,  1.31s/it]  9%|▉         | 43/471 [00:54<09:18,  1.31s/it]  9%|▉         | 44/471 [00:55<09:17,  1.31s/it] 10%|▉         | 45/471 [00:56<09:17,  1.31s/it] 10%|▉         | 46/471 [00:58<09:15,  1.31s/it] 10%|▉         | 47/471 [00:59<09:14,  1.31s/it] 10%|█         | 48/471 [01:00<09:12,  1.31s/it] 10%|█         | 49/471 [01:01<09:12,  1.31s/it] 11%|█         | 50/471 [01:03<09:11,  1.31s/it] 11%|█         | 51/471 [01:04<09:10,  1.31s/it] 11%|█         | 52/471 [01:05<09:09,  1.31s/it] 11%|█▏        | 53/471 [01:07<09:08,  1.31s/it] 11%|█▏        | 54/471 [01:08<09:07,  1.31s/it] 12%|█▏        | 55/471 [01:09<09:05,  1.31s/it] 12%|█▏        | 56/471 [01:11<09:05,  1.31s/it] 12%|█▏        | 57/471 [01:12<09:04,  1.32s/it] 12%|█▏        | 58/471 [01:13<09:03,  1.31s/it] 13%|█▎        | 59/471 [01:15<09:01,  1.32s/it] 13%|█▎        | 60/471 [01:16<09:00,  1.31s/it] 13%|█▎        | 61/471 [01:17<08:59,  1.32s/it] 13%|█▎        | 62/471 [01:19<08:57,  1.32s/it] 13%|█▎        | 63/471 [01:20<08:56,  1.31s/it] 14%|█▎        | 64/471 [01:21<08:55,  1.32s/it] 14%|█▍        | 65/471 [01:22<08:53,  1.31s/it] 14%|█▍        | 66/471 [01:24<08:53,  1.32s/it] 14%|█▍        | 67/471 [01:25<08:52,  1.32s/it] 14%|█▍        | 68/471 [01:26<08:49,  1.31s/it] 15%|█▍        | 69/471 [01:28<08:48,  1.32s/it] 15%|█▍        | 70/471 [01:29<08:48,  1.32s/it] 15%|█▌        | 71/471 [01:30<08:47,  1.32s/it] 15%|█▌        | 72/471 [01:32<08:45,  1.32s/it] 15%|█▌        | 73/471 [01:33<08:44,  1.32s/it] 16%|█▌        | 74/471 [01:34<08:41,  1.31s/it] 16%|█▌        | 75/471 [01:36<08:41,  1.32s/it] 16%|█▌        | 76/471 [01:37<08:39,  1.32s/it] 16%|█▋        | 77/471 [01:38<08:38,  1.32s/it] 17%|█▋        | 78/471 [01:40<08:37,  1.32s/it] 17%|█▋        | 79/471 [01:41<08:36,  1.32s/it] 17%|█▋        | 80/471 [01:42<08:35,  1.32s/it] 17%|█▋        | 81/471 [01:44<08:33,  1.32s/it] 17%|█▋        | 82/471 [01:45<08:32,  1.32s/it] 18%|█▊        | 83/471 [01:46<08:31,  1.32s/it] 18%|█▊        | 84/471 [01:47<08:30,  1.32s/it] 18%|█▊        | 85/471 [01:49<08:29,  1.32s/it] 18%|█▊        | 86/471 [01:50<08:27,  1.32s/it] 18%|█▊        | 87/471 [01:51<08:26,  1.32s/it] 19%|█▊        | 88/471 [01:53<08:24,  1.32s/it] 19%|█▉        | 89/471 [01:54<08:22,  1.32s/it] 19%|█▉        | 90/471 [01:55<08:21,  1.32s/it] 19%|█▉        | 91/471 [01:57<08:19,  1.32s/it] 20%|█▉        | 92/471 [01:58<08:18,  1.32s/it] 20%|█▉        | 93/471 [01:59<08:17,  1.32s/it] 20%|█▉        | 94/471 [02:01<08:16,  1.32s/it] 20%|██        | 95/471 [02:02<08:15,  1.32s/it] 20%|██        | 96/471 [02:03<08:13,  1.32s/it] 21%|██        | 97/471 [02:05<08:13,  1.32s/it] 21%|██        | 98/471 [02:06<08:11,  1.32s/it] 21%|██        | 99/471 [02:07<08:09,  1.32s/it] 21%|██        | 100/471 [02:09<08:08,  1.32s/it] 21%|██▏       | 101/471 [02:10<08:07,  1.32s/it] 22%|██▏       | 102/471 [02:11<08:06,  1.32s/it] 22%|██▏       | 103/471 [02:13<08:05,  1.32s/it] 22%|██▏       | 104/471 [02:14<08:04,  1.32s/it] 22%|██▏       | 105/471 [02:15<08:04,  1.32s/it] 23%|██▎       | 106/471 [02:16<08:02,  1.32s/it] 23%|██▎       | 107/471 [02:18<08:00,  1.32s/it] 23%|██▎       | 108/471 [02:19<07:59,  1.32s/it] 23%|██▎       | 109/471 [02:20<07:57,  1.32s/it] 23%|██▎       | 110/471 [02:22<07:54,  1.31s/it] 24%|██▎       | 111/471 [02:23<07:54,  1.32s/it] 24%|██▍       | 112/471 [02:24<07:52,  1.32s/it] 24%|██▍       | 113/471 [02:26<07:51,  1.32s/it] 24%|██▍       | 114/471 [02:27<07:50,  1.32s/it] 24%|██▍       | 115/471 [02:28<07:49,  1.32s/it] 25%|██▍       | 116/471 [02:30<07:47,  1.32s/it] 25%|██▍       | 117/471 [02:31<07:46,  1.32s/it] 25%|██▌       | 118/471 [02:32<07:45,  1.32s/it] 25%|██▌       | 119/471 [02:34<07:44,  1.32s/it] 25%|██▌       | 120/471 [02:35<07:43,  1.32s/it] 26%|██▌       | 121/471 [02:36<07:42,  1.32s/it] 26%|██▌       | 122/471 [02:38<07:40,  1.32s/it] 26%|██▌       | 123/471 [02:39<07:39,  1.32s/it] 26%|██▋       | 124/471 [02:40<07:38,  1.32s/it] 27%|██▋       | 125/471 [02:42<07:37,  1.32s/it] 27%|██▋       | 126/471 [02:43<07:35,  1.32s/it] 27%|██▋       | 127/471 [02:44<07:34,  1.32s/it] 27%|██▋       | 128/471 [02:46<07:33,  1.32s/it] 27%|██▋       | 129/471 [02:47<07:31,  1.32s/it] 28%|██▊       | 130/471 [02:48<07:30,  1.32s/it] 28%|██▊       | 131/471 [02:49<07:29,  1.32s/it] 28%|██▊       | 132/471 [02:51<07:28,  1.32s/it] 28%|██▊       | 133/471 [02:52<07:26,  1.32s/it] 28%|██▊       | 134/471 [02:53<07:26,  1.32s/it] 29%|██▊       | 135/471 [02:55<07:24,  1.32s/it] 29%|██▉       | 136/471 [02:56<07:22,  1.32s/it] 29%|██▉       | 137/471 [02:57<07:21,  1.32s/it] 29%|██▉       | 138/471 [02:59<07:20,  1.32s/it] 30%|██▉       | 139/471 [03:00<07:19,  1.32s/it] 30%|██▉       | 140/471 [03:01<07:17,  1.32s/it] 30%|██▉       | 141/471 [03:03<07:16,  1.32s/it] 30%|███       | 142/471 [03:04<07:14,  1.32s/it] 30%|███       | 143/471 [03:05<07:12,  1.32s/it] 31%|███       | 144/471 [03:07<07:13,  1.32s/it] 31%|███       | 145/471 [03:08<07:10,  1.32s/it] 31%|███       | 146/471 [03:09<07:09,  1.32s/it] 31%|███       | 147/471 [03:11<07:08,  1.32s/it] 31%|███▏      | 148/471 [03:12<07:07,  1.32s/it] 32%|███▏      | 149/471 [03:13<07:07,  1.33s/it] 32%|███▏      | 150/471 [03:15<07:06,  1.33s/it] 32%|███▏      | 151/471 [03:16<07:05,  1.33s/it] 32%|███▏      | 152/471 [03:17<07:03,  1.33s/it] 32%|███▏      | 153/471 [03:19<07:02,  1.33s/it] 33%|███▎      | 154/471 [03:20<07:00,  1.33s/it] 33%|███▎      | 155/471 [03:21<06:59,  1.33s/it] 33%|███▎      | 156/471 [03:23<06:57,  1.33s/it] 33%|███▎      | 157/471 [03:24<06:56,  1.33s/it] 34%|███▎      | 158/471 [03:25<06:54,  1.32s/it] 34%|███▍      | 159/471 [03:27<06:53,  1.32s/it] 34%|███▍      | 160/471 [03:28<06:52,  1.33s/it] 34%|███▍      | 161/471 [03:29<06:51,  1.33s/it] 34%|███▍      | 162/471 [03:31<06:50,  1.33s/it] 35%|███▍      | 163/471 [03:32<06:49,  1.33s/it] 35%|███▍      | 164/471 [03:33<06:48,  1.33s/it] 35%|███▌      | 165/471 [03:35<06:46,  1.33s/it] 35%|███▌      | 166/471 [03:36<06:45,  1.33s/it] 35%|███▌      | 167/471 [03:37<06:44,  1.33s/it] 36%|███▌      | 168/471 [03:39<06:43,  1.33s/it] 36%|███▌      | 169/471 [03:40<06:42,  1.33s/it] 36%|███▌      | 170/471 [03:41<06:42,  1.34s/it] 36%|███▋      | 171/471 [03:43<06:39,  1.33s/it] 37%|███▋      | 172/471 [03:44<06:37,  1.33s/it] 37%|███▋      | 173/471 [03:45<06:36,  1.33s/it] 37%|███▋      | 174/471 [03:47<06:35,  1.33s/it] 37%|███▋      | 175/471 [03:48<06:34,  1.33s/it] 37%|███▋      | 176/471 [03:49<06:33,  1.33s/it] 38%|███▊      | 177/471 [03:51<06:31,  1.33s/it] 38%|███▊      | 178/471 [03:52<06:30,  1.33s/it] 38%|███▊      | 179/471 [03:53<06:29,  1.33s/it] 38%|███▊      | 180/471 [03:55<06:27,  1.33s/it] 38%|███▊      | 181/471 [03:56<06:26,  1.33s/it] 39%|███▊      | 182/471 [03:57<06:25,  1.33s/it] 39%|███▉      | 183/471 [03:59<06:25,  1.34s/it] 39%|███▉      | 184/471 [04:00<06:23,  1.34s/it] 39%|███▉      | 185/471 [04:01<06:21,  1.34s/it] 39%|███▉      | 186/471 [04:03<06:21,  1.34s/it] 40%|███▉      | 187/471 [04:04<06:20,  1.34s/it] 40%|███▉      | 188/471 [04:05<06:19,  1.34s/it] 40%|████      | 189/471 [04:07<06:17,  1.34s/it] 40%|████      | 190/471 [04:08<06:15,  1.34s/it] 41%|████      | 191/471 [04:09<06:14,  1.34s/it] 41%|████      | 192/471 [04:11<06:13,  1.34s/it] 41%|████      | 193/471 [04:12<06:10,  1.33s/it] 41%|████      | 194/471 [04:13<06:09,  1.33s/it] 41%|████▏     | 195/471 [04:15<06:08,  1.34s/it] 42%|████▏     | 196/471 [04:16<06:07,  1.33s/it] 42%|████▏     | 197/471 [04:17<06:04,  1.33s/it] 42%|████▏     | 198/471 [04:19<06:03,  1.33s/it] 42%|████▏     | 199/471 [04:20<06:02,  1.33s/it] 42%|████▏     | 200/471 [04:21<06:01,  1.33s/it] 43%|████▎     | 201/471 [04:23<05:58,  1.33s/it] 43%|████▎     | 202/471 [04:24<05:58,  1.33s/it] 43%|████▎     | 203/471 [04:25<05:57,  1.33s/it] 43%|████▎     | 204/471 [04:27<05:55,  1.33s/it] 44%|████▎     | 205/471 [04:28<05:54,  1.33s/it] 44%|████▎     | 206/471 [04:29<05:52,  1.33s/it] 44%|████▍     | 207/471 [04:31<05:51,  1.33s/it] 44%|████▍     | 208/471 [04:32<05:49,  1.33s/it] 44%|████▍     | 209/471 [04:33<05:48,  1.33s/it] 45%|████▍     | 210/471 [04:35<05:47,  1.33s/it] 45%|████▍     | 211/471 [04:36<05:46,  1.33s/it] 45%|████▌     | 212/471 [04:37<05:44,  1.33s/it] 45%|████▌     | 213/471 [04:39<05:43,  1.33s/it] 45%|████▌     | 214/471 [04:40<05:42,  1.33s/it] 46%|████▌     | 215/471 [04:41<05:41,  1.33s/it] 46%|████▌     | 216/471 [04:43<05:40,  1.34s/it] 46%|████▌     | 217/471 [04:44<05:39,  1.34s/it] 46%|████▋     | 218/471 [04:45<05:38,  1.34s/it] 46%|████▋     | 219/471 [04:47<05:36,  1.34s/it] 47%|████▋     | 220/471 [04:48<05:35,  1.34s/it] 47%|████▋     | 221/471 [04:49<05:34,  1.34s/it] 47%|████▋     | 222/471 [04:51<05:32,  1.33s/it] 47%|████▋     | 223/471 [04:52<05:30,  1.33s/it] 48%|████▊     | 224/471 [04:53<05:29,  1.33s/it] 48%|████▊     | 225/471 [04:55<05:27,  1.33s/it] 48%|████▊     | 226/471 [04:56<05:26,  1.33s/it] 48%|████▊     | 227/471 [04:57<05:24,  1.33s/it] 48%|████▊     | 228/471 [04:59<05:23,  1.33s/it] 49%|████▊     | 229/471 [05:00<05:22,  1.33s/it] 49%|████▉     | 230/471 [05:01<05:21,  1.33s/it] 49%|████▉     | 231/471 [05:03<05:19,  1.33s/it] 49%|████▉     | 232/471 [05:04<05:17,  1.33s/it] 49%|████▉     | 233/471 [05:05<05:16,  1.33s/it] 50%|████▉     | 234/471 [05:07<05:15,  1.33s/it] 50%|████▉     | 235/471 [05:08<05:14,  1.33s/it] 50%|█████     | 236/471 [05:09<05:12,  1.33s/it] 50%|█████     | 237/471 [05:11<05:11,  1.33s/it] 51%|█████     | 238/471 [05:12<05:10,  1.33s/it] 51%|█████     | 239/471 [05:13<05:08,  1.33s/it] 51%|█████     | 240/471 [05:15<05:07,  1.33s/it] 51%|█████     | 241/471 [05:16<05:06,  1.33s/it] 51%|█████▏    | 242/471 [05:17<05:04,  1.33s/it] 52%|█████▏    | 243/471 [05:19<05:03,  1.33s/it] 52%|█████▏    | 244/471 [05:20<05:02,  1.33s/it] 52%|█████▏    | 245/471 [05:21<05:01,  1.33s/it] 52%|█████▏    | 246/471 [05:23<04:59,  1.33s/it] 52%|█████▏    | 247/471 [05:24<04:58,  1.33s/it] 53%|█████▎    | 248/471 [05:25<04:56,  1.33s/it] 53%|█████▎    | 249/471 [05:27<04:56,  1.33s/it] 53%|█████▎    | 250/471 [05:28<04:54,  1.33s/it] 53%|█████▎    | 251/471 [05:29<04:52,  1.33s/it] 54%|█████▎    | 252/471 [05:31<04:51,  1.33s/it] 54%|█████▎    | 253/471 [05:32<04:50,  1.33s/it] 54%|█████▍    | 254/471 [05:33<04:49,  1.33s/it] 54%|█████▍    | 255/471 [05:35<04:47,  1.33s/it] 54%|█████▍    | 256/471 [05:36<04:46,  1.33s/it] 55%|█████▍    | 257/471 [05:37<04:44,  1.33s/it] 55%|█████▍    | 258/471 [05:39<04:43,  1.33s/it] 55%|█████▍    | 259/471 [05:40<04:42,  1.33s/it] 55%|█████▌    | 260/471 [05:41<04:41,  1.33s/it] 55%|█████▌    | 261/471 [05:43<04:39,  1.33s/it] 56%|█████▌    | 262/471 [05:44<04:37,  1.33s/it] 56%|█████▌    | 263/471 [05:45<04:37,  1.33s/it] 56%|█████▌    | 264/471 [05:47<04:35,  1.33s/it] 56%|█████▋    | 265/471 [05:48<04:34,  1.33s/it] 56%|█████▋    | 266/471 [05:49<04:33,  1.33s/it] 57%|█████▋    | 267/471 [05:51<04:32,  1.33s/it] 57%|█████▋    | 268/471 [05:52<04:31,  1.34s/it] 57%|█████▋    | 269/471 [05:53<04:29,  1.33s/it] 57%|█████▋    | 270/471 [05:55<04:28,  1.33s/it] 58%|█████▊    | 271/471 [05:56<04:26,  1.33s/it] 58%|█████▊    | 272/471 [05:57<04:23,  1.33s/it] 58%|█████▊    | 273/471 [05:58<04:23,  1.33s/it] 58%|█████▊    | 274/471 [06:00<04:21,  1.33s/it] 58%|█████▊    | 275/471 [06:01<04:20,  1.33s/it] 59%|█████▊    | 276/471 [06:02<04:19,  1.33s/it] 59%|█████▉    | 277/471 [06:04<04:18,  1.33s/it] 59%|█████▉    | 278/471 [06:05<04:16,  1.33s/it] 59%|█████▉    | 279/471 [06:06<04:15,  1.33s/it] 59%|█████▉    | 280/471 [06:08<04:14,  1.33s/it] 60%|█████▉    | 281/471 [06:09<04:12,  1.33s/it] 60%|█████▉    | 282/471 [06:10<04:11,  1.33s/it] 60%|██████    | 283/471 [06:12<04:10,  1.33s/it] 60%|██████    | 284/471 [06:13<04:08,  1.33s/it] 61%|██████    | 285/471 [06:14<04:07,  1.33s/it] 61%|██████    | 286/471 [06:16<04:06,  1.33s/it] 61%|██████    | 287/471 [06:17<04:05,  1.33s/it] 61%|██████    | 288/471 [06:18<04:04,  1.33s/it] 61%|██████▏   | 289/471 [06:20<04:02,  1.33s/it] 62%|██████▏   | 290/471 [06:21<04:00,  1.33s/it] 62%|██████▏   | 291/471 [06:22<03:59,  1.33s/it] 62%|██████▏   | 292/471 [06:24<03:57,  1.33s/it] 62%|██████▏   | 293/471 [06:25<03:56,  1.33s/it] 62%|██████▏   | 294/471 [06:26<03:55,  1.33s/it] 63%|██████▎   | 295/471 [06:28<03:53,  1.33s/it] 63%|██████▎   | 296/471 [06:29<03:52,  1.33s/it] 63%|██████▎   | 297/471 [06:30<03:51,  1.33s/it] 63%|██████▎   | 298/471 [06:32<03:50,  1.33s/it] 63%|██████▎   | 299/471 [06:33<03:48,  1.33s/it] 64%|██████▎   | 300/471 [06:34<03:47,  1.33s/it] 64%|██████▍   | 301/471 [06:36<03:46,  1.33s/it] 64%|██████▍   | 302/471 [06:37<03:44,  1.33s/it] 64%|██████▍   | 303/471 [06:38<03:43,  1.33s/it] 65%|██████▍   | 304/471 [06:40<03:41,  1.33s/it] 65%|██████▍   | 305/471 [06:41<03:40,  1.33s/it] 65%|██████▍   | 306/471 [06:42<03:39,  1.33s/it] 65%|██████▌   | 307/471 [06:44<03:38,  1.33s/it] 65%|██████▌   | 308/471 [06:45<03:36,  1.33s/it] 66%|██████▌   | 309/471 [06:46<03:35,  1.33s/it] 66%|██████▌   | 310/471 [06:48<03:34,  1.33s/it] 66%|██████▌   | 311/471 [06:49<03:32,  1.33s/it] 66%|██████▌   | 312/471 [06:50<03:31,  1.33s/it] 66%|██████▋   | 313/471 [06:52<03:29,  1.33s/it] 67%|██████▋   | 314/471 [06:53<03:28,  1.33s/it] 67%|██████▋   | 315/471 [06:54<03:27,  1.33s/it] 67%|██████▋   | 316/471 [06:56<03:25,  1.33s/it] 67%|██████▋   | 317/471 [06:57<03:24,  1.33s/it] 68%|██████▊   | 318/471 [06:58<03:23,  1.33s/it] 68%|██████▊   | 319/471 [07:00<03:21,  1.33s/it] 68%|██████▊   | 320/471 [07:01<03:20,  1.33s/it] 68%|██████▊   | 321/471 [07:02<03:19,  1.33s/it] 68%|██████▊   | 322/471 [07:04<03:17,  1.33s/it] 69%|██████▊   | 323/471 [07:05<03:16,  1.33s/it] 69%|██████▉   | 324/471 [07:06<03:15,  1.33s/it] 69%|██████▉   | 325/471 [07:08<03:14,  1.33s/it] 69%|██████▉   | 326/471 [07:09<03:12,  1.33s/it] 69%|██████▉   | 327/471 [07:10<03:10,  1.33s/it] 70%|██████▉   | 328/471 [07:12<03:09,  1.33s/it] 70%|██████▉   | 329/471 [07:13<03:08,  1.33s/it] 70%|███████   | 330/471 [07:14<03:06,  1.33s/it] 70%|███████   | 331/471 [07:16<03:05,  1.33s/it] 70%|███████   | 332/471 [07:17<03:04,  1.33s/it] 71%|███████   | 333/471 [07:18<03:03,  1.33s/it] 71%|███████   | 334/471 [07:20<03:01,  1.33s/it] 71%|███████   | 335/471 [07:21<03:00,  1.33s/it] 71%|███████▏  | 336/471 [07:22<02:59,  1.33s/it] 72%|███████▏  | 337/471 [07:24<02:57,  1.33s/it] 72%|███████▏  | 338/471 [07:25<02:56,  1.32s/it] 72%|███████▏  | 339/471 [07:26<02:55,  1.33s/it] 72%|███████▏  | 340/471 [07:28<02:53,  1.33s/it] 72%|███████▏  | 341/471 [07:29<02:51,  1.32s/it] 73%|███████▎  | 342/471 [07:30<02:50,  1.32s/it] 73%|███████▎  | 343/471 [07:31<02:49,  1.32s/it] 73%|███████▎  | 344/471 [07:33<02:47,  1.32s/it] 73%|███████▎  | 345/471 [07:34<02:46,  1.32s/it] 73%|███████▎  | 346/471 [07:35<02:45,  1.32s/it] 74%|███████▎  | 347/471 [07:37<02:43,  1.32s/it] 74%|███████▍  | 348/471 [07:38<02:42,  1.32s/it] 74%|███████▍  | 349/471 [07:39<02:41,  1.32s/it] 74%|███████▍  | 350/471 [07:41<02:39,  1.32s/it] 75%|███████▍  | 351/471 [07:42<02:38,  1.32s/it] 75%|███████▍  | 352/471 [07:43<02:37,  1.32s/it] 75%|███████▍  | 353/471 [07:45<02:36,  1.32s/it] 75%|███████▌  | 354/471 [07:46<02:34,  1.32s/it] 75%|███████▌  | 355/471 [07:47<02:33,  1.32s/it] 76%|███████▌  | 356/471 [07:49<02:32,  1.32s/it] 76%|███████▌  | 357/471 [07:50<02:30,  1.32s/it] 76%|███████▌  | 358/471 [07:51<02:29,  1.32s/it] 76%|███████▌  | 359/471 [07:53<02:28,  1.32s/it] 76%|███████▋  | 360/471 [07:54<02:26,  1.32s/it] 77%|███████▋  | 361/471 [07:55<02:25,  1.32s/it] 77%|███████▋  | 362/471 [07:57<02:24,  1.32s/it] 77%|███████▋  | 363/471 [07:58<02:22,  1.32s/it] 77%|███████▋  | 364/471 [07:59<02:21,  1.32s/it] 77%|███████▋  | 365/471 [08:01<02:20,  1.32s/it] 78%|███████▊  | 366/471 [08:02<02:19,  1.32s/it] 78%|███████▊  | 367/471 [08:03<02:17,  1.33s/it] 78%|███████▊  | 368/471 [08:05<02:16,  1.33s/it] 78%|███████▊  | 369/471 [08:06<02:14,  1.32s/it] 79%|███████▊  | 370/471 [08:07<02:13,  1.32s/it] 79%|███████▉  | 371/471 [08:09<02:12,  1.33s/it] 79%|███████▉  | 372/471 [08:10<02:11,  1.33s/it] 79%|███████▉  | 373/471 [08:11<02:10,  1.33s/it] 79%|███████▉  | 374/471 [08:12<02:08,  1.33s/it] 80%|███████▉  | 375/471 [08:14<02:07,  1.32s/it] 80%|███████▉  | 376/471 [08:15<02:05,  1.32s/it] 80%|████████  | 377/471 [08:16<02:04,  1.32s/it] 80%|████████  | 378/471 [08:18<02:03,  1.32s/it] 80%|████████  | 379/471 [08:19<02:01,  1.33s/it] 81%|████████  | 380/471 [08:20<02:00,  1.33s/it] 81%|████████  | 381/471 [08:22<01:59,  1.33s/it] 81%|████████  | 382/471 [08:23<01:58,  1.33s/it] 81%|████████▏ | 383/471 [08:24<01:56,  1.33s/it] 82%|████████▏ | 384/471 [08:26<01:55,  1.33s/it] 82%|████████▏ | 385/471 [08:27<01:54,  1.33s/it] 82%|████████▏ | 386/471 [08:28<01:52,  1.33s/it] 82%|████████▏ | 387/471 [08:30<01:51,  1.33s/it] 82%|████████▏ | 388/471 [08:31<01:50,  1.33s/it] 83%|████████▎ | 389/471 [08:32<01:48,  1.33s/it] 83%|████████▎ | 390/471 [08:34<01:47,  1.33s/it] 83%|████████▎ | 391/471 [08:35<01:46,  1.33s/it] 83%|████████▎ | 392/471 [08:36<01:45,  1.33s/it] 83%|████████▎ | 393/471 [08:38<01:43,  1.33s/it] 84%|████████▎ | 394/471 [08:39<01:42,  1.33s/it] 84%|████████▍ | 395/471 [08:40<01:41,  1.33s/it] 84%|████████▍ | 396/471 [08:42<01:39,  1.33s/it] 84%|████████▍ | 397/471 [08:43<01:38,  1.33s/it] 85%|████████▍ | 398/471 [08:44<01:37,  1.33s/it] 85%|████████▍ | 399/471 [08:46<01:36,  1.33s/it] 85%|████████▍ | 400/471 [08:47<01:34,  1.33s/it] 85%|████████▌ | 401/471 [08:48<01:33,  1.33s/it] 85%|████████▌ | 402/471 [08:50<01:31,  1.33s/it] 86%|████████▌ | 403/471 [08:51<01:30,  1.33s/it] 86%|████████▌ | 404/471 [08:52<01:29,  1.33s/it] 86%|████████▌ | 405/471 [08:54<01:28,  1.33s/it] 86%|████████▌ | 406/471 [08:55<01:26,  1.33s/it] 86%|████████▋ | 407/471 [08:56<01:25,  1.33s/it] 87%|████████▋ | 408/471 [08:58<01:24,  1.33s/it] 87%|████████▋ | 409/471 [08:59<01:22,  1.34s/it] 87%|████████▋ | 410/471 [09:00<01:21,  1.33s/it] 87%|████████▋ | 411/471 [09:02<01:19,  1.33s/it] 87%|████████▋ | 412/471 [09:03<01:18,  1.33s/it] 88%|████████▊ | 413/471 [09:04<01:17,  1.34s/it] 88%|████████▊ | 414/471 [09:06<01:16,  1.34s/it] 88%|████████▊ | 415/471 [09:07<01:14,  1.33s/it] 88%|████████▊ | 416/471 [09:08<01:13,  1.34s/it] 89%|████████▊ | 417/471 [09:10<01:12,  1.34s/it] 89%|████████▊ | 418/471 [09:11<01:10,  1.34s/it] 89%|████████▉ | 419/471 [09:12<01:09,  1.34s/it] 89%|████████▉ | 420/471 [09:14<01:08,  1.34s/it] 89%|████████▉ | 421/471 [09:15<01:06,  1.34s/it] 90%|████████▉ | 422/471 [09:16<01:05,  1.34s/it] 90%|████████▉ | 423/471 [09:18<01:04,  1.33s/it] 90%|█████████ | 424/471 [09:19<01:02,  1.34s/it] 90%|█████████ | 425/471 [09:20<01:01,  1.33s/it] 90%|█████████ | 426/471 [09:22<01:00,  1.34s/it] 91%|█████████ | 427/471 [09:23<00:58,  1.34s/it] 91%|█████████ | 428/471 [09:24<00:57,  1.34s/it] 91%|█████████ | 429/471 [09:26<00:56,  1.34s/it] 91%|█████████▏| 430/471 [09:27<00:54,  1.34s/it] 92%|█████████▏| 431/471 [09:28<00:53,  1.34s/it] 92%|█████████▏| 432/471 [09:30<00:52,  1.34s/it] 92%|█████████▏| 433/471 [09:31<00:50,  1.34s/it] 92%|█████████▏| 434/471 [09:32<00:49,  1.34s/it] 92%|█████████▏| 435/471 [09:34<00:48,  1.34s/it] 93%|█████████▎| 436/471 [09:35<00:46,  1.34s/it] 93%|█████████▎| 437/471 [09:36<00:45,  1.34s/it] 93%|█████████▎| 438/471 [09:38<00:44,  1.34s/it] 93%|█████████▎| 439/471 [09:39<00:42,  1.34s/it] 93%|█████████▎| 440/471 [09:40<00:41,  1.34s/it] 94%|█████████▎| 441/471 [09:42<00:40,  1.34s/it] 94%|█████████▍| 442/471 [09:43<00:38,  1.33s/it] 94%|█████████▍| 443/471 [09:44<00:37,  1.33s/it] 94%|█████████▍| 444/471 [09:46<00:36,  1.34s/it] 94%|█████████▍| 445/471 [09:47<00:34,  1.34s/it] 95%|█████████▍| 446/471 [09:49<00:33,  1.34s/it] 95%|█████████▍| 447/471 [09:50<00:32,  1.34s/it] 95%|█████████▌| 448/471 [09:51<00:30,  1.33s/it] 95%|█████████▌| 449/471 [09:53<00:29,  1.33s/it] 96%|█████████▌| 450/471 [09:54<00:28,  1.34s/it] 96%|█████████▌| 451/471 [09:55<00:26,  1.33s/it] 96%|█████████▌| 452/471 [09:57<00:25,  1.33s/it] 96%|█████████▌| 453/471 [09:58<00:24,  1.34s/it] 96%|█████████▋| 454/471 [09:59<00:22,  1.34s/it] 97%|█████████▋| 455/471 [10:01<00:21,  1.34s/it] 97%|█████████▋| 456/471 [10:02<00:20,  1.34s/it] 97%|█████████▋| 457/471 [10:03<00:18,  1.34s/it] 97%|█████████▋| 458/471 [10:05<00:17,  1.34s/it] 97%|█████████▋| 459/471 [10:06<00:16,  1.34s/it] 98%|█████████▊| 460/471 [10:07<00:14,  1.34s/it] 98%|█████████▊| 461/471 [10:09<00:13,  1.34s/it] 98%|█████████▊| 462/471 [10:10<00:12,  1.34s/it] 98%|█████████▊| 463/471 [10:11<00:10,  1.34s/it] 99%|█████████▊| 464/471 [10:13<00:09,  1.34s/it] 99%|█████████▊| 465/471 [10:14<00:08,  1.33s/it] 99%|█████████▉| 466/471 [10:15<00:06,  1.33s/it] 99%|█████████▉| 467/471 [10:17<00:05,  1.34s/it] 99%|█████████▉| 468/471 [10:18<00:04,  1.33s/it]100%|█████████▉| 469/471 [10:19<00:02,  1.33s/it]100%|█████████▉| 470/471 [10:21<00:01,  1.33s/it]100%|██████████| 471/471 [10:22<00:00,  1.22s/it]100%|██████████| 471/471 [10:22<00:00,  1.32s/it]
{'eval_loss': 4.969352722167969, 'eval_model_preparation_time': 0.0159, 'eval_acc': 0.12838555496548062, 'eval_runtime': 623.2449, 'eval_samples_per_second': 12.085, 'eval_steps_per_second': 0.756}
ROUND:3
CLIENT:17
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:43,  2.66s/it]                                              {'loss': 4.9146, 'grad_norm': 5.953012466430664, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:43,  2.66s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 5.5026, 'grad_norm': 4.70102071762085, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:07<01:24,  2.28s/it]                                              {'loss': 4.2152, 'grad_norm': 4.619091510772705, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:21,  2.25s/it]                                              {'loss': 4.1731, 'grad_norm': 3.983863592147827, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 2.928, 'grad_norm': 10.506688117980957, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 5.2495, 'grad_norm': 7.163984298706055, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 3.4657, 'grad_norm': 49.19297790527344, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 8.4555, 'grad_norm': 40.785221099853516, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:53,  1.74s/it]                                              {'loss': 3.7281, 'grad_norm': 6.444386959075928, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:53,  1.74s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.87s/it]                                               {'loss': 1.0041, 'grad_norm': 4.135403633117676, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.87s/it] 28%|██▊       | 11/40 [00:22<00:56,  1.96s/it]                                               {'loss': 2.2389, 'grad_norm': 5.457983493804932, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:56,  1.96s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 1.1883, 'grad_norm': 3.902395486831665, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 1.9771, 'grad_norm': 5.620763778686523, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 1.4751, 'grad_norm': 7.717784881591797, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 2.6489, 'grad_norm': 12.042222023010254, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0039, 'grad_norm': 0.13758006691932678, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.686, 'grad_norm': 3.362009048461914, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.5919, 'grad_norm': 3.6220686435699463, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it]                                               {'loss': 1.2427, 'grad_norm': 5.13784646987915, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it] 50%|█████     | 20/40 [00:40<00:42,  2.12s/it]                                               {'loss': 1.1337, 'grad_norm': 4.382425785064697, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:42<00:41,  2.16s/it]                                               {'loss': 0.3934, 'grad_norm': 6.2892985343933105, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:41,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it]                                               {'loss': 0.6037, 'grad_norm': 5.770501136779785, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.8123, 'grad_norm': 3.664191961288452, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.082, 'grad_norm': 2.959437608718872, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.3845, 'grad_norm': 3.7750015258789062, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.1957, 'grad_norm': 2.498056173324585, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it]                                               {'loss': 0.2001, 'grad_norm': 2.167724132537842, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.9791, 'grad_norm': 4.492718696594238, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.2104, 'grad_norm': 1.9607467651367188, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.2243, 'grad_norm': 3.7026164531707764, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.4503, 'grad_norm': 4.818995952606201, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.5642, 'grad_norm': 14.885709762573242, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0563, 'grad_norm': 0.7775865197181702, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.043, 'grad_norm': 0.5260621309280396, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.3319, 'grad_norm': 7.054708957672119, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.6775, 'grad_norm': 5.016897678375244, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.5613, 'grad_norm': 5.4402875900268555, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.132, 'grad_norm': 2.3660216331481934, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.0818, 'grad_norm': 1.4386217594146729, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.1084, 'grad_norm': 6.186437129974365, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.8979, 'train_samples_per_second': 7.072, 'train_steps_per_second': 0.501, 'train_loss': 1.597877654118929, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  2.00s/it]
CLIENT:33
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]                                              {'loss': 5.5828, 'grad_norm': 4.809755802154541, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]                                              {'loss': 5.3223, 'grad_norm': 7.1851019859313965, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]  8%|▊         | 3/40 [00:06<01:22,  2.24s/it]                                              {'loss': 3.365, 'grad_norm': 5.421156406402588, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.24s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 4.3186, 'grad_norm': 5.903650760650635, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it]                                              {'loss': 4.0994, 'grad_norm': 6.176994323730469, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 3.2817, 'grad_norm': 9.478974342346191, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 3.5506, 'grad_norm': 6.40943717956543, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 1.9485, 'grad_norm': 19.23164939880371, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 1.467, 'grad_norm': 4.05549430847168, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.3812, 'grad_norm': 9.365968704223633, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.8503, 'grad_norm': 5.948389053344727, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 2.2164, 'grad_norm': 7.927413463592529, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 1.7602, 'grad_norm': 9.127504348754883, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 1.3543, 'grad_norm': 5.625726222991943, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 2.0996, 'grad_norm': 7.795157432556152, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 3.3461, 'grad_norm': 31.569133758544922, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it]                                               {'loss': 0.4251, 'grad_norm': 4.290396690368652, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it]                                               {'loss': 0.7456, 'grad_norm': 8.284794807434082, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.9352, 'grad_norm': 4.570397853851318, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:42,  2.11s/it]                                               {'loss': 1.0114, 'grad_norm': 6.9439239501953125, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it]                                               {'loss': 1.1718, 'grad_norm': 13.70647144317627, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 0.939, 'grad_norm': 7.448524475097656, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 1.4835, 'grad_norm': 63.78450012207031, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.4488, 'grad_norm': 7.248723030090332, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it]                                               {'loss': 0.2615, 'grad_norm': 3.1720423698425293, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.6499, 'grad_norm': 4.869752407073975, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.57, 'grad_norm': 16.79768943786621, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.4782, 'grad_norm': 6.6953864097595215, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.17s/it]                                               {'loss': 0.4044, 'grad_norm': 3.4125189781188965, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.6596, 'grad_norm': 4.7756476402282715, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.5632, 'grad_norm': 6.374511241912842, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:03<00:13,  1.63s/it]                                               {'loss': 0.8936, 'grad_norm': 22.505329132080078, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.2903, 'grad_norm': 7.468845367431641, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.3664, 'grad_norm': 6.259824275970459, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.08s/it]                                               {'loss': 0.1525, 'grad_norm': 2.2112975120544434, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.5129, 'grad_norm': 4.402368068695068, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.3271, 'grad_norm': 2.939791440963745, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.8938, 'grad_norm': 7.537860870361328, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.2664, 'grad_norm': 4.223560333251953, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.0211, 'grad_norm': 1.0877035856246948, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 80.3115, 'train_samples_per_second': 7.035, 'train_steps_per_second': 0.498, 'train_loss': 1.5353786373045295, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:76
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:43,  2.67s/it]                                              {'loss': 6.1029, 'grad_norm': 3.686455488204956, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:43,  2.67s/it]  5%|▌         | 2/40 [00:04<01:29,  2.37s/it]                                              {'loss': 4.0053, 'grad_norm': 4.184050559997559, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.37s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 4.7613, 'grad_norm': 5.412094593048096, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 5.5291, 'grad_norm': 5.633073806762695, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 2.4131, 'grad_norm': 4.166060447692871, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 3.1974, 'grad_norm': 11.596076965332031, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 3.1686, 'grad_norm': 14.51418399810791, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 5.6395, 'grad_norm': 32.943817138671875, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 1.1901, 'grad_norm': 4.552059173583984, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 1.4772, 'grad_norm': 4.788980484008789, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 1.1402, 'grad_norm': 4.685093402862549, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 1.1647, 'grad_norm': 5.709689140319824, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it]                                               {'loss': 1.2776, 'grad_norm': 6.308019161224365, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.12s/it]                                               {'loss': 1.076, 'grad_norm': 21.86158561706543, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it]                                               {'loss': 1.9295, 'grad_norm': 10.813307762145996, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 1.5983, 'grad_norm': 23.81805419921875, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.2964, 'grad_norm': 3.2832016944885254, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.5158, 'grad_norm': 6.2642998695373535, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.1663, 'grad_norm': 2.033550500869751, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.871, 'grad_norm': 8.876797676086426, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.2592, 'grad_norm': 3.445833444595337, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 0.8568, 'grad_norm': 8.305587768554688, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.15s/it]                                               {'loss': 1.3827, 'grad_norm': 6.153573989868164, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.15s/it] 60%|██████    | 24/40 [00:47<00:24,  1.56s/it]                                               {'loss': 0.5711, 'grad_norm': 8.344657897949219, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:24,  1.56s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.76s/it]                                               {'loss': 0.2663, 'grad_norm': 2.5451176166534424, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.76s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.0721, 'grad_norm': 0.8164482116699219, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it]                                               {'loss': 0.2263, 'grad_norm': 3.3913707733154297, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it] 70%|███████   | 28/40 [00:56<00:25,  2.08s/it]                                               {'loss': 0.3829, 'grad_norm': 6.553041934967041, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.3822, 'grad_norm': 5.488393306732178, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.2648, 'grad_norm': 2.8974270820617676, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it]                                               {'loss': 0.8441, 'grad_norm': 6.53265905380249, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0407, 'grad_norm': 2.506523370742798, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.77s/it]                                               {'loss': 0.03, 'grad_norm': 0.5334842205047607, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.77s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it]                                               {'loss': 0.4959, 'grad_norm': 16.65367889404297, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.5191, 'grad_norm': 34.73448944091797, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.0312, 'grad_norm': 1.0479989051818848, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.1677, 'grad_norm': 2.6341066360473633, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.2947, 'grad_norm': 3.133524179458618, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.0862, 'grad_norm': 1.307633638381958, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0321, 'grad_norm': 2.5628225803375244, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.3356, 'train_samples_per_second': 7.122, 'train_steps_per_second': 0.504, 'train_loss': 1.3681587369646877, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:3
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:31,  2.33s/it]                                              {'loss': 4.5292, 'grad_norm': 8.105956077575684, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:31,  2.33s/it]  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]                                              {'loss': 3.5518, 'grad_norm': 3.3995304107666016, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]  8%|▊         | 3/40 [00:06<01:20,  2.17s/it]                                              {'loss': 4.6464, 'grad_norm': 5.81845760345459, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.17s/it] 10%|█         | 4/40 [00:08<01:18,  2.18s/it]                                              {'loss': 4.8469, 'grad_norm': 4.6788787841796875, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.18s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it]                                              {'loss': 4.7298, 'grad_norm': 15.191339492797852, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 4.3568, 'grad_norm': 6.636778354644775, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.18s/it]                                              {'loss': 4.5528, 'grad_norm': 7.094780921936035, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 5.7744, 'grad_norm': 15.551178932189941, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 2.3077, 'grad_norm': 6.815664291381836, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:19<00:57,  1.90s/it]                                               {'loss': 1.6193, 'grad_norm': 10.847872734069824, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 2.2363, 'grad_norm': 6.205062389373779, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.0808, 'grad_norm': 7.397125244140625, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it]                                               {'loss': 1.597, 'grad_norm': 5.228760719299316, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 1.2024, 'grad_norm': 7.248918533325195, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.16s/it]                                               {'loss': 1.769, 'grad_norm': 6.503958225250244, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 3.3557, 'grad_norm': 26.628049850463867, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.9282, 'grad_norm': 4.421144962310791, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.5833, 'grad_norm': 4.404721260070801, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it]                                               {'loss': 0.4645, 'grad_norm': 3.2733981609344482, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it] 50%|█████     | 20/40 [00:40<00:42,  2.12s/it]                                               {'loss': 1.2646, 'grad_norm': 8.002809524536133, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it]                                               {'loss': 0.4553, 'grad_norm': 7.923170566558838, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.20s/it]                                               {'loss': 0.5791, 'grad_norm': 13.320377349853516, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.8834, 'grad_norm': 8.447023391723633, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0231, 'grad_norm': 0.7506685256958008, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it]                                               {'loss': 0.3538, 'grad_norm': 4.886775493621826, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.95s/it]                                               {'loss': 0.1475, 'grad_norm': 2.0678141117095947, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.1632, 'grad_norm': 2.945899486541748, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.8748, 'grad_norm': 4.9005208015441895, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.1057, 'grad_norm': 1.8443106412887573, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.1713, 'grad_norm': 2.1196796894073486, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.3195, 'grad_norm': 3.505035877227783, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.0165, 'grad_norm': 0.8996084928512573, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.83s/it]                                               {'loss': 0.1015, 'grad_norm': 1.715294599533081, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.83s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.0419, 'grad_norm': 0.9011936783790588, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it]                                               {'loss': 0.0983, 'grad_norm': 2.673511266708374, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.15s/it]                                               {'loss': 0.1373, 'grad_norm': 2.8895633220672607, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.20s/it]                                               {'loss': 0.9437, 'grad_norm': 4.89768648147583, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.20s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it]                                               {'loss': 0.922, 'grad_norm': 7.393387317657471, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.25s/it]                                               {'loss': 0.1184, 'grad_norm': 1.9201990365982056, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.25s/it]100%|██████████| 40/40 [01:19<00:00,  1.63s/it]                                               {'loss': 0.9191, 'grad_norm': 21.123388290405273, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.63s/it]                                               {'train_runtime': 80.029, 'train_samples_per_second': 7.06, 'train_steps_per_second': 0.5, 'train_loss': 1.5693111596163363, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:56
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:31,  2.34s/it]                                              {'loss': 6.5479, 'grad_norm': 3.988513231277466, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:31,  2.34s/it]  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]                                              {'loss': 3.816, 'grad_norm': 5.287072658538818, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 4.4707, 'grad_norm': 6.679104804992676, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 5.4022, 'grad_norm': 4.7628583908081055, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 3.9505, 'grad_norm': 7.038157939910889, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it]                                              {'loss': 3.763, 'grad_norm': 19.296903610229492, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 4.5215, 'grad_norm': 22.16368865966797, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 5.8996, 'grad_norm': 35.24007797241211, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 2.8377, 'grad_norm': 12.327688217163086, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 2.4247, 'grad_norm': 23.994831085205078, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.04s/it]                                               {'loss': 2.3022, 'grad_norm': 8.094712257385254, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.04s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 1.8836, 'grad_norm': 11.183682441711426, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 3.358, 'grad_norm': 12.581900596618652, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 1.9782, 'grad_norm': 10.175607681274414, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it]                                               {'loss': 1.0425, 'grad_norm': 16.771244049072266, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 5.6947, 'grad_norm': 32.01359176635742, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.8721, 'grad_norm': 6.468369483947754, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 1.3216, 'grad_norm': 11.412463188171387, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 1.145, 'grad_norm': 27.9250431060791, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:42,  2.11s/it]                                               {'loss': 1.7886, 'grad_norm': 11.270801544189453, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.16s/it]                                               {'loss': 1.064, 'grad_norm': 14.124927520751953, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 1.7664, 'grad_norm': 13.780540466308594, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 1.9914, 'grad_norm': 5.407830715179443, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.1511, 'grad_norm': 4.237805366516113, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it]                                               {'loss': 1.0397, 'grad_norm': 7.885918617248535, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.8474, 'grad_norm': 13.780447959899902, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 1.0506, 'grad_norm': 5.702760219573975, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.12s/it]                                               {'loss': 0.4093, 'grad_norm': 3.5845634937286377, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.5949, 'grad_norm': 4.930722713470459, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.22s/it]                                               {'loss': 0.6269, 'grad_norm': 5.585869789123535, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.22s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it]                                               {'loss': 0.4292, 'grad_norm': 5.668264389038086, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.6758, 'grad_norm': 28.025768280029297, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it]                                               {'loss': 0.3056, 'grad_norm': 6.023780822753906, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.4107, 'grad_norm': 6.278816223144531, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it]                                               {'loss': 0.7412, 'grad_norm': 24.40114974975586, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it]                                               {'loss': 0.8788, 'grad_norm': 28.033700942993164, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it]                                               {'loss': 0.3856, 'grad_norm': 5.91846227645874, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it]                                               {'loss': 0.916, 'grad_norm': 7.997293949127197, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]                                               {'loss': 0.1863, 'grad_norm': 2.4673376083374023, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.0462, 'grad_norm': 1.9372648000717163, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.6217, 'train_samples_per_second': 7.008, 'train_steps_per_second': 0.496, 'train_loss': 1.988435406796634, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:0
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:31,  2.34s/it]                                              {'loss': 4.6398, 'grad_norm': 4.157023906707764, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:31,  2.34s/it]  5%|▌         | 2/40 [00:04<01:24,  2.23s/it]                                              {'loss': 5.828, 'grad_norm': 6.260391712188721, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.23s/it]  8%|▊         | 3/40 [00:06<01:22,  2.24s/it]                                              {'loss': 4.4799, 'grad_norm': 4.514197826385498, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.24s/it] 10%|█         | 4/40 [00:08<01:19,  2.22s/it]                                              {'loss': 5.0884, 'grad_norm': 5.1717424392700195, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.22s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it]                                              {'loss': 4.6891, 'grad_norm': 5.882157325744629, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 4.7253, 'grad_norm': 4.953007221221924, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 2.5027, 'grad_norm': 10.006328582763672, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 1.684, 'grad_norm': 34.07382583618164, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it]                                              {'loss': 1.6392, 'grad_norm': 7.18428373336792, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 2.3609, 'grad_norm': 11.651176452636719, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.8826, 'grad_norm': 7.401818752288818, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.8634, 'grad_norm': 7.539475440979004, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 1.4086, 'grad_norm': 4.866777420043945, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it]                                               {'loss': 2.4823, 'grad_norm': 15.34851360321045, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 1.4514, 'grad_norm': 6.634456157684326, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 6.2715, 'grad_norm': 27.228830337524414, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.5228, 'grad_norm': 3.8465418815612793, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it]                                               {'loss': 0.3931, 'grad_norm': 3.2648284435272217, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.5015, 'grad_norm': 6.199851989746094, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.6425, 'grad_norm': 4.337475299835205, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.5037, 'grad_norm': 2.811630964279175, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.9482, 'grad_norm': 5.874861240386963, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.3971, 'grad_norm': 5.799983024597168, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0043, 'grad_norm': 0.18292289972305298, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.1369, 'grad_norm': 2.1768875122070312, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.7276, 'grad_norm': 5.838130950927734, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.4069, 'grad_norm': 4.494266986846924, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.1428, 'grad_norm': 2.5604374408721924, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.2835, 'grad_norm': 4.045800685882568, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.3653, 'grad_norm': 3.594914197921753, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.3129, 'grad_norm': 2.9191086292266846, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0137, 'grad_norm': 0.8008465766906738, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0431, 'grad_norm': 0.5387760996818542, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it]                                               {'loss': 0.2257, 'grad_norm': 4.792057037353516, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it]                                               {'loss': 0.4582, 'grad_norm': 6.091647148132324, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.2082, 'grad_norm': 3.0434415340423584, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.1032, 'grad_norm': 2.5679850578308105, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.0673, 'grad_norm': 1.2960807085037231, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.0654, 'grad_norm': 1.2858426570892334, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0125, 'grad_norm': 0.8738762140274048, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.4537, 'train_samples_per_second': 7.111, 'train_steps_per_second': 0.503, 'train_loss': 1.5120896821841598, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:34,  2.43s/it]                                              {'loss': 5.4622, 'grad_norm': 4.508204460144043, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:34,  2.43s/it]  5%|▌         | 2/40 [00:04<01:27,  2.30s/it]                                              {'loss': 5.2784, 'grad_norm': 4.45720911026001, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:27,  2.30s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 3.0081, 'grad_norm': 4.733510494232178, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 3.5171, 'grad_norm': 5.851690292358398, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 2.9453, 'grad_norm': 6.715662002563477, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 5.0696, 'grad_norm': 8.472896575927734, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 4.1885, 'grad_norm': 5.41018009185791, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 0.4234, 'grad_norm': 9.311017990112305, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 1.8912, 'grad_norm': 4.372365951538086, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.9681, 'grad_norm': 6.907299518585205, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.9179, 'grad_norm': 6.435256481170654, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 1.2886, 'grad_norm': 3.741675615310669, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 1.9423, 'grad_norm': 6.278252124786377, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 1.6534, 'grad_norm': 4.459719181060791, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it]                                               {'loss': 1.4535, 'grad_norm': 5.416222095489502, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.3089, 'grad_norm': 11.199609756469727, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.4253, 'grad_norm': 2.8736824989318848, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.91s/it]                                               {'loss': 0.2021, 'grad_norm': 3.170534610748291, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.537, 'grad_norm': 7.923028945922852, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.4698, 'grad_norm': 2.6221671104431152, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.3836, 'grad_norm': 3.0724828243255615, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it]                                               {'loss': 0.5078, 'grad_norm': 5.150818347930908, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 1.3332, 'grad_norm': 10.995867729187012, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.2384, 'grad_norm': 9.767165184020996, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it]                                               {'loss': 1.0551, 'grad_norm': 79.53215789794922, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.1659, 'grad_norm': 2.2298245429992676, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.8752, 'grad_norm': 9.342331886291504, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.574, 'grad_norm': 8.279577255249023, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.8398, 'grad_norm': 12.510954856872559, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it]                                               {'loss': 0.28, 'grad_norm': 3.854985475540161, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it]                                               {'loss': 0.6845, 'grad_norm': 10.375387191772461, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.0798, 'grad_norm': 4.875393390655518, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it]                                               {'loss': 0.1638, 'grad_norm': 4.1428446769714355, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it]                                               {'loss': 0.397, 'grad_norm': 7.176370620727539, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.6838, 'grad_norm': 5.332475185394287, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.1398, 'grad_norm': 10.355680465698242, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.2642, 'grad_norm': 5.582089424133301, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.3326, 'grad_norm': 2.851006507873535, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.9023, 'grad_norm': 113.27727508544922, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0034, 'grad_norm': 0.1115080788731575, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.061, 'train_samples_per_second': 7.057, 'train_steps_per_second': 0.5, 'train_loss': 1.3213767619512509, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:8
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:45,  2.70s/it]                                              {'loss': 2.9772, 'grad_norm': 3.54294490814209, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:45,  2.70s/it]  5%|▌         | 2/40 [00:04<01:31,  2.41s/it]                                              {'loss': 4.3586, 'grad_norm': 5.582708358764648, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:31,  2.41s/it]  8%|▊         | 3/40 [00:07<01:25,  2.30s/it]                                              {'loss': 3.1909, 'grad_norm': 7.880490779876709, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.30s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 5.6219, 'grad_norm': 6.937506675720215, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 4.3864, 'grad_norm': 12.43026351928711, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 3.6075, 'grad_norm': 6.162353992462158, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 3.1962, 'grad_norm': 7.54836893081665, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 3.2748, 'grad_norm': 23.172779083251953, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 1.1199, 'grad_norm': 4.8929266929626465, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 1.946, 'grad_norm': 9.994384765625, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.3812, 'grad_norm': 5.644271373748779, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 2.174, 'grad_norm': 7.767332553863525, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 1.5213, 'grad_norm': 6.210933685302734, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it]                                               {'loss': 2.4854, 'grad_norm': 10.621895790100098, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 1.5559, 'grad_norm': 5.015031337738037, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 1.5581, 'grad_norm': 13.559165000915527, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it]                                               {'loss': 0.8428, 'grad_norm': 3.6937735080718994, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it]                                               {'loss': 1.0268, 'grad_norm': 25.084793090820312, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 1.2285, 'grad_norm': 4.047935962677002, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:42,  2.10s/it]                                               {'loss': 0.6699, 'grad_norm': 3.699082851409912, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 0.5339, 'grad_norm': 5.15648078918457, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.578, 'grad_norm': 4.160114765167236, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.8062, 'grad_norm': 7.865499973297119, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.2225, 'grad_norm': 4.715015888214111, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it]                                               {'loss': 0.4429, 'grad_norm': 5.251908779144287, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it]                                               {'loss': 0.1668, 'grad_norm': 3.3223376274108887, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.3572, 'grad_norm': 3.703524112701416, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.559, 'grad_norm': 3.189586877822876, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it]                                               {'loss': 0.4982, 'grad_norm': 3.627218723297119, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.5357, 'grad_norm': 10.907437324523926, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.3881, 'grad_norm': 26.770893096923828, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0922, 'grad_norm': 3.4662744998931885, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.79s/it]                                               {'loss': 0.2432, 'grad_norm': 3.5940754413604736, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.1021, 'grad_norm': 3.4662177562713623, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.188, 'grad_norm': 3.264091730117798, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it]                                               {'loss': 0.1435, 'grad_norm': 3.972975730895996, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.413, 'grad_norm': 7.661561489105225, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.4413, 'grad_norm': 5.739357948303223, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.1384, 'grad_norm': 2.4153177738189697, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.5935, 'grad_norm': 29.9361515045166, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 80.2405, 'train_samples_per_second': 7.041, 'train_steps_per_second': 0.499, 'train_loss': 1.389171516150236, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.60s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:60
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:45,  2.71s/it]                                              {'loss': 6.0886, 'grad_norm': 4.899038314819336, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:45,  2.71s/it]  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]                                              {'loss': 5.1762, 'grad_norm': 4.428970813751221, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]  8%|▊         | 3/40 [00:07<01:24,  2.30s/it]                                              {'loss': 4.9479, 'grad_norm': 3.6690473556518555, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.30s/it] 10%|█         | 4/40 [00:09<01:20,  2.25s/it]                                              {'loss': 5.1942, 'grad_norm': 4.3472580909729, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 4.1836, 'grad_norm': 6.446130275726318, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 3.7845, 'grad_norm': 6.042128086090088, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 3.12, 'grad_norm': 6.318183422088623, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 6.8078, 'grad_norm': 36.16322326660156, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 2.2079, 'grad_norm': 7.409035682678223, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it]                                               {'loss': 2.4298, 'grad_norm': 5.564237117767334, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.9139, 'grad_norm': 4.794466972351074, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 2.3223, 'grad_norm': 6.998692989349365, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 1.6389, 'grad_norm': 6.369255542755127, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it]                                               {'loss': 1.6283, 'grad_norm': 8.404594421386719, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it]                                               {'loss': 2.1939, 'grad_norm': 14.20673942565918, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 5.6728, 'grad_norm': 23.38793182373047, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.4412, 'grad_norm': 3.7324576377868652, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:43,  2.00s/it]                                               {'loss': 0.7019, 'grad_norm': 4.154843330383301, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  2.00s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.07s/it]                                               {'loss': 0.5576, 'grad_norm': 4.944749355316162, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.07s/it] 50%|█████     | 20/40 [00:40<00:42,  2.13s/it]                                               {'loss': 0.4475, 'grad_norm': 5.379932880401611, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.13s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 0.759, 'grad_norm': 6.903368949890137, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.7914, 'grad_norm': 6.252771854400635, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.6013, 'grad_norm': 4.536391735076904, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 1.178, 'grad_norm': 27.866533279418945, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it]                                               {'loss': 0.0674, 'grad_norm': 0.8902145624160767, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.116, 'grad_norm': 1.424328327178955, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.2298, 'grad_norm': 2.8792104721069336, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.0487, 'grad_norm': 0.6330288052558899, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it]                                               {'loss': 0.051, 'grad_norm': 0.6361891031265259, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.2758, 'grad_norm': 1.3916661739349365, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.22s/it]                                               {'loss': 0.2073, 'grad_norm': 3.0826504230499268, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.0057, 'grad_norm': 0.2499600350856781, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.0149, 'grad_norm': 0.49238458275794983, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it]                                               {'loss': 0.0592, 'grad_norm': 1.910586953163147, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.4965, 'grad_norm': 2.7565863132476807, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it]                                               {'loss': 0.0232, 'grad_norm': 0.5640352368354797, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.0611, 'grad_norm': 2.247478485107422, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it]                                               {'loss': 0.0257, 'grad_norm': 0.8111262917518616, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]                                               {'loss': 0.3077, 'grad_norm': 3.5030648708343506, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.1202, 'grad_norm': 5.578813552856445, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.6882, 'train_samples_per_second': 7.002, 'train_steps_per_second': 0.496, 'train_loss': 1.647461541404482, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:67
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:45,  2.71s/it]                                              {'loss': 4.8852, 'grad_norm': 4.250006675720215, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:45,  2.71s/it]  5%|▌         | 2/40 [00:04<01:30,  2.38s/it]                                              {'loss': 3.5456, 'grad_norm': 4.420639514923096, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.38s/it]  8%|▊         | 3/40 [00:07<01:24,  2.30s/it]                                              {'loss': 3.3137, 'grad_norm': 4.162298202514648, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.30s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 5.4019, 'grad_norm': 9.318785667419434, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 4.409, 'grad_norm': 9.095479965209961, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 4.5767, 'grad_norm': 16.562023162841797, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 3.8157, 'grad_norm': 23.19463539123535, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 9.2806, 'grad_norm': 43.5184440612793, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 2.3302, 'grad_norm': 12.139962196350098, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 2.1943, 'grad_norm': 20.7019100189209, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 1.9235, 'grad_norm': 16.33099937438965, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 1.4951, 'grad_norm': 13.963410377502441, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it]                                               {'loss': 2.8728, 'grad_norm': 26.86817169189453, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it]                                               {'loss': 1.6518, 'grad_norm': 14.596656799316406, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 1.7269, 'grad_norm': 32.27702331542969, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 1.905, 'grad_norm': 105.71585083007812, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 2.2477, 'grad_norm': 15.68855094909668, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it]                                               {'loss': 1.3079, 'grad_norm': 7.514444828033447, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it]                                               {'loss': 1.051, 'grad_norm': 6.11769437789917, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 1.0009, 'grad_norm': 14.987896919250488, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.9641, 'grad_norm': 11.753973007202148, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.15s/it]                                               {'loss': 1.2093, 'grad_norm': 11.437505722045898, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.848, 'grad_norm': 6.722530364990234, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 1.2059, 'grad_norm': 62.72244644165039, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.4962, 'grad_norm': 15.264066696166992, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 1.945, 'grad_norm': 35.19479751586914, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.3576, 'grad_norm': 4.839412689208984, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.9056, 'grad_norm': 34.344844818115234, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.4177, 'grad_norm': 7.059004306793213, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.7028, 'grad_norm': 6.218295574188232, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.18s/it]                                               {'loss': 0.1733, 'grad_norm': 3.192194700241089, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.18s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 4.5738, 'grad_norm': 157.4617462158203, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it]                                               {'loss': 0.0713, 'grad_norm': 2.966010093688965, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.1303, 'grad_norm': 2.570713758468628, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.3462, 'grad_norm': 5.165091037750244, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.2296, 'grad_norm': 3.4495959281921387, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.2533, 'grad_norm': 3.226635456085205, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.5155, 'grad_norm': 4.163958549499512, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]                                               {'loss': 0.5717, 'grad_norm': 4.930491924285889, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'loss': 0.3578, 'grad_norm': 15.303418159484863, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'train_runtime': 79.6147, 'train_samples_per_second': 7.097, 'train_steps_per_second': 0.502, 'train_loss': 1.9302589008584619, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:54,  1.59it/s]  1%|          | 3/471 [00:02<06:55,  1.13it/s]  1%|          | 4/471 [00:03<08:00,  1.03s/it]  1%|          | 5/471 [00:05<08:37,  1.11s/it]  1%|▏         | 6/471 [00:06<09:00,  1.16s/it]  1%|▏         | 7/471 [00:07<09:14,  1.20s/it]  2%|▏         | 8/471 [00:08<09:24,  1.22s/it]  2%|▏         | 9/471 [00:10<09:30,  1.23s/it]  2%|▏         | 10/471 [00:11<09:34,  1.25s/it]  2%|▏         | 11/471 [00:12<09:36,  1.25s/it]  3%|▎         | 12/471 [00:13<09:38,  1.26s/it]  3%|▎         | 13/471 [00:15<09:40,  1.27s/it]  3%|▎         | 14/471 [00:16<09:40,  1.27s/it]  3%|▎         | 15/471 [00:17<09:40,  1.27s/it]  3%|▎         | 16/471 [00:19<09:40,  1.28s/it]  4%|▎         | 17/471 [00:20<09:39,  1.28s/it]  4%|▍         | 18/471 [00:21<09:39,  1.28s/it]  4%|▍         | 19/471 [00:22<09:38,  1.28s/it]  4%|▍         | 20/471 [00:24<09:38,  1.28s/it]  4%|▍         | 21/471 [00:25<09:37,  1.28s/it]  5%|▍         | 22/471 [00:26<09:37,  1.29s/it]  5%|▍         | 23/471 [00:28<09:35,  1.29s/it]  5%|▌         | 24/471 [00:29<09:35,  1.29s/it]  5%|▌         | 25/471 [00:30<09:33,  1.29s/it]  6%|▌         | 26/471 [00:31<09:32,  1.29s/it]  6%|▌         | 27/471 [00:33<09:32,  1.29s/it]  6%|▌         | 28/471 [00:34<09:31,  1.29s/it]  6%|▌         | 29/471 [00:35<09:29,  1.29s/it]  6%|▋         | 30/471 [00:37<09:29,  1.29s/it]  7%|▋         | 31/471 [00:38<09:28,  1.29s/it]  7%|▋         | 32/471 [00:39<09:26,  1.29s/it]  7%|▋         | 33/471 [00:40<09:24,  1.29s/it]  7%|▋         | 34/471 [00:42<09:23,  1.29s/it]  7%|▋         | 35/471 [00:43<09:23,  1.29s/it]  8%|▊         | 36/471 [00:44<09:22,  1.29s/it]  8%|▊         | 37/471 [00:46<09:22,  1.30s/it]  8%|▊         | 38/471 [00:47<09:21,  1.30s/it]  8%|▊         | 39/471 [00:48<09:19,  1.30s/it]  8%|▊         | 40/471 [00:50<09:18,  1.30s/it]  9%|▊         | 41/471 [00:51<09:17,  1.30s/it]  9%|▉         | 42/471 [00:52<09:16,  1.30s/it]  9%|▉         | 43/471 [00:53<09:14,  1.30s/it]  9%|▉         | 44/471 [00:55<09:13,  1.30s/it] 10%|▉         | 45/471 [00:56<09:12,  1.30s/it] 10%|▉         | 46/471 [00:57<09:11,  1.30s/it] 10%|▉         | 47/471 [00:59<09:10,  1.30s/it] 10%|█         | 48/471 [01:00<09:08,  1.30s/it] 10%|█         | 49/471 [01:01<09:08,  1.30s/it] 11%|█         | 50/471 [01:03<09:07,  1.30s/it] 11%|█         | 51/471 [01:04<09:06,  1.30s/it] 11%|█         | 52/471 [01:05<09:05,  1.30s/it] 11%|█▏        | 53/471 [01:06<09:04,  1.30s/it] 11%|█▏        | 54/471 [01:08<09:04,  1.30s/it] 12%|█▏        | 55/471 [01:09<09:02,  1.30s/it] 12%|█▏        | 56/471 [01:10<09:02,  1.31s/it] 12%|█▏        | 57/471 [01:12<09:00,  1.31s/it] 12%|█▏        | 58/471 [01:13<08:59,  1.31s/it] 13%|█▎        | 59/471 [01:14<08:58,  1.31s/it] 13%|█▎        | 60/471 [01:16<08:56,  1.31s/it] 13%|█▎        | 61/471 [01:17<08:55,  1.31s/it] 13%|█▎        | 62/471 [01:18<08:53,  1.31s/it] 13%|█▎        | 63/471 [01:19<08:52,  1.31s/it] 14%|█▎        | 64/471 [01:21<08:52,  1.31s/it] 14%|█▍        | 65/471 [01:22<08:50,  1.31s/it] 14%|█▍        | 66/471 [01:23<08:50,  1.31s/it] 14%|█▍        | 67/471 [01:25<08:49,  1.31s/it] 14%|█▍        | 68/471 [01:26<08:47,  1.31s/it] 15%|█▍        | 69/471 [01:27<08:46,  1.31s/it] 15%|█▍        | 70/471 [01:29<08:45,  1.31s/it] 15%|█▌        | 71/471 [01:30<08:44,  1.31s/it] 15%|█▌        | 72/471 [01:31<08:42,  1.31s/it] 15%|█▌        | 73/471 [01:33<08:41,  1.31s/it] 16%|█▌        | 74/471 [01:34<08:38,  1.31s/it] 16%|█▌        | 75/471 [01:35<08:38,  1.31s/it] 16%|█▌        | 76/471 [01:37<08:37,  1.31s/it] 16%|█▋        | 77/471 [01:38<08:36,  1.31s/it] 17%|█▋        | 78/471 [01:39<08:35,  1.31s/it] 17%|█▋        | 79/471 [01:40<08:34,  1.31s/it] 17%|█▋        | 80/471 [01:42<08:33,  1.31s/it] 17%|█▋        | 81/471 [01:43<08:31,  1.31s/it] 17%|█▋        | 82/471 [01:44<08:30,  1.31s/it] 18%|█▊        | 83/471 [01:46<08:29,  1.31s/it] 18%|█▊        | 84/471 [01:47<08:28,  1.31s/it] 18%|█▊        | 85/471 [01:48<08:27,  1.32s/it] 18%|█▊        | 86/471 [01:50<08:26,  1.32s/it] 18%|█▊        | 87/471 [01:51<08:25,  1.32s/it] 19%|█▊        | 88/471 [01:52<08:23,  1.32s/it] 19%|█▉        | 89/471 [01:54<08:22,  1.32s/it] 19%|█▉        | 90/471 [01:55<08:21,  1.32s/it] 19%|█▉        | 91/471 [01:56<08:19,  1.32s/it] 20%|█▉        | 92/471 [01:58<08:19,  1.32s/it] 20%|█▉        | 93/471 [01:59<08:18,  1.32s/it] 20%|█▉        | 94/471 [02:00<08:16,  1.32s/it] 20%|██        | 95/471 [02:02<08:15,  1.32s/it] 20%|██        | 96/471 [02:03<08:14,  1.32s/it] 21%|██        | 97/471 [02:04<08:14,  1.32s/it] 21%|██        | 98/471 [02:05<08:12,  1.32s/it] 21%|██        | 99/471 [02:07<08:11,  1.32s/it] 21%|██        | 100/471 [02:08<08:10,  1.32s/it] 21%|██▏       | 101/471 [02:09<08:08,  1.32s/it] 22%|██▏       | 102/471 [02:11<08:08,  1.32s/it] 22%|██▏       | 103/471 [02:12<08:07,  1.32s/it] 22%|██▏       | 104/471 [02:13<08:06,  1.33s/it] 22%|██▏       | 105/471 [02:15<08:05,  1.33s/it] 23%|██▎       | 106/471 [02:16<08:03,  1.33s/it] 23%|██▎       | 107/471 [02:17<08:02,  1.32s/it] 23%|██▎       | 108/471 [02:19<08:01,  1.33s/it] 23%|██▎       | 109/471 [02:20<07:59,  1.32s/it] 23%|██▎       | 110/471 [02:21<07:56,  1.32s/it] 24%|██▎       | 111/471 [02:23<07:56,  1.32s/it] 24%|██▍       | 112/471 [02:24<07:56,  1.33s/it] 24%|██▍       | 113/471 [02:25<07:54,  1.32s/it] 24%|██▍       | 114/471 [02:27<07:53,  1.33s/it] 24%|██▍       | 115/471 [02:28<07:52,  1.33s/it] 25%|██▍       | 116/471 [02:29<07:50,  1.33s/it] 25%|██▍       | 117/471 [02:31<07:49,  1.33s/it] 25%|██▌       | 118/471 [02:32<07:48,  1.33s/it] 25%|██▌       | 119/471 [02:33<07:46,  1.33s/it] 25%|██▌       | 120/471 [02:35<07:46,  1.33s/it] 26%|██▌       | 121/471 [02:36<07:45,  1.33s/it] 26%|██▌       | 122/471 [02:37<07:43,  1.33s/it] 26%|██▌       | 123/471 [02:39<07:42,  1.33s/it] 26%|██▋       | 124/471 [02:40<07:41,  1.33s/it] 27%|██▋       | 125/471 [02:41<07:40,  1.33s/it] 27%|██▋       | 126/471 [02:43<07:39,  1.33s/it] 27%|██▋       | 127/471 [02:44<07:38,  1.33s/it] 27%|██▋       | 128/471 [02:45<07:36,  1.33s/it] 27%|██▋       | 129/471 [02:47<07:34,  1.33s/it] 28%|██▊       | 130/471 [02:48<07:33,  1.33s/it] 28%|██▊       | 131/471 [02:49<07:32,  1.33s/it] 28%|██▊       | 132/471 [02:51<07:31,  1.33s/it] 28%|██▊       | 133/471 [02:52<07:30,  1.33s/it] 28%|██▊       | 134/471 [02:53<07:29,  1.33s/it] 29%|██▊       | 135/471 [02:55<07:28,  1.33s/it] 29%|██▉       | 136/471 [02:56<07:26,  1.33s/it] 29%|██▉       | 137/471 [02:57<07:25,  1.33s/it] 29%|██▉       | 138/471 [02:59<07:23,  1.33s/it] 30%|██▉       | 139/471 [03:00<07:22,  1.33s/it] 30%|██▉       | 140/471 [03:01<07:20,  1.33s/it] 30%|██▉       | 141/471 [03:03<07:19,  1.33s/it] 30%|███       | 142/471 [03:04<07:17,  1.33s/it] 30%|███       | 143/471 [03:05<07:15,  1.33s/it] 31%|███       | 144/471 [03:07<07:15,  1.33s/it] 31%|███       | 145/471 [03:08<07:13,  1.33s/it] 31%|███       | 146/471 [03:09<07:11,  1.33s/it] 31%|███       | 147/471 [03:11<07:10,  1.33s/it] 31%|███▏      | 148/471 [03:12<07:09,  1.33s/it] 32%|███▏      | 149/471 [03:13<07:08,  1.33s/it] 32%|███▏      | 150/471 [03:15<07:07,  1.33s/it] 32%|███▏      | 151/471 [03:16<07:05,  1.33s/it] 32%|███▏      | 152/471 [03:17<07:04,  1.33s/it] 32%|███▏      | 153/471 [03:19<07:02,  1.33s/it] 33%|███▎      | 154/471 [03:20<07:00,  1.33s/it] 33%|███▎      | 155/471 [03:21<06:59,  1.33s/it] 33%|███▎      | 156/471 [03:23<06:57,  1.33s/it] 33%|███▎      | 157/471 [03:24<06:56,  1.33s/it] 34%|███▎      | 158/471 [03:25<06:54,  1.32s/it] 34%|███▍      | 159/471 [03:26<06:52,  1.32s/it] 34%|███▍      | 160/471 [03:28<06:51,  1.32s/it] 34%|███▍      | 161/471 [03:29<06:50,  1.32s/it] 34%|███▍      | 162/471 [03:30<06:49,  1.32s/it] 35%|███▍      | 163/471 [03:32<06:48,  1.33s/it] 35%|███▍      | 164/471 [03:33<06:46,  1.32s/it] 35%|███▌      | 165/471 [03:34<06:45,  1.32s/it] 35%|███▌      | 166/471 [03:36<06:44,  1.33s/it] 35%|███▌      | 167/471 [03:37<06:43,  1.33s/it] 36%|███▌      | 168/471 [03:38<06:41,  1.33s/it] 36%|███▌      | 169/471 [03:40<06:41,  1.33s/it] 36%|███▌      | 170/471 [03:41<06:39,  1.33s/it] 36%|███▋      | 171/471 [03:42<06:37,  1.33s/it] 37%|███▋      | 172/471 [03:44<06:35,  1.32s/it] 37%|███▋      | 173/471 [03:45<06:34,  1.33s/it] 37%|███▋      | 174/471 [03:46<06:33,  1.33s/it] 37%|███▋      | 175/471 [03:48<06:32,  1.33s/it] 37%|███▋      | 176/471 [03:49<06:30,  1.32s/it] 38%|███▊      | 177/471 [03:50<06:29,  1.32s/it] 38%|███▊      | 178/471 [03:52<06:28,  1.32s/it] 38%|███▊      | 179/471 [03:53<06:26,  1.32s/it] 38%|███▊      | 180/471 [03:54<06:25,  1.32s/it] 38%|███▊      | 181/471 [03:56<06:24,  1.32s/it] 39%|███▊      | 182/471 [03:57<06:22,  1.32s/it] 39%|███▉      | 183/471 [03:58<06:21,  1.32s/it] 39%|███▉      | 184/471 [04:00<06:19,  1.32s/it] 39%|███▉      | 185/471 [04:01<06:18,  1.32s/it] 39%|███▉      | 186/471 [04:02<06:17,  1.32s/it] 40%|███▉      | 187/471 [04:04<06:16,  1.33s/it] 40%|███▉      | 188/471 [04:05<06:15,  1.33s/it] 40%|████      | 189/471 [04:06<06:13,  1.32s/it] 40%|████      | 190/471 [04:08<06:12,  1.32s/it] 41%|████      | 191/471 [04:09<06:11,  1.33s/it] 41%|████      | 192/471 [04:10<06:09,  1.32s/it] 41%|████      | 193/471 [04:12<06:07,  1.32s/it] 41%|████      | 194/471 [04:13<06:06,  1.32s/it] 41%|████▏     | 195/471 [04:14<06:05,  1.32s/it] 42%|████▏     | 196/471 [04:16<06:04,  1.32s/it] 42%|████▏     | 197/471 [04:17<06:02,  1.32s/it] 42%|████▏     | 198/471 [04:18<06:00,  1.32s/it] 42%|████▏     | 199/471 [04:19<05:59,  1.32s/it] 42%|████▏     | 200/471 [04:21<05:58,  1.32s/it] 43%|████▎     | 201/471 [04:22<05:56,  1.32s/it] 43%|████▎     | 202/471 [04:23<05:55,  1.32s/it] 43%|████▎     | 203/471 [04:25<05:54,  1.32s/it] 43%|████▎     | 204/471 [04:26<05:53,  1.32s/it] 44%|████▎     | 205/471 [04:27<05:51,  1.32s/it] 44%|████▎     | 206/471 [04:29<05:50,  1.32s/it] 44%|████▍     | 207/471 [04:30<05:49,  1.32s/it] 44%|████▍     | 208/471 [04:31<05:47,  1.32s/it] 44%|████▍     | 209/471 [04:33<05:45,  1.32s/it] 45%|████▍     | 210/471 [04:34<05:44,  1.32s/it] 45%|████▍     | 211/471 [04:35<05:43,  1.32s/it] 45%|████▌     | 212/471 [04:37<05:41,  1.32s/it] 45%|████▌     | 213/471 [04:38<05:40,  1.32s/it] 45%|████▌     | 214/471 [04:39<05:39,  1.32s/it] 46%|████▌     | 215/471 [04:41<05:38,  1.32s/it] 46%|████▌     | 216/471 [04:42<05:37,  1.32s/it] 46%|████▌     | 217/471 [04:43<05:36,  1.32s/it] 46%|████▋     | 218/471 [04:45<05:35,  1.32s/it] 46%|████▋     | 219/471 [04:46<05:33,  1.32s/it] 47%|████▋     | 220/471 [04:47<05:32,  1.32s/it] 47%|████▋     | 221/471 [04:49<05:31,  1.32s/it] 47%|████▋     | 222/471 [04:50<05:29,  1.32s/it] 47%|████▋     | 223/471 [04:51<05:27,  1.32s/it] 48%|████▊     | 224/471 [04:53<05:26,  1.32s/it] 48%|████▊     | 225/471 [04:54<05:25,  1.32s/it] 48%|████▊     | 226/471 [04:55<05:24,  1.32s/it] 48%|████▊     | 227/471 [04:56<05:22,  1.32s/it] 48%|████▊     | 228/471 [04:58<05:21,  1.32s/it] 49%|████▊     | 229/471 [04:59<05:20,  1.32s/it] 49%|████▉     | 230/471 [05:00<05:19,  1.32s/it] 49%|████▉     | 231/471 [05:02<05:17,  1.32s/it] 49%|████▉     | 232/471 [05:03<05:15,  1.32s/it] 49%|████▉     | 233/471 [05:04<05:14,  1.32s/it] 50%|████▉     | 234/471 [05:06<05:13,  1.32s/it] 50%|████▉     | 235/471 [05:07<05:12,  1.32s/it] 50%|█████     | 236/471 [05:08<05:10,  1.32s/it] 50%|█████     | 237/471 [05:10<05:08,  1.32s/it] 51%|█████     | 238/471 [05:11<05:07,  1.32s/it] 51%|█████     | 239/471 [05:12<05:06,  1.32s/it] 51%|█████     | 240/471 [05:14<05:05,  1.32s/it] 51%|█████     | 241/471 [05:15<05:04,  1.32s/it] 51%|█████▏    | 242/471 [05:16<05:02,  1.32s/it] 52%|█████▏    | 243/471 [05:18<05:01,  1.32s/it] 52%|█████▏    | 244/471 [05:19<05:00,  1.32s/it] 52%|█████▏    | 245/471 [05:20<04:59,  1.32s/it] 52%|█████▏    | 246/471 [05:22<04:57,  1.32s/it] 52%|█████▏    | 247/471 [05:23<04:56,  1.32s/it] 53%|█████▎    | 248/471 [05:24<04:54,  1.32s/it] 53%|█████▎    | 249/471 [05:26<04:53,  1.32s/it] 53%|█████▎    | 250/471 [05:27<04:51,  1.32s/it] 53%|█████▎    | 251/471 [05:28<04:50,  1.32s/it] 54%|█████▎    | 252/471 [05:30<04:48,  1.32s/it] 54%|█████▎    | 253/471 [05:31<04:47,  1.32s/it] 54%|█████▍    | 254/471 [05:32<04:46,  1.32s/it] 54%|█████▍    | 255/471 [05:33<04:44,  1.32s/it] 54%|█████▍    | 256/471 [05:35<04:43,  1.32s/it] 55%|█████▍    | 257/471 [05:36<04:42,  1.32s/it] 55%|█████▍    | 258/471 [05:37<04:41,  1.32s/it] 55%|█████▍    | 259/471 [05:39<04:39,  1.32s/it] 55%|█████▌    | 260/471 [05:40<04:38,  1.32s/it] 55%|█████▌    | 261/471 [05:41<04:36,  1.32s/it] 56%|█████▌    | 262/471 [05:43<04:35,  1.32s/it] 56%|█████▌    | 263/471 [05:44<04:34,  1.32s/it] 56%|█████▌    | 264/471 [05:45<04:32,  1.32s/it] 56%|█████▋    | 265/471 [05:47<04:31,  1.32s/it] 56%|█████▋    | 266/471 [05:48<04:30,  1.32s/it] 57%|█████▋    | 267/471 [05:49<04:28,  1.32s/it] 57%|█████▋    | 268/471 [05:51<04:27,  1.32s/it] 57%|█████▋    | 269/471 [05:52<04:26,  1.32s/it] 57%|█████▋    | 270/471 [05:53<04:24,  1.32s/it] 58%|█████▊    | 271/471 [05:55<04:23,  1.32s/it] 58%|█████▊    | 272/471 [05:56<04:21,  1.31s/it] 58%|█████▊    | 273/471 [05:57<04:20,  1.31s/it] 58%|█████▊    | 274/471 [05:59<04:18,  1.31s/it] 58%|█████▊    | 275/471 [06:00<04:17,  1.31s/it] 59%|█████▊    | 276/471 [06:01<04:16,  1.32s/it] 59%|█████▉    | 277/471 [06:02<04:15,  1.32s/it] 59%|█████▉    | 278/471 [06:04<04:14,  1.32s/it] 59%|█████▉    | 279/471 [06:05<04:12,  1.32s/it] 59%|█████▉    | 280/471 [06:06<04:11,  1.32s/it] 60%|█████▉    | 281/471 [06:08<04:10,  1.32s/it] 60%|█████▉    | 282/471 [06:09<04:08,  1.32s/it] 60%|██████    | 283/471 [06:10<04:07,  1.32s/it] 60%|██████    | 284/471 [06:12<04:06,  1.32s/it] 61%|██████    | 285/471 [06:13<04:05,  1.32s/it] 61%|██████    | 286/471 [06:14<04:04,  1.32s/it] 61%|██████    | 287/471 [06:16<04:02,  1.32s/it] 61%|██████    | 288/471 [06:17<04:01,  1.32s/it] 61%|██████▏   | 289/471 [06:18<03:59,  1.32s/it] 62%|██████▏   | 290/471 [06:20<03:58,  1.32s/it] 62%|██████▏   | 291/471 [06:21<03:57,  1.32s/it] 62%|██████▏   | 292/471 [06:22<03:55,  1.32s/it] 62%|██████▏   | 293/471 [06:24<03:54,  1.32s/it] 62%|██████▏   | 294/471 [06:25<03:53,  1.32s/it] 63%|██████▎   | 295/471 [06:26<03:51,  1.32s/it] 63%|██████▎   | 296/471 [06:28<03:50,  1.32s/it] 63%|██████▎   | 297/471 [06:29<03:49,  1.32s/it] 63%|██████▎   | 298/471 [06:30<03:48,  1.32s/it] 63%|██████▎   | 299/471 [06:31<03:47,  1.32s/it] 64%|██████▎   | 300/471 [06:33<03:45,  1.32s/it] 64%|██████▍   | 301/471 [06:34<03:44,  1.32s/it] 64%|██████▍   | 302/471 [06:35<03:43,  1.32s/it] 64%|██████▍   | 303/471 [06:37<03:41,  1.32s/it] 65%|██████▍   | 304/471 [06:38<03:40,  1.32s/it] 65%|██████▍   | 305/471 [06:39<03:39,  1.32s/it] 65%|██████▍   | 306/471 [06:41<03:38,  1.32s/it] 65%|██████▌   | 307/471 [06:42<03:37,  1.32s/it] 65%|██████▌   | 308/471 [06:43<03:36,  1.33s/it] 66%|██████▌   | 309/471 [06:45<03:34,  1.33s/it] 66%|██████▌   | 310/471 [06:46<03:33,  1.32s/it] 66%|██████▌   | 311/471 [06:47<03:31,  1.32s/it] 66%|██████▌   | 312/471 [06:49<03:30,  1.32s/it] 66%|██████▋   | 313/471 [06:50<03:29,  1.32s/it] 67%|██████▋   | 314/471 [06:51<03:27,  1.32s/it] 67%|██████▋   | 315/471 [06:53<03:26,  1.32s/it] 67%|██████▋   | 316/471 [06:54<03:25,  1.32s/it] 67%|██████▋   | 317/471 [06:55<03:24,  1.32s/it] 68%|██████▊   | 318/471 [06:57<03:22,  1.33s/it] 68%|██████▊   | 319/471 [06:58<03:21,  1.33s/it] 68%|██████▊   | 320/471 [06:59<03:20,  1.33s/it] 68%|██████▊   | 321/471 [07:01<03:19,  1.33s/it] 68%|██████▊   | 322/471 [07:02<03:18,  1.33s/it] 69%|██████▊   | 323/471 [07:03<03:17,  1.33s/it] 69%|██████▉   | 324/471 [07:05<03:15,  1.33s/it] 69%|██████▉   | 325/471 [07:06<03:14,  1.33s/it] 69%|██████▉   | 326/471 [07:07<03:12,  1.33s/it] 69%|██████▉   | 327/471 [07:09<03:11,  1.33s/it] 70%|██████▉   | 328/471 [07:10<03:10,  1.33s/it] 70%|██████▉   | 329/471 [07:11<03:08,  1.33s/it] 70%|███████   | 330/471 [07:13<03:07,  1.33s/it] 70%|███████   | 331/471 [07:14<03:06,  1.33s/it] 70%|███████   | 332/471 [07:15<03:05,  1.33s/it] 71%|███████   | 333/471 [07:17<03:03,  1.33s/it] 71%|███████   | 334/471 [07:18<03:02,  1.33s/it] 71%|███████   | 335/471 [07:19<03:01,  1.33s/it] 71%|███████▏  | 336/471 [07:21<02:59,  1.33s/it] 72%|███████▏  | 337/471 [07:22<02:58,  1.33s/it] 72%|███████▏  | 338/471 [07:23<02:57,  1.33s/it] 72%|███████▏  | 339/471 [07:25<02:56,  1.33s/it] 72%|███████▏  | 340/471 [07:26<02:54,  1.33s/it] 72%|███████▏  | 341/471 [07:27<02:53,  1.33s/it] 73%|███████▎  | 342/471 [07:29<02:52,  1.33s/it] 73%|███████▎  | 343/471 [07:30<02:50,  1.34s/it] 73%|███████▎  | 344/471 [07:31<02:49,  1.33s/it] 73%|███████▎  | 345/471 [07:33<02:48,  1.33s/it] 73%|███████▎  | 346/471 [07:34<02:46,  1.33s/it] 74%|███████▎  | 347/471 [07:35<02:45,  1.33s/it] 74%|███████▍  | 348/471 [07:37<02:44,  1.33s/it] 74%|███████▍  | 349/471 [07:38<02:42,  1.34s/it] 74%|███████▍  | 350/471 [07:39<02:41,  1.34s/it] 75%|███████▍  | 351/471 [07:41<02:40,  1.33s/it] 75%|███████▍  | 352/471 [07:42<02:38,  1.33s/it] 75%|███████▍  | 353/471 [07:43<02:37,  1.34s/it] 75%|███████▌  | 354/471 [07:45<02:36,  1.34s/it] 75%|███████▌  | 355/471 [07:46<02:35,  1.34s/it] 76%|███████▌  | 356/471 [07:47<02:33,  1.33s/it] 76%|███████▌  | 357/471 [07:49<02:32,  1.34s/it] 76%|███████▌  | 358/471 [07:50<02:30,  1.33s/it] 76%|███████▌  | 359/471 [07:51<02:29,  1.34s/it] 76%|███████▋  | 360/471 [07:53<02:28,  1.33s/it] 77%|███████▋  | 361/471 [07:54<02:26,  1.33s/it] 77%|███████▋  | 362/471 [07:55<02:25,  1.33s/it] 77%|███████▋  | 363/471 [07:57<02:23,  1.33s/it] 77%|███████▋  | 364/471 [07:58<02:22,  1.33s/it] 77%|███████▋  | 365/471 [07:59<02:21,  1.34s/it] 78%|███████▊  | 366/471 [08:01<02:20,  1.34s/it] 78%|███████▊  | 367/471 [08:02<02:19,  1.34s/it] 78%|███████▊  | 368/471 [08:03<02:17,  1.34s/it] 78%|███████▊  | 369/471 [08:05<02:15,  1.33s/it] 79%|███████▊  | 370/471 [08:06<02:14,  1.34s/it] 79%|███████▉  | 371/471 [08:07<02:13,  1.34s/it] 79%|███████▉  | 372/471 [08:09<02:12,  1.34s/it] 79%|███████▉  | 373/471 [08:10<02:10,  1.34s/it] 79%|███████▉  | 374/471 [08:11<02:09,  1.33s/it] 80%|███████▉  | 375/471 [08:13<02:07,  1.33s/it] 80%|███████▉  | 376/471 [08:14<02:06,  1.33s/it] 80%|████████  | 377/471 [08:15<02:05,  1.33s/it] 80%|████████  | 378/471 [08:17<02:03,  1.33s/it] 80%|████████  | 379/471 [08:18<02:02,  1.33s/it] 81%|████████  | 380/471 [08:19<02:01,  1.33s/it] 81%|████████  | 381/471 [08:21<01:59,  1.33s/it] 81%|████████  | 382/471 [08:22<01:58,  1.33s/it] 81%|████████▏ | 383/471 [08:23<01:57,  1.33s/it] 82%|████████▏ | 384/471 [08:25<01:56,  1.33s/it] 82%|████████▏ | 385/471 [08:26<01:54,  1.33s/it] 82%|████████▏ | 386/471 [08:27<01:53,  1.33s/it] 82%|████████▏ | 387/471 [08:29<01:51,  1.33s/it] 82%|████████▏ | 388/471 [08:30<01:50,  1.33s/it] 83%|████████▎ | 389/471 [08:31<01:48,  1.33s/it] 83%|████████▎ | 390/471 [08:33<01:47,  1.33s/it] 83%|████████▎ | 391/471 [08:34<01:46,  1.33s/it] 83%|████████▎ | 392/471 [08:35<01:45,  1.33s/it] 83%|████████▎ | 393/471 [08:37<01:43,  1.33s/it] 84%|████████▎ | 394/471 [08:38<01:42,  1.33s/it] 84%|████████▍ | 395/471 [08:39<01:41,  1.33s/it] 84%|████████▍ | 396/471 [08:41<01:39,  1.33s/it] 84%|████████▍ | 397/471 [08:42<01:38,  1.33s/it] 85%|████████▍ | 398/471 [08:43<01:37,  1.33s/it] 85%|████████▍ | 399/471 [08:45<01:35,  1.33s/it] 85%|████████▍ | 400/471 [08:46<01:34,  1.33s/it] 85%|████████▌ | 401/471 [08:47<01:33,  1.33s/it] 85%|████████▌ | 402/471 [08:49<01:31,  1.33s/it] 86%|████████▌ | 403/471 [08:50<01:30,  1.33s/it] 86%|████████▌ | 404/471 [08:51<01:28,  1.33s/it] 86%|████████▌ | 405/471 [08:53<01:27,  1.33s/it] 86%|████████▌ | 406/471 [08:54<01:26,  1.33s/it] 86%|████████▋ | 407/471 [08:55<01:24,  1.33s/it] 87%|████████▋ | 408/471 [08:57<01:23,  1.33s/it] 87%|████████▋ | 409/471 [08:58<01:22,  1.33s/it] 87%|████████▋ | 410/471 [08:59<01:20,  1.33s/it] 87%|████████▋ | 411/471 [09:01<01:19,  1.32s/it] 87%|████████▋ | 412/471 [09:02<01:18,  1.32s/it] 88%|████████▊ | 413/471 [09:03<01:16,  1.32s/it] 88%|████████▊ | 414/471 [09:05<01:15,  1.33s/it] 88%|████████▊ | 415/471 [09:06<01:14,  1.32s/it] 88%|████████▊ | 416/471 [09:07<01:12,  1.33s/it] 89%|████████▊ | 417/471 [09:08<01:11,  1.32s/it] 89%|████████▊ | 418/471 [09:10<01:10,  1.33s/it] 89%|████████▉ | 419/471 [09:11<01:08,  1.32s/it] 89%|████████▉ | 420/471 [09:12<01:07,  1.32s/it] 89%|████████▉ | 421/471 [09:14<01:06,  1.32s/it] 90%|████████▉ | 422/471 [09:15<01:04,  1.32s/it] 90%|████████▉ | 423/471 [09:16<01:03,  1.32s/it] 90%|█████████ | 424/471 [09:18<01:02,  1.32s/it] 90%|█████████ | 425/471 [09:19<01:00,  1.32s/it] 90%|█████████ | 426/471 [09:20<00:59,  1.32s/it] 91%|█████████ | 427/471 [09:22<00:58,  1.32s/it] 91%|█████████ | 428/471 [09:23<00:56,  1.32s/it] 91%|█████████ | 429/471 [09:24<00:55,  1.32s/it] 91%|█████████▏| 430/471 [09:26<00:54,  1.32s/it] 92%|█████████▏| 431/471 [09:27<00:52,  1.32s/it] 92%|█████████▏| 432/471 [09:28<00:51,  1.32s/it] 92%|█████████▏| 433/471 [09:30<00:50,  1.32s/it] 92%|█████████▏| 434/471 [09:31<00:48,  1.32s/it] 92%|█████████▏| 435/471 [09:32<00:47,  1.32s/it] 93%|█████████▎| 436/471 [09:34<00:46,  1.32s/it] 93%|█████████▎| 437/471 [09:35<00:45,  1.33s/it] 93%|█████████▎| 438/471 [09:36<00:43,  1.33s/it] 93%|█████████▎| 439/471 [09:38<00:42,  1.33s/it] 93%|█████████▎| 440/471 [09:39<00:41,  1.33s/it] 94%|█████████▎| 441/471 [09:40<00:39,  1.33s/it] 94%|█████████▍| 442/471 [09:42<00:38,  1.32s/it] 94%|█████████▍| 443/471 [09:43<00:37,  1.32s/it] 94%|█████████▍| 444/471 [09:44<00:35,  1.33s/it] 94%|█████████▍| 445/471 [09:46<00:34,  1.33s/it] 95%|█████████▍| 446/471 [09:47<00:33,  1.33s/it] 95%|█████████▍| 447/471 [09:48<00:31,  1.33s/it] 95%|█████████▌| 448/471 [09:50<00:30,  1.33s/it] 95%|█████████▌| 449/471 [09:51<00:29,  1.33s/it] 96%|█████████▌| 450/471 [09:52<00:27,  1.33s/it] 96%|█████████▌| 451/471 [09:53<00:26,  1.32s/it] 96%|█████████▌| 452/471 [09:55<00:25,  1.33s/it] 96%|█████████▌| 453/471 [09:56<00:23,  1.33s/it] 96%|█████████▋| 454/471 [09:57<00:22,  1.33s/it] 97%|█████████▋| 455/471 [09:59<00:21,  1.33s/it] 97%|█████████▋| 456/471 [10:00<00:19,  1.33s/it] 97%|█████████▋| 457/471 [10:01<00:18,  1.33s/it] 97%|█████████▋| 458/471 [10:03<00:17,  1.33s/it] 97%|█████████▋| 459/471 [10:04<00:15,  1.33s/it] 98%|█████████▊| 460/471 [10:05<00:14,  1.33s/it] 98%|█████████▊| 461/471 [10:07<00:13,  1.33s/it] 98%|█████████▊| 462/471 [10:08<00:11,  1.33s/it] 98%|█████████▊| 463/471 [10:09<00:10,  1.32s/it] 99%|█████████▊| 464/471 [10:11<00:09,  1.33s/it] 99%|█████████▊| 465/471 [10:12<00:07,  1.32s/it] 99%|█████████▉| 466/471 [10:13<00:06,  1.33s/it] 99%|█████████▉| 467/471 [10:15<00:05,  1.33s/it] 99%|█████████▉| 468/471 [10:16<00:03,  1.33s/it]100%|█████████▉| 469/471 [10:17<00:02,  1.33s/it]100%|█████████▉| 470/471 [10:19<00:01,  1.33s/it]100%|██████████| 471/471 [10:20<00:00,  1.21s/it]100%|██████████| 471/471 [10:20<00:00,  1.32s/it]
{'eval_loss': 4.841746807098389, 'eval_model_preparation_time': 0.0142, 'eval_acc': 0.136218799787573, 'eval_runtime': 621.3867, 'eval_samples_per_second': 12.121, 'eval_steps_per_second': 0.758}
ROUND:4
CLIENT:88
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:33,  2.39s/it]                                              {'loss': 4.6017, 'grad_norm': 4.080743312835693, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:33,  2.39s/it]  5%|▌         | 2/40 [00:04<01:24,  2.23s/it]                                              {'loss': 3.1066, 'grad_norm': 4.220209121704102, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.23s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 3.17, 'grad_norm': 7.090151309967041, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 4.207, 'grad_norm': 38.800987243652344, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it]                                              {'loss': 3.3733, 'grad_norm': 6.362821578979492, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 3.1467, 'grad_norm': 10.320256233215332, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 4.3167, 'grad_norm': 14.829876899719238, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 1.1391, 'grad_norm': 27.835886001586914, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it]                                              {'loss': 2.1159, 'grad_norm': 12.34429931640625, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it]                                               {'loss': 1.7649, 'grad_norm': 8.85055923461914, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.97s/it]                                               {'loss': 2.7192, 'grad_norm': 86.97638702392578, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.97s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 3.6384, 'grad_norm': 261.0141296386719, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it]                                               {'loss': 3.2516, 'grad_norm': 37.76225280761719, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it]                                               {'loss': 2.0497, 'grad_norm': 8.82303237915039, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it]                                               {'loss': 1.9622, 'grad_norm': 34.451568603515625, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 1.1434, 'grad_norm': 14.3088960647583, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:39,  1.74s/it]                                               {'loss': 1.6971, 'grad_norm': 6.9097981452941895, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:39,  1.74s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it]                                               {'loss': 2.2576, 'grad_norm': 10.4388427734375, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it]                                               {'loss': 1.324, 'grad_norm': 3.7799649238586426, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it] 50%|█████     | 20/40 [00:39<00:41,  2.07s/it]                                               {'loss': 1.315, 'grad_norm': 4.806620121002197, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 1.5349, 'grad_norm': 7.2961626052856445, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it]                                               {'loss': 1.0471, 'grad_norm': 5.928871154785156, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 1.2852, 'grad_norm': 8.948410034179688, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:46<00:25,  1.58s/it]                                               {'loss': 3.4505, 'grad_norm': 43.81187057495117, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 1.0022, 'grad_norm': 4.622469425201416, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.5488, 'grad_norm': 3.8325233459472656, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.03s/it]                                               {'loss': 0.837, 'grad_norm': 6.270918369293213, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.03s/it] 70%|███████   | 28/40 [00:55<00:25,  2.11s/it]                                               {'loss': 0.6052, 'grad_norm': 6.1623616218566895, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.4041, 'grad_norm': 5.410737037658691, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it]                                               {'loss': 0.5655, 'grad_norm': 4.716777324676514, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.2691, 'grad_norm': 3.0106942653656006, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:02<00:12,  1.60s/it]                                               {'loss': 0.0904, 'grad_norm': 3.5246195793151855, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.3049, 'grad_norm': 6.3123626708984375, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.3662, 'grad_norm': 4.948200225830078, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.05s/it]                                               {'loss': 0.5133, 'grad_norm': 10.213837623596191, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.1723, 'grad_norm': 3.238111734390259, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.8315, 'grad_norm': 5.422020435333252, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.20s/it]                                               {'loss': 0.1259, 'grad_norm': 2.389437198638916, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.22s/it]                                               {'loss': 0.2911, 'grad_norm': 5.962141036987305, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.5706, 'grad_norm': 13.261995315551758, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.32, 'train_samples_per_second': 7.123, 'train_steps_per_second': 0.504, 'train_loss': 1.6779003033414484, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:4
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:35,  2.44s/it]                                              {'loss': 5.2208, 'grad_norm': 5.532866477966309, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:35,  2.44s/it]  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]                                              {'loss': 4.7274, 'grad_norm': 4.627378463745117, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]  8%|▊         | 3/40 [00:06<01:22,  2.23s/it]                                              {'loss': 3.9438, 'grad_norm': 7.674951076507568, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.23s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 4.2505, 'grad_norm': 8.834675788879395, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it]                                              {'loss': 3.1586, 'grad_norm': 5.8677263259887695, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:13,  2.16s/it]                                              {'loss': 3.6688, 'grad_norm': 7.374196529388428, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:13,  2.16s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it]                                              {'loss': 4.6418, 'grad_norm': 7.865484714508057, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 6.4463, 'grad_norm': 26.659212112426758, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it]                                              {'loss': 2.2954, 'grad_norm': 5.837371349334717, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it]                                               {'loss': 1.9256, 'grad_norm': 5.045756816864014, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 1.8904, 'grad_norm': 5.616672992706299, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 0.9666, 'grad_norm': 4.667888641357422, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it]                                               {'loss': 0.8627, 'grad_norm': 3.906055450439453, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 1.1853, 'grad_norm': 4.788514614105225, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.14s/it]                                               {'loss': 1.7392, 'grad_norm': 8.77453327178955, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.14s/it] 40%|████      | 16/40 [00:31<00:37,  1.55s/it]                                               {'loss': 1.8482, 'grad_norm': 50.233123779296875, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.55s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.8295, 'grad_norm': 7.858715534210205, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.5682, 'grad_norm': 6.148612976074219, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.07s/it]                                               {'loss': 0.3533, 'grad_norm': 2.457768440246582, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.07s/it] 50%|█████     | 20/40 [00:40<00:42,  2.10s/it]                                               {'loss': 0.6264, 'grad_norm': 4.391079425811768, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.7448, 'grad_norm': 5.4265336990356445, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.5564, 'grad_norm': 5.216586589813232, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 0.835, 'grad_norm': 7.133256435394287, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:47<00:25,  1.57s/it]                                               {'loss': 3.1014, 'grad_norm': 17.410539627075195, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.75s/it]                                               {'loss': 0.3918, 'grad_norm': 2.115434408187866, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.75s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.89s/it]                                               {'loss': 0.1529, 'grad_norm': 2.280734062194824, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.89s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it]                                               {'loss': 0.3792, 'grad_norm': 2.7409796714782715, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it] 70%|███████   | 28/40 [00:55<00:24,  2.07s/it]                                               {'loss': 0.3349, 'grad_norm': 2.081552028656006, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.2577, 'grad_norm': 3.366396427154541, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.498, 'grad_norm': 1.97882080078125, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.21s/it]                                               {'loss': 0.1646, 'grad_norm': 1.7935951948165894, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.21s/it] 80%|████████  | 32/40 [01:02<00:12,  1.60s/it]                                               {'loss': 0.3976, 'grad_norm': 9.764921188354492, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.1582, 'grad_norm': 0.3624379336833954, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.2285, 'grad_norm': 1.5645695924758911, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.2406, 'grad_norm': 0.7837020754814148, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it]                                               {'loss': 0.2901, 'grad_norm': 2.3219716548919678, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.2104, 'grad_norm': 2.4316465854644775, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.16s/it]                                               {'loss': 0.2667, 'grad_norm': 2.248586416244507, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.16s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]                                               {'loss': 0.0573, 'grad_norm': 0.690584659576416, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 0.0098, 'grad_norm': 0.5616070628166199, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 79.2268, 'train_samples_per_second': 7.131, 'train_steps_per_second': 0.505, 'train_loss': 1.510610108752735, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:79
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:32,  2.37s/it]                                              {'loss': 4.6909, 'grad_norm': 5.3511834144592285, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:32,  2.37s/it]  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]                                              {'loss': 4.015, 'grad_norm': 5.622426986694336, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]  8%|▊         | 3/40 [00:06<01:22,  2.22s/it]                                              {'loss': 5.3984, 'grad_norm': 6.135945796966553, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.22s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 3.1929, 'grad_norm': 6.1781229972839355, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 3.6639, 'grad_norm': 9.566856384277344, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 3.0756, 'grad_norm': 9.058401107788086, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it]                                              {'loss': 3.7947, 'grad_norm': 12.892139434814453, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 4.757, 'grad_norm': 77.60975646972656, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 1.9117, 'grad_norm': 11.610871315002441, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.8456, 'grad_norm': 6.55134391784668, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.5817, 'grad_norm': 5.036236763000488, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 1.0811, 'grad_norm': 5.274920463562012, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it]                                               {'loss': 0.8034, 'grad_norm': 11.580327987670898, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.15s/it]                                               {'loss': 0.8803, 'grad_norm': 4.654059410095215, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 1.0694, 'grad_norm': 7.078042984008789, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.5809, 'grad_norm': 14.70656681060791, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.1914, 'grad_norm': 2.159886360168457, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.91s/it]                                               {'loss': 0.2725, 'grad_norm': 3.313166618347168, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it]                                               {'loss': 1.0741, 'grad_norm': 5.777058124542236, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.6147, 'grad_norm': 4.976771354675293, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.2328, 'grad_norm': 3.460683822631836, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it]                                               {'loss': 0.5111, 'grad_norm': 5.556517124176025, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.2818, 'grad_norm': 3.6114203929901123, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.62s/it]                                               {'loss': 0.1126, 'grad_norm': 3.6678097248077393, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it]                                               {'loss': 0.0591, 'grad_norm': 0.8635863065719604, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.94s/it]                                               {'loss': 0.1131, 'grad_norm': 2.5175020694732666, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.2599, 'grad_norm': 4.564363479614258, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.7645, 'grad_norm': 3.7396490573883057, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.3794, 'grad_norm': 9.256071090698242, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it]                                               {'loss': 0.1652, 'grad_norm': 2.552150249481201, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.2735, 'grad_norm': 4.308974266052246, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.7546, 'grad_norm': 26.997568130493164, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it]                                               {'loss': 0.0679, 'grad_norm': 1.2374780178070068, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.0407, 'grad_norm': 0.7079846858978271, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it]                                               {'loss': 0.6772, 'grad_norm': 8.069038391113281, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it]                                               {'loss': 0.2613, 'grad_norm': 7.887811660766602, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it]                                               {'loss': 0.1394, 'grad_norm': 2.4524378776550293, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.2085, 'grad_norm': 7.592920303344727, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]                                               {'loss': 0.0793, 'grad_norm': 1.6532427072525024, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.2441, 'grad_norm': 14.763410568237305, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 80.1258, 'train_samples_per_second': 7.051, 'train_steps_per_second': 0.499, 'train_loss': 1.2030329689383508, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:14
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:38,  2.54s/it]                                              {'loss': 4.0079, 'grad_norm': 8.575302124023438, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:38,  2.54s/it]  5%|▌         | 2/40 [00:04<01:28,  2.33s/it]                                              {'loss': 2.792, 'grad_norm': 4.078639984130859, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.33s/it]  8%|▊         | 3/40 [00:06<01:24,  2.27s/it]                                              {'loss': 6.2105, 'grad_norm': 5.162905216217041, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.27s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 4.5733, 'grad_norm': 8.830731391906738, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 2.2966, 'grad_norm': 4.9356160163879395, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 3.9041, 'grad_norm': 19.014785766601562, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 4.8155, 'grad_norm': 7.500739574432373, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 3.0654, 'grad_norm': 35.844818115234375, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 2.9817, 'grad_norm': 13.866829872131348, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 2.1324, 'grad_norm': 20.30487060546875, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.0942, 'grad_norm': 81.88329315185547, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.8241, 'grad_norm': 16.474529266357422, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 1.7334, 'grad_norm': 8.547920227050781, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 1.5166, 'grad_norm': 6.540182113647461, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 1.5323, 'grad_norm': 5.503814220428467, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.1222, 'grad_norm': 13.092935562133789, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.7407, 'grad_norm': 6.820080280303955, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.5478, 'grad_norm': 2.9365170001983643, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 1.0027, 'grad_norm': 4.647825717926025, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:41,  2.10s/it]                                               {'loss': 0.962, 'grad_norm': 4.748205184936523, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.10s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it]                                               {'loss': 1.1686, 'grad_norm': 6.996720314025879, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 1.0233, 'grad_norm': 6.253924369812012, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 1.503, 'grad_norm': 6.404027938842773, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.2171, 'grad_norm': 10.887149810791016, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.3039, 'grad_norm': 3.496067523956299, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.2766, 'grad_norm': 4.96750020980835, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.2257, 'grad_norm': 2.714648723602295, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:56<00:25,  2.12s/it]                                               {'loss': 0.2322, 'grad_norm': 3.5187065601348877, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it]                                               {'loss': 0.3914, 'grad_norm': 3.949141263961792, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.4638, 'grad_norm': 4.101826190948486, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.2245, 'grad_norm': 4.1838698387146, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.041, 'grad_norm': 1.9424501657485962, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0706, 'grad_norm': 0.7824164032936096, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.0745, 'grad_norm': 1.485925555229187, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.0607, 'grad_norm': 0.9426183700561523, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.1183, 'grad_norm': 3.1257214546203613, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.15s/it]                                               {'loss': 0.184, 'grad_norm': 4.640573501586914, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it]                                               {'loss': 0.1055, 'grad_norm': 1.7564276456832886, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.0931, 'grad_norm': 1.4739834070205688, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.66s/it]                                               {'loss': 0.0163, 'grad_norm': 0.9664271473884583, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.66s/it]                                               {'train_runtime': 80.6066, 'train_samples_per_second': 7.009, 'train_steps_per_second': 0.496, 'train_loss': 1.36624312591739, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.66s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:55
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]                                              {'loss': 5.0508, 'grad_norm': 5.386411190032959, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]                                              {'loss': 5.0509, 'grad_norm': 7.694097995758057, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]  8%|▊         | 3/40 [00:06<01:19,  2.16s/it]                                              {'loss': 4.2925, 'grad_norm': 12.246468544006348, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.16s/it] 10%|█         | 4/40 [00:08<01:18,  2.18s/it]                                              {'loss': 3.3485, 'grad_norm': 6.009375095367432, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.18s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it]                                              {'loss': 4.3033, 'grad_norm': 13.012979507446289, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 2.6691, 'grad_norm': 5.400637149810791, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 3.1046, 'grad_norm': 7.7155046463012695, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 3.341, 'grad_norm': 27.267709732055664, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 1.4366, 'grad_norm': 4.072850227355957, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:19<00:57,  1.90s/it]                                               {'loss': 1.0942, 'grad_norm': 4.95742130279541, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.5844, 'grad_norm': 6.382573127746582, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 2.3988, 'grad_norm': 6.304055690765381, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it]                                               {'loss': 1.4778, 'grad_norm': 13.061406135559082, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it]                                               {'loss': 1.2823, 'grad_norm': 6.6624040603637695, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 1.3111, 'grad_norm': 7.782730579376221, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 1.1588, 'grad_norm': 21.473058700561523, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.2699, 'grad_norm': 3.211704969406128, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it]                                               {'loss': 0.6418, 'grad_norm': 6.976782321929932, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.02s/it]                                               {'loss': 1.0735, 'grad_norm': 3.6283788681030273, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.9086, 'grad_norm': 7.012232780456543, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.8136, 'grad_norm': 6.011009693145752, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.7156, 'grad_norm': 12.308290481567383, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.20s/it]                                               {'loss': 0.5338, 'grad_norm': 5.562715530395508, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.001, 'grad_norm': 0.03444356843829155, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.4619, 'grad_norm': 4.537879467010498, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.6158, 'grad_norm': 16.301422119140625, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.4452, 'grad_norm': 7.078001976013184, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.6595, 'grad_norm': 3.238701105117798, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.4551, 'grad_norm': 3.2322285175323486, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.20s/it]                                               {'loss': 0.0908, 'grad_norm': 1.189746618270874, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.3021, 'grad_norm': 4.359590530395508, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0412, 'grad_norm': 1.5100146532058716, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.5885, 'grad_norm': 2.51706862449646, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.3121, 'grad_norm': 5.610408306121826, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.4663, 'grad_norm': 6.818827152252197, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0996, 'grad_norm': 2.2998898029327393, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.0749, 'grad_norm': 1.1303024291992188, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.0632, 'grad_norm': 1.5225971937179565, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.0823, 'grad_norm': 1.4567197561264038, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.0204, 'grad_norm': 0.9186686873435974, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 79.6609, 'train_samples_per_second': 7.093, 'train_steps_per_second': 0.502, 'train_loss': 1.3160340736299987, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:3
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:03<02:04,  3.20s/it]                                              {'loss': 4.3641, 'grad_norm': 8.856575965881348, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:03<02:04,  3.20s/it]  5%|▌         | 2/40 [00:05<01:40,  2.64s/it]                                              {'loss': 3.3888, 'grad_norm': 3.8655946254730225, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:40,  2.64s/it]  8%|▊         | 3/40 [00:07<01:29,  2.41s/it]                                              {'loss': 4.3866, 'grad_norm': 8.149141311645508, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:29,  2.41s/it] 10%|█         | 4/40 [00:09<01:23,  2.33s/it]                                              {'loss': 4.5955, 'grad_norm': 5.256858825683594, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:23,  2.33s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it]                                              {'loss': 4.287, 'grad_norm': 8.489258766174316, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it] 15%|█▌        | 6/40 [00:14<01:16,  2.25s/it]                                              {'loss': 4.2239, 'grad_norm': 8.071908950805664, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:14<01:16,  2.25s/it] 18%|█▊        | 7/40 [00:16<01:13,  2.22s/it]                                              {'loss': 3.8318, 'grad_norm': 8.660277366638184, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 5.4736, 'grad_norm': 19.806550979614258, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 1.6083, 'grad_norm': 7.774987697601318, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 1.2393, 'grad_norm': 13.501219749450684, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:23<00:58,  2.01s/it]                                               {'loss': 1.8123, 'grad_norm': 7.82994270324707, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:58,  2.01s/it] 30%|███       | 12/40 [00:25<00:58,  2.08s/it]                                               {'loss': 0.9822, 'grad_norm': 11.604612350463867, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 1.6056, 'grad_norm': 5.271636009216309, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 0.9558, 'grad_norm': 5.435208797454834, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:32<00:54,  2.17s/it]                                               {'loss': 1.3653, 'grad_norm': 6.9845662117004395, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:54,  2.17s/it] 40%|████      | 16/40 [00:32<00:37,  1.57s/it]                                               {'loss': 2.9701, 'grad_norm': 53.895748138427734, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it]                                               {'loss': 0.7717, 'grad_norm': 4.376608371734619, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it]                                               {'loss': 0.5232, 'grad_norm': 5.018890380859375, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:39<00:44,  2.13s/it]                                               {'loss': 0.6134, 'grad_norm': 5.405732154846191, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:44,  2.13s/it] 50%|█████     | 20/40 [00:41<00:43,  2.15s/it]                                               {'loss': 0.7238, 'grad_norm': 26.75595474243164, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:43,  2.15s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it]                                               {'loss': 0.5872, 'grad_norm': 10.156816482543945, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it] 55%|█████▌    | 22/40 [00:46<00:39,  2.22s/it]                                               {'loss': 0.368, 'grad_norm': 4.38427209854126, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:39,  2.22s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it]                                               {'loss': 0.6046, 'grad_norm': 4.993211269378662, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it] 60%|██████    | 24/40 [00:48<00:25,  1.61s/it]                                               {'loss': 0.0495, 'grad_norm': 1.4194499254226685, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.213, 'grad_norm': 2.928522825241089, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.96s/it]                                               {'loss': 0.1547, 'grad_norm': 3.9687931537628174, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it]                                               {'loss': 0.091, 'grad_norm': 1.3360888957977295, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.152, 'grad_norm': 2.683601140975952, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.2781, 'grad_norm': 5.297382831573486, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:02<00:21,  2.19s/it]                                               {'loss': 0.2904, 'grad_norm': 2.9234540462493896, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it]                                               {'loss': 0.516, 'grad_norm': 4.825277805328369, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it] 80%|████████  | 32/40 [01:04<00:12,  1.60s/it]                                               {'loss': 0.0016, 'grad_norm': 0.08034364134073257, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.3014, 'grad_norm': 2.9066686630249023, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.95s/it]                                               {'loss': 0.1627, 'grad_norm': 4.095864295959473, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it]                                               {'loss': 0.0572, 'grad_norm': 1.1030185222625732, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it]                                               {'loss': 0.0344, 'grad_norm': 1.098166584968567, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.18s/it]                                               {'loss': 0.6863, 'grad_norm': 4.818185329437256, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.20s/it]                                               {'loss': 0.7983, 'grad_norm': 9.534520149230957, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]                                               {'loss': 0.2417, 'grad_norm': 5.275652885437012, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.1291, 'grad_norm': 8.175531387329102, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 81.1592, 'train_samples_per_second': 6.962, 'train_steps_per_second': 0.493, 'train_loss': 1.3859966993913986, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.62s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
CLIENT:19
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:45,  2.71s/it]                                              {'loss': 4.5567, 'grad_norm': 4.588502407073975, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:45,  2.71s/it]  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]                                              {'loss': 4.7051, 'grad_norm': 4.759686470031738, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]  8%|▊         | 3/40 [00:07<01:24,  2.29s/it]                                              {'loss': 5.1264, 'grad_norm': 11.954586029052734, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 4.2865, 'grad_norm': 7.999581336975098, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 4.1753, 'grad_norm': 9.577568054199219, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 3.4509, 'grad_norm': 7.818970203399658, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 4.0242, 'grad_norm': 8.278422355651855, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 9.7107, 'grad_norm': 56.732032775878906, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 1.6919, 'grad_norm': 7.231030464172363, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 2.0008, 'grad_norm': 11.646418571472168, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 1.9557, 'grad_norm': 10.57282829284668, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:58,  2.07s/it]                                               {'loss': 2.1549, 'grad_norm': 9.581411361694336, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 1.6175, 'grad_norm': 6.363714218139648, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 1.1205, 'grad_norm': 5.813710689544678, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.963, 'grad_norm': 5.324502468109131, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 1.2575, 'grad_norm': 56.277549743652344, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it]                                               {'loss': 0.3886, 'grad_norm': 4.599876403808594, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it]                                               {'loss': 0.8136, 'grad_norm': 4.188682556152344, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it]                                               {'loss': 0.9781, 'grad_norm': 5.3635573387146, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.2883, 'grad_norm': 3.39194393157959, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.4292, 'grad_norm': 3.2738778591156006, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it]                                               {'loss': 0.625, 'grad_norm': 5.010662078857422, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.5366, 'grad_norm': 3.6347312927246094, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.4228, 'grad_norm': 32.36960220336914, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it]                                               {'loss': 0.3842, 'grad_norm': 26.70473289489746, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.1866, 'grad_norm': 5.309638500213623, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.4851, 'grad_norm': 5.5145487785339355, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.2191, 'grad_norm': 3.4352264404296875, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.3697, 'grad_norm': 5.119520664215088, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.2446, 'grad_norm': 2.7407853603363037, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.5334, 'grad_norm': 4.593625068664551, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0323, 'grad_norm': 1.4677700996398926, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.1819, 'grad_norm': 3.152785301208496, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.1334, 'grad_norm': 2.1832094192504883, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.0393, 'grad_norm': 0.6106882095336914, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.4336, 'grad_norm': 3.7553999423980713, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.2145, 'grad_norm': 3.4588916301727295, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.8029, 'grad_norm': 5.068734645843506, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.467, 'grad_norm': 4.2690815925598145, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.051, 'grad_norm': 3.0267374515533447, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.0672, 'train_samples_per_second': 7.057, 'train_steps_per_second': 0.5, 'train_loss': 1.5514599020592867, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:28
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:37,  2.50s/it]                                              {'loss': 4.2769, 'grad_norm': 4.578275203704834, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:37,  2.50s/it]  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]                                              {'loss': 3.9579, 'grad_norm': 3.682619571685791, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]  8%|▊         | 3/40 [00:06<01:22,  2.24s/it]                                              {'loss': 5.1095, 'grad_norm': 4.78678560256958, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.24s/it] 10%|█         | 4/40 [00:09<01:19,  2.22s/it]                                              {'loss': 2.0656, 'grad_norm': 4.922618389129639, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:19,  2.22s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it]                                              {'loss': 4.045, 'grad_norm': 5.805888652801514, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 3.1464, 'grad_norm': 4.558468818664551, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 3.2368, 'grad_norm': 6.710824489593506, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 10.6183, 'grad_norm': 36.0138053894043, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 1.5676, 'grad_norm': 9.826579093933105, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it]                                               {'loss': 1.0275, 'grad_norm': 6.130560398101807, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.97s/it]                                               {'loss': 1.107, 'grad_norm': 11.057205200195312, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.97s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 1.6883, 'grad_norm': 6.7449259757995605, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 0.8519, 'grad_norm': 5.1922760009765625, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 1.4663, 'grad_norm': 7.364890098571777, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it]                                               {'loss': 0.6768, 'grad_norm': 3.931711196899414, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 0.4152, 'grad_norm': 8.82215690612793, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.339, 'grad_norm': 8.290620803833008, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.1802, 'grad_norm': 1.6688494682312012, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it]                                               {'loss': 0.3387, 'grad_norm': 2.7321038246154785, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.2017, 'grad_norm': 1.3565326929092407, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.5359, 'grad_norm': 2.4652609825134277, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.2723, 'grad_norm': 3.9687516689300537, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it]                                               {'loss': 0.16, 'grad_norm': 3.082123279571533, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.7222, 'grad_norm': 72.41902923583984, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.1428, 'grad_norm': 3.2258074283599854, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.0928, 'grad_norm': 2.890501022338867, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it]                                               {'loss': 0.3324, 'grad_norm': 5.447268009185791, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.2655, 'grad_norm': 9.893316268920898, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.0942, 'grad_norm': 1.9876368045806885, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.0457, 'grad_norm': 0.9289001822471619, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.3658, 'grad_norm': 5.1697492599487305, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.149, 'grad_norm': 8.608410835266113, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0484, 'grad_norm': 1.457192301750183, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.0257, 'grad_norm': 0.5724295973777771, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it]                                               {'loss': 0.0225, 'grad_norm': 0.40909242630004883, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.1891, 'grad_norm': 3.3363404273986816, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.0704, 'grad_norm': 1.479367971420288, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.0698, 'grad_norm': 1.0768218040466309, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.133, 'grad_norm': 3.672344446182251, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0219, 'grad_norm': 1.4537789821624756, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.4223, 'train_samples_per_second': 7.114, 'train_steps_per_second': 0.504, 'train_loss': 1.251898007420823, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:94
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]                                              {'loss': 5.5538, 'grad_norm': 6.659763813018799, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 4.5504, 'grad_norm': 5.143547058105469, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:07<01:24,  2.29s/it]                                              {'loss': 3.6512, 'grad_norm': 5.504417419433594, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:21,  2.25s/it]                                              {'loss': 3.2921, 'grad_norm': 4.846292495727539, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 5.5573, 'grad_norm': 9.822195053100586, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.5084, 'grad_norm': 7.778877258300781, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 4.0242, 'grad_norm': 9.4271821975708, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.2611, 'grad_norm': 28.129032135009766, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:53,  1.74s/it]                                              {'loss': 4.6779, 'grad_norm': 99.86077880859375, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:53,  1.74s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it]                                               {'loss': 4.6063, 'grad_norm': 65.69327545166016, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 3.9253, 'grad_norm': 68.13966369628906, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:58,  2.07s/it]                                               {'loss': 1.4856, 'grad_norm': 35.533687591552734, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 1.4462, 'grad_norm': 14.324835777282715, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 2.2181, 'grad_norm': 14.208313941955566, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 2.1998, 'grad_norm': 14.265654563903809, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 5.8958, 'grad_norm': 46.26168441772461, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 1.26, 'grad_norm': 11.736495971679688, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 1.2669, 'grad_norm': 3.886216878890991, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:44,  2.13s/it]                                               {'loss': 1.5554, 'grad_norm': 10.777592658996582, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:44,  2.13s/it] 50%|█████     | 20/40 [00:40<00:42,  2.14s/it]                                               {'loss': 2.114, 'grad_norm': 12.41292953491211, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.14s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 1.3281, 'grad_norm': 9.275762557983398, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 1.7318, 'grad_norm': 15.355743408203125, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it]                                               {'loss': 2.2885, 'grad_norm': 7.8207106590271, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it] 60%|██████    | 24/40 [00:47<00:25,  1.62s/it]                                               {'loss': 0.0119, 'grad_norm': 0.43150031566619873, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.5202, 'grad_norm': 15.035714149475098, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.7578, 'grad_norm': 7.3935322761535645, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.5822, 'grad_norm': 3.9567182064056396, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.6863, 'grad_norm': 5.862462520599365, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it]                                               {'loss': 0.7549, 'grad_norm': 9.622249603271484, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.6927, 'grad_norm': 4.945804119110107, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.5408, 'grad_norm': 7.42897367477417, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:04<00:12,  1.60s/it]                                               {'loss': 0.7657, 'grad_norm': 21.06403923034668, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.153, 'grad_norm': 1.836669683456421, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.3193, 'grad_norm': 3.8348350524902344, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.2019, 'grad_norm': 3.0708229541778564, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it]                                               {'loss': 0.1128, 'grad_norm': 2.6872973442077637, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.2401, 'grad_norm': 3.2382802963256836, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.2744, 'grad_norm': 26.10800552368164, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.3523, 'grad_norm': 6.600261211395264, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:20<00:00,  1.61s/it]                                               {'loss': 0.0251, 'grad_norm': 1.2550888061523438, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]                                               {'train_runtime': 80.4169, 'train_samples_per_second': 7.026, 'train_steps_per_second': 0.497, 'train_loss': 1.8597422959282994, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:25
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:29,  2.29s/it]                                              {'loss': 3.8771, 'grad_norm': 5.176571846008301, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:29,  2.29s/it]  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]                                              {'loss': 4.4362, 'grad_norm': 5.704996109008789, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]  8%|▊         | 3/40 [00:06<01:20,  2.18s/it]                                              {'loss': 3.2759, 'grad_norm': 5.269857406616211, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.18s/it] 10%|█         | 4/40 [00:08<01:18,  2.19s/it]                                              {'loss': 4.3008, 'grad_norm': 5.685246467590332, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.19s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.20s/it]                                              {'loss': 4.0694, 'grad_norm': 7.384054183959961, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 5.1843, 'grad_norm': 10.605013847351074, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 3.7076, 'grad_norm': 9.182130813598633, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 1.6064, 'grad_norm': 61.37531661987305, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 1.1239, 'grad_norm': 7.13625955581665, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it]                                               {'loss': 3.0914, 'grad_norm': 5.575629711151123, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 1.8144, 'grad_norm': 5.718846797943115, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.1478, 'grad_norm': 6.318334579467773, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 1.4236, 'grad_norm': 4.392910003662109, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it]                                               {'loss': 0.8525, 'grad_norm': 4.126260757446289, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 1.3559, 'grad_norm': 9.218706130981445, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 1.2209, 'grad_norm': 40.25190734863281, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.4965, 'grad_norm': 6.319977283477783, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.9157, 'grad_norm': 4.88023567199707, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it]                                               {'loss': 0.9434, 'grad_norm': 12.2683744430542, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.5805, 'grad_norm': 3.912346839904785, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.4387, 'grad_norm': 2.348820209503174, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.7684, 'grad_norm': 3.8427305221557617, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.20s/it]                                               {'loss': 0.5626, 'grad_norm': 4.225156307220459, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0766, 'grad_norm': 2.7552967071533203, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.1511, 'grad_norm': 3.2175025939941406, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.2451, 'grad_norm': 8.942695617675781, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.1586, 'grad_norm': 2.3162224292755127, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.4194, 'grad_norm': 4.3573503494262695, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.17s/it]                                               {'loss': 0.1028, 'grad_norm': 1.5424551963806152, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.2122, 'grad_norm': 2.8001601696014404, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.21s/it]                                               {'loss': 0.3886, 'grad_norm': 1.6208571195602417, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0096, 'grad_norm': 0.30885711312294006, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.1136, 'grad_norm': 1.170947790145874, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.2631, 'grad_norm': 2.793104410171509, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it]                                               {'loss': 0.0561, 'grad_norm': 1.4807895421981812, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.361, 'grad_norm': 2.8717141151428223, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.1271, 'grad_norm': 1.5786210298538208, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.1211, 'grad_norm': 1.6293352842330933, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.1112, 'grad_norm': 2.2352263927459717, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.014, 'grad_norm': 0.5368836522102356, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.3559, 'train_samples_per_second': 7.12, 'train_steps_per_second': 0.504, 'train_loss': 1.2531264711171388, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:57,  1.58it/s]  1%|          | 3/471 [00:02<07:00,  1.11it/s]  1%|          | 4/471 [00:03<08:06,  1.04s/it]  1%|          | 5/471 [00:05<08:43,  1.12s/it]  1%|▏         | 6/471 [00:06<09:06,  1.18s/it]  1%|▏         | 7/471 [00:07<09:22,  1.21s/it]  2%|▏         | 8/471 [00:08<09:31,  1.23s/it]  2%|▏         | 9/471 [00:10<09:37,  1.25s/it]  2%|▏         | 10/471 [00:11<09:42,  1.26s/it]  2%|▏         | 11/471 [00:12<09:44,  1.27s/it]  3%|▎         | 12/471 [00:14<09:46,  1.28s/it]  3%|▎         | 13/471 [00:15<09:47,  1.28s/it]  3%|▎         | 14/471 [00:16<09:48,  1.29s/it]  3%|▎         | 15/471 [00:17<09:48,  1.29s/it]  3%|▎         | 16/471 [00:19<09:48,  1.29s/it]  4%|▎         | 17/471 [00:20<09:48,  1.30s/it]  4%|▍         | 18/471 [00:21<09:48,  1.30s/it]  4%|▍         | 19/471 [00:23<09:48,  1.30s/it]  4%|▍         | 20/471 [00:24<09:48,  1.30s/it]  4%|▍         | 21/471 [00:25<09:47,  1.31s/it]  5%|▍         | 22/471 [00:27<09:47,  1.31s/it]  5%|▍         | 23/471 [00:28<09:47,  1.31s/it]  5%|▌         | 24/471 [00:29<09:46,  1.31s/it]  5%|▌         | 25/471 [00:31<09:45,  1.31s/it]  6%|▌         | 26/471 [00:32<09:45,  1.31s/it]  6%|▌         | 27/471 [00:33<09:44,  1.32s/it]  6%|▌         | 28/471 [00:35<09:43,  1.32s/it]  6%|▌         | 29/471 [00:36<09:43,  1.32s/it]  6%|▋         | 30/471 [00:37<09:42,  1.32s/it]  7%|▋         | 31/471 [00:39<09:41,  1.32s/it]  7%|▋         | 32/471 [00:40<09:40,  1.32s/it]  7%|▋         | 33/471 [00:41<09:37,  1.32s/it]  7%|▋         | 34/471 [00:42<09:36,  1.32s/it]  7%|▋         | 35/471 [00:44<09:36,  1.32s/it]  8%|▊         | 36/471 [00:45<09:35,  1.32s/it]  8%|▊         | 37/471 [00:46<09:35,  1.33s/it]  8%|▊         | 38/471 [00:48<09:34,  1.33s/it]  8%|▊         | 39/471 [00:49<09:33,  1.33s/it]  8%|▊         | 40/471 [00:50<09:32,  1.33s/it]  9%|▊         | 41/471 [00:52<09:31,  1.33s/it]  9%|▉         | 42/471 [00:53<09:31,  1.33s/it]  9%|▉         | 43/471 [00:54<09:29,  1.33s/it]  9%|▉         | 44/471 [00:56<09:28,  1.33s/it] 10%|▉         | 45/471 [00:57<09:28,  1.33s/it] 10%|▉         | 46/471 [00:58<09:26,  1.33s/it] 10%|▉         | 47/471 [01:00<09:25,  1.33s/it] 10%|█         | 48/471 [01:01<09:24,  1.33s/it] 10%|█         | 49/471 [01:02<09:24,  1.34s/it] 11%|█         | 50/471 [01:04<09:22,  1.34s/it] 11%|█         | 51/471 [01:05<09:22,  1.34s/it] 11%|█         | 52/471 [01:06<09:21,  1.34s/it] 11%|█▏        | 53/471 [01:08<09:20,  1.34s/it] 11%|█▏        | 54/471 [01:09<09:19,  1.34s/it] 12%|█▏        | 55/471 [01:11<09:17,  1.34s/it] 12%|█▏        | 56/471 [01:12<09:17,  1.34s/it] 12%|█▏        | 57/471 [01:13<09:16,  1.34s/it] 12%|█▏        | 58/471 [01:15<09:14,  1.34s/it] 13%|█▎        | 59/471 [01:16<09:13,  1.34s/it] 13%|█▎        | 60/471 [01:17<09:11,  1.34s/it] 13%|█▎        | 61/471 [01:19<09:10,  1.34s/it] 13%|█▎        | 62/471 [01:20<09:08,  1.34s/it] 13%|█▎        | 63/471 [01:21<09:07,  1.34s/it] 14%|█▎        | 64/471 [01:23<09:06,  1.34s/it] 14%|█▍        | 65/471 [01:24<09:04,  1.34s/it] 14%|█▍        | 66/471 [01:25<09:03,  1.34s/it] 14%|█▍        | 67/471 [01:27<09:02,  1.34s/it] 14%|█▍        | 68/471 [01:28<09:01,  1.34s/it] 15%|█▍        | 69/471 [01:29<09:00,  1.34s/it] 15%|█▍        | 70/471 [01:31<08:59,  1.35s/it] 15%|█▌        | 71/471 [01:32<08:58,  1.35s/it] 15%|█▌        | 72/471 [01:33<08:57,  1.35s/it] 15%|█▌        | 73/471 [01:35<08:55,  1.35s/it] 16%|█▌        | 74/471 [01:36<08:53,  1.34s/it] 16%|█▌        | 75/471 [01:37<08:52,  1.35s/it] 16%|█▌        | 76/471 [01:39<08:50,  1.34s/it] 16%|█▋        | 77/471 [01:40<08:49,  1.34s/it] 17%|█▋        | 78/471 [01:41<08:48,  1.35s/it] 17%|█▋        | 79/471 [01:43<08:47,  1.35s/it] 17%|█▋        | 80/471 [01:44<08:46,  1.35s/it] 17%|█▋        | 81/471 [01:45<08:44,  1.35s/it] 17%|█▋        | 82/471 [01:47<08:43,  1.35s/it] 18%|█▊        | 83/471 [01:48<08:42,  1.35s/it] 18%|█▊        | 84/471 [01:50<08:41,  1.35s/it] 18%|█▊        | 85/471 [01:51<08:40,  1.35s/it] 18%|█▊        | 86/471 [01:52<08:39,  1.35s/it] 18%|█▊        | 87/471 [01:54<08:37,  1.35s/it] 19%|█▊        | 88/471 [01:55<08:35,  1.35s/it] 19%|█▉        | 89/471 [01:56<08:34,  1.35s/it] 19%|█▉        | 90/471 [01:58<08:33,  1.35s/it] 19%|█▉        | 91/471 [01:59<08:31,  1.35s/it] 20%|█▉        | 92/471 [02:00<08:29,  1.35s/it] 20%|█▉        | 93/471 [02:02<08:29,  1.35s/it] 20%|█▉        | 94/471 [02:03<08:27,  1.35s/it] 20%|██        | 95/471 [02:04<08:25,  1.34s/it] 20%|██        | 96/471 [02:06<08:23,  1.34s/it] 21%|██        | 97/471 [02:07<08:22,  1.34s/it] 21%|██        | 98/471 [02:08<08:20,  1.34s/it] 21%|██        | 99/471 [02:10<08:19,  1.34s/it] 21%|██        | 100/471 [02:11<08:17,  1.34s/it] 21%|██▏       | 101/471 [02:12<08:16,  1.34s/it] 22%|██▏       | 102/471 [02:14<08:15,  1.34s/it] 22%|██▏       | 103/471 [02:15<08:13,  1.34s/it] 22%|██▏       | 104/471 [02:16<08:12,  1.34s/it] 22%|██▏       | 105/471 [02:18<08:11,  1.34s/it] 23%|██▎       | 106/471 [02:19<08:09,  1.34s/it] 23%|██▎       | 107/471 [02:20<08:07,  1.34s/it] 23%|██▎       | 108/471 [02:22<08:06,  1.34s/it] 23%|██▎       | 109/471 [02:23<08:04,  1.34s/it] 23%|██▎       | 110/471 [02:24<08:01,  1.33s/it] 24%|██▎       | 111/471 [02:26<08:01,  1.34s/it] 24%|██▍       | 112/471 [02:27<07:59,  1.34s/it] 24%|██▍       | 113/471 [02:28<07:58,  1.34s/it] 24%|██▍       | 114/471 [02:30<07:57,  1.34s/it] 24%|██▍       | 115/471 [02:31<07:56,  1.34s/it] 25%|██▍       | 116/471 [02:32<07:54,  1.34s/it] 25%|██▍       | 117/471 [02:34<07:53,  1.34s/it] 25%|██▌       | 118/471 [02:35<07:52,  1.34s/it] 25%|██▌       | 119/471 [02:36<07:50,  1.34s/it] 25%|██▌       | 120/471 [02:38<07:49,  1.34s/it] 26%|██▌       | 121/471 [02:39<07:47,  1.34s/it] 26%|██▌       | 122/471 [02:40<07:46,  1.34s/it] 26%|██▌       | 123/471 [02:42<07:45,  1.34s/it] 26%|██▋       | 124/471 [02:43<07:43,  1.34s/it] 27%|██▋       | 125/471 [02:44<07:42,  1.34s/it] 27%|██▋       | 126/471 [02:46<07:40,  1.34s/it] 27%|██▋       | 127/471 [02:47<07:39,  1.34s/it] 27%|██▋       | 128/471 [02:48<07:37,  1.33s/it] 27%|██▋       | 129/471 [02:50<07:35,  1.33s/it] 28%|██▊       | 130/471 [02:51<07:34,  1.33s/it] 28%|██▊       | 131/471 [02:52<07:33,  1.33s/it] 28%|██▊       | 132/471 [02:54<07:31,  1.33s/it] 28%|██▊       | 133/471 [02:55<07:30,  1.33s/it] 28%|██▊       | 134/471 [02:56<07:29,  1.33s/it] 29%|██▊       | 135/471 [02:58<07:27,  1.33s/it] 29%|██▉       | 136/471 [02:59<07:26,  1.33s/it] 29%|██▉       | 137/471 [03:00<07:25,  1.33s/it] 29%|██▉       | 138/471 [03:02<07:23,  1.33s/it] 30%|██▉       | 139/471 [03:03<07:22,  1.33s/it] 30%|██▉       | 140/471 [03:04<07:21,  1.33s/it] 30%|██▉       | 141/471 [03:06<07:19,  1.33s/it] 30%|███       | 142/471 [03:07<07:18,  1.33s/it] 30%|███       | 143/471 [03:08<07:16,  1.33s/it] 31%|███       | 144/471 [03:10<07:15,  1.33s/it] 31%|███       | 145/471 [03:11<07:13,  1.33s/it] 31%|███       | 146/471 [03:12<07:12,  1.33s/it] 31%|███       | 147/471 [03:14<07:11,  1.33s/it] 31%|███▏      | 148/471 [03:15<07:10,  1.33s/it] 32%|███▏      | 149/471 [03:16<07:09,  1.33s/it] 32%|███▏      | 150/471 [03:18<07:07,  1.33s/it] 32%|███▏      | 151/471 [03:19<07:06,  1.33s/it] 32%|███▏      | 152/471 [03:20<07:04,  1.33s/it] 32%|███▏      | 153/471 [03:22<07:03,  1.33s/it] 33%|███▎      | 154/471 [03:23<07:01,  1.33s/it] 33%|███▎      | 155/471 [03:24<07:00,  1.33s/it] 33%|███▎      | 156/471 [03:26<06:59,  1.33s/it] 33%|███▎      | 157/471 [03:27<06:57,  1.33s/it] 34%|███▎      | 158/471 [03:28<06:55,  1.33s/it] 34%|███▍      | 159/471 [03:30<06:53,  1.33s/it] 34%|███▍      | 160/471 [03:31<06:53,  1.33s/it] 34%|███▍      | 161/471 [03:32<06:52,  1.33s/it] 34%|███▍      | 162/471 [03:34<06:51,  1.33s/it] 35%|███▍      | 163/471 [03:35<06:50,  1.33s/it] 35%|███▍      | 164/471 [03:36<06:48,  1.33s/it] 35%|███▌      | 165/471 [03:38<06:47,  1.33s/it] 35%|███▌      | 166/471 [03:39<06:45,  1.33s/it] 35%|███▌      | 167/471 [03:40<06:44,  1.33s/it] 36%|███▌      | 168/471 [03:42<06:43,  1.33s/it] 36%|███▌      | 169/471 [03:43<06:42,  1.33s/it] 36%|███▌      | 170/471 [03:44<06:40,  1.33s/it] 36%|███▋      | 171/471 [03:46<06:39,  1.33s/it] 37%|███▋      | 172/471 [03:47<06:37,  1.33s/it] 37%|███▋      | 173/471 [03:48<06:36,  1.33s/it] 37%|███▋      | 174/471 [03:50<06:35,  1.33s/it] 37%|███▋      | 175/471 [03:51<06:34,  1.33s/it] 37%|███▋      | 176/471 [03:52<06:32,  1.33s/it] 38%|███▊      | 177/471 [03:54<06:31,  1.33s/it] 38%|███▊      | 178/471 [03:55<06:29,  1.33s/it] 38%|███▊      | 179/471 [03:56<06:27,  1.33s/it] 38%|███▊      | 180/471 [03:58<06:26,  1.33s/it] 38%|███▊      | 181/471 [03:59<06:24,  1.33s/it] 39%|███▊      | 182/471 [04:00<06:23,  1.33s/it] 39%|███▉      | 183/471 [04:02<06:22,  1.33s/it] 39%|███▉      | 184/471 [04:03<06:20,  1.33s/it] 39%|███▉      | 185/471 [04:04<06:19,  1.33s/it] 39%|███▉      | 186/471 [04:06<06:18,  1.33s/it] 40%|███▉      | 187/471 [04:07<06:17,  1.33s/it] 40%|███▉      | 188/471 [04:08<06:16,  1.33s/it] 40%|████      | 189/471 [04:10<06:14,  1.33s/it] 40%|████      | 190/471 [04:11<06:12,  1.33s/it] 41%|████      | 191/471 [04:12<06:11,  1.33s/it] 41%|████      | 192/471 [04:14<06:10,  1.33s/it] 41%|████      | 193/471 [04:15<06:08,  1.33s/it] 41%|████      | 194/471 [04:16<06:07,  1.33s/it] 41%|████▏     | 195/471 [04:18<06:06,  1.33s/it] 42%|████▏     | 196/471 [04:19<06:04,  1.33s/it] 42%|████▏     | 197/471 [04:20<06:02,  1.32s/it] 42%|████▏     | 198/471 [04:22<06:01,  1.32s/it] 42%|████▏     | 199/471 [04:23<06:00,  1.33s/it] 42%|████▏     | 200/471 [04:24<05:59,  1.33s/it] 43%|████▎     | 201/471 [04:26<05:57,  1.32s/it] 43%|████▎     | 202/471 [04:27<05:56,  1.33s/it] 43%|████▎     | 203/471 [04:28<05:55,  1.33s/it] 43%|████▎     | 204/471 [04:30<05:54,  1.33s/it] 44%|████▎     | 205/471 [04:31<05:52,  1.32s/it] 44%|████▎     | 206/471 [04:32<05:51,  1.32s/it] 44%|████▍     | 207/471 [04:34<05:50,  1.33s/it] 44%|████▍     | 208/471 [04:35<05:48,  1.32s/it] 44%|████▍     | 209/471 [04:36<05:47,  1.32s/it] 45%|████▍     | 210/471 [04:37<05:45,  1.33s/it] 45%|████▍     | 211/471 [04:39<05:44,  1.33s/it] 45%|████▌     | 212/471 [04:40<05:43,  1.32s/it] 45%|████▌     | 213/471 [04:41<05:41,  1.33s/it] 45%|████▌     | 214/471 [04:43<05:40,  1.32s/it] 46%|████▌     | 215/471 [04:44<05:38,  1.32s/it] 46%|████▌     | 216/471 [04:45<05:38,  1.33s/it] 46%|████▌     | 217/471 [04:47<05:37,  1.33s/it] 46%|████▋     | 218/471 [04:48<05:35,  1.33s/it] 46%|████▋     | 219/471 [04:49<05:34,  1.33s/it] 47%|████▋     | 220/471 [04:51<05:33,  1.33s/it] 47%|████▋     | 221/471 [04:52<05:32,  1.33s/it] 47%|████▋     | 222/471 [04:53<05:30,  1.33s/it] 47%|████▋     | 223/471 [04:55<05:29,  1.33s/it] 48%|████▊     | 224/471 [04:56<05:27,  1.33s/it] 48%|████▊     | 225/471 [04:57<05:26,  1.33s/it] 48%|████▊     | 226/471 [04:59<05:25,  1.33s/it] 48%|████▊     | 227/471 [05:00<05:23,  1.33s/it] 48%|████▊     | 228/471 [05:01<05:23,  1.33s/it] 49%|████▊     | 229/471 [05:03<05:21,  1.33s/it] 49%|████▉     | 230/471 [05:04<05:20,  1.33s/it] 49%|████▉     | 231/471 [05:05<05:19,  1.33s/it] 49%|████▉     | 232/471 [05:07<05:17,  1.33s/it] 49%|████▉     | 233/471 [05:08<05:16,  1.33s/it] 50%|████▉     | 234/471 [05:09<05:15,  1.33s/it] 50%|████▉     | 235/471 [05:11<05:14,  1.33s/it] 50%|█████     | 236/471 [05:12<05:12,  1.33s/it] 50%|█████     | 237/471 [05:13<05:11,  1.33s/it] 51%|█████     | 238/471 [05:15<05:10,  1.33s/it] 51%|█████     | 239/471 [05:16<05:09,  1.33s/it] 51%|█████     | 240/471 [05:17<05:07,  1.33s/it] 51%|█████     | 241/471 [05:19<05:06,  1.33s/it] 51%|█████▏    | 242/471 [05:20<05:05,  1.33s/it] 52%|█████▏    | 243/471 [05:21<05:03,  1.33s/it] 52%|█████▏    | 244/471 [05:23<05:02,  1.33s/it] 52%|█████▏    | 245/471 [05:24<05:01,  1.33s/it] 52%|█████▏    | 246/471 [05:25<04:59,  1.33s/it] 52%|█████▏    | 247/471 [05:27<04:58,  1.33s/it] 53%|█████▎    | 248/471 [05:28<04:57,  1.33s/it] 53%|█████▎    | 249/471 [05:29<04:56,  1.34s/it] 53%|█████▎    | 250/471 [05:31<04:54,  1.33s/it] 53%|█████▎    | 251/471 [05:32<04:53,  1.33s/it] 54%|█████▎    | 252/471 [05:33<04:52,  1.33s/it] 54%|█████▎    | 253/471 [05:35<04:51,  1.34s/it] 54%|█████▍    | 254/471 [05:36<04:50,  1.34s/it] 54%|█████▍    | 255/471 [05:37<04:48,  1.34s/it] 54%|█████▍    | 256/471 [05:39<04:47,  1.33s/it] 55%|█████▍    | 257/471 [05:40<04:45,  1.34s/it] 55%|█████▍    | 258/471 [05:41<04:44,  1.34s/it] 55%|█████▍    | 259/471 [05:43<04:43,  1.34s/it] 55%|█████▌    | 260/471 [05:44<04:42,  1.34s/it] 55%|█████▌    | 261/471 [05:45<04:40,  1.34s/it] 56%|█████▌    | 262/471 [05:47<04:39,  1.34s/it] 56%|█████▌    | 263/471 [05:48<04:38,  1.34s/it] 56%|█████▌    | 264/471 [05:49<04:36,  1.34s/it] 56%|█████▋    | 265/471 [05:51<04:35,  1.34s/it] 56%|█████▋    | 266/471 [05:52<04:34,  1.34s/it] 57%|█████▋    | 267/471 [05:53<04:33,  1.34s/it] 57%|█████▋    | 268/471 [05:55<04:32,  1.34s/it] 57%|█████▋    | 269/471 [05:56<04:31,  1.34s/it] 57%|█████▋    | 270/471 [05:57<04:29,  1.34s/it] 58%|█████▊    | 271/471 [05:59<04:28,  1.34s/it] 58%|█████▊    | 272/471 [06:00<04:26,  1.34s/it] 58%|█████▊    | 273/471 [06:01<04:25,  1.34s/it] 58%|█████▊    | 274/471 [06:03<04:23,  1.34s/it] 58%|█████▊    | 275/471 [06:04<04:22,  1.34s/it] 59%|█████▊    | 276/471 [06:05<04:21,  1.34s/it] 59%|█████▉    | 277/471 [06:07<04:19,  1.34s/it] 59%|█████▉    | 278/471 [06:08<04:18,  1.34s/it] 59%|█████▉    | 279/471 [06:10<04:16,  1.34s/it] 59%|█████▉    | 280/471 [06:11<04:15,  1.34s/it] 60%|█████▉    | 281/471 [06:12<04:14,  1.34s/it] 60%|█████▉    | 282/471 [06:14<04:12,  1.34s/it] 60%|██████    | 283/471 [06:15<04:11,  1.34s/it] 60%|██████    | 284/471 [06:16<04:10,  1.34s/it] 61%|██████    | 285/471 [06:18<04:09,  1.34s/it] 61%|██████    | 286/471 [06:19<04:07,  1.34s/it] 61%|██████    | 287/471 [06:20<04:06,  1.34s/it] 61%|██████    | 288/471 [06:22<04:05,  1.34s/it] 61%|██████▏   | 289/471 [06:23<04:03,  1.34s/it] 62%|██████▏   | 290/471 [06:24<04:01,  1.34s/it] 62%|██████▏   | 291/471 [06:26<04:00,  1.33s/it] 62%|██████▏   | 292/471 [06:27<03:58,  1.33s/it] 62%|██████▏   | 293/471 [06:28<03:57,  1.33s/it] 62%|██████▏   | 294/471 [06:30<03:55,  1.33s/it] 63%|██████▎   | 295/471 [06:31<03:54,  1.33s/it] 63%|██████▎   | 296/471 [06:32<03:53,  1.33s/it] 63%|██████▎   | 297/471 [06:34<03:51,  1.33s/it] 63%|██████▎   | 298/471 [06:35<03:50,  1.33s/it] 63%|██████▎   | 299/471 [06:36<03:49,  1.33s/it] 64%|██████▎   | 300/471 [06:38<03:47,  1.33s/it] 64%|██████▍   | 301/471 [06:39<03:46,  1.33s/it] 64%|██████▍   | 302/471 [06:40<03:45,  1.33s/it] 64%|██████▍   | 303/471 [06:42<03:43,  1.33s/it] 65%|██████▍   | 304/471 [06:43<03:42,  1.33s/it] 65%|██████▍   | 305/471 [06:44<03:40,  1.33s/it] 65%|██████▍   | 306/471 [06:46<03:39,  1.33s/it] 65%|██████▌   | 307/471 [06:47<03:38,  1.33s/it] 65%|██████▌   | 308/471 [06:48<03:37,  1.33s/it] 66%|██████▌   | 309/471 [06:50<03:35,  1.33s/it] 66%|██████▌   | 310/471 [06:51<03:34,  1.33s/it] 66%|██████▌   | 311/471 [06:52<03:32,  1.33s/it] 66%|██████▌   | 312/471 [06:54<03:31,  1.33s/it] 66%|██████▋   | 313/471 [06:55<03:29,  1.33s/it] 67%|██████▋   | 314/471 [06:56<03:28,  1.33s/it] 67%|██████▋   | 315/471 [06:57<03:26,  1.33s/it] 67%|██████▋   | 316/471 [06:59<03:25,  1.33s/it] 67%|██████▋   | 317/471 [07:00<03:24,  1.33s/it] 68%|██████▊   | 318/471 [07:01<03:23,  1.33s/it] 68%|██████▊   | 319/471 [07:03<03:21,  1.33s/it] 68%|██████▊   | 320/471 [07:04<03:20,  1.33s/it] 68%|██████▊   | 321/471 [07:05<03:19,  1.33s/it] 68%|██████▊   | 322/471 [07:07<03:17,  1.33s/it] 69%|██████▊   | 323/471 [07:08<03:16,  1.33s/it] 69%|██████▉   | 324/471 [07:09<03:15,  1.33s/it] 69%|██████▉   | 325/471 [07:11<03:14,  1.33s/it] 69%|██████▉   | 326/471 [07:12<03:12,  1.33s/it] 69%|██████▉   | 327/471 [07:13<03:11,  1.33s/it] 70%|██████▉   | 328/471 [07:15<03:09,  1.33s/it] 70%|██████▉   | 329/471 [07:16<03:08,  1.33s/it] 70%|███████   | 330/471 [07:17<03:06,  1.33s/it] 70%|███████   | 331/471 [07:19<03:05,  1.33s/it] 70%|███████   | 332/471 [07:20<03:04,  1.33s/it] 71%|███████   | 333/471 [07:21<03:03,  1.33s/it] 71%|███████   | 334/471 [07:23<03:01,  1.33s/it] 71%|███████   | 335/471 [07:24<03:00,  1.33s/it] 71%|███████▏  | 336/471 [07:25<02:59,  1.33s/it] 72%|███████▏  | 337/471 [07:27<02:57,  1.33s/it] 72%|███████▏  | 338/471 [07:28<02:56,  1.32s/it] 72%|███████▏  | 339/471 [07:29<02:55,  1.33s/it] 72%|███████▏  | 340/471 [07:31<02:53,  1.33s/it] 72%|███████▏  | 341/471 [07:32<02:52,  1.32s/it] 73%|███████▎  | 342/471 [07:33<02:50,  1.32s/it] 73%|███████▎  | 343/471 [07:35<02:49,  1.33s/it] 73%|███████▎  | 344/471 [07:36<02:48,  1.32s/it] 73%|███████▎  | 345/471 [07:37<02:46,  1.33s/it] 73%|███████▎  | 346/471 [07:39<02:45,  1.33s/it] 74%|███████▎  | 347/471 [07:40<02:44,  1.32s/it] 74%|███████▍  | 348/471 [07:41<02:42,  1.32s/it] 74%|███████▍  | 349/471 [07:43<02:41,  1.33s/it] 74%|███████▍  | 350/471 [07:44<02:40,  1.33s/it] 75%|███████▍  | 351/471 [07:45<02:38,  1.32s/it] 75%|███████▍  | 352/471 [07:47<02:37,  1.32s/it] 75%|███████▍  | 353/471 [07:48<02:36,  1.33s/it] 75%|███████▌  | 354/471 [07:49<02:35,  1.33s/it] 75%|███████▌  | 355/471 [07:51<02:33,  1.33s/it] 76%|███████▌  | 356/471 [07:52<02:32,  1.33s/it] 76%|███████▌  | 357/471 [07:53<02:31,  1.33s/it] 76%|███████▌  | 358/471 [07:55<02:29,  1.33s/it] 76%|███████▌  | 359/471 [07:56<02:28,  1.33s/it] 76%|███████▋  | 360/471 [07:57<02:27,  1.33s/it] 77%|███████▋  | 361/471 [07:59<02:25,  1.33s/it] 77%|███████▋  | 362/471 [08:00<02:24,  1.33s/it] 77%|███████▋  | 363/471 [08:01<02:22,  1.32s/it] 77%|███████▋  | 364/471 [08:02<02:21,  1.32s/it] 77%|███████▋  | 365/471 [08:04<02:20,  1.32s/it] 78%|███████▊  | 366/471 [08:05<02:19,  1.33s/it] 78%|███████▊  | 367/471 [08:06<02:17,  1.33s/it] 78%|███████▊  | 368/471 [08:08<02:16,  1.32s/it] 78%|███████▊  | 369/471 [08:09<02:14,  1.32s/it] 79%|███████▊  | 370/471 [08:10<02:13,  1.32s/it] 79%|███████▉  | 371/471 [08:12<02:12,  1.32s/it] 79%|███████▉  | 372/471 [08:13<02:11,  1.32s/it] 79%|███████▉  | 373/471 [08:14<02:09,  1.33s/it] 79%|███████▉  | 374/471 [08:16<02:08,  1.32s/it] 80%|███████▉  | 375/471 [08:17<02:06,  1.32s/it] 80%|███████▉  | 376/471 [08:18<02:05,  1.32s/it] 80%|████████  | 377/471 [08:20<02:04,  1.32s/it] 80%|████████  | 378/471 [08:21<02:02,  1.32s/it] 80%|████████  | 379/471 [08:22<02:01,  1.32s/it] 81%|████████  | 380/471 [08:24<02:00,  1.32s/it] 81%|████████  | 381/471 [08:25<01:59,  1.32s/it] 81%|████████  | 382/471 [08:26<01:57,  1.32s/it] 81%|████████▏ | 383/471 [08:28<01:56,  1.32s/it] 82%|████████▏ | 384/471 [08:29<01:55,  1.32s/it] 82%|████████▏ | 385/471 [08:30<01:53,  1.32s/it] 82%|████████▏ | 386/471 [08:32<01:52,  1.32s/it] 82%|████████▏ | 387/471 [08:33<01:51,  1.32s/it] 82%|████████▏ | 388/471 [08:34<01:49,  1.32s/it] 83%|████████▎ | 389/471 [08:36<01:48,  1.32s/it] 83%|████████▎ | 390/471 [08:37<01:47,  1.32s/it] 83%|████████▎ | 391/471 [08:38<01:45,  1.32s/it] 83%|████████▎ | 392/471 [08:40<01:44,  1.32s/it] 83%|████████▎ | 393/471 [08:41<01:43,  1.32s/it] 84%|████████▎ | 394/471 [08:42<01:41,  1.32s/it] 84%|████████▍ | 395/471 [08:43<01:40,  1.32s/it] 84%|████████▍ | 396/471 [08:45<01:39,  1.32s/it] 84%|████████▍ | 397/471 [08:46<01:37,  1.32s/it] 85%|████████▍ | 398/471 [08:47<01:36,  1.32s/it] 85%|████████▍ | 399/471 [08:49<01:35,  1.32s/it] 85%|████████▍ | 400/471 [08:50<01:33,  1.32s/it] 85%|████████▌ | 401/471 [08:51<01:32,  1.32s/it] 85%|████████▌ | 402/471 [08:53<01:30,  1.32s/it] 86%|████████▌ | 403/471 [08:54<01:29,  1.32s/it] 86%|████████▌ | 404/471 [08:55<01:28,  1.31s/it] 86%|████████▌ | 405/471 [08:57<01:26,  1.32s/it] 86%|████████▌ | 406/471 [08:58<01:25,  1.32s/it] 86%|████████▋ | 407/471 [08:59<01:24,  1.31s/it] 87%|████████▋ | 408/471 [09:01<01:22,  1.32s/it] 87%|████████▋ | 409/471 [09:02<01:21,  1.32s/it] 87%|████████▋ | 410/471 [09:03<01:20,  1.31s/it] 87%|████████▋ | 411/471 [09:05<01:18,  1.31s/it] 87%|████████▋ | 412/471 [09:06<01:17,  1.32s/it] 88%|████████▊ | 413/471 [09:07<01:16,  1.32s/it] 88%|████████▊ | 414/471 [09:08<01:14,  1.32s/it] 88%|████████▊ | 415/471 [09:10<01:13,  1.31s/it] 88%|████████▊ | 416/471 [09:11<01:12,  1.32s/it] 89%|████████▊ | 417/471 [09:12<01:11,  1.32s/it] 89%|████████▊ | 418/471 [09:14<01:09,  1.32s/it] 89%|████████▉ | 419/471 [09:15<01:08,  1.32s/it] 89%|████████▉ | 420/471 [09:16<01:07,  1.31s/it] 89%|████████▉ | 421/471 [09:18<01:05,  1.31s/it] 90%|████████▉ | 422/471 [09:19<01:04,  1.31s/it] 90%|████████▉ | 423/471 [09:20<01:03,  1.31s/it] 90%|█████████ | 424/471 [09:22<01:01,  1.31s/it] 90%|█████████ | 425/471 [09:23<01:00,  1.31s/it] 90%|█████████ | 426/471 [09:24<00:59,  1.32s/it] 91%|█████████ | 427/471 [09:26<00:57,  1.32s/it] 91%|█████████ | 428/471 [09:27<00:56,  1.32s/it] 91%|█████████ | 429/471 [09:28<00:55,  1.32s/it] 91%|█████████▏| 430/471 [09:30<00:53,  1.32s/it] 92%|█████████▏| 431/471 [09:31<00:52,  1.32s/it] 92%|█████████▏| 432/471 [09:32<00:51,  1.32s/it] 92%|█████████▏| 433/471 [09:33<00:50,  1.32s/it] 92%|█████████▏| 434/471 [09:35<00:48,  1.32s/it] 92%|█████████▏| 435/471 [09:36<00:47,  1.32s/it] 93%|█████████▎| 436/471 [09:37<00:46,  1.32s/it] 93%|█████████▎| 437/471 [09:39<00:44,  1.32s/it] 93%|█████████▎| 438/471 [09:40<00:43,  1.32s/it] 93%|█████████▎| 439/471 [09:41<00:42,  1.32s/it] 93%|█████████▎| 440/471 [09:43<00:40,  1.32s/it] 94%|█████████▎| 441/471 [09:44<00:39,  1.32s/it] 94%|█████████▍| 442/471 [09:45<00:38,  1.32s/it] 94%|█████████▍| 443/471 [09:47<00:36,  1.32s/it] 94%|█████████▍| 444/471 [09:48<00:35,  1.32s/it] 94%|█████████▍| 445/471 [09:49<00:34,  1.32s/it] 95%|█████████▍| 446/471 [09:51<00:32,  1.32s/it] 95%|█████████▍| 447/471 [09:52<00:31,  1.32s/it] 95%|█████████▌| 448/471 [09:53<00:30,  1.32s/it] 95%|█████████▌| 449/471 [09:55<00:29,  1.32s/it] 96%|█████████▌| 450/471 [09:56<00:27,  1.32s/it] 96%|█████████▌| 451/471 [09:57<00:26,  1.32s/it] 96%|█████████▌| 452/471 [09:59<00:25,  1.32s/it] 96%|█████████▌| 453/471 [10:00<00:23,  1.32s/it] 96%|█████████▋| 454/471 [10:01<00:22,  1.33s/it] 97%|█████████▋| 455/471 [10:03<00:21,  1.33s/it] 97%|█████████▋| 456/471 [10:04<00:19,  1.32s/it] 97%|█████████▋| 457/471 [10:05<00:18,  1.33s/it] 97%|█████████▋| 458/471 [10:07<00:17,  1.33s/it] 97%|█████████▋| 459/471 [10:08<00:15,  1.33s/it] 98%|█████████▊| 460/471 [10:09<00:14,  1.33s/it] 98%|█████████▊| 461/471 [10:11<00:13,  1.33s/it] 98%|█████████▊| 462/471 [10:12<00:11,  1.33s/it] 98%|█████████▊| 463/471 [10:13<00:10,  1.33s/it] 99%|█████████▊| 464/471 [10:14<00:09,  1.33s/it] 99%|█████████▊| 465/471 [10:16<00:07,  1.33s/it] 99%|█████████▉| 466/471 [10:17<00:06,  1.33s/it] 99%|█████████▉| 467/471 [10:18<00:05,  1.33s/it] 99%|█████████▉| 468/471 [10:20<00:03,  1.33s/it]100%|█████████▉| 469/471 [10:21<00:02,  1.33s/it]100%|█████████▉| 470/471 [10:22<00:01,  1.33s/it]100%|██████████| 471/471 [10:23<00:00,  1.22s/it]100%|██████████| 471/471 [10:23<00:00,  1.32s/it]
{'eval_loss': 4.655346393585205, 'eval_model_preparation_time': 0.0124, 'eval_acc': 0.14617631439192777, 'eval_runtime': 625.1801, 'eval_samples_per_second': 12.048, 'eval_steps_per_second': 0.753}
ROUND:5
CLIENT:79
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:39,  2.54s/it]                                              {'loss': 4.4173, 'grad_norm': 7.526424407958984, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:39,  2.54s/it]  5%|▌         | 2/40 [00:04<01:27,  2.32s/it]                                              {'loss': 3.6996, 'grad_norm': 5.959280967712402, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:27,  2.32s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 4.9325, 'grad_norm': 9.146950721740723, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 2.868, 'grad_norm': 6.853351593017578, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 3.2483, 'grad_norm': 9.749162673950195, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 2.8554, 'grad_norm': 8.9432954788208, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 3.3129, 'grad_norm': 13.882184028625488, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 3.198, 'grad_norm': 51.815895080566406, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 1.9894, 'grad_norm': 10.087897300720215, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it]                                               {'loss': 0.7121, 'grad_norm': 5.379446506500244, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.7161, 'grad_norm': 5.266289710998535, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.7689, 'grad_norm': 4.957636833190918, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it]                                               {'loss': 0.9226, 'grad_norm': 6.297505855560303, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 1.1427, 'grad_norm': 5.4759111404418945, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 1.2905, 'grad_norm': 9.042694091796875, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0836, 'grad_norm': 2.6281678676605225, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.2558, 'grad_norm': 22.161073684692383, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it]                                               {'loss': 0.456, 'grad_norm': 4.5393595695495605, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it]                                               {'loss': 1.0606, 'grad_norm': 10.5563383102417, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.3325, 'grad_norm': 3.4947104454040527, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.2391, 'grad_norm': 2.90531063079834, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.4441, 'grad_norm': 5.9657697677612305, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.2187, 'grad_norm': 2.9039433002471924, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0107, 'grad_norm': 0.849234938621521, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0758, 'grad_norm': 0.7070711255073547, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.1001, 'grad_norm': 2.1338558197021484, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it]                                               {'loss': 0.1651, 'grad_norm': 2.7857916355133057, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.7236, 'grad_norm': 3.9258675575256348, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.2181, 'grad_norm': 13.036999702453613, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.0798, 'grad_norm': 1.4877476692199707, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.0547, 'grad_norm': 0.8926762342453003, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.1527, 'grad_norm': 42.62360382080078, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.1483, 'grad_norm': 4.01333475112915, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.0693, 'grad_norm': 1.9520444869995117, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.806, 'grad_norm': 16.49128532409668, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.064, 'grad_norm': 1.022200584411621, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.1725, 'grad_norm': 3.574291229248047, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 0.3227, 'grad_norm': 5.253602504730225, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]                                               {'loss': 0.1568, 'grad_norm': 4.574280738830566, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.5105, 'grad_norm': 28.19632911682129, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.626, 'train_samples_per_second': 7.096, 'train_steps_per_second': 0.502, 'train_loss': 1.074888789933175, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:75
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:03<01:58,  3.03s/it]                                              {'loss': 5.4641, 'grad_norm': 4.936936378479004, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:03<01:58,  3.03s/it]  5%|▌         | 2/40 [00:05<01:34,  2.50s/it]                                              {'loss': 4.0485, 'grad_norm': 5.497087001800537, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:34,  2.50s/it]  8%|▊         | 3/40 [00:07<01:26,  2.34s/it]                                              {'loss': 2.6658, 'grad_norm': 6.742347240447998, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:26,  2.34s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 2.5508, 'grad_norm': 19.59793472290039, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 2.9781, 'grad_norm': 8.150347709655762, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 2.9996, 'grad_norm': 9.436019897460938, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 3.1113, 'grad_norm': 24.937213897705078, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:16<00:49,  1.56s/it]                                              {'loss': 2.8997, 'grad_norm': 86.51925659179688, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 1.126, 'grad_norm': 8.775346755981445, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 1.2739, 'grad_norm': 12.608980178833008, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 1.7334, 'grad_norm': 7.194612503051758, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:56,  2.03s/it]                                               {'loss': 1.0438, 'grad_norm': 6.526381015777588, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:56,  2.03s/it] 32%|███▎      | 13/40 [00:27<00:55,  2.06s/it]                                               {'loss': 2.2333, 'grad_norm': 5.831928730010986, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:55,  2.06s/it] 35%|███▌      | 14/40 [00:29<00:54,  2.11s/it]                                               {'loss': 1.322, 'grad_norm': 6.662422180175781, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:54,  2.11s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.13s/it]                                               {'loss': 1.9112, 'grad_norm': 17.01424217224121, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.13s/it] 40%|████      | 16/40 [00:31<00:37,  1.54s/it]                                               {'loss': 1.43, 'grad_norm': 39.234901428222656, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.54s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it]                                               {'loss': 0.3451, 'grad_norm': 14.657934188842773, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.3595, 'grad_norm': 3.8397531509399414, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 1.0387, 'grad_norm': 5.5435075759887695, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.7352, 'grad_norm': 5.644266128540039, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:39,  2.09s/it]                                               {'loss': 0.7789, 'grad_norm': 4.853238582611084, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:39,  2.09s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 0.4294, 'grad_norm': 2.9488449096679688, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:47<00:36,  2.15s/it]                                               {'loss': 0.2271, 'grad_norm': 66.00897979736328, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:36,  2.15s/it] 60%|██████    | 24/40 [00:47<00:24,  1.56s/it]                                               {'loss': 0.5791, 'grad_norm': 12.576229095458984, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:24,  1.56s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.75s/it]                                               {'loss': 0.7617, 'grad_norm': 8.337260246276855, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.75s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it]                                               {'loss': 0.9136, 'grad_norm': 8.946494102478027, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it]                                               {'loss': 0.4829, 'grad_norm': 4.8214802742004395, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it] 70%|███████   | 28/40 [00:56<00:24,  2.06s/it]                                               {'loss': 0.2813, 'grad_norm': 2.5054314136505127, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.06s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.11s/it]                                               {'loss': 0.2374, 'grad_norm': 4.0709686279296875, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.11s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.15s/it]                                               {'loss': 0.1918, 'grad_norm': 7.024102210998535, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.15s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.17s/it]                                               {'loss': 0.4633, 'grad_norm': 4.363255023956299, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.17s/it] 80%|████████  | 32/40 [01:03<00:12,  1.57s/it]                                               {'loss': 0.0032, 'grad_norm': 0.17472916841506958, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.57s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it]                                               {'loss': 0.1339, 'grad_norm': 3.418379783630371, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it]                                               {'loss': 0.6787, 'grad_norm': 12.041431427001953, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.01s/it]                                               {'loss': 0.0892, 'grad_norm': 1.8746397495269775, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.01s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.07s/it]                                               {'loss': 0.0855, 'grad_norm': 1.3880856037139893, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.07s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.11s/it]                                               {'loss': 0.0543, 'grad_norm': 0.8819580674171448, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.11s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it]                                               {'loss': 0.5008, 'grad_norm': 34.635475158691406, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]                                               {'loss': 0.1883, 'grad_norm': 4.099185466766357, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'loss': 0.0173, 'grad_norm': 0.7251511812210083, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'train_runtime': 79.1717, 'train_samples_per_second': 7.136, 'train_steps_per_second': 0.505, 'train_loss': 1.209188714332413, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.63s/it]                                              {'loss': 4.3568, 'grad_norm': 6.3683342933654785, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.63s/it]  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]                                              {'loss': 2.8194, 'grad_norm': 3.798835277557373, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]  8%|▊         | 3/40 [00:06<01:23,  2.24s/it]                                              {'loss': 2.9014, 'grad_norm': 5.786239147186279, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.24s/it] 10%|█         | 4/40 [00:09<01:19,  2.20s/it]                                              {'loss': 4.0349, 'grad_norm': 4.947232246398926, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it]                                              {'loss': 1.7188, 'grad_norm': 18.86897087097168, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 3.9004, 'grad_norm': 9.774035453796387, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 3.0858, 'grad_norm': 7.91428279876709, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 5.902, 'grad_norm': 30.012046813964844, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 1.447, 'grad_norm': 9.429640769958496, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.3246, 'grad_norm': 5.89329195022583, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.1039, 'grad_norm': 6.545355796813965, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 1.4429, 'grad_norm': 6.184159278869629, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:55,  2.07s/it]                                               {'loss': 1.3895, 'grad_norm': 6.00623083114624, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:55,  2.07s/it] 35%|███▌      | 14/40 [00:28<00:54,  2.11s/it]                                               {'loss': 1.8417, 'grad_norm': 5.8352484703063965, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:54,  2.11s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it]                                               {'loss': 0.9796, 'grad_norm': 3.765167474746704, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 6.3686, 'grad_norm': 26.305971145629883, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.74s/it]                                               {'loss': 0.2143, 'grad_norm': 1.32052481174469, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.74s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it]                                               {'loss': 1.0329, 'grad_norm': 7.3339643478393555, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.07s/it]                                               {'loss': 0.4399, 'grad_norm': 4.800215721130371, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.07s/it] 50%|█████     | 20/40 [00:40<00:42,  2.11s/it]                                               {'loss': 0.6061, 'grad_norm': 2.391340970993042, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.5797, 'grad_norm': 4.369178771972656, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it]                                               {'loss': 0.4388, 'grad_norm': 2.7099523544311523, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.5734, 'grad_norm': 4.713888645172119, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.5679, 'grad_norm': 18.461557388305664, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it]                                               {'loss': 0.165, 'grad_norm': 3.139137029647827, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.6835, 'grad_norm': 3.817770481109619, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it]                                               {'loss': 0.0918, 'grad_norm': 1.5151877403259277, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.2036, 'grad_norm': 2.436195135116577, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.2623, 'grad_norm': 3.719609498977661, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.1833, 'grad_norm': 4.414625644683838, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.3589, 'grad_norm': 5.304562568664551, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.1848, 'grad_norm': 12.232841491699219, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.2022, 'grad_norm': 4.6688408851623535, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.2014, 'grad_norm': 3.965939998626709, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.0681, 'grad_norm': 0.9922700524330139, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.362, 'grad_norm': 6.475253105163574, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.2229, 'grad_norm': 2.5261309146881104, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.20s/it]                                               {'loss': 0.1164, 'grad_norm': 2.6029415130615234, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.058, 'grad_norm': 0.8727364540100098, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.0366, 'grad_norm': 1.8762191534042358, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 79.6272, 'train_samples_per_second': 7.096, 'train_steps_per_second': 0.502, 'train_loss': 1.3117738725617527, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:15
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]                                              {'loss': 4.7243, 'grad_norm': 4.319192886352539, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]                                              {'loss': 5.8113, 'grad_norm': 6.239791393280029, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]  8%|▊         | 3/40 [00:06<01:22,  2.22s/it]                                              {'loss': 3.4016, 'grad_norm': 6.808439254760742, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.22s/it] 10%|█         | 4/40 [00:08<01:20,  2.22s/it]                                              {'loss': 3.011, 'grad_norm': 7.807816982269287, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:20,  2.22s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 3.7024, 'grad_norm': 11.358210563659668, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 4.0734, 'grad_norm': 12.901618957519531, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it]                                              {'loss': 2.6267, 'grad_norm': 12.188921928405762, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 5.3776, 'grad_norm': 73.13645935058594, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 1.4424, 'grad_norm': 20.504161834716797, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 1.7544, 'grad_norm': 13.675113677978516, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 1.6407, 'grad_norm': 10.376675605773926, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 1.3697, 'grad_norm': 9.485017776489258, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 1.6869, 'grad_norm': 8.944348335266113, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 1.0361, 'grad_norm': 10.6884183883667, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.23s/it]                                               {'loss': 0.9799, 'grad_norm': 7.011491298675537, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.23s/it] 40%|████      | 16/40 [00:31<00:38,  1.62s/it]                                               {'loss': 1.3603, 'grad_norm': 21.11106300354004, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.62s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it]                                               {'loss': 1.1415, 'grad_norm': 6.6257710456848145, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it]                                               {'loss': 0.6629, 'grad_norm': 3.135744333267212, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it]                                               {'loss': 0.67, 'grad_norm': 4.676395893096924, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it] 50%|█████     | 20/40 [00:41<00:42,  2.13s/it]                                               {'loss': 0.8946, 'grad_norm': 5.962484836578369, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.13s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it]                                               {'loss': 0.486, 'grad_norm': 6.56566047668457, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it] 55%|█████▌    | 22/40 [00:45<00:40,  2.22s/it]                                               {'loss': 0.2987, 'grad_norm': 4.163260459899902, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:40,  2.22s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it]                                               {'loss': 0.6045, 'grad_norm': 5.024202823638916, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it] 60%|██████    | 24/40 [00:48<00:25,  1.62s/it]                                               {'loss': 0.0957, 'grad_norm': 3.4471614360809326, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it]                                               {'loss': 0.2334, 'grad_norm': 4.954525947570801, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.644, 'grad_norm': 11.567962646484375, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.08s/it]                                               {'loss': 0.4353, 'grad_norm': 34.81686782836914, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.08s/it] 70%|███████   | 28/40 [00:57<00:25,  2.16s/it]                                               {'loss': 0.2846, 'grad_norm': 32.842403411865234, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.16s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.20s/it]                                               {'loss': 0.4209, 'grad_norm': 7.827303409576416, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.20s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.23s/it]                                               {'loss': 0.1213, 'grad_norm': 3.11372447013855, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.23s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.26s/it]                                               {'loss': 0.6507, 'grad_norm': 5.021780490875244, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.26s/it] 80%|████████  | 32/40 [01:04<00:13,  1.64s/it]                                               {'loss': 0.0371, 'grad_norm': 2.2191643714904785, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.64s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it]                                               {'loss': 0.3376, 'grad_norm': 1.5225672721862793, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.99s/it]                                               {'loss': 0.3561, 'grad_norm': 1.078654170036316, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.99s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it]                                               {'loss': 0.0873, 'grad_norm': 1.5820801258087158, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.16s/it]                                               {'loss': 0.4073, 'grad_norm': 4.36895751953125, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.16s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.21s/it]                                               {'loss': 0.0912, 'grad_norm': 4.9608049392700195, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.21s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.24s/it]                                               {'loss': 0.072, 'grad_norm': 1.4575530290603638, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.24s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.27s/it]                                               {'loss': 0.5622, 'grad_norm': 10.405107498168945, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.27s/it]100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'loss': 0.0851, 'grad_norm': 5.169966220855713, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'train_runtime': 81.3009, 'train_samples_per_second': 6.949, 'train_steps_per_second': 0.492, 'train_loss': 1.3419752050191165, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.65s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
CLIENT:38
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:23,  2.14s/it]                                              {'loss': 5.3292, 'grad_norm': 5.403266429901123, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:23,  2.14s/it]  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]                                              {'loss': 5.2204, 'grad_norm': 6.011970520019531, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]  8%|▊         | 3/40 [00:06<01:20,  2.17s/it]                                              {'loss': 2.2637, 'grad_norm': 4.955080509185791, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.17s/it] 10%|█         | 4/40 [00:08<01:17,  2.16s/it]                                              {'loss': 2.1537, 'grad_norm': 5.681180477142334, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.16s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it]                                              {'loss': 3.8525, 'grad_norm': 9.562050819396973, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 3.1031, 'grad_norm': 9.695575714111328, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 2.8216, 'grad_norm': 11.503433227539062, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 0.1986, 'grad_norm': 7.037950038909912, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 2.3445, 'grad_norm': 24.316091537475586, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:19<00:57,  1.91s/it]                                               {'loss': 1.9716, 'grad_norm': 15.52480697631836, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.3005, 'grad_norm': 6.851027488708496, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.8598, 'grad_norm': 8.46435260772705, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it]                                               {'loss': 1.2275, 'grad_norm': 6.832248687744141, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it] 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it]                                               {'loss': 0.7294, 'grad_norm': 4.236196517944336, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 1.6255, 'grad_norm': 7.069286823272705, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 3.4923, 'grad_norm': 20.626632690429688, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.8278, 'grad_norm': 7.36842679977417, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.91s/it]                                               {'loss': 0.3701, 'grad_norm': 5.31062650680542, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.02s/it]                                               {'loss': 0.4941, 'grad_norm': 9.082136154174805, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 1.1057, 'grad_norm': 7.3763837814331055, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.8917, 'grad_norm': 10.310105323791504, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it]                                               {'loss': 0.4754, 'grad_norm': 9.25036907196045, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.4826, 'grad_norm': 4.397233963012695, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.0091, 'grad_norm': 0.3464588224887848, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it]                                               {'loss': 0.2637, 'grad_norm': 5.41046142578125, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.95s/it]                                               {'loss': 0.0848, 'grad_norm': 3.9897727966308594, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.2603, 'grad_norm': 5.657707214355469, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:56<00:25,  2.14s/it]                                               {'loss': 0.2552, 'grad_norm': 4.756284236907959, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.18s/it]                                               {'loss': 0.2684, 'grad_norm': 2.5434000492095947, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.18s/it] 75%|███████▌  | 30/40 [01:00<00:22,  2.22s/it]                                               {'loss': 0.8593, 'grad_norm': 5.39451265335083, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:22,  2.22s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it]                                               {'loss': 0.1136, 'grad_norm': 2.096801280975342, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.0394, 'grad_norm': 1.4544168710708618, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it]                                               {'loss': 0.046, 'grad_norm': 1.0197317600250244, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.0699, 'grad_norm': 1.6504637002944946, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.08s/it]                                               {'loss': 0.2463, 'grad_norm': 5.113582611083984, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.14s/it]                                               {'loss': 0.2538, 'grad_norm': 1.473670482635498, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.19s/it]                                               {'loss': 0.0808, 'grad_norm': 2.44328236579895, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.19s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it]                                               {'loss': 0.06, 'grad_norm': 1.356533169746399, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.25s/it]                                               {'loss': 0.3398, 'grad_norm': 4.280559062957764, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.25s/it]100%|██████████| 40/40 [01:19<00:00,  1.63s/it]                                               {'loss': 0.0064, 'grad_norm': 0.5476087927818298, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.63s/it]                                               {'train_runtime': 80.0234, 'train_samples_per_second': 7.06, 'train_steps_per_second': 0.5, 'train_loss': 1.1849502811790444, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:11
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:48,  2.78s/it]                                              {'loss': 4.7453, 'grad_norm': 4.574140548706055, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:48,  2.78s/it]  5%|▌         | 2/40 [00:05<01:33,  2.45s/it]                                              {'loss': 4.3041, 'grad_norm': 6.396560192108154, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:33,  2.45s/it]  8%|▊         | 3/40 [00:07<01:27,  2.35s/it]                                              {'loss': 5.5883, 'grad_norm': 23.467998504638672, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:27,  2.35s/it] 10%|█         | 4/40 [00:09<01:23,  2.31s/it]                                              {'loss': 2.4317, 'grad_norm': 5.807142734527588, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:23,  2.31s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.28s/it]                                              {'loss': 2.3555, 'grad_norm': 6.8223443031311035, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.28s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.26s/it]                                              {'loss': 3.3973, 'grad_norm': 8.274374008178711, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.26s/it] 18%|█▊        | 7/40 [00:16<01:13,  2.24s/it]                                              {'loss': 2.8159, 'grad_norm': 9.920296669006348, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:13,  2.24s/it] 20%|██        | 8/40 [00:16<00:50,  1.59s/it]                                              {'loss': 0.6019, 'grad_norm': 17.1742000579834, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 1.5463, 'grad_norm': 5.988700866699219, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 1.7188, 'grad_norm': 22.44382095336914, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:23<00:58,  2.03s/it]                                               {'loss': 3.2198, 'grad_norm': 11.032718658447266, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:58,  2.03s/it] 30%|███       | 12/40 [00:25<00:58,  2.09s/it]                                               {'loss': 1.0242, 'grad_norm': 4.356070518493652, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.15s/it]                                               {'loss': 0.5869, 'grad_norm': 4.337214946746826, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.15s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 0.3941, 'grad_norm': 2.4108612537384033, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:32<00:55,  2.21s/it]                                               {'loss': 1.0223, 'grad_norm': 4.33826208114624, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:55,  2.21s/it] 40%|████      | 16/40 [00:32<00:38,  1.59s/it]                                               {'loss': 0.1886, 'grad_norm': 3.902308940887451, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.6197, 'grad_norm': 3.990710973739624, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.1291, 'grad_norm': 1.4578509330749512, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:39<00:42,  2.04s/it]                                               {'loss': 0.97, 'grad_norm': 6.798705577850342, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:42,  2.04s/it] 50%|█████     | 20/40 [00:41<00:41,  2.10s/it]                                               {'loss': 0.5951, 'grad_norm': 3.410935401916504, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:41,  2.10s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 1.0409, 'grad_norm': 10.205172538757324, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it]                                               {'loss': 0.1181, 'grad_norm': 1.1502512693405151, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it]                                               {'loss': 0.7786, 'grad_norm': 6.611623764038086, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it] 60%|██████    | 24/40 [00:48<00:25,  1.61s/it]                                               {'loss': 0.029, 'grad_norm': 0.8588276505470276, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it]                                               {'loss': 0.4946, 'grad_norm': 3.975407361984253, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it]                                               {'loss': 0.0876, 'grad_norm': 1.6928240060806274, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.04s/it]                                               {'loss': 0.1225, 'grad_norm': 2.5195693969726562, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.04s/it] 70%|███████   | 28/40 [00:57<00:25,  2.13s/it]                                               {'loss': 0.0364, 'grad_norm': 0.5782970786094666, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.13s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.0775, 'grad_norm': 2.0911455154418945, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.22s/it]                                               {'loss': 0.0759, 'grad_norm': 1.4736143350601196, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.22s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.24s/it]                                               {'loss': 0.0531, 'grad_norm': 0.8208277821540833, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.24s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.0228, 'grad_norm': 0.8179253935813904, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it]                                               {'loss': 0.038, 'grad_norm': 0.7584069967269897, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.96s/it]                                               {'loss': 0.059, 'grad_norm': 2.121671199798584, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.06s/it]                                               {'loss': 0.0165, 'grad_norm': 0.3059331476688385, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it]                                               {'loss': 0.0102, 'grad_norm': 0.22208036482334137, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.4205, 'grad_norm': 4.213192462921143, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.20s/it]                                               {'loss': 1.0125, 'grad_norm': 4.306714057922363, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.0871, 'grad_norm': 3.388725519180298, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.0221, 'grad_norm': 1.2669024467468262, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.9871, 'train_samples_per_second': 6.976, 'train_steps_per_second': 0.494, 'train_loss': 1.0714430116349831, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:40
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:41,  2.61s/it]                                              {'loss': 5.0124, 'grad_norm': 5.104065418243408, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:41,  2.61s/it]  5%|▌         | 2/40 [00:04<01:27,  2.31s/it]                                              {'loss': 5.2609, 'grad_norm': 5.893481731414795, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:27,  2.31s/it]  8%|▊         | 3/40 [00:06<01:23,  2.24s/it]                                              {'loss': 3.3763, 'grad_norm': 5.9004435539245605, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.24s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 4.0264, 'grad_norm': 6.657263278961182, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 3.5815, 'grad_norm': 7.991212368011475, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 3.3112, 'grad_norm': 10.602709770202637, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 3.3141, 'grad_norm': 13.491110801696777, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 5.7998, 'grad_norm': 31.403400421142578, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 1.4629, 'grad_norm': 4.8974080085754395, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it]                                               {'loss': 1.1119, 'grad_norm': 5.860785484313965, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 1.479, 'grad_norm': 5.798432350158691, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 2.0589, 'grad_norm': 12.396316528320312, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 1.9967, 'grad_norm': 5.480386734008789, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.5405, 'grad_norm': 3.1483592987060547, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it]                                               {'loss': 0.5643, 'grad_norm': 4.458072662353516, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.3806, 'grad_norm': 14.588163375854492, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.9197, 'grad_norm': 10.537392616271973, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.167, 'grad_norm': 1.4204788208007812, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.2728, 'grad_norm': 3.2211036682128906, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:41,  2.10s/it]                                               {'loss': 0.614, 'grad_norm': 3.7709808349609375, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.10s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.6008, 'grad_norm': 4.7168474197387695, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it]                                               {'loss': 0.4176, 'grad_norm': 8.257109642028809, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.4571, 'grad_norm': 2.709031343460083, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.1128, 'grad_norm': 6.751288414001465, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it]                                               {'loss': 0.0352, 'grad_norm': 0.4118728041648865, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it]                                               {'loss': 0.2569, 'grad_norm': 2.8397111892700195, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.1906, 'grad_norm': 1.2522510290145874, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.18, 'grad_norm': 2.886906862258911, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.3651, 'grad_norm': 4.196852684020996, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.2615, 'grad_norm': 3.347153425216675, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.3792, 'grad_norm': 3.045239210128784, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0536, 'grad_norm': 2.910703659057617, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0312, 'grad_norm': 2.044186592102051, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.0406, 'grad_norm': 0.44504934549331665, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it]                                               {'loss': 0.412, 'grad_norm': 4.206725120544434, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0879, 'grad_norm': 1.9681316614151, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.0888, 'grad_norm': 1.8732802867889404, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.5989, 'grad_norm': 10.799957275390625, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.0863, 'grad_norm': 2.259704351425171, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0868, 'grad_norm': 5.129603862762451, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.7507, 'train_samples_per_second': 7.085, 'train_steps_per_second': 0.502, 'train_loss': 1.2498465746175498, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:45
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.68s/it]                                              {'loss': 5.0389, 'grad_norm': 4.886413097381592, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.68s/it]  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]                                              {'loss': 3.487, 'grad_norm': 5.172664642333984, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]  8%|▊         | 3/40 [00:07<01:24,  2.29s/it]                                              {'loss': 4.7034, 'grad_norm': 9.101932525634766, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:21,  2.27s/it]                                              {'loss': 3.1017, 'grad_norm': 7.941169738769531, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.27s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 3.5783, 'grad_norm': 10.626598358154297, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 3.6009, 'grad_norm': 15.403847694396973, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 3.8285, 'grad_norm': 100.24712371826172, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 3.0079, 'grad_norm': 37.13807678222656, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 2.4537, 'grad_norm': 11.068206787109375, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.1847, 'grad_norm': 6.4553608894348145, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 1.1265, 'grad_norm': 17.9481201171875, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 1.7162, 'grad_norm': 12.89623737335205, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 2.1217, 'grad_norm': 15.274292945861816, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 2.4134, 'grad_norm': 34.62206268310547, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 2.4519, 'grad_norm': 187.7220001220703, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 1.1286, 'grad_norm': 41.13627243041992, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 1.5391, 'grad_norm': 18.249670028686523, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 1.4299, 'grad_norm': 15.586833953857422, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.9216, 'grad_norm': 5.407562732696533, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.10s/it]                                               {'loss': 0.7709, 'grad_norm': 8.500054359436035, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.10s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 1.2805, 'grad_norm': 6.455526828765869, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.8645, 'grad_norm': 7.318277835845947, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.5422, 'grad_norm': 5.359838962554932, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.5836, 'grad_norm': 16.394487380981445, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it]                                               {'loss': 0.6405, 'grad_norm': 3.6252052783966064, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.3837, 'grad_norm': 4.172576904296875, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.105, 'grad_norm': 1.75132417678833, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.8433, 'grad_norm': 7.926519393920898, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.14s/it]                                               {'loss': 0.246, 'grad_norm': 2.870741844177246, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.971, 'grad_norm': 4.056655406951904, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it]                                               {'loss': 0.7778, 'grad_norm': 4.438953876495361, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 2.5236, 'grad_norm': 35.532447814941406, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.3167, 'grad_norm': 4.043487548828125, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.3817, 'grad_norm': 5.541588306427002, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it]                                               {'loss': 0.0996, 'grad_norm': 2.1683058738708496, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it]                                               {'loss': 0.1425, 'grad_norm': 14.86324691772461, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.4022, 'grad_norm': 4.578038215637207, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.275, 'grad_norm': 9.630332946777344, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.4502, 'grad_norm': 6.131600379943848, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.3959, 'grad_norm': 11.03099536895752, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.392, 'train_samples_per_second': 7.028, 'train_steps_per_second': 0.498, 'train_loss': 1.545755659416318, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:39
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:45,  2.69s/it]                                              {'loss': 4.4527, 'grad_norm': 5.309047222137451, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:45,  2.69s/it]  5%|▌         | 2/40 [00:04<01:30,  2.39s/it]                                              {'loss': 3.8954, 'grad_norm': 8.609132766723633, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.39s/it]  8%|▊         | 3/40 [00:07<01:24,  2.29s/it]                                              {'loss': 4.328, 'grad_norm': 8.478103637695312, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 3.3952, 'grad_norm': 7.866706848144531, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 4.9817, 'grad_norm': 13.06912899017334, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.382, 'grad_norm': 10.404273986816406, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 2.923, 'grad_norm': 9.261219024658203, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 4.1268, 'grad_norm': 64.44485473632812, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 1.9297, 'grad_norm': 10.520496368408203, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.5721, 'grad_norm': 6.388411045074463, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.1657, 'grad_norm': 5.975729465484619, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 1.3866, 'grad_norm': 5.546140193939209, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it]                                               {'loss': 0.8789, 'grad_norm': 4.965356349945068, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 0.7255, 'grad_norm': 4.924609184265137, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 1.263, 'grad_norm': 6.577576160430908, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 3.9057, 'grad_norm': 60.376556396484375, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.469, 'grad_norm': 2.3372628688812256, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.89s/it]                                               {'loss': 0.5824, 'grad_norm': 15.11154842376709, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it]                                               {'loss': 0.216, 'grad_norm': 1.9561916589736938, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.6553, 'grad_norm': 3.7868988513946533, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.5434, 'grad_norm': 5.437652587890625, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it]                                               {'loss': 0.2111, 'grad_norm': 1.5235041379928589, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.322, 'grad_norm': 3.431398868560791, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.2038, 'grad_norm': 7.1576828956604, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.1564, 'grad_norm': 1.9866173267364502, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.3161, 'grad_norm': 1.6282615661621094, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.1209, 'grad_norm': 2.1964149475097656, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.2252, 'grad_norm': 2.3791120052337646, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.1085, 'grad_norm': 1.2104483842849731, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.17s/it]                                               {'loss': 0.4614, 'grad_norm': 7.06695556640625, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.3244, 'grad_norm': 6.554955959320068, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.026, 'grad_norm': 1.0980533361434937, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it]                                               {'loss': 0.6077, 'grad_norm': 13.829821586608887, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.1573, 'grad_norm': 3.05256724357605, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it]                                               {'loss': 0.0776, 'grad_norm': 2.351219892501831, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0928, 'grad_norm': 3.3877310752868652, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.2202, 'grad_norm': 3.478677272796631, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0506, 'grad_norm': 0.9325580596923828, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.0979, 'grad_norm': 2.8521299362182617, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0022, 'grad_norm': 0.16876649856567383, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.7855, 'train_samples_per_second': 7.081, 'train_steps_per_second': 0.501, 'train_loss': 1.239011025603395, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:62
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.63s/it]                                              {'loss': 4.5072, 'grad_norm': 6.328490257263184, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.63s/it]  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]                                              {'loss': 3.3947, 'grad_norm': 5.17557430267334, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]  8%|▊         | 3/40 [00:06<01:24,  2.28s/it]                                              {'loss': 3.6991, 'grad_norm': 9.427464485168457, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 2.6944, 'grad_norm': 5.5662384033203125, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it]                                              {'loss': 4.3645, 'grad_norm': 8.426582336425781, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 3.5223, 'grad_norm': 8.944323539733887, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 2.702, 'grad_norm': 8.36837387084961, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 5.6887, 'grad_norm': 34.059913635253906, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 1.5211, 'grad_norm': 6.824995040893555, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 1.4086, 'grad_norm': 8.064957618713379, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.9338, 'grad_norm': 6.1650872230529785, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 1.1105, 'grad_norm': 11.083195686340332, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 0.9298, 'grad_norm': 6.063167095184326, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 0.6507, 'grad_norm': 4.764075756072998, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 1.0583, 'grad_norm': 4.738474369049072, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0203, 'grad_norm': 0.784197211265564, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.2956, 'grad_norm': 3.1400575637817383, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.91s/it]                                               {'loss': 0.2643, 'grad_norm': 5.153663158416748, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.6282, 'grad_norm': 2.986027240753174, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:42,  2.10s/it]                                               {'loss': 0.5169, 'grad_norm': 6.008328914642334, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.16s/it]                                               {'loss': 0.0755, 'grad_norm': 1.3500399589538574, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.1359, 'grad_norm': 2.293480157852173, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.2381, 'grad_norm': 3.084411382675171, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.003, 'grad_norm': 0.15972250699996948, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.0724, 'grad_norm': 2.3542397022247314, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it]                                               {'loss': 0.1327, 'grad_norm': 1.7904517650604248, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it]                                               {'loss': 0.1421, 'grad_norm': 6.22668981552124, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it] 70%|███████   | 28/40 [00:57<00:25,  2.14s/it]                                               {'loss': 0.0607, 'grad_norm': 0.7255855798721313, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it]                                               {'loss': 0.0789, 'grad_norm': 1.324662685394287, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.22s/it]                                               {'loss': 0.1817, 'grad_norm': 5.95922327041626, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.22s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it]                                               {'loss': 0.1529, 'grad_norm': 2.946646213531494, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it] 80%|████████  | 32/40 [01:04<00:13,  1.63s/it]                                               {'loss': 0.0512, 'grad_norm': 2.539339542388916, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it]                                               {'loss': 0.4721, 'grad_norm': 3.9670708179473877, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.1262, 'grad_norm': 4.431194305419922, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.09s/it]                                               {'loss': 0.1108, 'grad_norm': 2.520822048187256, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.09s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it]                                               {'loss': 0.0432, 'grad_norm': 0.8244147300720215, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it]                                               {'loss': 0.2424, 'grad_norm': 6.48701810836792, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.24s/it]                                               {'loss': 0.0766, 'grad_norm': 3.3746700286865234, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.24s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.2808, 'grad_norm': 10.422292709350586, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.0214, 'grad_norm': 1.1020201444625854, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.7711, 'train_samples_per_second': 6.995, 'train_steps_per_second': 0.495, 'train_loss': 1.0652402529260143, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<05:00,  1.56it/s]  1%|          | 3/471 [00:02<07:04,  1.10it/s]  1%|          | 4/471 [00:03<08:10,  1.05s/it]  1%|          | 5/471 [00:05<08:47,  1.13s/it]  1%|▏         | 6/471 [00:06<09:10,  1.18s/it]  1%|▏         | 7/471 [00:07<09:26,  1.22s/it]  2%|▏         | 8/471 [00:09<09:35,  1.24s/it]  2%|▏         | 9/471 [00:10<09:41,  1.26s/it]  2%|▏         | 10/471 [00:11<09:44,  1.27s/it]  2%|▏         | 11/471 [00:12<09:47,  1.28s/it]  3%|▎         | 12/471 [00:14<09:49,  1.28s/it]  3%|▎         | 13/471 [00:15<09:51,  1.29s/it]  3%|▎         | 14/471 [00:16<09:52,  1.30s/it]  3%|▎         | 15/471 [00:18<09:51,  1.30s/it]  3%|▎         | 16/471 [00:19<09:52,  1.30s/it]  4%|▎         | 17/471 [00:20<09:51,  1.30s/it]  4%|▍         | 18/471 [00:22<09:51,  1.31s/it]  4%|▍         | 19/471 [00:23<09:50,  1.31s/it]  4%|▍         | 20/471 [00:24<09:49,  1.31s/it]  4%|▍         | 21/471 [00:25<09:49,  1.31s/it]  5%|▍         | 22/471 [00:27<09:48,  1.31s/it]  5%|▍         | 23/471 [00:28<09:48,  1.31s/it]  5%|▌         | 24/471 [00:29<09:48,  1.32s/it]  5%|▌         | 25/471 [00:31<09:46,  1.31s/it]  6%|▌         | 26/471 [00:32<09:45,  1.32s/it]  6%|▌         | 27/471 [00:33<09:44,  1.32s/it]  6%|▌         | 28/471 [00:35<09:43,  1.32s/it]  6%|▌         | 29/471 [00:36<09:42,  1.32s/it]  6%|▋         | 30/471 [00:37<09:41,  1.32s/it]  7%|▋         | 31/471 [00:39<09:40,  1.32s/it]  7%|▋         | 32/471 [00:40<09:38,  1.32s/it]  7%|▋         | 33/471 [00:41<09:36,  1.32s/it]  7%|▋         | 34/471 [00:43<09:35,  1.32s/it]  7%|▋         | 35/471 [00:44<09:35,  1.32s/it]  8%|▊         | 36/471 [00:45<09:34,  1.32s/it]  8%|▊         | 37/471 [00:47<09:33,  1.32s/it]  8%|▊         | 38/471 [00:48<09:32,  1.32s/it]  8%|▊         | 39/471 [00:49<09:30,  1.32s/it]  8%|▊         | 40/471 [00:51<09:29,  1.32s/it]  9%|▊         | 41/471 [00:52<09:28,  1.32s/it]  9%|▉         | 42/471 [00:53<09:28,  1.32s/it]  9%|▉         | 43/471 [00:55<09:26,  1.32s/it]  9%|▉         | 44/471 [00:56<09:24,  1.32s/it] 10%|▉         | 45/471 [00:57<09:24,  1.32s/it] 10%|▉         | 46/471 [00:58<09:23,  1.33s/it] 10%|▉         | 47/471 [01:00<09:21,  1.33s/it] 10%|█         | 48/471 [01:01<09:20,  1.33s/it] 10%|█         | 49/471 [01:02<09:20,  1.33s/it] 11%|█         | 50/471 [01:04<09:19,  1.33s/it] 11%|█         | 51/471 [01:05<09:17,  1.33s/it] 11%|█         | 52/471 [01:06<09:16,  1.33s/it] 11%|█▏        | 53/471 [01:08<09:15,  1.33s/it] 11%|█▏        | 54/471 [01:09<09:14,  1.33s/it] 12%|█▏        | 55/471 [01:10<09:13,  1.33s/it] 12%|█▏        | 56/471 [01:12<09:13,  1.33s/it] 12%|█▏        | 57/471 [01:13<09:11,  1.33s/it] 12%|█▏        | 58/471 [01:14<09:10,  1.33s/it] 13%|█▎        | 59/471 [01:16<09:09,  1.33s/it] 13%|█▎        | 60/471 [01:17<09:07,  1.33s/it] 13%|█▎        | 61/471 [01:18<09:06,  1.33s/it] 13%|█▎        | 62/471 [01:20<09:04,  1.33s/it] 13%|█▎        | 63/471 [01:21<09:03,  1.33s/it] 14%|█▎        | 64/471 [01:22<09:02,  1.33s/it] 14%|█▍        | 65/471 [01:24<09:01,  1.33s/it] 14%|█▍        | 66/471 [01:25<08:59,  1.33s/it] 14%|█▍        | 67/471 [01:26<08:58,  1.33s/it] 14%|█▍        | 68/471 [01:28<08:56,  1.33s/it] 15%|█▍        | 69/471 [01:29<08:55,  1.33s/it] 15%|█▍        | 70/471 [01:30<08:54,  1.33s/it] 15%|█▌        | 71/471 [01:32<08:52,  1.33s/it] 15%|█▌        | 72/471 [01:33<08:51,  1.33s/it] 15%|█▌        | 73/471 [01:34<08:49,  1.33s/it] 16%|█▌        | 74/471 [01:36<08:47,  1.33s/it] 16%|█▌        | 75/471 [01:37<08:47,  1.33s/it] 16%|█▌        | 76/471 [01:38<08:45,  1.33s/it] 16%|█▋        | 77/471 [01:40<08:44,  1.33s/it] 17%|█▋        | 78/471 [01:41<08:42,  1.33s/it] 17%|█▋        | 79/471 [01:42<08:42,  1.33s/it] 17%|█▋        | 80/471 [01:44<08:41,  1.33s/it] 17%|█▋        | 81/471 [01:45<08:39,  1.33s/it] 17%|█▋        | 82/471 [01:46<08:38,  1.33s/it] 18%|█▊        | 83/471 [01:48<08:37,  1.33s/it] 18%|█▊        | 84/471 [01:49<08:35,  1.33s/it] 18%|█▊        | 85/471 [01:50<08:34,  1.33s/it] 18%|█▊        | 86/471 [01:52<08:33,  1.33s/it] 18%|█▊        | 87/471 [01:53<08:31,  1.33s/it] 19%|█▊        | 88/471 [01:54<08:29,  1.33s/it] 19%|█▉        | 89/471 [01:56<08:28,  1.33s/it] 19%|█▉        | 90/471 [01:57<08:27,  1.33s/it] 19%|█▉        | 91/471 [01:58<08:25,  1.33s/it] 20%|█▉        | 92/471 [02:00<08:24,  1.33s/it] 20%|█▉        | 93/471 [02:01<08:23,  1.33s/it] 20%|█▉        | 94/471 [02:02<08:21,  1.33s/it] 20%|██        | 95/471 [02:04<08:20,  1.33s/it] 20%|██        | 96/471 [02:05<08:18,  1.33s/it] 21%|██        | 97/471 [02:06<08:18,  1.33s/it] 21%|██        | 98/471 [02:08<08:16,  1.33s/it] 21%|██        | 99/471 [02:09<08:14,  1.33s/it] 21%|██        | 100/471 [02:10<08:13,  1.33s/it] 21%|██▏       | 101/471 [02:12<08:11,  1.33s/it] 22%|██▏       | 102/471 [02:13<08:11,  1.33s/it] 22%|██▏       | 103/471 [02:14<08:10,  1.33s/it] 22%|██▏       | 104/471 [02:16<08:09,  1.33s/it] 22%|██▏       | 105/471 [02:17<08:08,  1.34s/it] 23%|██▎       | 106/471 [02:18<08:06,  1.33s/it] 23%|██▎       | 107/471 [02:20<08:04,  1.33s/it] 23%|██▎       | 108/471 [02:21<08:03,  1.33s/it] 23%|██▎       | 109/471 [02:22<08:01,  1.33s/it] 23%|██▎       | 110/471 [02:24<07:58,  1.33s/it] 24%|██▎       | 111/471 [02:25<07:58,  1.33s/it] 24%|██▍       | 112/471 [02:26<07:57,  1.33s/it] 24%|██▍       | 113/471 [02:28<07:55,  1.33s/it] 24%|██▍       | 114/471 [02:29<07:55,  1.33s/it] 24%|██▍       | 115/471 [02:30<07:53,  1.33s/it] 25%|██▍       | 116/471 [02:32<07:52,  1.33s/it] 25%|██▍       | 117/471 [02:33<07:51,  1.33s/it] 25%|██▌       | 118/471 [02:34<07:50,  1.33s/it] 25%|██▌       | 119/471 [02:36<07:49,  1.33s/it] 25%|██▌       | 120/471 [02:37<07:48,  1.33s/it] 26%|██▌       | 121/471 [02:38<07:46,  1.33s/it] 26%|██▌       | 122/471 [02:40<07:44,  1.33s/it] 26%|██▌       | 123/471 [02:41<07:44,  1.33s/it] 26%|██▋       | 124/471 [02:42<07:42,  1.33s/it] 27%|██▋       | 125/471 [02:44<07:41,  1.33s/it] 27%|██▋       | 126/471 [02:45<07:40,  1.33s/it] 27%|██▋       | 127/471 [02:46<07:39,  1.33s/it] 27%|██▋       | 128/471 [02:48<07:37,  1.33s/it] 27%|██▋       | 129/471 [02:49<07:35,  1.33s/it] 28%|██▊       | 130/471 [02:50<07:33,  1.33s/it] 28%|██▊       | 131/471 [02:52<07:32,  1.33s/it] 28%|██▊       | 132/471 [02:53<07:31,  1.33s/it] 28%|██▊       | 133/471 [02:54<07:29,  1.33s/it] 28%|██▊       | 134/471 [02:56<07:28,  1.33s/it] 29%|██▊       | 135/471 [02:57<07:27,  1.33s/it] 29%|██▉       | 136/471 [02:58<07:25,  1.33s/it] 29%|██▉       | 137/471 [03:00<07:24,  1.33s/it] 29%|██▉       | 138/471 [03:01<07:23,  1.33s/it] 30%|██▉       | 139/471 [03:02<07:22,  1.33s/it] 30%|██▉       | 140/471 [03:04<07:20,  1.33s/it] 30%|██▉       | 141/471 [03:05<07:19,  1.33s/it] 30%|███       | 142/471 [03:06<07:17,  1.33s/it] 30%|███       | 143/471 [03:08<07:16,  1.33s/it] 31%|███       | 144/471 [03:09<07:15,  1.33s/it] 31%|███       | 145/471 [03:10<07:13,  1.33s/it] 31%|███       | 146/471 [03:12<07:13,  1.33s/it] 31%|███       | 147/471 [03:13<07:12,  1.33s/it] 31%|███▏      | 148/471 [03:14<07:10,  1.33s/it] 32%|███▏      | 149/471 [03:16<07:09,  1.34s/it] 32%|███▏      | 150/471 [03:17<07:08,  1.34s/it] 32%|███▏      | 151/471 [03:18<07:07,  1.34s/it] 32%|███▏      | 152/471 [03:20<07:05,  1.33s/it] 32%|███▏      | 153/471 [03:21<07:05,  1.34s/it] 33%|███▎      | 154/471 [03:22<07:02,  1.33s/it] 33%|███▎      | 155/471 [03:24<07:01,  1.34s/it] 33%|███▎      | 156/471 [03:25<07:00,  1.33s/it] 33%|███▎      | 157/471 [03:26<06:58,  1.33s/it] 34%|███▎      | 158/471 [03:28<06:56,  1.33s/it] 34%|███▍      | 159/471 [03:29<06:55,  1.33s/it] 34%|███▍      | 160/471 [03:30<06:54,  1.33s/it] 34%|███▍      | 161/471 [03:32<06:53,  1.33s/it] 34%|███▍      | 162/471 [03:33<06:52,  1.34s/it] 35%|███▍      | 163/471 [03:34<06:52,  1.34s/it] 35%|███▍      | 164/471 [03:36<06:50,  1.34s/it] 35%|███▌      | 165/471 [03:37<06:49,  1.34s/it] 35%|███▌      | 166/471 [03:38<06:48,  1.34s/it] 35%|███▌      | 167/471 [03:40<06:47,  1.34s/it] 36%|███▌      | 168/471 [03:41<06:46,  1.34s/it] 36%|███▌      | 169/471 [03:42<06:45,  1.34s/it] 36%|███▌      | 170/471 [03:44<06:43,  1.34s/it] 36%|███▋      | 171/471 [03:45<06:42,  1.34s/it] 37%|███▋      | 172/471 [03:46<06:41,  1.34s/it] 37%|███▋      | 173/471 [03:48<06:40,  1.34s/it] 37%|███▋      | 174/471 [03:49<06:39,  1.34s/it] 37%|███▋      | 175/471 [03:50<06:37,  1.34s/it] 37%|███▋      | 176/471 [03:52<06:36,  1.34s/it] 38%|███▊      | 177/471 [03:53<06:35,  1.34s/it] 38%|███▊      | 178/471 [03:54<06:34,  1.35s/it] 38%|███▊      | 179/471 [03:56<06:32,  1.34s/it] 38%|███▊      | 180/471 [03:57<06:31,  1.34s/it] 38%|███▊      | 181/471 [03:59<06:29,  1.34s/it] 39%|███▊      | 182/471 [04:00<06:28,  1.34s/it] 39%|███▉      | 183/471 [04:01<06:27,  1.34s/it] 39%|███▉      | 184/471 [04:03<06:25,  1.34s/it] 39%|███▉      | 185/471 [04:04<06:23,  1.34s/it] 39%|███▉      | 186/471 [04:05<06:23,  1.34s/it] 40%|███▉      | 187/471 [04:07<06:22,  1.35s/it] 40%|███▉      | 188/471 [04:08<06:20,  1.35s/it] 40%|████      | 189/471 [04:09<06:18,  1.34s/it] 40%|████      | 190/471 [04:11<06:17,  1.35s/it] 41%|████      | 191/471 [04:12<06:17,  1.35s/it] 41%|████      | 192/471 [04:13<06:15,  1.35s/it] 41%|████      | 193/471 [04:15<06:13,  1.35s/it] 41%|████      | 194/471 [04:16<06:12,  1.35s/it] 41%|████▏     | 195/471 [04:17<06:11,  1.35s/it] 42%|████▏     | 196/471 [04:19<06:10,  1.35s/it] 42%|████▏     | 197/471 [04:20<06:07,  1.34s/it] 42%|████▏     | 198/471 [04:21<06:06,  1.34s/it] 42%|████▏     | 199/471 [04:23<06:05,  1.34s/it] 42%|████▏     | 200/471 [04:24<06:04,  1.34s/it] 43%|████▎     | 201/471 [04:25<06:01,  1.34s/it] 43%|████▎     | 202/471 [04:27<06:01,  1.34s/it] 43%|████▎     | 203/471 [04:28<05:59,  1.34s/it] 43%|████▎     | 204/471 [04:29<05:58,  1.34s/it] 44%|████▎     | 205/471 [04:31<05:56,  1.34s/it] 44%|████▎     | 206/471 [04:32<05:55,  1.34s/it] 44%|████▍     | 207/471 [04:33<05:54,  1.34s/it] 44%|████▍     | 208/471 [04:35<05:52,  1.34s/it] 44%|████▍     | 209/471 [04:36<05:51,  1.34s/it] 45%|████▍     | 210/471 [04:37<05:50,  1.34s/it] 45%|████▍     | 211/471 [04:39<05:48,  1.34s/it] 45%|████▌     | 212/471 [04:40<05:47,  1.34s/it] 45%|████▌     | 213/471 [04:41<05:46,  1.34s/it] 45%|████▌     | 214/471 [04:43<05:45,  1.34s/it] 46%|████▌     | 215/471 [04:44<05:44,  1.34s/it] 46%|████▌     | 216/471 [04:46<05:42,  1.35s/it] 46%|████▌     | 217/471 [04:47<05:42,  1.35s/it] 46%|████▋     | 218/471 [04:48<05:40,  1.35s/it] 46%|████▋     | 219/471 [04:50<05:38,  1.35s/it] 47%|████▋     | 220/471 [04:51<05:37,  1.34s/it] 47%|████▋     | 221/471 [04:52<05:36,  1.34s/it] 47%|████▋     | 222/471 [04:54<05:34,  1.34s/it] 47%|████▋     | 223/471 [04:55<05:32,  1.34s/it] 48%|████▊     | 224/471 [04:56<05:31,  1.34s/it] 48%|████▊     | 225/471 [04:58<05:30,  1.34s/it] 48%|████▊     | 226/471 [04:59<05:28,  1.34s/it] 48%|████▊     | 227/471 [05:00<05:27,  1.34s/it] 48%|████▊     | 228/471 [05:02<05:25,  1.34s/it] 49%|████▊     | 229/471 [05:03<05:24,  1.34s/it] 49%|████▉     | 230/471 [05:04<05:23,  1.34s/it] 49%|████▉     | 231/471 [05:06<05:21,  1.34s/it] 49%|████▉     | 232/471 [05:07<05:19,  1.34s/it] 49%|████▉     | 233/471 [05:08<05:18,  1.34s/it] 50%|████▉     | 234/471 [05:10<05:17,  1.34s/it] 50%|████▉     | 235/471 [05:11<05:16,  1.34s/it] 50%|█████     | 236/471 [05:12<05:14,  1.34s/it] 50%|█████     | 237/471 [05:14<05:13,  1.34s/it] 51%|█████     | 238/471 [05:15<05:11,  1.34s/it] 51%|█████     | 239/471 [05:16<05:10,  1.34s/it] 51%|█████     | 240/471 [05:18<05:09,  1.34s/it] 51%|█████     | 241/471 [05:19<05:08,  1.34s/it] 51%|█████▏    | 242/471 [05:20<05:06,  1.34s/it] 52%|█████▏    | 243/471 [05:22<05:05,  1.34s/it] 52%|█████▏    | 244/471 [05:23<05:03,  1.34s/it] 52%|█████▏    | 245/471 [05:24<05:02,  1.34s/it] 52%|█████▏    | 246/471 [05:26<05:00,  1.34s/it] 52%|█████▏    | 247/471 [05:27<04:59,  1.34s/it] 53%|█████▎    | 248/471 [05:28<04:57,  1.34s/it] 53%|█████▎    | 249/471 [05:30<04:56,  1.34s/it] 53%|█████▎    | 250/471 [05:31<04:55,  1.34s/it] 53%|█████▎    | 251/471 [05:32<04:53,  1.34s/it] 54%|█████▎    | 252/471 [05:34<04:52,  1.34s/it] 54%|█████▎    | 253/471 [05:35<04:51,  1.34s/it] 54%|█████▍    | 254/471 [05:36<04:50,  1.34s/it] 54%|█████▍    | 255/471 [05:38<04:48,  1.34s/it] 54%|█████▍    | 256/471 [05:39<04:47,  1.34s/it] 55%|█████▍    | 257/471 [05:40<04:45,  1.34s/it] 55%|█████▍    | 258/471 [05:42<04:44,  1.34s/it] 55%|█████▍    | 259/471 [05:43<04:43,  1.34s/it] 55%|█████▌    | 260/471 [05:44<04:42,  1.34s/it] 55%|█████▌    | 261/471 [05:46<04:40,  1.34s/it] 56%|█████▌    | 262/471 [05:47<04:38,  1.33s/it] 56%|█████▌    | 263/471 [05:48<04:37,  1.33s/it] 56%|█████▌    | 264/471 [05:50<04:36,  1.33s/it] 56%|█████▋    | 265/471 [05:51<04:34,  1.33s/it] 56%|█████▋    | 266/471 [05:52<04:33,  1.34s/it] 57%|█████▋    | 267/471 [05:54<04:32,  1.34s/it] 57%|█████▋    | 268/471 [05:55<04:30,  1.33s/it] 57%|█████▋    | 269/471 [05:56<04:29,  1.33s/it] 57%|█████▋    | 270/471 [05:58<04:27,  1.33s/it] 58%|█████▊    | 271/471 [05:59<04:26,  1.33s/it] 58%|█████▊    | 272/471 [06:00<04:24,  1.33s/it] 58%|█████▊    | 273/471 [06:02<04:23,  1.33s/it] 58%|█████▊    | 274/471 [06:03<04:21,  1.33s/it] 58%|█████▊    | 275/471 [06:04<04:20,  1.33s/it] 59%|█████▊    | 276/471 [06:06<04:19,  1.33s/it] 59%|█████▉    | 277/471 [06:07<04:18,  1.33s/it] 59%|█████▉    | 278/471 [06:08<04:17,  1.33s/it] 59%|█████▉    | 279/471 [06:10<04:15,  1.33s/it] 59%|█████▉    | 280/471 [06:11<04:13,  1.33s/it] 60%|█████▉    | 281/471 [06:12<04:12,  1.33s/it] 60%|█████▉    | 282/471 [06:14<04:11,  1.33s/it] 60%|██████    | 283/471 [06:15<04:10,  1.33s/it] 60%|██████    | 284/471 [06:16<04:08,  1.33s/it] 61%|██████    | 285/471 [06:18<04:07,  1.33s/it] 61%|██████    | 286/471 [06:19<04:06,  1.33s/it] 61%|██████    | 287/471 [06:20<04:05,  1.33s/it] 61%|██████    | 288/471 [06:22<04:03,  1.33s/it] 61%|██████▏   | 289/471 [06:23<04:02,  1.33s/it] 62%|██████▏   | 290/471 [06:24<04:00,  1.33s/it] 62%|██████▏   | 291/471 [06:26<03:59,  1.33s/it] 62%|██████▏   | 292/471 [06:27<03:57,  1.33s/it] 62%|██████▏   | 293/471 [06:28<03:56,  1.33s/it] 62%|██████▏   | 294/471 [06:30<03:54,  1.33s/it] 63%|██████▎   | 295/471 [06:31<03:53,  1.33s/it] 63%|██████▎   | 296/471 [06:32<03:52,  1.33s/it] 63%|██████▎   | 297/471 [06:34<03:50,  1.33s/it] 63%|██████▎   | 298/471 [06:35<03:49,  1.33s/it] 63%|██████▎   | 299/471 [06:36<03:48,  1.33s/it] 64%|██████▎   | 300/471 [06:38<03:47,  1.33s/it] 64%|██████▍   | 301/471 [06:39<03:46,  1.33s/it] 64%|██████▍   | 302/471 [06:40<03:44,  1.33s/it] 64%|██████▍   | 303/471 [06:42<03:43,  1.33s/it] 65%|██████▍   | 304/471 [06:43<03:41,  1.33s/it] 65%|██████▍   | 305/471 [06:44<03:40,  1.33s/it] 65%|██████▍   | 306/471 [06:46<03:39,  1.33s/it] 65%|██████▌   | 307/471 [06:47<03:38,  1.33s/it] 65%|██████▌   | 308/471 [06:48<03:37,  1.33s/it] 66%|██████▌   | 309/471 [06:50<03:35,  1.33s/it] 66%|██████▌   | 310/471 [06:51<03:34,  1.33s/it] 66%|██████▌   | 311/471 [06:52<03:32,  1.33s/it] 66%|██████▌   | 312/471 [06:54<03:31,  1.33s/it] 66%|██████▋   | 313/471 [06:55<03:29,  1.33s/it] 67%|██████▋   | 314/471 [06:56<03:28,  1.33s/it] 67%|██████▋   | 315/471 [06:58<03:27,  1.33s/it] 67%|██████▋   | 316/471 [06:59<03:25,  1.33s/it] 67%|██████▋   | 317/471 [07:00<03:24,  1.33s/it] 68%|██████▊   | 318/471 [07:02<03:23,  1.33s/it] 68%|██████▊   | 319/471 [07:03<03:22,  1.33s/it] 68%|██████▊   | 320/471 [07:04<03:20,  1.33s/it] 68%|██████▊   | 321/471 [07:06<03:19,  1.33s/it] 68%|██████▊   | 322/471 [07:07<03:18,  1.33s/it] 69%|██████▊   | 323/471 [07:08<03:17,  1.33s/it] 69%|██████▉   | 324/471 [07:10<03:16,  1.34s/it] 69%|██████▉   | 325/471 [07:11<03:14,  1.33s/it] 69%|██████▉   | 326/471 [07:12<03:13,  1.33s/it] 69%|██████▉   | 327/471 [07:14<03:11,  1.33s/it] 70%|██████▉   | 328/471 [07:15<03:10,  1.33s/it] 70%|██████▉   | 329/471 [07:16<03:09,  1.33s/it] 70%|███████   | 330/471 [07:18<03:07,  1.33s/it] 70%|███████   | 331/471 [07:19<03:06,  1.33s/it] 70%|███████   | 332/471 [07:20<03:05,  1.33s/it] 71%|███████   | 333/471 [07:22<03:03,  1.33s/it] 71%|███████   | 334/471 [07:23<03:02,  1.33s/it] 71%|███████   | 335/471 [07:24<03:01,  1.33s/it] 71%|███████▏  | 336/471 [07:26<03:00,  1.33s/it] 72%|███████▏  | 337/471 [07:27<02:58,  1.33s/it] 72%|███████▏  | 338/471 [07:28<02:56,  1.33s/it] 72%|███████▏  | 339/471 [07:30<02:55,  1.33s/it] 72%|███████▏  | 340/471 [07:31<02:54,  1.33s/it] 72%|███████▏  | 341/471 [07:32<02:52,  1.33s/it] 73%|███████▎  | 342/471 [07:34<02:51,  1.33s/it] 73%|███████▎  | 343/471 [07:35<02:50,  1.33s/it] 73%|███████▎  | 344/471 [07:36<02:48,  1.33s/it] 73%|███████▎  | 345/471 [07:38<02:47,  1.33s/it] 73%|███████▎  | 346/471 [07:39<02:46,  1.33s/it] 74%|███████▎  | 347/471 [07:40<02:44,  1.33s/it] 74%|███████▍  | 348/471 [07:42<02:43,  1.33s/it] 74%|███████▍  | 349/471 [07:43<02:42,  1.33s/it] 74%|███████▍  | 350/471 [07:44<02:41,  1.33s/it] 75%|███████▍  | 351/471 [07:46<02:39,  1.33s/it] 75%|███████▍  | 352/471 [07:47<02:38,  1.33s/it] 75%|███████▍  | 353/471 [07:48<02:37,  1.33s/it] 75%|███████▌  | 354/471 [07:50<02:35,  1.33s/it] 75%|███████▌  | 355/471 [07:51<02:34,  1.33s/it] 76%|███████▌  | 356/471 [07:52<02:33,  1.33s/it] 76%|███████▌  | 357/471 [07:54<02:31,  1.33s/it] 76%|███████▌  | 358/471 [07:55<02:30,  1.33s/it] 76%|███████▌  | 359/471 [07:56<02:29,  1.33s/it] 76%|███████▋  | 360/471 [07:58<02:27,  1.33s/it] 77%|███████▋  | 361/471 [07:59<02:26,  1.33s/it] 77%|███████▋  | 362/471 [08:00<02:24,  1.33s/it] 77%|███████▋  | 363/471 [08:02<02:23,  1.33s/it] 77%|███████▋  | 364/471 [08:03<02:22,  1.33s/it] 77%|███████▋  | 365/471 [08:04<02:21,  1.33s/it] 78%|███████▊  | 366/471 [08:06<02:20,  1.33s/it] 78%|███████▊  | 367/471 [08:07<02:18,  1.33s/it] 78%|███████▊  | 368/471 [08:08<02:17,  1.33s/it] 78%|███████▊  | 369/471 [08:09<02:15,  1.33s/it] 79%|███████▊  | 370/471 [08:11<02:14,  1.33s/it] 79%|███████▉  | 371/471 [08:12<02:13,  1.33s/it] 79%|███████▉  | 372/471 [08:13<02:11,  1.33s/it] 79%|███████▉  | 373/471 [08:15<02:10,  1.33s/it] 79%|███████▉  | 374/471 [08:16<02:09,  1.33s/it] 80%|███████▉  | 375/471 [08:17<02:07,  1.33s/it] 80%|███████▉  | 376/471 [08:19<02:06,  1.33s/it] 80%|████████  | 377/471 [08:20<02:05,  1.33s/it] 80%|████████  | 378/471 [08:21<02:03,  1.33s/it] 80%|████████  | 379/471 [08:23<02:02,  1.34s/it] 81%|████████  | 380/471 [08:24<02:01,  1.34s/it] 81%|████████  | 381/471 [08:26<02:00,  1.34s/it] 81%|████████  | 382/471 [08:27<01:59,  1.34s/it] 81%|████████▏ | 383/471 [08:28<01:57,  1.34s/it] 82%|████████▏ | 384/471 [08:30<01:56,  1.34s/it] 82%|████████▏ | 385/471 [08:31<01:55,  1.34s/it] 82%|████████▏ | 386/471 [08:32<01:53,  1.34s/it] 82%|████████▏ | 387/471 [08:34<01:52,  1.34s/it] 82%|████████▏ | 388/471 [08:35<01:51,  1.34s/it] 83%|████████▎ | 389/471 [08:36<01:49,  1.34s/it] 83%|████████▎ | 390/471 [08:38<01:48,  1.34s/it] 83%|████████▎ | 391/471 [08:39<01:47,  1.34s/it] 83%|████████▎ | 392/471 [08:40<01:46,  1.34s/it] 83%|████████▎ | 393/471 [08:42<01:44,  1.34s/it] 84%|████████▎ | 394/471 [08:43<01:43,  1.34s/it] 84%|████████▍ | 395/471 [08:44<01:42,  1.34s/it] 84%|████████▍ | 396/471 [08:46<01:40,  1.34s/it] 84%|████████▍ | 397/471 [08:47<01:39,  1.34s/it] 85%|████████▍ | 398/471 [08:48<01:37,  1.34s/it] 85%|████████▍ | 399/471 [08:50<01:36,  1.34s/it] 85%|████████▍ | 400/471 [08:51<01:35,  1.34s/it] 85%|████████▌ | 401/471 [08:52<01:33,  1.34s/it] 85%|████████▌ | 402/471 [08:54<01:32,  1.34s/it] 86%|████████▌ | 403/471 [08:55<01:31,  1.34s/it] 86%|████████▌ | 404/471 [08:56<01:29,  1.34s/it] 86%|████████▌ | 405/471 [08:58<01:28,  1.34s/it] 86%|████████▌ | 406/471 [08:59<01:27,  1.34s/it] 86%|████████▋ | 407/471 [09:00<01:25,  1.34s/it] 87%|████████▋ | 408/471 [09:02<01:24,  1.34s/it] 87%|████████▋ | 409/471 [09:03<01:23,  1.35s/it] 87%|████████▋ | 410/471 [09:04<01:22,  1.34s/it] 87%|████████▋ | 411/471 [09:06<01:20,  1.35s/it] 87%|████████▋ | 412/471 [09:07<01:19,  1.35s/it] 88%|████████▊ | 413/471 [09:08<01:18,  1.35s/it] 88%|████████▊ | 414/471 [09:10<01:16,  1.35s/it] 88%|████████▊ | 415/471 [09:11<01:15,  1.35s/it] 88%|████████▊ | 416/471 [09:13<01:14,  1.35s/it] 89%|████████▊ | 417/471 [09:14<01:12,  1.35s/it] 89%|████████▊ | 418/471 [09:15<01:11,  1.35s/it] 89%|████████▉ | 419/471 [09:17<01:10,  1.35s/it] 89%|████████▉ | 420/471 [09:18<01:08,  1.35s/it] 89%|████████▉ | 421/471 [09:19<01:07,  1.35s/it] 90%|████████▉ | 422/471 [09:21<01:05,  1.35s/it] 90%|████████▉ | 423/471 [09:22<01:04,  1.35s/it] 90%|█████████ | 424/471 [09:23<01:03,  1.35s/it] 90%|█████████ | 425/471 [09:25<01:01,  1.35s/it] 90%|█████████ | 426/471 [09:26<01:00,  1.35s/it] 91%|█████████ | 427/471 [09:27<00:59,  1.35s/it] 91%|█████████ | 428/471 [09:29<00:57,  1.35s/it] 91%|█████████ | 429/471 [09:30<00:56,  1.35s/it] 91%|█████████▏| 430/471 [09:31<00:55,  1.35s/it] 92%|█████████▏| 431/471 [09:33<00:53,  1.35s/it] 92%|█████████▏| 432/471 [09:34<00:52,  1.35s/it] 92%|█████████▏| 433/471 [09:35<00:51,  1.35s/it] 92%|█████████▏| 434/471 [09:37<00:49,  1.35s/it] 92%|█████████▏| 435/471 [09:38<00:48,  1.35s/it] 93%|█████████▎| 436/471 [09:39<00:47,  1.35s/it] 93%|█████████▎| 437/471 [09:41<00:45,  1.35s/it] 93%|█████████▎| 438/471 [09:42<00:44,  1.35s/it] 93%|█████████▎| 439/471 [09:44<00:42,  1.34s/it] 93%|█████████▎| 440/471 [09:45<00:41,  1.34s/it] 94%|█████████▎| 441/471 [09:46<00:40,  1.34s/it] 94%|█████████▍| 442/471 [09:48<00:38,  1.34s/it] 94%|█████████▍| 443/471 [09:49<00:37,  1.34s/it] 94%|█████████▍| 444/471 [09:50<00:36,  1.34s/it] 94%|█████████▍| 445/471 [09:52<00:34,  1.34s/it] 95%|█████████▍| 446/471 [09:53<00:33,  1.35s/it] 95%|█████████▍| 447/471 [09:54<00:32,  1.35s/it] 95%|█████████▌| 448/471 [09:56<00:30,  1.34s/it] 95%|█████████▌| 449/471 [09:57<00:29,  1.34s/it] 96%|█████████▌| 450/471 [09:58<00:28,  1.35s/it] 96%|█████████▌| 451/471 [10:00<00:26,  1.34s/it] 96%|█████████▌| 452/471 [10:01<00:25,  1.34s/it] 96%|█████████▌| 453/471 [10:02<00:24,  1.35s/it] 96%|█████████▋| 454/471 [10:04<00:22,  1.35s/it] 97%|█████████▋| 455/471 [10:05<00:21,  1.35s/it] 97%|█████████▋| 456/471 [10:06<00:20,  1.35s/it] 97%|█████████▋| 457/471 [10:08<00:18,  1.35s/it] 97%|█████████▋| 458/471 [10:09<00:17,  1.35s/it] 97%|█████████▋| 459/471 [10:10<00:16,  1.34s/it] 98%|█████████▊| 460/471 [10:12<00:14,  1.34s/it] 98%|█████████▊| 461/471 [10:13<00:13,  1.34s/it] 98%|█████████▊| 462/471 [10:14<00:12,  1.34s/it] 98%|█████████▊| 463/471 [10:16<00:10,  1.34s/it] 99%|█████████▊| 464/471 [10:17<00:09,  1.34s/it] 99%|█████████▊| 465/471 [10:18<00:08,  1.34s/it] 99%|█████████▉| 466/471 [10:20<00:06,  1.34s/it] 99%|█████████▉| 467/471 [10:21<00:05,  1.34s/it] 99%|█████████▉| 468/471 [10:23<00:04,  1.34s/it]100%|█████████▉| 469/471 [10:24<00:02,  1.34s/it]100%|█████████▉| 470/471 [10:25<00:01,  1.34s/it]100%|██████████| 471/471 [10:26<00:00,  1.23s/it]100%|██████████| 471/471 [10:26<00:00,  1.33s/it]
{'eval_loss': 4.441004753112793, 'eval_model_preparation_time': 0.0109, 'eval_acc': 0.15918746680828466, 'eval_runtime': 627.9105, 'eval_samples_per_second': 11.995, 'eval_steps_per_second': 0.75}
ROUND:6
CLIENT:69
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.64s/it]                                              {'loss': 4.1306, 'grad_norm': 5.313421726226807, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.64s/it]  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]                                              {'loss': 3.8537, 'grad_norm': 6.335142612457275, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]  8%|▊         | 3/40 [00:07<01:25,  2.30s/it]                                              {'loss': 4.0672, 'grad_norm': 7.093076229095459, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.30s/it] 10%|█         | 4/40 [00:09<01:20,  2.25s/it]                                              {'loss': 4.297, 'grad_norm': 7.293919563293457, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.26s/it]                                              {'loss': 2.032, 'grad_norm': 6.144467830657959, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.26s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 3.6873, 'grad_norm': 12.19204044342041, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 2.0748, 'grad_norm': 11.210037231445312, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 1.0276, 'grad_norm': 37.028141021728516, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 1.2207, 'grad_norm': 11.318343162536621, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.0624, 'grad_norm': 24.15531349182129, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.7663, 'grad_norm': 13.41749382019043, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.07s/it]                                               {'loss': 1.0727, 'grad_norm': 5.267879962921143, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 1.5005, 'grad_norm': 5.787596702575684, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.8847, 'grad_norm': 6.31777286529541, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.5397, 'grad_norm': 3.9446089267730713, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.58s/it]                                               {'loss': 0.1584, 'grad_norm': 3.7694153785705566, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.58s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it]                                               {'loss': 0.4737, 'grad_norm': 4.197891712188721, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.3591, 'grad_norm': 6.004367828369141, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.5845, 'grad_norm': 3.6503281593322754, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.2624, 'grad_norm': 21.161861419677734, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.13s/it]                                               {'loss': 0.5972, 'grad_norm': 6.3664445877075195, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it]                                               {'loss': 0.8885, 'grad_norm': 6.275454044342041, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.787, 'grad_norm': 5.808853626251221, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.2027, 'grad_norm': 7.386627674102783, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.80s/it]                                               {'loss': 0.1466, 'grad_norm': 1.8172414302825928, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it]                                               {'loss': 0.2369, 'grad_norm': 2.846634864807129, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.2173, 'grad_norm': 4.256931781768799, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.3177, 'grad_norm': 4.9834089279174805, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.14s/it]                                               {'loss': 0.211, 'grad_norm': 2.641502857208252, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.2457, 'grad_norm': 3.5380475521087646, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.1824, 'grad_norm': 4.0238728523254395, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.2834, 'grad_norm': 15.379575729370117, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it]                                               {'loss': 0.0297, 'grad_norm': 0.41654250025749207, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.0443, 'grad_norm': 0.7695935368537903, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.0239, 'grad_norm': 0.4556369185447693, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.1483, 'grad_norm': 2.5384912490844727, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.15s/it]                                               {'loss': 0.0286, 'grad_norm': 0.47774839401245117, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it]                                               {'loss': 0.2874, 'grad_norm': 5.6194000244140625, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.0874, 'grad_norm': 1.4591411352157593, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0272, 'grad_norm': 1.7248785495758057, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 80.0166, 'train_samples_per_second': 7.061, 'train_steps_per_second': 0.5, 'train_loss': 1.001218721922487, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.60s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:74
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:56,  2.99s/it]                                              {'loss': 5.9698, 'grad_norm': 6.899147987365723, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:56,  2.99s/it]  5%|▌         | 2/40 [00:05<01:35,  2.52s/it]                                              {'loss': 3.3991, 'grad_norm': 5.122984409332275, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:35,  2.52s/it]  8%|▊         | 3/40 [00:07<01:26,  2.33s/it]                                              {'loss': 3.7852, 'grad_norm': 5.530477046966553, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:26,  2.33s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 3.349, 'grad_norm': 6.357742786407471, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 4.0183, 'grad_norm': 9.362685203552246, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 5.5937, 'grad_norm': 12.739725112915039, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 3.1756, 'grad_norm': 7.592258930206299, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:16<00:49,  1.55s/it]                                              {'loss': 3.7207, 'grad_norm': 45.31311798095703, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 2.3073, 'grad_norm': 6.701557636260986, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 1.1414, 'grad_norm': 4.758947849273682, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 0.9266, 'grad_norm': 4.541010856628418, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 1.5517, 'grad_norm': 5.302519798278809, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.10s/it]                                               {'loss': 1.5886, 'grad_norm': 6.118963718414307, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.12s/it]                                               {'loss': 1.8782, 'grad_norm': 6.569686412811279, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.13s/it]                                               {'loss': 1.6854, 'grad_norm': 5.844520092010498, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.13s/it] 40%|████      | 16/40 [00:31<00:37,  1.55s/it]                                               {'loss': 1.0224, 'grad_norm': 18.9791316986084, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.55s/it] 42%|████▎     | 17/40 [00:33<00:39,  1.73s/it]                                               {'loss': 1.2794, 'grad_norm': 6.847606182098389, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:39,  1.73s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.88s/it]                                               {'loss': 1.0572, 'grad_norm': 10.210036277770996, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.88s/it] 48%|████▊     | 19/40 [00:38<00:41,  1.98s/it]                                               {'loss': 0.414, 'grad_norm': 4.305943012237549, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  1.98s/it] 50%|█████     | 20/40 [00:40<00:40,  2.05s/it]                                               {'loss': 0.2995, 'grad_norm': 3.2836952209472656, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:40,  2.05s/it] 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it]                                               {'loss': 0.4666, 'grad_norm': 4.511885643005371, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 1.185, 'grad_norm': 8.079106330871582, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:47<00:36,  2.17s/it]                                               {'loss': 0.7005, 'grad_norm': 4.78277587890625, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:36,  2.17s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.8983, 'grad_norm': 10.324075698852539, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.75s/it]                                               {'loss': 0.5051, 'grad_norm': 2.9686055183410645, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.75s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it]                                               {'loss': 0.2641, 'grad_norm': 2.5797228813171387, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it]                                               {'loss': 0.1515, 'grad_norm': 3.081486940383911, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.1833, 'grad_norm': 1.7332627773284912, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it]                                               {'loss': 0.4764, 'grad_norm': 3.235456705093384, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.8105, 'grad_norm': 8.549395561218262, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it]                                               {'loss': 1.1533, 'grad_norm': 5.10339879989624, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it] 80%|████████  | 32/40 [01:03<00:12,  1.58s/it]                                               {'loss': 0.0767, 'grad_norm': 3.983981132507324, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.76s/it]                                               {'loss': 0.3686, 'grad_norm': 2.655867338180542, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.76s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it]                                               {'loss': 0.7587, 'grad_norm': 3.162146806716919, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.00s/it]                                               {'loss': 0.0994, 'grad_norm': 1.2071694135665894, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.00s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0367, 'grad_norm': 0.5523073673248291, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.12s/it]                                               {'loss': 0.4353, 'grad_norm': 4.696932792663574, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.12s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.16s/it]                                               {'loss': 0.6812, 'grad_norm': 6.975902080535889, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.16s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.0904, 'grad_norm': 1.4773653745651245, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'loss': 0.1243, 'grad_norm': 3.9773709774017334, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'train_runtime': 79.297, 'train_samples_per_second': 7.125, 'train_steps_per_second': 0.504, 'train_loss': 1.4407238668762148, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:34
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:31,  2.36s/it]                                              {'loss': 5.3764, 'grad_norm': 5.011690139770508, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:31,  2.36s/it]  5%|▌         | 2/40 [00:04<01:24,  2.23s/it]                                              {'loss': 4.172, 'grad_norm': 5.931631565093994, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.23s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 2.4181, 'grad_norm': 5.680750370025635, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 4.4332, 'grad_norm': 6.499090194702148, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it]                                              {'loss': 5.1642, 'grad_norm': 8.361567497253418, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.5358, 'grad_norm': 8.674660682678223, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.5827, 'grad_norm': 7.857787609100342, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 3.0026, 'grad_norm': 24.082902908325195, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it]                                              {'loss': 1.1306, 'grad_norm': 3.959803342819214, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.9612, 'grad_norm': 8.212014198303223, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.5955, 'grad_norm': 5.522964000701904, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 1.3346, 'grad_norm': 7.549802303314209, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 1.0557, 'grad_norm': 7.434271812438965, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 1.2702, 'grad_norm': 10.540386199951172, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 1.1977, 'grad_norm': 8.586526870727539, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 3.8212, 'grad_norm': 44.53848648071289, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.3638, 'grad_norm': 2.757571220397949, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.2559, 'grad_norm': 2.3299334049224854, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.5449, 'grad_norm': 4.3438310623168945, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.3708, 'grad_norm': 4.5507121086120605, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.4611, 'grad_norm': 4.713366508483887, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it]                                               {'loss': 0.3019, 'grad_norm': 4.863223075866699, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.3861, 'grad_norm': 5.464820384979248, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0096, 'grad_norm': 0.48659515380859375, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0781, 'grad_norm': 1.30588960647583, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.94s/it]                                               {'loss': 0.19, 'grad_norm': 2.6466622352600098, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.1128, 'grad_norm': 1.7751421928405762, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.0471, 'grad_norm': 0.6120707988739014, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.2247, 'grad_norm': 3.0990166664123535, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.04, 'grad_norm': 0.665537416934967, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.0617, 'grad_norm': 1.4011536836624146, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.031, 'grad_norm': 2.3458259105682373, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it]                                               {'loss': 0.0194, 'grad_norm': 0.3273673951625824, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it]                                               {'loss': 0.0165, 'grad_norm': 0.4211721420288086, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.0389, 'grad_norm': 0.677577018737793, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.0566, 'grad_norm': 1.5456832647323608, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.0339, 'grad_norm': 0.7547040581703186, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0848, 'grad_norm': 2.0047473907470703, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.0152, 'grad_norm': 0.4631338119506836, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.63s/it]                                               {'loss': 0.79, 'grad_norm': 28.22658348083496, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.63s/it]                                               {'train_runtime': 80.4062, 'train_samples_per_second': 7.027, 'train_steps_per_second': 0.497, 'train_loss': 1.1396579423220827, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:68
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:33,  2.40s/it]                                              {'loss': 3.1759, 'grad_norm': 6.326890468597412, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:33,  2.40s/it]  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]                                              {'loss': 3.8052, 'grad_norm': 7.24772310256958, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 3.2971, 'grad_norm': 8.2279052734375, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:08<01:20,  2.22s/it]                                              {'loss': 4.1913, 'grad_norm': 8.73021125793457, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:20,  2.22s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 3.0642, 'grad_norm': 13.100939750671387, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 3.7264, 'grad_norm': 16.535890579223633, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 3.2651, 'grad_norm': 10.969942092895508, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 1.0911, 'grad_norm': 26.766393661499023, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 0.9184, 'grad_norm': 6.150162220001221, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.8851, 'grad_norm': 4.344557762145996, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.5798, 'grad_norm': 5.990307807922363, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.931, 'grad_norm': 7.4603190422058105, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it]                                               {'loss': 0.4774, 'grad_norm': 8.5220365524292, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 1.9908, 'grad_norm': 7.826539039611816, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.6328, 'grad_norm': 8.744153022766113, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.58s/it]                                               {'loss': 0.4804, 'grad_norm': 16.0084171295166, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.2868, 'grad_norm': 2.3549234867095947, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.7554, 'grad_norm': 8.23145866394043, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.1568, 'grad_norm': 1.5157620906829834, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:42,  2.10s/it]                                               {'loss': 0.1824, 'grad_norm': 2.7992467880249023, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it]                                               {'loss': 0.0799, 'grad_norm': 0.8621717691421509, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.1803, 'grad_norm': 2.1080055236816406, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.3198, 'grad_norm': 4.281851291656494, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 2.9365, 'grad_norm': 94.42688751220703, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it]                                               {'loss': 0.0858, 'grad_norm': 1.169617772102356, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it]                                               {'loss': 0.1965, 'grad_norm': 12.8855562210083, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.0984, 'grad_norm': 1.1965664625167847, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.0297, 'grad_norm': 0.40418025851249695, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.0285, 'grad_norm': 0.5023744106292725, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.1655, 'grad_norm': 5.939787864685059, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.0946, 'grad_norm': 1.727639079093933, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.1544, 'grad_norm': 5.444849491119385, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0171, 'grad_norm': 0.36402055621147156, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it]                                               {'loss': 0.0396, 'grad_norm': 1.1506688594818115, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it]                                               {'loss': 0.0153, 'grad_norm': 0.33076757192611694, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it]                                               {'loss': 0.1916, 'grad_norm': 2.723235607147217, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.0256, 'grad_norm': 0.86659836769104, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0875, 'grad_norm': 2.820549964904785, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.0449, 'grad_norm': 0.6124414801597595, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0089, 'grad_norm': 0.30057674646377563, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.0611, 'train_samples_per_second': 7.057, 'train_steps_per_second': 0.5, 'train_loss': 0.9923394970595837, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:27,  2.25s/it]                                              {'loss': 3.5651, 'grad_norm': 7.1867804527282715, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:27,  2.25s/it]  5%|▌         | 2/40 [00:04<01:23,  2.20s/it]                                              {'loss': 3.5555, 'grad_norm': 7.295393943786621, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.20s/it]  8%|▊         | 3/40 [00:06<01:21,  2.19s/it]                                              {'loss': 2.682, 'grad_norm': 6.112939834594727, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.19s/it] 10%|█         | 4/40 [00:08<01:18,  2.18s/it]                                              {'loss': 4.9387, 'grad_norm': 7.8746490478515625, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.18s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 2.4738, 'grad_norm': 7.3055100440979, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 3.1851, 'grad_norm': 8.313118934631348, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.4215, 'grad_norm': 7.535776615142822, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 4.2407, 'grad_norm': 39.33289337158203, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it]                                              {'loss': 2.1705, 'grad_norm': 15.618593215942383, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.4132, 'grad_norm': 8.785584449768066, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.8188, 'grad_norm': 4.3421630859375, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 1.0704, 'grad_norm': 5.086303234100342, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it]                                               {'loss': 1.4136, 'grad_norm': 7.972235202789307, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.19s/it]                                               {'loss': 0.7756, 'grad_norm': 12.79433536529541, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.19s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 1.1992, 'grad_norm': 14.412847518920898, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 3.2049, 'grad_norm': 24.81311798095703, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.5227, 'grad_norm': 3.9404923915863037, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.3438, 'grad_norm': 5.244870662689209, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.366, 'grad_norm': 3.6406490802764893, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:42,  2.10s/it]                                               {'loss': 0.3256, 'grad_norm': 2.1411526203155518, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:42<00:41,  2.16s/it]                                               {'loss': 0.4371, 'grad_norm': 4.9299163818359375, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:41,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it]                                               {'loss': 0.6479, 'grad_norm': 6.995426177978516, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it]                                               {'loss': 0.8132, 'grad_norm': 6.475692272186279, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it] 60%|██████    | 24/40 [00:47<00:25,  1.62s/it]                                               {'loss': 0.0235, 'grad_norm': 0.8000633716583252, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.82s/it]                                               {'loss': 0.0838, 'grad_norm': 2.4012606143951416, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.4152, 'grad_norm': 4.265021324157715, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it]                                               {'loss': 0.1186, 'grad_norm': 1.972485899925232, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it] 70%|███████   | 28/40 [00:56<00:25,  2.13s/it]                                               {'loss': 0.42, 'grad_norm': 4.0511603355407715, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.13s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it]                                               {'loss': 0.0895, 'grad_norm': 1.4451295137405396, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it]                                               {'loss': 0.1016, 'grad_norm': 3.060866594314575, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.26s/it]                                               {'loss': 0.2813, 'grad_norm': 3.545665740966797, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.26s/it] 80%|████████  | 32/40 [01:03<00:13,  1.64s/it]                                               {'loss': 0.0795, 'grad_norm': 5.377114772796631, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:13,  1.64s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it]                                               {'loss': 0.1042, 'grad_norm': 3.950493574142456, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.2897, 'grad_norm': 11.96802806854248, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it]                                               {'loss': 0.0898, 'grad_norm': 3.573530435562134, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it]                                               {'loss': 0.0652, 'grad_norm': 0.8471630215644836, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it]                                               {'loss': 0.0805, 'grad_norm': 2.2739806175231934, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.24s/it]                                               {'loss': 0.3459, 'grad_norm': 5.869894981384277, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.24s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.28s/it]                                               {'loss': 0.1439, 'grad_norm': 3.097404956817627, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.28s/it]100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'loss': 0.1172, 'grad_norm': 7.718900203704834, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'train_runtime': 80.6308, 'train_samples_per_second': 7.007, 'train_steps_per_second': 0.496, 'train_loss': 1.1358584414236248, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.65s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:0
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:28,  2.26s/it]                                              {'loss': 4.0629, 'grad_norm': 5.025153160095215, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:28,  2.26s/it]  5%|▌         | 2/40 [00:04<01:24,  2.21s/it]                                              {'loss': 5.0214, 'grad_norm': 9.686844825744629, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.21s/it]  8%|▊         | 3/40 [00:06<01:22,  2.22s/it]                                              {'loss': 3.4306, 'grad_norm': 9.547350883483887, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.22s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 4.1722, 'grad_norm': 15.071309089660645, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it]                                              {'loss': 3.2835, 'grad_norm': 13.071621894836426, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.21s/it]                                              {'loss': 3.2164, 'grad_norm': 12.56566047668457, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 1.6187, 'grad_norm': 13.68631362915039, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.7577, 'grad_norm': 37.12849807739258, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 0.5996, 'grad_norm': 5.997045993804932, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.8964, 'grad_norm': 15.62944221496582, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.302, 'grad_norm': 11.296074867248535, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.6576, 'grad_norm': 6.535751819610596, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it]                                               {'loss': 1.5202, 'grad_norm': 8.696212768554688, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 1.0516, 'grad_norm': 5.601253509521484, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 1.0194, 'grad_norm': 5.093639850616455, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.9145, 'grad_norm': 25.879762649536133, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.3369, 'grad_norm': 4.648542881011963, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.7548, 'grad_norm': 28.769733428955078, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.5094, 'grad_norm': 16.874263763427734, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.3088, 'grad_norm': 9.379063606262207, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.4227, 'grad_norm': 5.1480302810668945, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.6903, 'grad_norm': 6.217345714569092, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.2614, 'grad_norm': 6.783103942871094, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0066, 'grad_norm': 0.4130541682243347, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.0782, 'grad_norm': 1.7395011186599731, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.9096, 'grad_norm': 20.117431640625, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.9256, 'grad_norm': 10.119038581848145, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.139, 'grad_norm': 2.086063861846924, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.8769, 'grad_norm': 6.790288925170898, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.1897, 'grad_norm': 5.915169715881348, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it]                                               {'loss': 0.3938, 'grad_norm': 4.919809818267822, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.1254, 'grad_norm': 6.073976516723633, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it]                                               {'loss': 0.046, 'grad_norm': 0.9037964940071106, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it]                                               {'loss': 0.0897, 'grad_norm': 1.613261342048645, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.6283, 'grad_norm': 4.7950568199157715, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0487, 'grad_norm': 1.1954728364944458, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.1186, 'grad_norm': 2.7665934562683105, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.1433, 'grad_norm': 3.0605413913726807, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.0452, 'grad_norm': 0.8610967993736267, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0069, 'grad_norm': 0.4789254665374756, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.8145, 'train_samples_per_second': 7.079, 'train_steps_per_second': 0.501, 'train_loss': 1.0645073623862118, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  2.00s/it]
CLIENT:32
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:41,  2.59s/it]                                              {'loss': 5.3277, 'grad_norm': 9.6973876953125, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:41,  2.59s/it]  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]                                              {'loss': 4.4746, 'grad_norm': 5.4124321937561035, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 4.8091, 'grad_norm': 8.931029319763184, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:21,  2.27s/it]                                              {'loss': 3.9019, 'grad_norm': 6.728754043579102, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.27s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 2.6652, 'grad_norm': 18.931320190429688, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 3.1801, 'grad_norm': 11.708483695983887, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 2.9675, 'grad_norm': 11.646758079528809, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 5.3046, 'grad_norm': 46.75154495239258, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 2.2057, 'grad_norm': 11.944496154785156, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 2.0594, 'grad_norm': 20.12560272216797, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.4161, 'grad_norm': 15.58497142791748, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 2.3093, 'grad_norm': 17.630708694458008, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 1.1072, 'grad_norm': 10.19736099243164, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 1.8794, 'grad_norm': 12.942557334899902, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it]                                               {'loss': 1.8822, 'grad_norm': 9.117409706115723, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 2.1675, 'grad_norm': 24.382143020629883, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.78s/it]                                               {'loss': 0.5437, 'grad_norm': 4.571179389953613, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 1.2478, 'grad_norm': 8.02906322479248, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 1.1512, 'grad_norm': 6.894387245178223, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 1.0679, 'grad_norm': 5.2256646156311035, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 0.9014, 'grad_norm': 6.202445983886719, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 1.0617, 'grad_norm': 4.796465873718262, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 1.1244, 'grad_norm': 8.559330940246582, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.2662, 'grad_norm': 9.067320823669434, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.2262, 'grad_norm': 2.624518632888794, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.2131, 'grad_norm': 3.589416980743408, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.1882, 'grad_norm': 3.675492525100708, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:56<00:25,  2.13s/it]                                               {'loss': 0.288, 'grad_norm': 3.0737500190734863, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.13s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.549, 'grad_norm': 4.356892108917236, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it]                                               {'loss': 0.1955, 'grad_norm': 2.531308174133301, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.4309, 'grad_norm': 5.618290901184082, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.0148, 'grad_norm': 0.6138479113578796, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it]                                               {'loss': 0.2108, 'grad_norm': 3.6803438663482666, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.98s/it]                                               {'loss': 0.3503, 'grad_norm': 2.117643356323242, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.98s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it]                                               {'loss': 0.1591, 'grad_norm': 4.741952419281006, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it]                                               {'loss': 0.318, 'grad_norm': 4.7457966804504395, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it]                                               {'loss': 0.0824, 'grad_norm': 2.3035619258880615, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it]                                               {'loss': 0.057, 'grad_norm': 1.5039993524551392, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.2314, 'grad_norm': 6.774065971374512, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.052, 'grad_norm': 3.264554023742676, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.7325, 'train_samples_per_second': 6.998, 'train_steps_per_second': 0.495, 'train_loss': 1.4647030268097296, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:88
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:41,  2.61s/it]                                              {'loss': 4.2963, 'grad_norm': 5.1177215576171875, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:41,  2.61s/it]  5%|▌         | 2/40 [00:04<01:29,  2.34s/it]                                              {'loss': 2.7021, 'grad_norm': 5.534032344818115, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.34s/it]  8%|▊         | 3/40 [00:06<01:24,  2.29s/it]                                              {'loss': 2.5434, 'grad_norm': 10.621567726135254, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 3.4121, 'grad_norm': 9.144315719604492, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 2.6928, 'grad_norm': 8.214635848999023, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 3.0, 'grad_norm': 17.901639938354492, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.8656, 'grad_norm': 13.2456636428833, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 2.0125, 'grad_norm': 38.409366607666016, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.77s/it]                                              {'loss': 1.1642, 'grad_norm': 8.09639835357666, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.3454, 'grad_norm': 8.584280014038086, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.8276, 'grad_norm': 6.512093544006348, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.07s/it]                                               {'loss': 1.8688, 'grad_norm': 8.574152946472168, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 1.3851, 'grad_norm': 6.135878086090088, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.15s/it]                                               {'loss': 1.1173, 'grad_norm': 6.3500213623046875, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.6059, 'grad_norm': 5.264353275299072, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.1751, 'grad_norm': 6.428672790527344, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.767, 'grad_norm': 11.915144920349121, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it]                                               {'loss': 0.7404, 'grad_norm': 32.591590881347656, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.4265, 'grad_norm': 6.533854961395264, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:42,  2.10s/it]                                               {'loss': 0.5171, 'grad_norm': 4.154934883117676, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it]                                               {'loss': 0.2717, 'grad_norm': 3.091420888900757, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 0.3615, 'grad_norm': 3.2676610946655273, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.4136, 'grad_norm': 8.916707992553711, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0313, 'grad_norm': 1.3127031326293945, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it]                                               {'loss': 0.37, 'grad_norm': 3.724838972091675, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.4007, 'grad_norm': 4.057194709777832, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.4031, 'grad_norm': 4.617496490478516, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.12s/it]                                               {'loss': 0.1122, 'grad_norm': 1.5320179462432861, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it]                                               {'loss': 0.0728, 'grad_norm': 1.0636229515075684, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.6172, 'grad_norm': 5.80714750289917, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.2012, 'grad_norm': 2.3636865615844727, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.2344, 'grad_norm': 10.319955825805664, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.78s/it]                                               {'loss': 0.0445, 'grad_norm': 1.12743079662323, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.0541, 'grad_norm': 1.3488273620605469, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.1775, 'grad_norm': 5.832531452178955, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.267, 'grad_norm': 2.3525185585021973, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.3031, 'grad_norm': 2.823052406311035, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.187, 'grad_norm': 3.5767176151275635, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.2521, 'grad_norm': 6.990017414093018, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.1807, 'grad_norm': 7.393101692199707, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.1825, 'train_samples_per_second': 7.046, 'train_steps_per_second': 0.499, 'train_loss': 0.985517106205225, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:8
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]                                              {'loss': 2.3767, 'grad_norm': 4.74228572845459, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]  5%|▌         | 2/40 [00:04<01:23,  2.20s/it]                                              {'loss': 3.7827, 'grad_norm': 5.595343589782715, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.20s/it]  8%|▊         | 3/40 [00:06<01:20,  2.18s/it]                                              {'loss': 2.2456, 'grad_norm': 45.9629020690918, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.18s/it] 10%|█         | 4/40 [00:08<01:18,  2.17s/it]                                              {'loss': 4.3988, 'grad_norm': 12.084423065185547, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.17s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.17s/it]                                              {'loss': 2.6985, 'grad_norm': 12.820039749145508, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.17s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 2.8813, 'grad_norm': 15.146842002868652, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 2.9266, 'grad_norm': 11.932084083557129, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 0.7965, 'grad_norm': 40.385154724121094, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it]                                              {'loss': 0.7416, 'grad_norm': 19.666011810302734, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:19<00:57,  1.91s/it]                                               {'loss': 1.6667, 'grad_norm': 38.0207405090332, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.4382, 'grad_norm': 13.271113395690918, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 1.5633, 'grad_norm': 7.648819923400879, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 0.9005, 'grad_norm': 5.148412227630615, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it]                                               {'loss': 1.5603, 'grad_norm': 10.013505935668945, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 1.1179, 'grad_norm': 7.583500385284424, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.0582, 'grad_norm': 2.6279282569885254, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.2561, 'grad_norm': 3.248162269592285, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it]                                               {'loss': 0.3313, 'grad_norm': 2.931674003601074, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.6738, 'grad_norm': 4.0313615798950195, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 1.0299, 'grad_norm': 7.025745391845703, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.6083, 'grad_norm': 6.2087554931640625, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it]                                               {'loss': 0.3113, 'grad_norm': 3.2280385494232178, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.6091, 'grad_norm': 3.2423243522644043, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.1103, 'grad_norm': 3.874429941177368, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it]                                               {'loss': 0.1834, 'grad_norm': 1.6256459951400757, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.1058, 'grad_norm': 1.671812653541565, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.0912, 'grad_norm': 2.0602502822875977, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.0661, 'grad_norm': 1.7896021604537964, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.1497, 'grad_norm': 2.297075033187866, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it]                                               {'loss': 0.4566, 'grad_norm': 9.072386741638184, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.2149, 'grad_norm': 3.1016273498535156, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0747, 'grad_norm': 3.387617826461792, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0439, 'grad_norm': 0.9369763135910034, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it]                                               {'loss': 0.068, 'grad_norm': 1.896010160446167, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.1068, 'grad_norm': 1.817419409751892, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it]                                               {'loss': 0.041, 'grad_norm': 6.9947333335876465, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.18s/it]                                               {'loss': 0.0478, 'grad_norm': 0.7669093012809753, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.2305, 'grad_norm': 7.4336347579956055, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.0689, 'grad_norm': 2.2076730728149414, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0744, 'grad_norm': 4.517960548400879, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.7379, 'train_samples_per_second': 7.086, 'train_steps_per_second': 0.502, 'train_loss': 0.9276746662333608, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:3
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:31,  2.36s/it]                                              {'loss': 3.9253, 'grad_norm': 9.848448753356934, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:31,  2.36s/it]  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]                                              {'loss': 2.9236, 'grad_norm': 4.896846771240234, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]  8%|▊         | 3/40 [00:06<01:21,  2.20s/it]                                              {'loss': 3.7342, 'grad_norm': 10.88927173614502, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.20s/it] 10%|█         | 4/40 [00:08<01:19,  2.22s/it]                                              {'loss': 3.7119, 'grad_norm': 7.9612274169921875, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.22s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it]                                              {'loss': 3.7368, 'grad_norm': 13.857329368591309, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 3.9724, 'grad_norm': 13.869107246398926, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 3.3485, 'grad_norm': 25.460445404052734, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 2.9712, 'grad_norm': 29.2028751373291, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 1.835, 'grad_norm': 16.689863204956055, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 2.0494, 'grad_norm': 13.969305992126465, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it]                                               {'loss': 1.7253, 'grad_norm': 11.747452735900879, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 0.9708, 'grad_norm': 7.225415229797363, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it]                                               {'loss': 1.2391, 'grad_norm': 6.177757740020752, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.6186, 'grad_norm': 5.8289313316345215, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 1.1512, 'grad_norm': 21.471296310424805, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.6952, 'grad_norm': 11.931051254272461, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.895, 'grad_norm': 4.849359512329102, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.5994, 'grad_norm': 6.99409818649292, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.7546, 'grad_norm': 4.757857799530029, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:42,  2.10s/it]                                               {'loss': 1.0914, 'grad_norm': 8.82541275024414, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it]                                               {'loss': 0.6482, 'grad_norm': 4.635996341705322, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it]                                               {'loss': 0.3657, 'grad_norm': 3.701618194580078, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it]                                               {'loss': 0.6208, 'grad_norm': 5.4197235107421875, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.4115, 'grad_norm': 27.150251388549805, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.2824, 'grad_norm': 4.269076347351074, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it]                                               {'loss': 0.3212, 'grad_norm': 7.001463413238525, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it]                                               {'loss': 0.2768, 'grad_norm': 4.809905052185059, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it] 70%|███████   | 28/40 [00:56<00:25,  2.14s/it]                                               {'loss': 0.7216, 'grad_norm': 5.978835582733154, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it]                                               {'loss': 0.2386, 'grad_norm': 3.4101803302764893, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it]                                               {'loss': 0.2779, 'grad_norm': 3.335132360458374, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.3341, 'grad_norm': 3.9519083499908447, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.0096, 'grad_norm': 0.592393696308136, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it]                                               {'loss': 0.0602, 'grad_norm': 1.635704755783081, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.1148, 'grad_norm': 4.669037342071533, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it]                                               {'loss': 0.1818, 'grad_norm': 3.679766893386841, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it]                                               {'loss': 0.1485, 'grad_norm': 2.3003952503204346, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it]                                               {'loss': 0.2791, 'grad_norm': 7.162683963775635, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it]                                               {'loss': 0.9207, 'grad_norm': 15.161288261413574, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.1212, 'grad_norm': 2.1086342334747314, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.2601, 'grad_norm': 11.36919116973877, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.6017, 'train_samples_per_second': 7.01, 'train_steps_per_second': 0.496, 'train_loss': 1.2135858681984246, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<05:00,  1.56it/s]  1%|          | 3/471 [00:02<07:04,  1.10it/s]  1%|          | 4/471 [00:03<08:11,  1.05s/it]  1%|          | 5/471 [00:05<08:49,  1.14s/it]  1%|▏         | 6/471 [00:06<09:12,  1.19s/it]  1%|▏         | 7/471 [00:07<09:28,  1.22s/it]  2%|▏         | 8/471 [00:09<09:37,  1.25s/it]  2%|▏         | 9/471 [00:10<09:44,  1.26s/it]  2%|▏         | 10/471 [00:11<09:48,  1.28s/it]  2%|▏         | 11/471 [00:12<09:50,  1.28s/it]  3%|▎         | 12/471 [00:14<09:52,  1.29s/it]  3%|▎         | 13/471 [00:15<09:54,  1.30s/it]  3%|▎         | 14/471 [00:16<09:54,  1.30s/it]  3%|▎         | 15/471 [00:18<09:54,  1.30s/it]  3%|▎         | 16/471 [00:19<09:54,  1.31s/it]  4%|▎         | 17/471 [00:20<09:54,  1.31s/it]  4%|▍         | 18/471 [00:22<09:53,  1.31s/it]  4%|▍         | 19/471 [00:23<09:53,  1.31s/it]  4%|▍         | 20/471 [00:24<09:52,  1.31s/it]  4%|▍         | 21/471 [00:26<09:51,  1.32s/it]  5%|▍         | 22/471 [00:27<09:51,  1.32s/it]  5%|▍         | 23/471 [00:28<09:49,  1.32s/it]  5%|▌         | 24/471 [00:30<09:49,  1.32s/it]  5%|▌         | 25/471 [00:31<09:47,  1.32s/it]  6%|▌         | 26/471 [00:32<09:47,  1.32s/it]  6%|▌         | 27/471 [00:34<09:46,  1.32s/it]  6%|▌         | 28/471 [00:35<09:45,  1.32s/it]  6%|▌         | 29/471 [00:36<09:44,  1.32s/it]  6%|▋         | 30/471 [00:37<09:44,  1.33s/it]  7%|▋         | 31/471 [00:39<09:43,  1.33s/it]  7%|▋         | 32/471 [00:40<09:42,  1.33s/it]  7%|▋         | 33/471 [00:41<09:39,  1.32s/it]  7%|▋         | 34/471 [00:43<09:38,  1.32s/it]  7%|▋         | 35/471 [00:44<09:38,  1.33s/it]  8%|▊         | 36/471 [00:45<09:36,  1.33s/it]  8%|▊         | 37/471 [00:47<09:36,  1.33s/it]  8%|▊         | 38/471 [00:48<09:35,  1.33s/it]  8%|▊         | 39/471 [00:49<09:34,  1.33s/it]  8%|▊         | 40/471 [00:51<09:32,  1.33s/it]  9%|▊         | 41/471 [00:52<09:32,  1.33s/it]  9%|▉         | 42/471 [00:53<09:32,  1.33s/it]  9%|▉         | 43/471 [00:55<09:29,  1.33s/it]  9%|▉         | 44/471 [00:56<09:28,  1.33s/it] 10%|▉         | 45/471 [00:57<09:27,  1.33s/it] 10%|▉         | 46/471 [00:59<09:26,  1.33s/it] 10%|▉         | 47/471 [01:00<09:24,  1.33s/it] 10%|█         | 48/471 [01:01<09:24,  1.33s/it] 10%|█         | 49/471 [01:03<09:23,  1.34s/it] 11%|█         | 50/471 [01:04<09:22,  1.34s/it] 11%|█         | 51/471 [01:05<09:21,  1.34s/it] 11%|█         | 52/471 [01:07<09:20,  1.34s/it] 11%|█▏        | 53/471 [01:08<09:20,  1.34s/it] 11%|█▏        | 54/471 [01:09<09:19,  1.34s/it] 12%|█▏        | 55/471 [01:11<09:18,  1.34s/it] 12%|█▏        | 56/471 [01:12<09:17,  1.34s/it] 12%|█▏        | 57/471 [01:14<09:16,  1.34s/it] 12%|█▏        | 58/471 [01:15<09:14,  1.34s/it] 13%|█▎        | 59/471 [01:16<09:14,  1.35s/it] 13%|█▎        | 60/471 [01:18<09:12,  1.35s/it] 13%|█▎        | 61/471 [01:19<09:11,  1.35s/it] 13%|█▎        | 62/471 [01:20<09:10,  1.35s/it] 13%|█▎        | 63/471 [01:22<09:08,  1.34s/it] 14%|█▎        | 64/471 [01:23<09:07,  1.34s/it] 14%|█▍        | 65/471 [01:24<09:05,  1.34s/it] 14%|█▍        | 66/471 [01:26<09:04,  1.34s/it] 14%|█▍        | 67/471 [01:27<09:03,  1.35s/it] 14%|█▍        | 68/471 [01:28<09:01,  1.34s/it] 15%|█▍        | 69/471 [01:30<09:00,  1.35s/it] 15%|█▍        | 70/471 [01:31<09:00,  1.35s/it] 15%|█▌        | 71/471 [01:32<08:58,  1.35s/it] 15%|█▌        | 72/471 [01:34<08:57,  1.35s/it] 15%|█▌        | 73/471 [01:35<08:55,  1.35s/it] 16%|█▌        | 74/471 [01:36<08:53,  1.34s/it] 16%|█▌        | 75/471 [01:38<08:53,  1.35s/it] 16%|█▌        | 76/471 [01:39<08:51,  1.35s/it] 16%|█▋        | 77/471 [01:40<08:50,  1.35s/it] 17%|█▋        | 78/471 [01:42<08:48,  1.35s/it] 17%|█▋        | 79/471 [01:43<08:48,  1.35s/it] 17%|█▋        | 80/471 [01:44<08:46,  1.35s/it] 17%|█▋        | 81/471 [01:46<08:44,  1.35s/it] 17%|█▋        | 82/471 [01:47<08:43,  1.35s/it] 18%|█▊        | 83/471 [01:49<08:42,  1.35s/it] 18%|█▊        | 84/471 [01:50<08:41,  1.35s/it] 18%|█▊        | 85/471 [01:51<08:40,  1.35s/it] 18%|█▊        | 86/471 [01:53<08:38,  1.35s/it] 18%|█▊        | 87/471 [01:54<08:37,  1.35s/it] 19%|█▊        | 88/471 [01:55<08:35,  1.35s/it] 19%|█▉        | 89/471 [01:57<08:33,  1.35s/it] 19%|█▉        | 90/471 [01:58<08:33,  1.35s/it] 19%|█▉        | 91/471 [01:59<08:31,  1.35s/it] 20%|█▉        | 92/471 [02:01<08:29,  1.34s/it] 20%|█▉        | 93/471 [02:02<08:28,  1.35s/it] 20%|█▉        | 94/471 [02:03<08:26,  1.34s/it] 20%|██        | 95/471 [02:05<08:25,  1.34s/it] 20%|██        | 96/471 [02:06<08:23,  1.34s/it] 21%|██        | 97/471 [02:07<08:23,  1.35s/it] 21%|██        | 98/471 [02:09<08:21,  1.34s/it] 21%|██        | 99/471 [02:10<08:19,  1.34s/it] 21%|██        | 100/471 [02:11<08:18,  1.34s/it] 21%|██▏       | 101/471 [02:13<08:17,  1.34s/it] 22%|██▏       | 102/471 [02:14<08:16,  1.35s/it] 22%|██▏       | 103/471 [02:15<08:15,  1.35s/it] 22%|██▏       | 104/471 [02:17<08:14,  1.35s/it] 22%|██▏       | 105/471 [02:18<08:14,  1.35s/it] 23%|██▎       | 106/471 [02:19<08:11,  1.35s/it] 23%|██▎       | 107/471 [02:21<08:10,  1.35s/it] 23%|██▎       | 108/471 [02:22<08:08,  1.35s/it] 23%|██▎       | 109/471 [02:23<08:06,  1.34s/it] 23%|██▎       | 110/471 [02:25<08:04,  1.34s/it] 24%|██▎       | 111/471 [02:26<08:03,  1.34s/it] 24%|██▍       | 112/471 [02:28<08:02,  1.34s/it] 24%|██▍       | 113/471 [02:29<08:01,  1.34s/it] 24%|██▍       | 114/471 [02:30<08:00,  1.35s/it] 24%|██▍       | 115/471 [02:32<07:59,  1.35s/it] 25%|██▍       | 116/471 [02:33<07:58,  1.35s/it] 25%|██▍       | 117/471 [02:34<07:56,  1.35s/it] 25%|██▌       | 118/471 [02:36<07:55,  1.35s/it] 25%|██▌       | 119/471 [02:37<07:54,  1.35s/it] 25%|██▌       | 120/471 [02:38<07:53,  1.35s/it] 26%|██▌       | 121/471 [02:40<07:52,  1.35s/it] 26%|██▌       | 122/471 [02:41<07:48,  1.34s/it] 26%|██▌       | 123/471 [02:42<07:47,  1.34s/it] 26%|██▋       | 124/471 [02:44<07:47,  1.35s/it] 27%|██▋       | 125/471 [02:45<07:46,  1.35s/it] 27%|██▋       | 126/471 [02:46<07:45,  1.35s/it] 27%|██▋       | 127/471 [02:48<07:43,  1.35s/it] 27%|██▋       | 128/471 [02:49<07:42,  1.35s/it] 27%|██▋       | 129/471 [02:50<07:40,  1.35s/it] 28%|██▊       | 130/471 [02:52<07:39,  1.35s/it] 28%|██▊       | 131/471 [02:53<07:39,  1.35s/it] 28%|██▊       | 132/471 [02:54<07:37,  1.35s/it] 28%|██▊       | 133/471 [02:56<07:36,  1.35s/it] 28%|██▊       | 134/471 [02:57<07:35,  1.35s/it] 29%|██▊       | 135/471 [02:59<07:34,  1.35s/it] 29%|██▉       | 136/471 [03:00<07:32,  1.35s/it] 29%|██▉       | 137/471 [03:01<07:31,  1.35s/it] 29%|██▉       | 138/471 [03:03<07:30,  1.35s/it] 30%|██▉       | 139/471 [03:04<07:29,  1.35s/it] 30%|██▉       | 140/471 [03:05<07:27,  1.35s/it] 30%|██▉       | 141/471 [03:07<07:26,  1.35s/it] 30%|███       | 142/471 [03:08<07:25,  1.35s/it] 30%|███       | 143/471 [03:09<07:23,  1.35s/it] 31%|███       | 144/471 [03:11<07:23,  1.36s/it] 31%|███       | 145/471 [03:12<07:21,  1.35s/it] 31%|███       | 146/471 [03:13<07:20,  1.36s/it] 31%|███       | 147/471 [03:15<07:19,  1.36s/it] 31%|███▏      | 148/471 [03:16<07:18,  1.36s/it] 32%|███▏      | 149/471 [03:18<07:17,  1.36s/it] 32%|███▏      | 150/471 [03:19<07:16,  1.36s/it] 32%|███▏      | 151/471 [03:20<07:14,  1.36s/it] 32%|███▏      | 152/471 [03:22<07:13,  1.36s/it] 32%|███▏      | 153/471 [03:23<07:12,  1.36s/it] 33%|███▎      | 154/471 [03:24<07:10,  1.36s/it] 33%|███▎      | 155/471 [03:26<07:09,  1.36s/it] 33%|███▎      | 156/471 [03:27<07:07,  1.36s/it] 33%|███▎      | 157/471 [03:28<07:05,  1.36s/it] 34%|███▎      | 158/471 [03:30<07:04,  1.36s/it] 34%|███▍      | 159/471 [03:31<07:02,  1.36s/it] 34%|███▍      | 160/471 [03:32<07:02,  1.36s/it] 34%|███▍      | 161/471 [03:34<07:01,  1.36s/it] 34%|███▍      | 162/471 [03:35<07:00,  1.36s/it] 35%|███▍      | 163/471 [03:37<06:59,  1.36s/it] 35%|███▍      | 164/471 [03:38<06:57,  1.36s/it] 35%|███▌      | 165/471 [03:39<06:56,  1.36s/it] 35%|███▌      | 166/471 [03:41<06:55,  1.36s/it] 35%|███▌      | 167/471 [03:42<06:53,  1.36s/it] 36%|███▌      | 168/471 [03:43<06:52,  1.36s/it] 36%|███▌      | 169/471 [03:45<06:51,  1.36s/it] 36%|███▌      | 170/471 [03:46<06:49,  1.36s/it] 36%|███▋      | 171/471 [03:47<06:48,  1.36s/it] 37%|███▋      | 172/471 [03:49<06:46,  1.36s/it] 37%|███▋      | 173/471 [03:50<06:45,  1.36s/it] 37%|███▋      | 174/471 [03:51<06:44,  1.36s/it] 37%|███▋      | 175/471 [03:53<06:43,  1.36s/it] 37%|███▋      | 176/471 [03:54<06:40,  1.36s/it] 38%|███▊      | 177/471 [03:56<06:39,  1.36s/it] 38%|███▊      | 178/471 [03:57<06:38,  1.36s/it] 38%|███▊      | 179/471 [03:58<06:36,  1.36s/it] 38%|███▊      | 180/471 [04:00<06:35,  1.36s/it] 38%|███▊      | 181/471 [04:01<06:33,  1.36s/it] 39%|███▊      | 182/471 [04:02<06:32,  1.36s/it] 39%|███▉      | 183/471 [04:04<06:31,  1.36s/it] 39%|███▉      | 184/471 [04:05<06:29,  1.36s/it] 39%|███▉      | 185/471 [04:06<06:28,  1.36s/it] 39%|███▉      | 186/471 [04:08<06:27,  1.36s/it] 40%|███▉      | 187/471 [04:09<06:25,  1.36s/it] 40%|███▉      | 188/471 [04:11<06:24,  1.36s/it] 40%|████      | 189/471 [04:12<06:22,  1.36s/it] 40%|████      | 190/471 [04:13<06:21,  1.36s/it] 41%|████      | 191/471 [04:15<06:20,  1.36s/it] 41%|████      | 192/471 [04:16<06:18,  1.36s/it] 41%|████      | 193/471 [04:17<06:16,  1.35s/it] 41%|████      | 194/471 [04:19<06:15,  1.36s/it] 41%|████▏     | 195/471 [04:20<06:14,  1.36s/it] 42%|████▏     | 196/471 [04:21<06:12,  1.36s/it] 42%|████▏     | 197/471 [04:23<06:10,  1.35s/it] 42%|████▏     | 198/471 [04:24<06:08,  1.35s/it] 42%|████▏     | 199/471 [04:25<06:07,  1.35s/it] 42%|████▏     | 200/471 [04:27<06:06,  1.35s/it] 43%|████▎     | 201/471 [04:28<06:04,  1.35s/it] 43%|████▎     | 202/471 [04:29<06:03,  1.35s/it] 43%|████▎     | 203/471 [04:31<06:01,  1.35s/it] 43%|████▎     | 204/471 [04:32<06:00,  1.35s/it] 44%|████▎     | 205/471 [04:33<05:59,  1.35s/it] 44%|████▎     | 206/471 [04:35<05:57,  1.35s/it] 44%|████▍     | 207/471 [04:36<05:56,  1.35s/it] 44%|████▍     | 208/471 [04:38<05:54,  1.35s/it] 44%|████▍     | 209/471 [04:39<05:52,  1.35s/it] 45%|████▍     | 210/471 [04:40<05:51,  1.35s/it] 45%|████▍     | 211/471 [04:42<05:50,  1.35s/it] 45%|████▌     | 212/471 [04:43<05:48,  1.35s/it] 45%|████▌     | 213/471 [04:44<05:47,  1.35s/it] 45%|████▌     | 214/471 [04:46<05:46,  1.35s/it] 46%|████▌     | 215/471 [04:47<05:44,  1.35s/it] 46%|████▌     | 216/471 [04:48<05:43,  1.35s/it] 46%|████▌     | 217/471 [04:50<05:42,  1.35s/it] 46%|████▋     | 218/471 [04:51<05:41,  1.35s/it] 46%|████▋     | 219/471 [04:52<05:40,  1.35s/it] 47%|████▋     | 220/471 [04:54<05:38,  1.35s/it] 47%|████▋     | 221/471 [04:55<05:37,  1.35s/it] 47%|████▋     | 222/471 [04:56<05:35,  1.35s/it] 47%|████▋     | 223/471 [04:58<05:34,  1.35s/it] 48%|████▊     | 224/471 [04:59<05:32,  1.35s/it] 48%|████▊     | 225/471 [05:00<05:31,  1.35s/it] 48%|████▊     | 226/471 [05:02<05:30,  1.35s/it] 48%|████▊     | 227/471 [05:03<05:28,  1.35s/it] 48%|████▊     | 228/471 [05:04<05:27,  1.35s/it] 49%|████▊     | 229/471 [05:06<05:26,  1.35s/it] 49%|████▉     | 230/471 [05:07<05:25,  1.35s/it] 49%|████▉     | 231/471 [05:09<05:23,  1.35s/it] 49%|████▉     | 232/471 [05:10<05:21,  1.35s/it] 49%|████▉     | 233/471 [05:11<05:20,  1.34s/it] 50%|████▉     | 234/471 [05:13<05:19,  1.35s/it] 50%|████▉     | 235/471 [05:14<05:17,  1.35s/it] 50%|█████     | 236/471 [05:15<05:15,  1.34s/it] 50%|█████     | 237/471 [05:17<05:14,  1.34s/it] 51%|█████     | 238/471 [05:18<05:13,  1.34s/it] 51%|█████     | 239/471 [05:19<05:12,  1.34s/it] 51%|█████     | 240/471 [05:21<05:10,  1.35s/it] 51%|█████     | 241/471 [05:22<05:09,  1.35s/it] 51%|█████▏    | 242/471 [05:23<05:08,  1.35s/it] 52%|█████▏    | 243/471 [05:25<05:06,  1.35s/it] 52%|█████▏    | 244/471 [05:26<05:05,  1.35s/it] 52%|█████▏    | 245/471 [05:27<05:04,  1.35s/it] 52%|█████▏    | 246/471 [05:29<05:02,  1.34s/it] 52%|█████▏    | 247/471 [05:30<05:00,  1.34s/it] 53%|█████▎    | 248/471 [05:31<05:00,  1.35s/it] 53%|█████▎    | 249/471 [05:33<04:59,  1.35s/it] 53%|█████▎    | 250/471 [05:34<04:57,  1.35s/it] 53%|█████▎    | 251/471 [05:35<04:56,  1.35s/it] 54%|█████▎    | 252/471 [05:37<04:55,  1.35s/it] 54%|█████▎    | 253/471 [05:38<04:53,  1.35s/it] 54%|█████▍    | 254/471 [05:40<04:52,  1.35s/it] 54%|█████▍    | 255/471 [05:41<04:51,  1.35s/it] 54%|█████▍    | 256/471 [05:42<04:50,  1.35s/it] 55%|█████▍    | 257/471 [05:44<04:48,  1.35s/it] 55%|█████▍    | 258/471 [05:45<04:47,  1.35s/it] 55%|█████▍    | 259/471 [05:46<04:46,  1.35s/it] 55%|█████▌    | 260/471 [05:48<04:44,  1.35s/it] 55%|█████▌    | 261/471 [05:49<04:43,  1.35s/it] 56%|█████▌    | 262/471 [05:50<04:41,  1.35s/it] 56%|█████▌    | 263/471 [05:52<04:40,  1.35s/it] 56%|█████▌    | 264/471 [05:53<04:38,  1.35s/it] 56%|█████▋    | 265/471 [05:54<04:37,  1.35s/it] 56%|█████▋    | 266/471 [05:56<04:36,  1.35s/it] 57%|█████▋    | 267/471 [05:57<04:35,  1.35s/it] 57%|█████▋    | 268/471 [05:58<04:34,  1.35s/it] 57%|█████▋    | 269/471 [06:00<04:32,  1.35s/it] 57%|█████▋    | 270/471 [06:01<04:31,  1.35s/it] 58%|█████▊    | 271/471 [06:02<04:30,  1.35s/it] 58%|█████▊    | 272/471 [06:04<04:28,  1.35s/it] 58%|█████▊    | 273/471 [06:05<04:27,  1.35s/it] 58%|█████▊    | 274/471 [06:06<04:25,  1.35s/it] 58%|█████▊    | 275/471 [06:08<04:24,  1.35s/it] 59%|█████▊    | 276/471 [06:09<04:23,  1.35s/it] 59%|█████▉    | 277/471 [06:11<04:22,  1.35s/it] 59%|█████▉    | 278/471 [06:12<04:20,  1.35s/it] 59%|█████▉    | 279/471 [06:13<04:19,  1.35s/it] 59%|█████▉    | 280/471 [06:15<04:17,  1.35s/it] 60%|█████▉    | 281/471 [06:16<04:16,  1.35s/it] 60%|█████▉    | 282/471 [06:17<04:14,  1.35s/it] 60%|██████    | 283/471 [06:19<04:13,  1.35s/it] 60%|██████    | 284/471 [06:20<04:12,  1.35s/it] 61%|██████    | 285/471 [06:21<04:11,  1.35s/it] 61%|██████    | 286/471 [06:23<04:10,  1.35s/it] 61%|██████    | 287/471 [06:24<04:08,  1.35s/it] 61%|██████    | 288/471 [06:25<04:07,  1.35s/it] 61%|██████▏   | 289/471 [06:27<04:05,  1.35s/it] 62%|██████▏   | 290/471 [06:28<04:04,  1.35s/it] 62%|██████▏   | 291/471 [06:29<04:03,  1.35s/it] 62%|██████▏   | 292/471 [06:31<04:01,  1.35s/it] 62%|██████▏   | 293/471 [06:32<03:59,  1.35s/it] 62%|██████▏   | 294/471 [06:33<03:58,  1.35s/it] 63%|██████▎   | 295/471 [06:35<03:57,  1.35s/it] 63%|██████▎   | 296/471 [06:36<03:55,  1.35s/it] 63%|██████▎   | 297/471 [06:38<03:54,  1.35s/it] 63%|██████▎   | 298/471 [06:39<03:53,  1.35s/it] 63%|██████▎   | 299/471 [06:40<03:52,  1.35s/it] 64%|██████▎   | 300/471 [06:42<03:50,  1.35s/it] 64%|██████▍   | 301/471 [06:43<03:49,  1.35s/it] 64%|██████▍   | 302/471 [06:44<03:48,  1.35s/it] 64%|██████▍   | 303/471 [06:46<03:46,  1.35s/it] 65%|██████▍   | 304/471 [06:47<03:45,  1.35s/it] 65%|██████▍   | 305/471 [06:48<03:44,  1.35s/it] 65%|██████▍   | 306/471 [06:50<03:43,  1.35s/it] 65%|██████▌   | 307/471 [06:51<03:41,  1.35s/it] 65%|██████▌   | 308/471 [06:52<03:40,  1.35s/it] 66%|██████▌   | 309/471 [06:54<03:39,  1.35s/it] 66%|██████▌   | 310/471 [06:55<03:37,  1.35s/it] 66%|██████▌   | 311/471 [06:56<03:36,  1.35s/it] 66%|██████▌   | 312/471 [06:58<03:34,  1.35s/it] 66%|██████▋   | 313/471 [06:59<03:33,  1.35s/it] 67%|██████▋   | 314/471 [07:00<03:31,  1.35s/it] 67%|██████▋   | 315/471 [07:02<03:30,  1.35s/it] 67%|██████▋   | 316/471 [07:03<03:29,  1.35s/it] 67%|██████▋   | 317/471 [07:05<03:27,  1.35s/it] 68%|██████▊   | 318/471 [07:06<03:26,  1.35s/it] 68%|██████▊   | 319/471 [07:07<03:25,  1.35s/it] 68%|██████▊   | 320/471 [07:09<03:23,  1.35s/it] 68%|██████▊   | 321/471 [07:10<03:22,  1.35s/it] 68%|██████▊   | 322/471 [07:11<03:21,  1.35s/it] 69%|██████▊   | 323/471 [07:13<03:20,  1.35s/it] 69%|██████▉   | 324/471 [07:14<03:19,  1.35s/it] 69%|██████▉   | 325/471 [07:15<03:17,  1.35s/it] 69%|██████▉   | 326/471 [07:17<03:16,  1.35s/it] 69%|██████▉   | 327/471 [07:18<03:14,  1.35s/it] 70%|██████▉   | 328/471 [07:19<03:13,  1.35s/it] 70%|██████▉   | 329/471 [07:21<03:12,  1.35s/it] 70%|███████   | 330/471 [07:22<03:10,  1.35s/it] 70%|███████   | 331/471 [07:23<03:09,  1.35s/it] 70%|███████   | 332/471 [07:25<03:08,  1.35s/it] 71%|███████   | 333/471 [07:26<03:06,  1.35s/it] 71%|███████   | 334/471 [07:28<03:05,  1.35s/it] 71%|███████   | 335/471 [07:29<03:04,  1.36s/it] 71%|███████▏  | 336/471 [07:30<03:02,  1.36s/it] 72%|███████▏  | 337/471 [07:32<03:01,  1.35s/it] 72%|███████▏  | 338/471 [07:33<03:00,  1.35s/it] 72%|███████▏  | 339/471 [07:34<02:59,  1.36s/it] 72%|███████▏  | 340/471 [07:36<02:57,  1.36s/it] 72%|███████▏  | 341/471 [07:37<02:56,  1.36s/it] 73%|███████▎  | 342/471 [07:38<02:54,  1.36s/it] 73%|███████▎  | 343/471 [07:40<02:53,  1.36s/it] 73%|███████▎  | 344/471 [07:41<02:52,  1.36s/it] 73%|███████▎  | 345/471 [07:42<02:50,  1.36s/it] 73%|███████▎  | 346/471 [07:44<02:49,  1.36s/it] 74%|███████▎  | 347/471 [07:45<02:48,  1.36s/it] 74%|███████▍  | 348/471 [07:47<02:46,  1.36s/it] 74%|███████▍  | 349/471 [07:48<02:45,  1.36s/it] 74%|███████▍  | 350/471 [07:49<02:44,  1.36s/it] 75%|███████▍  | 351/471 [07:51<02:42,  1.36s/it] 75%|███████▍  | 352/471 [07:52<02:41,  1.36s/it] 75%|███████▍  | 353/471 [07:53<02:40,  1.36s/it] 75%|███████▌  | 354/471 [07:55<02:38,  1.36s/it] 75%|███████▌  | 355/471 [07:56<02:37,  1.36s/it] 76%|███████▌  | 356/471 [07:57<02:36,  1.36s/it] 76%|███████▌  | 357/471 [07:59<02:34,  1.36s/it] 76%|███████▌  | 358/471 [08:00<02:33,  1.36s/it] 76%|███████▌  | 359/471 [08:01<02:32,  1.36s/it] 76%|███████▋  | 360/471 [08:03<02:30,  1.36s/it] 77%|███████▋  | 361/471 [08:04<02:29,  1.36s/it] 77%|███████▋  | 362/471 [08:06<02:28,  1.36s/it] 77%|███████▋  | 363/471 [08:07<02:26,  1.36s/it] 77%|███████▋  | 364/471 [08:08<02:25,  1.36s/it] 77%|███████▋  | 365/471 [08:10<02:24,  1.36s/it] 78%|███████▊  | 366/471 [08:11<02:23,  1.36s/it] 78%|███████▊  | 367/471 [08:12<02:21,  1.36s/it] 78%|███████▊  | 368/471 [08:14<02:20,  1.36s/it] 78%|███████▊  | 369/471 [08:15<02:18,  1.36s/it] 79%|███████▊  | 370/471 [08:16<02:17,  1.36s/it] 79%|███████▉  | 371/471 [08:18<02:16,  1.36s/it] 79%|███████▉  | 372/471 [08:19<02:14,  1.36s/it] 79%|███████▉  | 373/471 [08:21<02:13,  1.36s/it] 79%|███████▉  | 374/471 [08:22<02:11,  1.36s/it] 80%|███████▉  | 375/471 [08:23<02:10,  1.36s/it] 80%|███████▉  | 376/471 [08:25<02:09,  1.36s/it] 80%|████████  | 377/471 [08:26<02:07,  1.36s/it] 80%|████████  | 378/471 [08:27<02:06,  1.36s/it] 80%|████████  | 379/471 [08:29<02:05,  1.36s/it] 81%|████████  | 380/471 [08:30<02:03,  1.36s/it] 81%|████████  | 381/471 [08:31<02:02,  1.36s/it] 81%|████████  | 382/471 [08:33<02:01,  1.36s/it] 81%|████████▏ | 383/471 [08:34<01:59,  1.36s/it] 82%|████████▏ | 384/471 [08:35<01:58,  1.36s/it] 82%|████████▏ | 385/471 [08:37<01:57,  1.36s/it] 82%|████████▏ | 386/471 [08:38<01:55,  1.36s/it] 82%|████████▏ | 387/471 [08:40<01:54,  1.36s/it] 82%|████████▏ | 388/471 [08:41<01:53,  1.37s/it] 83%|████████▎ | 389/471 [08:42<01:51,  1.36s/it] 83%|████████▎ | 390/471 [08:44<01:50,  1.37s/it] 83%|████████▎ | 391/471 [08:45<01:49,  1.37s/it] 83%|████████▎ | 392/471 [08:46<01:47,  1.37s/it] 83%|████████▎ | 393/471 [08:48<01:46,  1.37s/it] 84%|████████▎ | 394/471 [08:49<01:45,  1.37s/it] 84%|████████▍ | 395/471 [08:51<01:43,  1.37s/it] 84%|████████▍ | 396/471 [08:52<01:42,  1.37s/it] 84%|████████▍ | 397/471 [08:53<01:41,  1.37s/it] 85%|████████▍ | 398/471 [08:55<01:39,  1.36s/it] 85%|████████▍ | 399/471 [08:56<01:38,  1.37s/it] 85%|████████▍ | 400/471 [08:57<01:37,  1.37s/it] 85%|████████▌ | 401/471 [08:59<01:35,  1.36s/it] 85%|████████▌ | 402/471 [09:00<01:34,  1.36s/it] 86%|████████▌ | 403/471 [09:01<01:32,  1.36s/it] 86%|████████▌ | 404/471 [09:03<01:31,  1.36s/it] 86%|████████▌ | 405/471 [09:04<01:30,  1.36s/it] 86%|████████▌ | 406/471 [09:06<01:28,  1.36s/it] 86%|████████▋ | 407/471 [09:07<01:27,  1.36s/it] 87%|████████▋ | 408/471 [09:08<01:25,  1.36s/it] 87%|████████▋ | 409/471 [09:10<01:24,  1.36s/it] 87%|████████▋ | 410/471 [09:11<01:23,  1.36s/it] 87%|████████▋ | 411/471 [09:12<01:21,  1.36s/it] 87%|████████▋ | 412/471 [09:14<01:20,  1.36s/it] 88%|████████▊ | 413/471 [09:15<01:18,  1.36s/it] 88%|████████▊ | 414/471 [09:16<01:17,  1.36s/it] 88%|████████▊ | 415/471 [09:18<01:16,  1.36s/it] 88%|████████▊ | 416/471 [09:19<01:15,  1.36s/it] 89%|████████▊ | 417/471 [09:20<01:13,  1.36s/it] 89%|████████▊ | 418/471 [09:22<01:12,  1.36s/it] 89%|████████▉ | 419/471 [09:23<01:10,  1.36s/it] 89%|████████▉ | 420/471 [09:25<01:09,  1.36s/it] 89%|████████▉ | 421/471 [09:26<01:08,  1.36s/it] 90%|████████▉ | 422/471 [09:27<01:06,  1.36s/it] 90%|████████▉ | 423/471 [09:29<01:05,  1.36s/it] 90%|█████████ | 424/471 [09:30<01:03,  1.36s/it] 90%|█████████ | 425/471 [09:31<01:02,  1.36s/it] 90%|█████████ | 426/471 [09:33<01:01,  1.36s/it] 91%|█████████ | 427/471 [09:34<00:59,  1.36s/it] 91%|█████████ | 428/471 [09:35<00:58,  1.36s/it] 91%|█████████ | 429/471 [09:37<00:57,  1.36s/it] 91%|█████████▏| 430/471 [09:38<00:55,  1.36s/it] 92%|█████████▏| 431/471 [09:40<00:54,  1.36s/it] 92%|█████████▏| 432/471 [09:41<00:53,  1.36s/it] 92%|█████████▏| 433/471 [09:42<00:51,  1.36s/it] 92%|█████████▏| 434/471 [09:44<00:50,  1.36s/it] 92%|█████████▏| 435/471 [09:45<00:49,  1.36s/it] 93%|█████████▎| 436/471 [09:46<00:47,  1.36s/it] 93%|█████████▎| 437/471 [09:48<00:46,  1.36s/it] 93%|█████████▎| 438/471 [09:49<00:44,  1.36s/it] 93%|█████████▎| 439/471 [09:50<00:43,  1.36s/it] 93%|█████████▎| 440/471 [09:52<00:42,  1.36s/it] 94%|█████████▎| 441/471 [09:53<00:40,  1.36s/it] 94%|█████████▍| 442/471 [09:55<00:39,  1.36s/it] 94%|█████████▍| 443/471 [09:56<00:38,  1.36s/it] 94%|█████████▍| 444/471 [09:57<00:36,  1.36s/it] 94%|█████████▍| 445/471 [09:59<00:35,  1.37s/it] 95%|█████████▍| 446/471 [10:00<00:34,  1.37s/it] 95%|█████████▍| 447/471 [10:01<00:32,  1.37s/it] 95%|█████████▌| 448/471 [10:03<00:31,  1.37s/it] 95%|█████████▌| 449/471 [10:04<00:30,  1.36s/it] 96%|█████████▌| 450/471 [10:05<00:28,  1.37s/it] 96%|█████████▌| 451/471 [10:07<00:27,  1.36s/it] 96%|█████████▌| 452/471 [10:08<00:25,  1.36s/it] 96%|█████████▌| 453/471 [10:10<00:24,  1.37s/it] 96%|█████████▋| 454/471 [10:11<00:23,  1.37s/it] 97%|█████████▋| 455/471 [10:12<00:21,  1.37s/it] 97%|█████████▋| 456/471 [10:14<00:20,  1.37s/it] 97%|█████████▋| 457/471 [10:15<00:19,  1.37s/it] 97%|█████████▋| 458/471 [10:16<00:17,  1.37s/it] 97%|█████████▋| 459/471 [10:18<00:16,  1.36s/it] 98%|█████████▊| 460/471 [10:19<00:15,  1.37s/it] 98%|█████████▊| 461/471 [10:21<00:13,  1.37s/it] 98%|█████████▊| 462/471 [10:22<00:12,  1.37s/it] 98%|█████████▊| 463/471 [10:23<00:10,  1.37s/it] 99%|█████████▊| 464/471 [10:25<00:09,  1.37s/it] 99%|█████████▊| 465/471 [10:26<00:08,  1.36s/it] 99%|█████████▉| 466/471 [10:27<00:06,  1.36s/it] 99%|█████████▉| 467/471 [10:29<00:05,  1.37s/it] 99%|█████████▉| 468/471 [10:30<00:04,  1.37s/it]100%|█████████▉| 469/471 [10:31<00:02,  1.37s/it]100%|█████████▉| 470/471 [10:33<00:01,  1.37s/it]100%|██████████| 471/471 [10:34<00:00,  1.25s/it]100%|██████████| 471/471 [10:34<00:00,  1.35s/it]
{'eval_loss': 4.209385871887207, 'eval_model_preparation_time': 0.0113, 'eval_acc': 0.1735262878385555, 'eval_runtime': 635.5308, 'eval_samples_per_second': 11.852, 'eval_steps_per_second': 0.741}
ROUND:7
CLIENT:71
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:37,  2.49s/it]                                              {'loss': 3.3683, 'grad_norm': 7.477166175842285, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:37,  2.49s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 3.4646, 'grad_norm': 4.7721171379089355, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:24,  2.29s/it]                                              {'loss': 3.3918, 'grad_norm': 8.513863563537598, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:21,  2.27s/it]                                              {'loss': 2.825, 'grad_norm': 10.09626579284668, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.27s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 1.4844, 'grad_norm': 8.188281059265137, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.26s/it]                                              {'loss': 3.2378, 'grad_norm': 10.63060474395752, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.26s/it] 18%|█▊        | 7/40 [00:15<01:14,  2.27s/it]                                              {'loss': 2.1685, 'grad_norm': 10.751625061035156, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:14,  2.27s/it] 20%|██        | 8/40 [00:16<00:51,  1.60s/it]                                              {'loss': 0.5738, 'grad_norm': 23.612424850463867, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.60s/it] 22%|██▎       | 9/40 [00:18<00:56,  1.81s/it]                                              {'loss': 4.7307, 'grad_norm': 53.00749969482422, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:56,  1.81s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.96s/it]                                               {'loss': 2.5047, 'grad_norm': 37.60929870605469, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.96s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.04s/it]                                               {'loss': 0.5695, 'grad_norm': 4.680483341217041, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.04s/it] 30%|███       | 12/40 [00:25<00:59,  2.11s/it]                                               {'loss': 0.8542, 'grad_norm': 18.0341739654541, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:59,  2.11s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.17s/it]                                               {'loss': 0.9602, 'grad_norm': 7.898509502410889, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.17s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it]                                               {'loss': 0.793, 'grad_norm': 6.595925807952881, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it] 38%|███▊      | 15/40 [00:32<00:56,  2.24s/it]                                               {'loss': 0.9364, 'grad_norm': 5.306909084320068, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:56,  2.24s/it] 40%|████      | 16/40 [00:32<00:38,  1.62s/it]                                               {'loss': 0.2936, 'grad_norm': 10.797667503356934, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.62s/it] 42%|████▎     | 17/40 [00:34<00:42,  1.84s/it]                                               {'loss': 0.2752, 'grad_norm': 3.085616111755371, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:42,  1.84s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.98s/it]                                               {'loss': 0.3712, 'grad_norm': 4.407920837402344, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.98s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.08s/it]                                               {'loss': 0.2426, 'grad_norm': 4.400859355926514, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.08s/it] 50%|█████     | 20/40 [00:41<00:42,  2.13s/it]                                               {'loss': 0.7336, 'grad_norm': 7.885602951049805, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.13s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it]                                               {'loss': 0.434, 'grad_norm': 5.168138027191162, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it] 55%|█████▌    | 22/40 [00:46<00:39,  2.21s/it]                                               {'loss': 0.6322, 'grad_norm': 3.7927308082580566, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.25s/it]                                               {'loss': 0.3307, 'grad_norm': 3.214655637741089, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.25s/it] 60%|██████    | 24/40 [00:48<00:26,  1.63s/it]                                               {'loss': 0.0381, 'grad_norm': 1.5240931510925293, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.63s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.85s/it]                                               {'loss': 0.0655, 'grad_norm': 1.1835993528366089, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.85s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it]                                               {'loss': 0.2858, 'grad_norm': 2.802809476852417, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.09s/it]                                               {'loss': 0.0616, 'grad_norm': 3.638036012649536, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.09s/it] 70%|███████   | 28/40 [00:57<00:25,  2.16s/it]                                               {'loss': 0.0498, 'grad_norm': 0.887643039226532, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.16s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.20s/it]                                               {'loss': 0.2344, 'grad_norm': 4.027008533477783, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.20s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.24s/it]                                               {'loss': 0.4955, 'grad_norm': 39.64472961425781, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.24s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.26s/it]                                               {'loss': 0.1199, 'grad_norm': 3.59403920173645, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.26s/it] 80%|████████  | 32/40 [01:05<00:13,  1.64s/it]                                               {'loss': 0.4077, 'grad_norm': 12.619396209716797, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.64s/it] 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it]                                               {'loss': 0.0297, 'grad_norm': 1.0392755270004272, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.99s/it]                                               {'loss': 0.1073, 'grad_norm': 4.852753639221191, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.99s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.10s/it]                                               {'loss': 0.4011, 'grad_norm': 13.729718208312988, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.10s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.16s/it]                                               {'loss': 0.5487, 'grad_norm': 8.683178901672363, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.16s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.22s/it]                                               {'loss': 0.2457, 'grad_norm': 8.285070419311523, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.22s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.26s/it]                                               {'loss': 1.2226, 'grad_norm': 24.86360740661621, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.26s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]                                               {'loss': 0.3739, 'grad_norm': 16.206480026245117, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]100%|██████████| 40/40 [01:21<00:00,  1.66s/it]                                               {'loss': 0.0816, 'grad_norm': 4.517940521240234, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.66s/it]                                               {'train_runtime': 81.9787, 'train_samples_per_second': 6.892, 'train_steps_per_second': 0.488, 'train_loss': 0.99861394376494, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.66s/it]100%|██████████| 40/40 [01:21<00:00,  2.05s/it]
CLIENT:33
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.18s/it]                                              {'loss': 4.6801, 'grad_norm': 7.249728202819824, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.18s/it]  5%|▌         | 2/40 [00:04<01:24,  2.23s/it]                                              {'loss': 4.4604, 'grad_norm': 8.009515762329102, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.23s/it]  8%|▊         | 3/40 [00:06<01:23,  2.25s/it]                                              {'loss': 2.5273, 'grad_norm': 7.682147026062012, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.25s/it] 10%|█         | 4/40 [00:08<01:20,  2.24s/it]                                              {'loss': 3.3563, 'grad_norm': 7.607166290283203, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 3.2736, 'grad_norm': 11.946786880493164, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:17,  2.27s/it]                                              {'loss': 2.5864, 'grad_norm': 10.372368812561035, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:17,  2.27s/it] 18%|█▊        | 7/40 [00:15<01:14,  2.27s/it]                                              {'loss': 3.4238, 'grad_norm': 12.571022987365723, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:14,  2.27s/it] 20%|██        | 8/40 [00:15<00:51,  1.60s/it]                                              {'loss': 1.6946, 'grad_norm': 246.16392517089844, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:51,  1.60s/it] 22%|██▎       | 9/40 [00:18<00:56,  1.82s/it]                                              {'loss': 1.3584, 'grad_norm': 6.979233741760254, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:56,  1.82s/it] 25%|██▌       | 10/40 [00:20<00:59,  1.97s/it]                                               {'loss': 1.0282, 'grad_norm': 5.9027419090271, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:59,  1.97s/it] 28%|██▊       | 11/40 [00:22<01:00,  2.08s/it]                                               {'loss': 1.1155, 'grad_norm': 5.472449779510498, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<01:00,  2.08s/it] 30%|███       | 12/40 [00:25<00:59,  2.14s/it]                                               {'loss': 1.1684, 'grad_norm': 7.183272361755371, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:59,  2.14s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.17s/it]                                               {'loss': 1.6264, 'grad_norm': 9.181821823120117, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.17s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.22s/it]                                               {'loss': 0.9373, 'grad_norm': 5.721677780151367, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.22s/it] 38%|███▊      | 15/40 [00:32<00:56,  2.25s/it]                                               {'loss': 1.2489, 'grad_norm': 10.275334358215332, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:56,  2.25s/it] 40%|████      | 16/40 [00:32<00:39,  1.63s/it]                                               {'loss': 0.1563, 'grad_norm': 6.139730453491211, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:39,  1.63s/it] 42%|████▎     | 17/40 [00:34<00:42,  1.84s/it]                                               {'loss': 0.6245, 'grad_norm': 8.296463012695312, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:42,  1.84s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.98s/it]                                               {'loss': 0.2087, 'grad_norm': 2.487255334854126, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.98s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it]                                               {'loss': 0.3809, 'grad_norm': 3.545788049697876, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it] 50%|█████     | 20/40 [00:41<00:43,  2.16s/it]                                               {'loss': 0.3066, 'grad_norm': 3.678518295288086, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:43,  2.16s/it] 52%|█████▎    | 21/40 [00:43<00:42,  2.21s/it]                                               {'loss': 0.5555, 'grad_norm': 5.303693771362305, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:42,  2.21s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.26s/it]                                               {'loss': 0.5216, 'grad_norm': 3.1998708248138428, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.26s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.28s/it]                                               {'loss': 0.6951, 'grad_norm': 5.028841972351074, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.28s/it] 60%|██████    | 24/40 [00:48<00:26,  1.65s/it]                                               {'loss': 0.5297, 'grad_norm': 16.965747833251953, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.65s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.86s/it]                                               {'loss': 0.0374, 'grad_norm': 0.6417297124862671, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.86s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it]                                               {'loss': 0.478, 'grad_norm': 4.236605167388916, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.10s/it]                                               {'loss': 0.1277, 'grad_norm': 2.3816821575164795, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.10s/it] 70%|███████   | 28/40 [00:58<00:26,  2.17s/it]                                               {'loss': 0.4938, 'grad_norm': 2.811007022857666, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:58<00:26,  2.17s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.23s/it]                                               {'loss': 0.0725, 'grad_norm': 1.2199269533157349, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.23s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.26s/it]                                               {'loss': 0.2122, 'grad_norm': 13.071889877319336, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.26s/it] 78%|███████▊  | 31/40 [01:05<00:20,  2.29s/it]                                               {'loss': 0.5465, 'grad_norm': 3.9395015239715576, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:05<00:20,  2.29s/it] 80%|████████  | 32/40 [01:05<00:13,  1.66s/it]                                               {'loss': 0.0052, 'grad_norm': 0.22354529798030853, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.66s/it] 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it]                                               {'loss': 0.1712, 'grad_norm': 2.124492645263672, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it] 85%|████████▌ | 34/40 [01:10<00:12,  2.02s/it]                                               {'loss': 0.0336, 'grad_norm': 0.499407023191452, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:10<00:12,  2.02s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.12s/it]                                               {'loss': 0.0296, 'grad_norm': 0.472184419631958, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.12s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.17s/it]                                               {'loss': 0.6393, 'grad_norm': 6.364792823791504, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.17s/it] 92%|█████████▎| 37/40 [01:17<00:06,  2.23s/it]                                               {'loss': 0.2475, 'grad_norm': 4.828287124633789, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:17<00:06,  2.23s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.26s/it]                                               {'loss': 0.2878, 'grad_norm': 5.467679500579834, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.26s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]                                               {'loss': 0.1072, 'grad_norm': 2.5052413940429688, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]100%|██████████| 40/40 [01:21<00:00,  1.66s/it]                                               {'loss': 0.0052, 'grad_norm': 0.2909286618232727, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.66s/it]                                               {'train_runtime': 82.2315, 'train_samples_per_second': 6.871, 'train_steps_per_second': 0.486, 'train_loss': 1.048974235507194, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.66s/it]100%|██████████| 40/40 [01:22<00:00,  2.06s/it]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:26,  2.21s/it]                                              {'loss': 4.185, 'grad_norm': 7.433109760284424, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:26,  2.21s/it]  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]                                              {'loss': 3.8478, 'grad_norm': 7.723954677581787, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]  8%|▊         | 3/40 [00:06<01:23,  2.25s/it]                                              {'loss': 1.9524, 'grad_norm': 7.792358875274658, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.25s/it] 10%|█         | 4/40 [00:08<01:20,  2.24s/it]                                              {'loss': 4.2217, 'grad_norm': 26.973262786865234, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 1.9317, 'grad_norm': 9.06752872467041, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 3.3764, 'grad_norm': 13.57876205444336, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it]                                              {'loss': 3.3564, 'grad_norm': 9.807354927062988, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it] 20%|██        | 8/40 [00:15<00:50,  1.59s/it]                                              {'loss': 0.3024, 'grad_norm': 14.852290153503418, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 0.6725, 'grad_norm': 5.874039649963379, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 0.8388, 'grad_norm': 8.286664962768555, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.05s/it]                                               {'loss': 1.2144, 'grad_norm': 15.672775268554688, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.05s/it] 30%|███       | 12/40 [00:25<00:59,  2.13s/it]                                               {'loss': 1.0146, 'grad_norm': 8.254831314086914, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:59,  2.13s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.17s/it]                                               {'loss': 2.1466, 'grad_norm': 44.35870361328125, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.17s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it]                                               {'loss': 1.0438, 'grad_norm': 29.465553283691406, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.22s/it]                                               {'loss': 1.4065, 'grad_norm': 8.829059600830078, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.22s/it] 40%|████      | 16/40 [00:31<00:38,  1.61s/it]                                               {'loss': 2.5664, 'grad_norm': 38.67196273803711, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.61s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it]                                               {'loss': 0.5087, 'grad_norm': 3.9510960578918457, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.1286, 'grad_norm': 1.9349544048309326, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it]                                               {'loss': 0.339, 'grad_norm': 3.341156482696533, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it] 50%|█████     | 20/40 [00:41<00:42,  2.14s/it]                                               {'loss': 0.41, 'grad_norm': 4.850129127502441, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.14s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.20s/it]                                               {'loss': 0.4033, 'grad_norm': 2.3993020057678223, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.20s/it] 55%|█████▌    | 22/40 [00:45<00:40,  2.22s/it]                                               {'loss': 0.7664, 'grad_norm': 3.8289732933044434, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:40,  2.22s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.26s/it]                                               {'loss': 0.7085, 'grad_norm': 5.720592498779297, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.26s/it] 60%|██████    | 24/40 [00:48<00:26,  1.64s/it]                                               {'loss': 0.0725, 'grad_norm': 4.211278438568115, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.64s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.84s/it]                                               {'loss': 0.3454, 'grad_norm': 3.783874273300171, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.84s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.98s/it]                                               {'loss': 0.0466, 'grad_norm': 0.9292953610420227, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.98s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.07s/it]                                               {'loss': 1.0056, 'grad_norm': 7.961842060089111, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.07s/it] 70%|███████   | 28/40 [00:57<00:25,  2.15s/it]                                               {'loss': 0.0951, 'grad_norm': 2.556591033935547, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.15s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.20s/it]                                               {'loss': 0.5717, 'grad_norm': 6.820870876312256, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.20s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.26s/it]                                               {'loss': 0.196, 'grad_norm': 3.8559417724609375, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.26s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.28s/it]                                               {'loss': 0.0655, 'grad_norm': 1.4183037281036377, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.28s/it] 80%|████████  | 32/40 [01:04<00:13,  1.65s/it]                                               {'loss': 0.0288, 'grad_norm': 1.1172797679901123, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.65s/it] 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it]                                               {'loss': 0.0108, 'grad_norm': 0.18252336978912354, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it] 85%|████████▌ | 34/40 [01:09<00:12,  2.01s/it]                                               {'loss': 0.023, 'grad_norm': 0.5976731777191162, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:12,  2.01s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.11s/it]                                               {'loss': 0.0895, 'grad_norm': 1.0686709880828857, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.11s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it]                                               {'loss': 0.0445, 'grad_norm': 1.1694519519805908, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.23s/it]                                               {'loss': 0.0513, 'grad_norm': 1.1037640571594238, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.23s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it]                                               {'loss': 0.3324, 'grad_norm': 4.453330993652344, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.28s/it]                                               {'loss': 1.7629, 'grad_norm': 18.439027786254883, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.28s/it]100%|██████████| 40/40 [01:21<00:00,  1.65s/it]                                               {'loss': 0.8979, 'grad_norm': 64.94744873046875, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.65s/it]                                               {'train_runtime': 81.7277, 'train_samples_per_second': 6.913, 'train_steps_per_second': 0.489, 'train_loss': 1.0745317545020954, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.65s/it]100%|██████████| 40/40 [01:21<00:00,  2.04s/it]
CLIENT:10
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:34,  2.42s/it]                                              {'loss': 5.689, 'grad_norm': 7.169192790985107, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:34,  2.42s/it]  5%|▌         | 2/40 [00:04<01:26,  2.29s/it]                                              {'loss': 4.6756, 'grad_norm': 7.833238124847412, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.29s/it]  8%|▊         | 3/40 [00:06<01:24,  2.29s/it]                                              {'loss': 4.4811, 'grad_norm': 8.609973907470703, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:21,  2.27s/it]                                              {'loss': 3.4287, 'grad_norm': 8.137381553649902, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.27s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.28s/it]                                              {'loss': 3.5086, 'grad_norm': 8.336616516113281, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.28s/it] 15%|█▌        | 6/40 [00:13<01:17,  2.28s/it]                                              {'loss': 3.6412, 'grad_norm': 11.79761791229248, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:17,  2.28s/it] 18%|█▊        | 7/40 [00:16<01:15,  2.28s/it]                                              {'loss': 3.0213, 'grad_norm': 8.970575332641602, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:15,  2.28s/it] 20%|██        | 8/40 [00:16<00:51,  1.62s/it]                                              {'loss': 0.937, 'grad_norm': 23.1308536529541, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.62s/it] 22%|██▎       | 9/40 [00:18<00:56,  1.83s/it]                                              {'loss': 2.3144, 'grad_norm': 8.603205680847168, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:56,  1.83s/it] 25%|██▌       | 10/40 [00:20<00:59,  1.98s/it]                                               {'loss': 1.4573, 'grad_norm': 8.184775352478027, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:59,  1.98s/it] 28%|██▊       | 11/40 [00:23<01:00,  2.09s/it]                                               {'loss': 0.8174, 'grad_norm': 4.942090034484863, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<01:00,  2.09s/it] 30%|███       | 12/40 [00:25<01:00,  2.15s/it]                                               {'loss': 1.6888, 'grad_norm': 7.347959041595459, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<01:00,  2.15s/it] 32%|███▎      | 13/40 [00:27<00:59,  2.19s/it]                                               {'loss': 1.1525, 'grad_norm': 4.9597978591918945, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:59,  2.19s/it] 35%|███▌      | 14/40 [00:30<00:57,  2.22s/it]                                               {'loss': 1.941, 'grad_norm': 13.818399429321289, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:30<00:57,  2.22s/it] 38%|███▊      | 15/40 [00:32<00:56,  2.27s/it]                                               {'loss': 1.7284, 'grad_norm': 18.418251037597656, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:56,  2.27s/it] 40%|████      | 16/40 [00:32<00:39,  1.64s/it]                                               {'loss': 0.6628, 'grad_norm': 22.308448791503906, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:39,  1.64s/it] 42%|████▎     | 17/40 [00:34<00:42,  1.84s/it]                                               {'loss': 0.0898, 'grad_norm': 1.779201626777649, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:42,  1.84s/it] 45%|████▌     | 18/40 [00:37<00:44,  2.00s/it]                                               {'loss': 0.0852, 'grad_norm': 1.6872824430465698, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:37<00:44,  2.00s/it] 48%|████▊     | 19/40 [00:39<00:44,  2.10s/it]                                               {'loss': 0.2547, 'grad_norm': 4.903256893157959, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:44,  2.10s/it] 50%|█████     | 20/40 [00:41<00:43,  2.18s/it]                                               {'loss': 0.5536, 'grad_norm': 10.971431732177734, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:43,  2.18s/it] 52%|█████▎    | 21/40 [00:44<00:42,  2.24s/it]                                               {'loss': 0.6494, 'grad_norm': 5.639305114746094, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:44<00:42,  2.24s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.26s/it]                                               {'loss': 0.5398, 'grad_norm': 31.270750045776367, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.26s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.28s/it]                                               {'loss': 0.8148, 'grad_norm': 4.5228705406188965, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.28s/it] 60%|██████    | 24/40 [00:49<00:26,  1.66s/it]                                               {'loss': 0.0784, 'grad_norm': 3.342475414276123, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:49<00:26,  1.66s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.86s/it]                                               {'loss': 0.2485, 'grad_norm': 2.072535276412964, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.86s/it] 65%|██████▌   | 26/40 [00:53<00:28,  2.00s/it]                                               {'loss': 0.0709, 'grad_norm': 1.4485247135162354, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:28,  2.00s/it] 68%|██████▊   | 27/40 [00:56<00:27,  2.12s/it]                                               {'loss': 0.0591, 'grad_norm': 0.7308713793754578, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:56<00:27,  2.12s/it] 70%|███████   | 28/40 [00:58<00:26,  2.21s/it]                                               {'loss': 0.1313, 'grad_norm': 2.56378436088562, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:58<00:26,  2.21s/it] 72%|███████▎  | 29/40 [01:01<00:24,  2.27s/it]                                               {'loss': 0.1675, 'grad_norm': 2.6463539600372314, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:01<00:24,  2.27s/it] 75%|███████▌  | 30/40 [01:03<00:22,  2.29s/it]                                               {'loss': 0.3918, 'grad_norm': 4.513096809387207, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:03<00:22,  2.29s/it] 78%|███████▊  | 31/40 [01:05<00:20,  2.32s/it]                                               {'loss': 0.119, 'grad_norm': 1.3965117931365967, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:05<00:20,  2.32s/it] 80%|████████  | 32/40 [01:05<00:13,  1.68s/it]                                               {'loss': 0.0404, 'grad_norm': 1.6141910552978516, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.68s/it] 82%|████████▎ | 33/40 [01:08<00:13,  1.89s/it]                                               {'loss': 0.0225, 'grad_norm': 0.40043458342552185, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:08<00:13,  1.89s/it] 85%|████████▌ | 34/40 [01:10<00:12,  2.05s/it]                                               {'loss': 0.0189, 'grad_norm': 0.35549017786979675, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:10<00:12,  2.05s/it] 88%|████████▊ | 35/40 [01:13<00:10,  2.15s/it]                                               {'loss': 0.2319, 'grad_norm': 3.972144365310669, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:13<00:10,  2.15s/it] 90%|█████████ | 36/40 [01:15<00:08,  2.23s/it]                                               {'loss': 0.0363, 'grad_norm': 0.892001748085022, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:15<00:08,  2.23s/it] 92%|█████████▎| 37/40 [01:17<00:06,  2.28s/it]                                               {'loss': 0.2051, 'grad_norm': 7.079738616943359, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:17<00:06,  2.28s/it] 95%|█████████▌| 38/40 [01:20<00:04,  2.32s/it]                                               {'loss': 0.0781, 'grad_norm': 1.8998868465423584, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:20<00:04,  2.32s/it] 98%|█████████▊| 39/40 [01:22<00:02,  2.35s/it]                                               {'loss': 0.1522, 'grad_norm': 1.7135646343231201, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:22<00:02,  2.35s/it]100%|██████████| 40/40 [01:23<00:00,  1.70s/it]                                               {'loss': 0.1878, 'grad_norm': 11.411014556884766, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:23<00:00,  1.70s/it]                                               {'train_runtime': 83.2775, 'train_samples_per_second': 6.785, 'train_steps_per_second': 0.48, 'train_loss': 1.1592926128767431, 'epoch': 5.0}
100%|██████████| 40/40 [01:23<00:00,  1.70s/it]100%|██████████| 40/40 [01:23<00:00,  2.08s/it]
CLIENT:44
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:29,  2.30s/it]                                              {'loss': 3.6544, 'grad_norm': 6.778061389923096, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:29,  2.30s/it]  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]                                              {'loss': 3.3221, 'grad_norm': 9.194910049438477, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 3.1005, 'grad_norm': 9.13691520690918, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:22,  2.28s/it]                                              {'loss': 3.045, 'grad_norm': 11.612488746643066, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.28s/it] 12%|█▎        | 5/40 [00:11<01:20,  2.30s/it]                                              {'loss': 3.5751, 'grad_norm': 14.981520652770996, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:20,  2.30s/it] 15%|█▌        | 6/40 [00:13<01:18,  2.30s/it]                                              {'loss': 2.1867, 'grad_norm': 11.439672470092773, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:18,  2.30s/it] 18%|█▊        | 7/40 [00:16<01:16,  2.32s/it]                                              {'loss': 3.0514, 'grad_norm': 19.082992553710938, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:16,  2.32s/it] 20%|██        | 8/40 [00:16<00:52,  1.64s/it]                                              {'loss': 0.9817, 'grad_norm': 117.84136199951172, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:52,  1.64s/it] 22%|██▎       | 9/40 [00:18<00:57,  1.86s/it]                                              {'loss': 0.9345, 'grad_norm': 11.085670471191406, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:57,  1.86s/it] 25%|██▌       | 10/40 [00:20<00:59,  2.00s/it]                                               {'loss': 1.6943, 'grad_norm': 15.570086479187012, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:59,  2.00s/it] 28%|██▊       | 11/40 [00:23<01:00,  2.10s/it]                                               {'loss': 0.8006, 'grad_norm': 8.070758819580078, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<01:00,  2.10s/it] 30%|███       | 12/40 [00:25<01:00,  2.17s/it]                                               {'loss': 0.9114, 'grad_norm': 7.706254005432129, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<01:00,  2.17s/it] 32%|███▎      | 13/40 [00:27<01:00,  2.23s/it]                                               {'loss': 1.3644, 'grad_norm': 5.646026611328125, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<01:00,  2.23s/it] 35%|███▌      | 14/40 [00:30<00:58,  2.26s/it]                                               {'loss': 1.0162, 'grad_norm': 6.833376884460449, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:30<00:58,  2.26s/it] 38%|███▊      | 15/40 [00:32<00:56,  2.27s/it]                                               {'loss': 1.3287, 'grad_norm': 6.683619499206543, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:56,  2.27s/it] 40%|████      | 16/40 [00:32<00:39,  1.65s/it]                                               {'loss': 0.0215, 'grad_norm': 1.2303268909454346, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:39,  1.65s/it] 42%|████▎     | 17/40 [00:35<00:42,  1.86s/it]                                               {'loss': 0.3791, 'grad_norm': 12.095550537109375, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:35<00:42,  1.86s/it] 45%|████▌     | 18/40 [00:37<00:44,  2.00s/it]                                               {'loss': 0.6347, 'grad_norm': 15.451128005981445, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:37<00:44,  2.00s/it] 48%|████▊     | 19/40 [00:39<00:44,  2.10s/it]                                               {'loss': 0.3919, 'grad_norm': 9.684197425842285, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:44,  2.10s/it] 50%|█████     | 20/40 [00:42<00:43,  2.17s/it]                                               {'loss': 0.2216, 'grad_norm': 3.3444275856018066, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:42<00:43,  2.17s/it] 52%|█████▎    | 21/40 [00:44<00:41,  2.21s/it]                                               {'loss': 0.4262, 'grad_norm': 5.047190189361572, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:44<00:41,  2.21s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.25s/it]                                               {'loss': 0.2718, 'grad_norm': 4.84453010559082, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.25s/it] 57%|█████▊    | 23/40 [00:49<00:38,  2.28s/it]                                               {'loss': 0.2157, 'grad_norm': 6.446356296539307, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:49<00:38,  2.28s/it] 60%|██████    | 24/40 [00:49<00:26,  1.65s/it]                                               {'loss': 0.0606, 'grad_norm': 2.075779676437378, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:49<00:26,  1.65s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.84s/it]                                               {'loss': 0.6375, 'grad_norm': 32.7198600769043, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.84s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.98s/it]                                               {'loss': 0.3256, 'grad_norm': 9.60481071472168, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.98s/it] 68%|██████▊   | 27/40 [00:56<00:27,  2.10s/it]                                               {'loss': 0.2714, 'grad_norm': 5.552702903747559, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:56<00:27,  2.10s/it] 70%|███████   | 28/40 [00:58<00:26,  2.18s/it]                                               {'loss': 0.3386, 'grad_norm': 4.188844680786133, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:58<00:26,  2.18s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.23s/it]                                               {'loss': 0.1568, 'grad_norm': 3.0904786586761475, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.23s/it] 75%|███████▌  | 30/40 [01:03<00:22,  2.27s/it]                                               {'loss': 0.1141, 'grad_norm': 1.8727779388427734, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:03<00:22,  2.27s/it] 78%|███████▊  | 31/40 [01:05<00:20,  2.29s/it]                                               {'loss': 0.2302, 'grad_norm': 4.587025165557861, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:05<00:20,  2.29s/it] 80%|████████  | 32/40 [01:05<00:13,  1.66s/it]                                               {'loss': 0.4514, 'grad_norm': 17.018436431884766, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.66s/it] 82%|████████▎ | 33/40 [01:08<00:13,  1.87s/it]                                               {'loss': 0.0429, 'grad_norm': 1.251303791999817, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:08<00:13,  1.87s/it] 85%|████████▌ | 34/40 [01:10<00:12,  2.01s/it]                                               {'loss': 0.1102, 'grad_norm': 6.372342586517334, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:10<00:12,  2.01s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.11s/it]                                               {'loss': 0.0608, 'grad_norm': 2.5410468578338623, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.11s/it] 90%|█████████ | 36/40 [01:15<00:08,  2.17s/it]                                               {'loss': 0.4221, 'grad_norm': 6.7770490646362305, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:15<00:08,  2.17s/it] 92%|█████████▎| 37/40 [01:17<00:06,  2.21s/it]                                               {'loss': 0.1702, 'grad_norm': 5.027578353881836, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:17<00:06,  2.21s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.25s/it]                                               {'loss': 0.1024, 'grad_norm': 1.7884622812271118, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.25s/it] 98%|█████████▊| 39/40 [01:22<00:02,  2.27s/it]                                               {'loss': 0.2729, 'grad_norm': 4.250919342041016, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:22<00:02,  2.27s/it]100%|██████████| 40/40 [01:22<00:00,  1.65s/it]                                               {'loss': 0.4741, 'grad_norm': 23.19673728942871, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.65s/it]                                               {'train_runtime': 82.7161, 'train_samples_per_second': 6.831, 'train_steps_per_second': 0.484, 'train_loss': 0.9442854181863367, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.65s/it]100%|██████████| 40/40 [01:22<00:00,  2.07s/it]
CLIENT:34
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:37,  2.51s/it]                                              {'loss': 5.2143, 'grad_norm': 5.444090366363525, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:37,  2.51s/it]  5%|▌         | 2/40 [00:04<01:27,  2.30s/it]                                              {'loss': 3.9002, 'grad_norm': 7.451541423797607, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:27,  2.30s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 2.2702, 'grad_norm': 6.698720932006836, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:21,  2.25s/it]                                              {'loss': 3.9636, 'grad_norm': 8.088160514831543, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 4.8731, 'grad_norm': 10.823592185974121, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.26s/it]                                              {'loss': 2.2124, 'grad_norm': 7.439757823944092, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.26s/it] 18%|█▊        | 7/40 [00:15<01:14,  2.26s/it]                                              {'loss': 2.2407, 'grad_norm': 13.466882705688477, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:14,  2.26s/it] 20%|██        | 8/40 [00:16<00:51,  1.60s/it]                                              {'loss': 1.9037, 'grad_norm': 27.164592742919922, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.60s/it] 22%|██▎       | 9/40 [00:18<00:56,  1.81s/it]                                              {'loss': 0.7877, 'grad_norm': 4.553067207336426, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:56,  1.81s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.96s/it]                                               {'loss': 0.8352, 'grad_norm': 10.772804260253906, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.96s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.05s/it]                                               {'loss': 0.476, 'grad_norm': 4.77246618270874, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.05s/it] 30%|███       | 12/40 [00:25<00:59,  2.11s/it]                                               {'loss': 1.0057, 'grad_norm': 8.07168197631836, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:59,  2.11s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.17s/it]                                               {'loss': 0.8608, 'grad_norm': 7.222692489624023, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.17s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it]                                               {'loss': 0.8055, 'grad_norm': 7.854536533355713, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.22s/it]                                               {'loss': 0.8933, 'grad_norm': 5.487558841705322, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.22s/it] 40%|████      | 16/40 [00:32<00:38,  1.61s/it]                                               {'loss': 2.1994, 'grad_norm': 52.887046813964844, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.61s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.82s/it]                                               {'loss': 0.3166, 'grad_norm': 2.635197877883911, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.82s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it]                                               {'loss': 0.2248, 'grad_norm': 2.7743642330169678, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it]                                               {'loss': 0.3909, 'grad_norm': 3.271777868270874, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it] 50%|█████     | 20/40 [00:41<00:42,  2.15s/it]                                               {'loss': 0.4349, 'grad_norm': 4.524741172790527, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.15s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.20s/it]                                               {'loss': 0.3055, 'grad_norm': 5.9919962882995605, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.20s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.23s/it]                                               {'loss': 0.3491, 'grad_norm': 5.463167667388916, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.23s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.24s/it]                                               {'loss': 0.246, 'grad_norm': 4.7548394203186035, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.24s/it] 60%|██████    | 24/40 [00:48<00:26,  1.63s/it]                                               {'loss': 0.0147, 'grad_norm': 0.8223933577537537, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.63s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it]                                               {'loss': 0.0544, 'grad_norm': 0.9053827524185181, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it]                                               {'loss': 0.1445, 'grad_norm': 2.470604419708252, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.10s/it]                                               {'loss': 0.0434, 'grad_norm': 0.8020328879356384, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.10s/it] 70%|███████   | 28/40 [00:57<00:26,  2.17s/it]                                               {'loss': 0.0439, 'grad_norm': 0.9222962260246277, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:26,  2.17s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.21s/it]                                               {'loss': 0.1073, 'grad_norm': 2.4597737789154053, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.21s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.24s/it]                                               {'loss': 0.0307, 'grad_norm': 0.9424059987068176, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.24s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.27s/it]                                               {'loss': 0.0861, 'grad_norm': 4.3029937744140625, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.27s/it] 80%|████████  | 32/40 [01:05<00:13,  1.65s/it]                                               {'loss': 0.0146, 'grad_norm': 0.9973834753036499, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.65s/it] 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it]                                               {'loss': 0.0341, 'grad_norm': 0.8073148131370544, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it] 85%|████████▌ | 34/40 [01:09<00:12,  2.00s/it]                                               {'loss': 0.0172, 'grad_norm': 0.2693256139755249, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:12,  2.00s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.09s/it]                                               {'loss': 0.0979, 'grad_norm': 2.11151385307312, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.09s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it]                                               {'loss': 0.0586, 'grad_norm': 1.166951298713684, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.23s/it]                                               {'loss': 0.1612, 'grad_norm': 3.5780954360961914, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.23s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.27s/it]                                               {'loss': 0.1202, 'grad_norm': 3.2877907752990723, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.27s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]                                               {'loss': 0.0525, 'grad_norm': 1.8763694763183594, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]100%|██████████| 40/40 [01:21<00:00,  1.66s/it]                                               {'loss': 0.0022, 'grad_norm': 0.14853398501873016, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.66s/it]                                               {'train_runtime': 81.9431, 'train_samples_per_second': 6.895, 'train_steps_per_second': 0.488, 'train_loss': 0.9448280147043988, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.66s/it]100%|██████████| 40/40 [01:21<00:00,  2.05s/it]
CLIENT:24
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:29,  2.29s/it]                                              {'loss': 4.0918, 'grad_norm': 6.681206703186035, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:29,  2.29s/it]  5%|▌         | 2/40 [00:04<01:24,  2.24s/it]                                              {'loss': 4.1504, 'grad_norm': 8.302806854248047, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.24s/it]  8%|▊         | 3/40 [00:06<01:23,  2.24s/it]                                              {'loss': 3.975, 'grad_norm': 8.053362846374512, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.24s/it] 10%|█         | 4/40 [00:09<01:21,  2.27s/it]                                              {'loss': 2.6017, 'grad_norm': 7.7033467292785645, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.27s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it]                                              {'loss': 2.7666, 'grad_norm': 10.671886444091797, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it]                                              {'loss': 3.0558, 'grad_norm': 18.145858764648438, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it] 18%|█▊        | 7/40 [00:15<01:14,  2.25s/it]                                              {'loss': 2.7301, 'grad_norm': 41.23030471801758, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:14,  2.25s/it] 20%|██        | 8/40 [00:15<00:50,  1.59s/it]                                              {'loss': 0.0045, 'grad_norm': 0.32921653985977173, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 1.8211, 'grad_norm': 19.66360855102539, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 0.7373, 'grad_norm': 14.054276466369629, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.05s/it]                                               {'loss': 0.9994, 'grad_norm': 8.189395904541016, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.05s/it] 30%|███       | 12/40 [00:25<00:59,  2.14s/it]                                               {'loss': 0.6282, 'grad_norm': 5.4700469970703125, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:59,  2.14s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.18s/it]                                               {'loss': 1.5425, 'grad_norm': 6.564408779144287, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.18s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.22s/it]                                               {'loss': 0.239, 'grad_norm': 3.6288115978240967, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.22s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.23s/it]                                               {'loss': 1.0406, 'grad_norm': 5.996115207672119, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.23s/it] 40%|████      | 16/40 [00:32<00:38,  1.62s/it]                                               {'loss': 0.0516, 'grad_norm': 2.1590793132781982, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.62s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.83s/it]                                               {'loss': 0.0963, 'grad_norm': 1.710464596748352, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.83s/it] 45%|████▌     | 18/40 [00:37<00:46,  2.10s/it]                                               {'loss': 0.4934, 'grad_norm': 9.744577407836914, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:37<00:46,  2.10s/it] 48%|████▊     | 19/40 [00:39<00:45,  2.16s/it]                                               {'loss': 0.5442, 'grad_norm': 5.7602410316467285, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:45,  2.16s/it] 50%|█████     | 20/40 [00:41<00:44,  2.21s/it]                                               {'loss': 0.8439, 'grad_norm': 11.647815704345703, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:44,  2.21s/it] 52%|█████▎    | 21/40 [00:44<00:42,  2.24s/it]                                               {'loss': 0.5938, 'grad_norm': 14.603442192077637, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:44<00:42,  2.24s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.26s/it]                                               {'loss': 0.6902, 'grad_norm': 4.860777854919434, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.26s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.29s/it]                                               {'loss': 0.7312, 'grad_norm': 10.56839656829834, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.29s/it] 60%|██████    | 24/40 [00:48<00:26,  1.66s/it]                                               {'loss': 0.0727, 'grad_norm': 4.554248332977295, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.66s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.86s/it]                                               {'loss': 1.015, 'grad_norm': 150.12490844726562, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.86s/it] 65%|██████▌   | 26/40 [00:53<00:27,  2.00s/it]                                               {'loss': 0.468, 'grad_norm': 71.46046447753906, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  2.00s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.11s/it]                                               {'loss': 1.0571, 'grad_norm': 12.159494400024414, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.11s/it] 70%|███████   | 28/40 [00:58<00:26,  2.18s/it]                                               {'loss': 0.1891, 'grad_norm': 3.8796274662017822, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:58<00:26,  2.18s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.24s/it]                                               {'loss': 0.3627, 'grad_norm': 3.9881062507629395, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.24s/it] 75%|███████▌  | 30/40 [01:03<00:22,  2.28s/it]                                               {'loss': 0.1233, 'grad_norm': 2.29667592048645, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:03<00:22,  2.28s/it] 78%|███████▊  | 31/40 [01:05<00:20,  2.29s/it]                                               {'loss': 0.1882, 'grad_norm': 2.5494797229766846, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:05<00:20,  2.29s/it] 80%|████████  | 32/40 [01:05<00:13,  1.66s/it]                                               {'loss': 0.0139, 'grad_norm': 0.5197963714599609, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.66s/it] 82%|████████▎ | 33/40 [01:07<00:13,  1.87s/it]                                               {'loss': 0.417, 'grad_norm': 6.86591100692749, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:13,  1.87s/it] 85%|████████▌ | 34/40 [01:10<00:12,  2.01s/it]                                               {'loss': 0.2512, 'grad_norm': 6.495117664337158, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:10<00:12,  2.01s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.12s/it]                                               {'loss': 0.2031, 'grad_norm': 1.8113962411880493, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.12s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it]                                               {'loss': 0.239, 'grad_norm': 3.402231454849243, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it] 92%|█████████▎| 37/40 [01:17<00:06,  2.24s/it]                                               {'loss': 0.2085, 'grad_norm': 3.118972063064575, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:17<00:06,  2.24s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.29s/it]                                               {'loss': 0.1237, 'grad_norm': 2.050551414489746, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.29s/it] 98%|█████████▊| 39/40 [01:22<00:02,  2.31s/it]                                               {'loss': 0.6555, 'grad_norm': 10.987361907958984, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:22<00:02,  2.31s/it]100%|██████████| 40/40 [01:22<00:00,  1.67s/it]                                               {'loss': 0.0034, 'grad_norm': 0.1242634654045105, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.67s/it]                                               {'train_runtime': 82.6159, 'train_samples_per_second': 6.839, 'train_steps_per_second': 0.484, 'train_loss': 1.0005025574821047, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.67s/it]100%|██████████| 40/40 [01:22<00:00,  2.07s/it]
CLIENT:98
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:39,  2.55s/it]                                              {'loss': 5.6756, 'grad_norm': 7.8465728759765625, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:39,  2.55s/it]  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]                                              {'loss': 3.8341, 'grad_norm': 8.903346061706543, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]  8%|▊         | 3/40 [00:06<01:24,  2.30s/it]                                              {'loss': 2.9013, 'grad_norm': 10.13763427734375, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.30s/it] 10%|█         | 4/40 [00:09<01:22,  2.28s/it]                                              {'loss': 3.3422, 'grad_norm': 12.399158477783203, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.28s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.28s/it]                                              {'loss': 4.2334, 'grad_norm': 24.804454803466797, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.28s/it] 15%|█▌        | 6/40 [00:13<01:17,  2.29s/it]                                              {'loss': 2.3605, 'grad_norm': 14.789969444274902, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:17,  2.29s/it] 18%|█▊        | 7/40 [00:16<01:15,  2.29s/it]                                              {'loss': 2.2638, 'grad_norm': 13.856943130493164, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:15,  2.29s/it] 20%|██        | 8/40 [00:16<00:51,  1.62s/it]                                              {'loss': 1.7126, 'grad_norm': 54.254085540771484, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.62s/it] 22%|██▎       | 9/40 [00:18<00:57,  1.84s/it]                                              {'loss': 1.3966, 'grad_norm': 13.120283126831055, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:57,  1.84s/it] 25%|██▌       | 10/40 [00:20<00:59,  1.98s/it]                                               {'loss': 1.5047, 'grad_norm': 12.815824508666992, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:59,  1.98s/it] 28%|██▊       | 11/40 [00:23<00:59,  2.07s/it]                                               {'loss': 0.6108, 'grad_norm': 6.831338405609131, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:59,  2.07s/it] 30%|███       | 12/40 [00:25<01:00,  2.14s/it]                                               {'loss': 1.2507, 'grad_norm': 8.308884620666504, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<01:00,  2.14s/it] 32%|███▎      | 13/40 [00:27<00:59,  2.19s/it]                                               {'loss': 1.599, 'grad_norm': 6.30587911605835, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:59,  2.19s/it] 35%|███▌      | 14/40 [00:30<00:58,  2.24s/it]                                               {'loss': 0.625, 'grad_norm': 5.410526275634766, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:30<00:58,  2.24s/it] 38%|███▊      | 15/40 [00:32<00:56,  2.25s/it]                                               {'loss': 0.4492, 'grad_norm': 3.702458143234253, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:56,  2.25s/it] 40%|████      | 16/40 [00:32<00:39,  1.63s/it]                                               {'loss': 5.8229, 'grad_norm': 36.21519088745117, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:39,  1.63s/it] 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it]                                               {'loss': 0.2852, 'grad_norm': 5.526683807373047, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it] 45%|████▌     | 18/40 [00:37<00:43,  1.98s/it]                                               {'loss': 0.2289, 'grad_norm': 4.946798801422119, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:37<00:43,  1.98s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it]                                               {'loss': 0.4196, 'grad_norm': 5.711313724517822, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it] 50%|█████     | 20/40 [00:41<00:43,  2.16s/it]                                               {'loss': 0.2304, 'grad_norm': 4.566435813903809, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:43,  2.16s/it] 52%|█████▎    | 21/40 [00:44<00:42,  2.22s/it]                                               {'loss': 0.2774, 'grad_norm': 6.518152236938477, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:44<00:42,  2.22s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.26s/it]                                               {'loss': 0.4867, 'grad_norm': 17.22269630432129, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.26s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.28s/it]                                               {'loss': 0.3199, 'grad_norm': 1.885682463645935, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.28s/it] 60%|██████    | 24/40 [00:49<00:26,  1.65s/it]                                               {'loss': 0.1636, 'grad_norm': 4.429051876068115, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:49<00:26,  1.65s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.87s/it]                                               {'loss': 0.0861, 'grad_norm': 2.177623748779297, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.87s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it]                                               {'loss': 0.0767, 'grad_norm': 1.38604736328125, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it] 68%|██████▊   | 27/40 [00:56<00:27,  2.09s/it]                                               {'loss': 0.1118, 'grad_norm': 1.8326239585876465, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:56<00:27,  2.09s/it] 70%|███████   | 28/40 [00:58<00:26,  2.17s/it]                                               {'loss': 0.0533, 'grad_norm': 2.1308722496032715, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:58<00:26,  2.17s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.22s/it]                                               {'loss': 0.0646, 'grad_norm': 1.20396888256073, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.22s/it] 75%|███████▌  | 30/40 [01:03<00:22,  2.26s/it]                                               {'loss': 0.1498, 'grad_norm': 4.2265801429748535, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:03<00:22,  2.26s/it] 78%|███████▊  | 31/40 [01:05<00:20,  2.30s/it]                                               {'loss': 0.1236, 'grad_norm': 3.1275012493133545, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:05<00:20,  2.30s/it] 80%|████████  | 32/40 [01:05<00:13,  1.67s/it]                                               {'loss': 0.0321, 'grad_norm': 1.3472776412963867, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.67s/it] 82%|████████▎ | 33/40 [01:07<00:12,  1.85s/it]                                               {'loss': 0.1249, 'grad_norm': 5.185981273651123, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:12,  1.85s/it] 85%|████████▌ | 34/40 [01:10<00:11,  2.00s/it]                                               {'loss': 0.0327, 'grad_norm': 0.5710880756378174, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:10<00:11,  2.00s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.11s/it]                                               {'loss': 0.0232, 'grad_norm': 0.4703826904296875, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.11s/it] 90%|█████████ | 36/40 [01:15<00:08,  2.19s/it]                                               {'loss': 0.0198, 'grad_norm': 0.6430132985115051, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:15<00:08,  2.19s/it] 92%|█████████▎| 37/40 [01:17<00:06,  2.24s/it]                                               {'loss': 0.057, 'grad_norm': 2.251019239425659, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:17<00:06,  2.24s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.30s/it]                                               {'loss': 0.0322, 'grad_norm': 0.9156323075294495, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.30s/it] 98%|█████████▊| 39/40 [01:22<00:02,  2.30s/it]                                               {'loss': 0.0358, 'grad_norm': 0.8407092094421387, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:22<00:02,  2.30s/it]100%|██████████| 40/40 [01:22<00:00,  1.67s/it]                                               {'loss': 0.0044, 'grad_norm': 0.23727749288082123, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.67s/it]                                               {'train_runtime': 82.6698, 'train_samples_per_second': 6.834, 'train_steps_per_second': 0.484, 'train_loss': 1.0755523828906006, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.67s/it]100%|██████████| 40/40 [01:22<00:00,  2.07s/it]
CLIENT:73
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:28,  2.27s/it]                                              {'loss': 4.9466, 'grad_norm': 6.240573883056641, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:28,  2.27s/it]  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]                                              {'loss': 3.3273, 'grad_norm': 8.63794231414795, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]  8%|▊         | 3/40 [00:06<01:22,  2.24s/it]                                              {'loss': 2.4515, 'grad_norm': 8.870537757873535, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.24s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 2.7656, 'grad_norm': 11.833588600158691, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it]                                              {'loss': 2.4383, 'grad_norm': 14.330918312072754, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it] 15%|█▌        | 6/40 [00:13<01:17,  2.28s/it]                                              {'loss': 2.0571, 'grad_norm': 12.312811851501465, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:17,  2.28s/it] 18%|█▊        | 7/40 [00:15<01:15,  2.28s/it]                                              {'loss': 1.8577, 'grad_norm': 8.399649620056152, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:15,  2.28s/it] 20%|██        | 8/40 [00:16<00:51,  1.61s/it]                                              {'loss': 3.4883, 'grad_norm': 59.59784698486328, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.61s/it] 22%|██▎       | 9/40 [00:18<00:56,  1.82s/it]                                              {'loss': 1.4928, 'grad_norm': 16.61884117126465, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:56,  1.82s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.96s/it]                                               {'loss': 0.5585, 'grad_norm': 6.5875349044799805, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.96s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.06s/it]                                               {'loss': 0.6682, 'grad_norm': 6.304410934448242, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.06s/it] 30%|███       | 12/40 [00:25<00:59,  2.13s/it]                                               {'loss': 1.3886, 'grad_norm': 9.040440559387207, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:59,  2.13s/it] 32%|███▎      | 13/40 [00:27<00:59,  2.20s/it]                                               {'loss': 0.3386, 'grad_norm': 3.7154269218444824, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:59,  2.20s/it] 35%|███▌      | 14/40 [00:29<00:58,  2.24s/it]                                               {'loss': 0.5762, 'grad_norm': 4.085312366485596, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:58,  2.24s/it] 38%|███▊      | 15/40 [00:32<00:56,  2.26s/it]                                               {'loss': 0.4485, 'grad_norm': 2.7412467002868652, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:56,  2.26s/it] 40%|████      | 16/40 [00:32<00:39,  1.64s/it]                                               {'loss': 1.0738, 'grad_norm': 41.34449768066406, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:39,  1.64s/it] 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it]                                               {'loss': 0.6642, 'grad_norm': 11.626778602600098, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it]                                               {'loss': 0.3767, 'grad_norm': 6.136622905731201, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.08s/it]                                               {'loss': 0.3618, 'grad_norm': 4.873135089874268, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.08s/it] 50%|█████     | 20/40 [00:41<00:42,  2.14s/it]                                               {'loss': 0.794, 'grad_norm': 8.536239624023438, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.14s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it]                                               {'loss': 0.143, 'grad_norm': 1.9039570093154907, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.24s/it]                                               {'loss': 0.2134, 'grad_norm': 2.578646421432495, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.24s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.26s/it]                                               {'loss': 0.1223, 'grad_norm': 2.206056594848633, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.26s/it] 60%|██████    | 24/40 [00:48<00:26,  1.64s/it]                                               {'loss': 0.0235, 'grad_norm': 1.4337363243103027, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.64s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.84s/it]                                               {'loss': 0.0201, 'grad_norm': 0.36704501509666443, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.84s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it]                                               {'loss': 0.0946, 'grad_norm': 1.5018645524978638, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.09s/it]                                               {'loss': 0.0632, 'grad_norm': 1.2093642950057983, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.09s/it] 70%|███████   | 28/40 [00:58<00:25,  2.16s/it]                                               {'loss': 0.0972, 'grad_norm': 2.222519636154175, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:58<00:25,  2.16s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.21s/it]                                               {'loss': 0.2417, 'grad_norm': 2.7952022552490234, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.21s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.24s/it]                                               {'loss': 0.1583, 'grad_norm': 3.0415375232696533, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.24s/it] 78%|███████▊  | 31/40 [01:05<00:20,  2.27s/it]                                               {'loss': 0.0379, 'grad_norm': 1.9150335788726807, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:05<00:20,  2.27s/it] 80%|████████  | 32/40 [01:05<00:13,  1.64s/it]                                               {'loss': 0.0177, 'grad_norm': 0.9665437936782837, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.64s/it] 82%|████████▎ | 33/40 [01:07<00:12,  1.85s/it]                                               {'loss': 0.0408, 'grad_norm': 1.9539748430252075, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:12,  1.85s/it] 85%|████████▌ | 34/40 [01:09<00:11,  2.00s/it]                                               {'loss': 0.0123, 'grad_norm': 0.5757849216461182, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  2.00s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.10s/it]                                               {'loss': 0.0206, 'grad_norm': 0.38636279106140137, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.10s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.17s/it]                                               {'loss': 0.0232, 'grad_norm': 1.0699278116226196, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.17s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.21s/it]                                               {'loss': 0.0203, 'grad_norm': 0.4425971508026123, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.21s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.25s/it]                                               {'loss': 0.0577, 'grad_norm': 1.2126182317733765, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.25s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.28s/it]                                               {'loss': 0.0418, 'grad_norm': 1.202818751335144, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.28s/it]100%|██████████| 40/40 [01:21<00:00,  1.65s/it]                                               {'loss': 0.0066, 'grad_norm': 0.3639765679836273, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.65s/it]                                               {'train_runtime': 82.0099, 'train_samples_per_second': 6.889, 'train_steps_per_second': 0.488, 'train_loss': 0.8382674091495573, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.65s/it]100%|██████████| 40/40 [01:22<00:00,  2.05s/it]
CLIENT:95
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:37,  2.51s/it]                                              {'loss': 5.3101, 'grad_norm': 10.3329439163208, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:37,  2.51s/it]  5%|▌         | 2/40 [00:04<01:28,  2.33s/it]                                              {'loss': 4.8335, 'grad_norm': 8.294663429260254, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.33s/it]  8%|▊         | 3/40 [00:06<01:25,  2.30s/it]                                              {'loss': 3.005, 'grad_norm': 9.928796768188477, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:25,  2.30s/it] 10%|█         | 4/40 [00:09<01:21,  2.28s/it]                                              {'loss': 3.4056, 'grad_norm': 10.52664852142334, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.28s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it]                                              {'loss': 3.4817, 'grad_norm': 16.994157791137695, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it]                                              {'loss': 2.5207, 'grad_norm': 17.55378532409668, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it] 18%|█▊        | 7/40 [00:15<01:14,  2.26s/it]                                              {'loss': 2.2055, 'grad_norm': 22.648679733276367, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:14,  2.26s/it] 20%|██        | 8/40 [00:16<00:51,  1.60s/it]                                              {'loss': 0.7318, 'grad_norm': 27.477781295776367, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.60s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 1.5249, 'grad_norm': 16.258302688598633, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.95s/it]                                               {'loss': 1.193, 'grad_norm': 5.59375, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.95s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.06s/it]                                               {'loss': 0.4966, 'grad_norm': 4.258691310882568, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.06s/it] 30%|███       | 12/40 [00:25<00:59,  2.11s/it]                                               {'loss': 1.2417, 'grad_norm': 12.624913215637207, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:59,  2.11s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it]                                               {'loss': 1.7519, 'grad_norm': 6.694870948791504, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it]                                               {'loss': 0.9051, 'grad_norm': 8.158247947692871, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it] 38%|███▊      | 15/40 [00:32<00:56,  2.24s/it]                                               {'loss': 0.7618, 'grad_norm': 10.854660034179688, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:56,  2.24s/it] 40%|████      | 16/40 [00:32<00:39,  1.63s/it]                                               {'loss': 0.9351, 'grad_norm': 21.77164077758789, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:39,  1.63s/it] 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it]                                               {'loss': 0.2204, 'grad_norm': 4.778488636016846, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.98s/it]                                               {'loss': 0.2646, 'grad_norm': 13.943771362304688, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.98s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.06s/it]                                               {'loss': 0.7521, 'grad_norm': 6.6020894050598145, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.06s/it] 50%|█████     | 20/40 [00:41<00:42,  2.15s/it]                                               {'loss': 0.3621, 'grad_norm': 6.094693183898926, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.15s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it]                                               {'loss': 0.7584, 'grad_norm': 8.000492095947266, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.23s/it]                                               {'loss': 0.1292, 'grad_norm': 2.186267852783203, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.23s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.26s/it]                                               {'loss': 0.4611, 'grad_norm': 4.604208946228027, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.26s/it] 60%|██████    | 24/40 [00:48<00:26,  1.64s/it]                                               {'loss': 0.0073, 'grad_norm': 0.4209353029727936, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.64s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.85s/it]                                               {'loss': 0.0374, 'grad_norm': 0.5844931602478027, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.85s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it]                                               {'loss': 0.0385, 'grad_norm': 0.7352981567382812, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.09s/it]                                               {'loss': 0.4523, 'grad_norm': 4.40410041809082, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.09s/it] 70%|███████   | 28/40 [00:57<00:25,  2.16s/it]                                               {'loss': 0.1901, 'grad_norm': 2.5524230003356934, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.16s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.21s/it]                                               {'loss': 0.136, 'grad_norm': 3.968693494796753, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.21s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.25s/it]                                               {'loss': 0.0751, 'grad_norm': 2.9950647354125977, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.25s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.28s/it]                                               {'loss': 0.2511, 'grad_norm': 4.088193893432617, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.28s/it] 80%|████████  | 32/40 [01:05<00:13,  1.65s/it]                                               {'loss': 0.0624, 'grad_norm': 2.4356863498687744, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.65s/it] 82%|████████▎ | 33/40 [01:07<00:12,  1.85s/it]                                               {'loss': 0.4073, 'grad_norm': 7.004324436187744, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:12,  1.85s/it] 85%|████████▌ | 34/40 [01:09<00:12,  2.00s/it]                                               {'loss': 0.3035, 'grad_norm': 5.998478889465332, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:12,  2.00s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.09s/it]                                               {'loss': 0.1634, 'grad_norm': 5.863545894622803, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.09s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.14s/it]                                               {'loss': 0.3391, 'grad_norm': 3.3041441440582275, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.22s/it]                                               {'loss': 0.0358, 'grad_norm': 0.6069696545600891, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.22s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.27s/it]                                               {'loss': 0.0387, 'grad_norm': 1.3039100170135498, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.27s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]                                               {'loss': 0.048, 'grad_norm': 2.9549543857574463, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]100%|██████████| 40/40 [01:21<00:00,  1.66s/it]                                               {'loss': 0.0791, 'grad_norm': 6.322959899902344, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.66s/it]                                               {'train_runtime': 82.0713, 'train_samples_per_second': 6.884, 'train_steps_per_second': 0.487, 'train_loss': 0.997920446912758, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.66s/it]100%|██████████| 40/40 [01:22<00:00,  2.05s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<05:03,  1.55it/s]  1%|          | 3/471 [00:02<07:09,  1.09it/s]  1%|          | 4/471 [00:03<08:17,  1.07s/it]  1%|          | 5/471 [00:05<08:55,  1.15s/it]  1%|▏         | 6/471 [00:06<09:18,  1.20s/it]  1%|▏         | 7/471 [00:07<09:34,  1.24s/it]  2%|▏         | 8/471 [00:09<09:44,  1.26s/it]  2%|▏         | 9/471 [00:10<09:50,  1.28s/it]  2%|▏         | 10/471 [00:11<09:54,  1.29s/it]  2%|▏         | 11/471 [00:13<09:56,  1.30s/it]  3%|▎         | 12/471 [00:14<09:58,  1.30s/it]  3%|▎         | 13/471 [00:15<10:00,  1.31s/it]  3%|▎         | 14/471 [00:17<10:00,  1.31s/it]  3%|▎         | 15/471 [00:18<10:00,  1.32s/it]  3%|▎         | 16/471 [00:19<10:00,  1.32s/it]  4%|▎         | 17/471 [00:21<10:00,  1.32s/it]  4%|▍         | 18/471 [00:22<10:00,  1.33s/it]  4%|▍         | 19/471 [00:23<09:59,  1.33s/it]  4%|▍         | 20/471 [00:25<09:59,  1.33s/it]  4%|▍         | 21/471 [00:26<09:59,  1.33s/it]  5%|▍         | 22/471 [00:27<09:58,  1.33s/it]  5%|▍         | 23/471 [00:29<09:58,  1.34s/it]  5%|▌         | 24/471 [00:30<09:57,  1.34s/it]  5%|▌         | 25/471 [00:31<09:56,  1.34s/it]  6%|▌         | 26/471 [00:33<09:56,  1.34s/it]  6%|▌         | 27/471 [00:34<09:55,  1.34s/it]  6%|▌         | 28/471 [00:35<09:53,  1.34s/it]  6%|▌         | 29/471 [00:37<09:52,  1.34s/it]  6%|▋         | 30/471 [00:38<09:52,  1.34s/it]  7%|▋         | 31/471 [00:39<09:51,  1.34s/it]  7%|▋         | 32/471 [00:41<09:49,  1.34s/it]  7%|▋         | 33/471 [00:42<09:46,  1.34s/it]  7%|▋         | 34/471 [00:43<09:46,  1.34s/it]  7%|▋         | 35/471 [00:45<09:45,  1.34s/it]  8%|▊         | 36/471 [00:46<09:44,  1.34s/it]  8%|▊         | 37/471 [00:47<09:44,  1.35s/it]  8%|▊         | 38/471 [00:49<09:43,  1.35s/it]  8%|▊         | 39/471 [00:50<09:42,  1.35s/it]  8%|▊         | 40/471 [00:51<09:40,  1.35s/it]  9%|▊         | 41/471 [00:53<09:39,  1.35s/it]  9%|▉         | 42/471 [00:54<09:39,  1.35s/it]  9%|▉         | 43/471 [00:55<09:37,  1.35s/it]  9%|▉         | 44/471 [00:57<09:35,  1.35s/it] 10%|▉         | 45/471 [00:58<09:35,  1.35s/it] 10%|▉         | 46/471 [01:00<09:33,  1.35s/it] 10%|▉         | 47/471 [01:01<09:32,  1.35s/it] 10%|█         | 48/471 [01:02<09:31,  1.35s/it] 10%|█         | 49/471 [01:04<09:31,  1.35s/it] 11%|█         | 50/471 [01:05<09:30,  1.35s/it] 11%|█         | 51/471 [01:06<09:28,  1.35s/it] 11%|█         | 52/471 [01:08<09:27,  1.35s/it] 11%|█▏        | 53/471 [01:09<09:26,  1.36s/it] 11%|█▏        | 54/471 [01:10<09:25,  1.36s/it] 12%|█▏        | 55/471 [01:12<09:24,  1.36s/it] 12%|█▏        | 56/471 [01:13<09:23,  1.36s/it] 12%|█▏        | 57/471 [01:14<09:22,  1.36s/it] 12%|█▏        | 58/471 [01:16<09:21,  1.36s/it] 13%|█▎        | 59/471 [01:17<09:20,  1.36s/it] 13%|█▎        | 60/471 [01:19<09:17,  1.36s/it] 13%|█▎        | 61/471 [01:20<09:16,  1.36s/it] 13%|█▎        | 62/471 [01:21<09:15,  1.36s/it] 13%|█▎        | 63/471 [01:23<09:13,  1.36s/it] 14%|█▎        | 64/471 [01:24<09:12,  1.36s/it] 14%|█▍        | 65/471 [01:25<09:11,  1.36s/it] 14%|█▍        | 66/471 [01:27<09:09,  1.36s/it] 14%|█▍        | 67/471 [01:28<09:08,  1.36s/it] 14%|█▍        | 68/471 [01:29<09:06,  1.36s/it] 15%|█▍        | 69/471 [01:31<09:05,  1.36s/it] 15%|█▍        | 70/471 [01:32<09:05,  1.36s/it] 15%|█▌        | 71/471 [01:33<09:04,  1.36s/it] 15%|█▌        | 72/471 [01:35<09:02,  1.36s/it] 15%|█▌        | 73/471 [01:36<09:00,  1.36s/it] 16%|█▌        | 74/471 [01:38<08:57,  1.35s/it] 16%|█▌        | 75/471 [01:39<08:57,  1.36s/it] 16%|█▌        | 76/471 [01:40<08:55,  1.36s/it] 16%|█▋        | 77/471 [01:42<08:54,  1.36s/it] 17%|█▋        | 78/471 [01:43<08:53,  1.36s/it] 17%|█▋        | 79/471 [01:44<08:52,  1.36s/it] 17%|█▋        | 80/471 [01:46<08:51,  1.36s/it] 17%|█▋        | 81/471 [01:47<08:49,  1.36s/it] 17%|█▋        | 82/471 [01:48<08:48,  1.36s/it] 18%|█▊        | 83/471 [01:50<08:47,  1.36s/it] 18%|█▊        | 84/471 [01:51<08:45,  1.36s/it] 18%|█▊        | 85/471 [01:52<08:44,  1.36s/it] 18%|█▊        | 86/471 [01:54<08:43,  1.36s/it] 18%|█▊        | 87/471 [01:55<08:41,  1.36s/it] 19%|█▊        | 88/471 [01:57<08:39,  1.36s/it] 19%|█▉        | 89/471 [01:58<08:38,  1.36s/it] 19%|█▉        | 90/471 [01:59<08:37,  1.36s/it] 19%|█▉        | 91/471 [02:01<08:35,  1.36s/it] 20%|█▉        | 92/471 [02:02<08:33,  1.36s/it] 20%|█▉        | 93/471 [02:03<08:32,  1.36s/it] 20%|█▉        | 94/471 [02:05<08:30,  1.35s/it] 20%|██        | 95/471 [02:06<08:29,  1.35s/it] 20%|██        | 96/471 [02:07<08:27,  1.35s/it] 21%|██        | 97/471 [02:09<08:27,  1.36s/it] 21%|██        | 98/471 [02:10<08:25,  1.36s/it] 21%|██        | 99/471 [02:11<08:24,  1.36s/it] 21%|██        | 100/471 [02:13<08:22,  1.36s/it] 21%|██▏       | 101/471 [02:14<08:21,  1.36s/it] 22%|██▏       | 102/471 [02:16<08:20,  1.36s/it] 22%|██▏       | 103/471 [02:17<08:19,  1.36s/it] 22%|██▏       | 104/471 [02:18<08:19,  1.36s/it] 22%|██▏       | 105/471 [02:20<08:18,  1.36s/it] 23%|██▎       | 106/471 [02:21<08:15,  1.36s/it] 23%|██▎       | 107/471 [02:22<08:14,  1.36s/it] 23%|██▎       | 108/471 [02:24<08:12,  1.36s/it] 23%|██▎       | 109/471 [02:25<08:10,  1.35s/it] 23%|██▎       | 110/471 [02:26<08:08,  1.35s/it] 24%|██▎       | 111/471 [02:28<08:07,  1.35s/it] 24%|██▍       | 112/471 [02:29<08:06,  1.36s/it] 24%|██▍       | 113/471 [02:30<08:05,  1.35s/it] 24%|██▍       | 114/471 [02:32<08:04,  1.36s/it] 24%|██▍       | 115/471 [02:33<08:02,  1.36s/it] 25%|██▍       | 116/471 [02:35<08:01,  1.36s/it] 25%|██▍       | 117/471 [02:36<08:00,  1.36s/it] 25%|██▌       | 118/471 [02:37<07:58,  1.36s/it] 25%|██▌       | 119/471 [02:39<07:57,  1.36s/it] 25%|██▌       | 120/471 [02:40<07:56,  1.36s/it] 26%|██▌       | 121/471 [02:41<07:54,  1.36s/it] 26%|██▌       | 122/471 [02:43<07:52,  1.36s/it] 26%|██▌       | 123/471 [02:44<07:51,  1.36s/it] 26%|██▋       | 124/471 [02:45<07:50,  1.36s/it] 27%|██▋       | 125/471 [02:47<07:49,  1.36s/it] 27%|██▋       | 126/471 [02:48<07:48,  1.36s/it] 27%|██▋       | 127/471 [02:49<07:47,  1.36s/it] 27%|██▋       | 128/471 [02:51<07:45,  1.36s/it] 27%|██▋       | 129/471 [02:52<07:43,  1.36s/it] 28%|██▊       | 130/471 [02:53<07:42,  1.36s/it] 28%|██▊       | 131/471 [02:55<07:40,  1.36s/it] 28%|██▊       | 132/471 [02:56<07:39,  1.36s/it] 28%|██▊       | 133/471 [02:58<07:38,  1.36s/it] 28%|██▊       | 134/471 [02:59<07:37,  1.36s/it] 29%|██▊       | 135/471 [03:00<07:35,  1.36s/it] 29%|██▉       | 136/471 [03:02<07:34,  1.36s/it] 29%|██▉       | 137/471 [03:03<07:32,  1.36s/it] 29%|██▉       | 138/471 [03:04<07:31,  1.36s/it] 30%|██▉       | 139/471 [03:06<07:30,  1.36s/it] 30%|██▉       | 140/471 [03:07<07:28,  1.36s/it] 30%|██▉       | 141/471 [03:08<07:27,  1.35s/it] 30%|███       | 142/471 [03:10<07:25,  1.35s/it] 30%|███       | 143/471 [03:11<07:23,  1.35s/it] 31%|███       | 144/471 [03:12<07:23,  1.36s/it] 31%|███       | 145/471 [03:14<07:21,  1.35s/it] 31%|███       | 146/471 [03:15<07:20,  1.36s/it] 31%|███       | 147/471 [03:17<07:19,  1.36s/it] 31%|███▏      | 148/471 [03:18<07:17,  1.36s/it] 32%|███▏      | 149/471 [03:19<07:17,  1.36s/it] 32%|███▏      | 150/471 [03:21<07:16,  1.36s/it] 32%|███▏      | 151/471 [03:22<07:15,  1.36s/it] 32%|███▏      | 152/471 [03:23<07:13,  1.36s/it] 32%|███▏      | 153/471 [03:25<07:12,  1.36s/it] 33%|███▎      | 154/471 [03:26<07:09,  1.36s/it] 33%|███▎      | 155/471 [03:27<07:08,  1.36s/it] 33%|███▎      | 156/471 [03:29<07:07,  1.36s/it] 33%|███▎      | 157/471 [03:30<07:05,  1.36s/it] 34%|███▎      | 158/471 [03:31<07:03,  1.35s/it] 34%|███▍      | 159/471 [03:33<07:02,  1.35s/it] 34%|███▍      | 160/471 [03:34<07:01,  1.36s/it] 34%|███▍      | 161/471 [03:36<07:00,  1.36s/it] 34%|███▍      | 162/471 [03:37<06:59,  1.36s/it] 35%|███▍      | 163/471 [03:38<06:57,  1.36s/it] 35%|███▍      | 164/471 [03:40<06:55,  1.36s/it] 35%|███▌      | 165/471 [03:41<06:54,  1.36s/it] 35%|███▌      | 166/471 [03:42<06:53,  1.36s/it] 35%|███▌      | 167/471 [03:44<06:52,  1.36s/it] 36%|███▌      | 168/471 [03:45<06:50,  1.36s/it] 36%|███▌      | 169/471 [03:46<06:50,  1.36s/it] 36%|███▌      | 170/471 [03:48<06:48,  1.36s/it] 36%|███▋      | 171/471 [03:49<06:46,  1.36s/it] 37%|███▋      | 172/471 [03:50<06:44,  1.35s/it] 37%|███▋      | 173/471 [03:52<06:43,  1.35s/it] 37%|███▋      | 174/471 [03:53<06:41,  1.35s/it] 37%|███▋      | 175/471 [03:55<06:40,  1.35s/it] 37%|███▋      | 176/471 [03:56<06:38,  1.35s/it] 38%|███▊      | 177/471 [03:57<06:37,  1.35s/it] 38%|███▊      | 178/471 [03:59<06:36,  1.35s/it] 38%|███▊      | 179/471 [04:00<06:34,  1.35s/it] 38%|███▊      | 180/471 [04:01<06:33,  1.35s/it] 38%|███▊      | 181/471 [04:03<06:31,  1.35s/it] 39%|███▊      | 182/471 [04:04<06:30,  1.35s/it] 39%|███▉      | 183/471 [04:05<06:29,  1.35s/it] 39%|███▉      | 184/471 [04:07<06:27,  1.35s/it] 39%|███▉      | 185/471 [04:08<06:26,  1.35s/it] 39%|███▉      | 186/471 [04:09<06:25,  1.35s/it] 40%|███▉      | 187/471 [04:11<06:24,  1.35s/it] 40%|███▉      | 188/471 [04:12<06:23,  1.35s/it] 40%|████      | 189/471 [04:13<06:20,  1.35s/it] 40%|████      | 190/471 [04:15<06:19,  1.35s/it] 41%|████      | 191/471 [04:16<06:18,  1.35s/it] 41%|████      | 192/471 [04:17<06:16,  1.35s/it] 41%|████      | 193/471 [04:19<06:14,  1.35s/it] 41%|████      | 194/471 [04:20<06:13,  1.35s/it] 41%|████▏     | 195/471 [04:22<06:12,  1.35s/it] 42%|████▏     | 196/471 [04:23<06:11,  1.35s/it] 42%|████▏     | 197/471 [04:24<06:09,  1.35s/it] 42%|████▏     | 198/471 [04:26<06:07,  1.35s/it] 42%|████▏     | 199/471 [04:27<06:06,  1.35s/it] 42%|████▏     | 200/471 [04:28<06:05,  1.35s/it] 43%|████▎     | 201/471 [04:30<06:03,  1.35s/it] 43%|████▎     | 202/471 [04:31<06:02,  1.35s/it] 43%|████▎     | 203/471 [04:32<06:01,  1.35s/it] 43%|████▎     | 204/471 [04:34<05:59,  1.35s/it] 44%|████▎     | 205/471 [04:35<05:58,  1.35s/it] 44%|████▎     | 206/471 [04:36<05:56,  1.35s/it] 44%|████▍     | 207/471 [04:38<05:56,  1.35s/it] 44%|████▍     | 208/471 [04:39<05:54,  1.35s/it] 44%|████▍     | 209/471 [04:40<05:52,  1.35s/it] 45%|████▍     | 210/471 [04:42<05:51,  1.35s/it] 45%|████▍     | 211/471 [04:43<05:50,  1.35s/it] 45%|████▌     | 212/471 [04:44<05:48,  1.35s/it] 45%|████▌     | 213/471 [04:46<05:47,  1.35s/it] 45%|████▌     | 214/471 [04:47<05:46,  1.35s/it] 46%|████▌     | 215/471 [04:48<05:45,  1.35s/it] 46%|████▌     | 216/471 [04:50<05:44,  1.35s/it] 46%|████▌     | 217/471 [04:51<05:43,  1.35s/it] 46%|████▋     | 218/471 [04:53<05:41,  1.35s/it] 46%|████▋     | 219/471 [04:54<05:40,  1.35s/it] 47%|████▋     | 220/471 [04:55<05:38,  1.35s/it] 47%|████▋     | 221/471 [04:57<05:37,  1.35s/it] 47%|████▋     | 222/471 [04:58<05:35,  1.35s/it] 47%|████▋     | 223/471 [04:59<05:34,  1.35s/it] 48%|████▊     | 224/471 [05:01<05:33,  1.35s/it] 48%|████▊     | 225/471 [05:02<05:32,  1.35s/it] 48%|████▊     | 226/471 [05:03<05:31,  1.35s/it] 48%|████▊     | 227/471 [05:05<05:29,  1.35s/it] 48%|████▊     | 228/471 [05:06<05:28,  1.35s/it] 49%|████▊     | 229/471 [05:07<05:26,  1.35s/it] 49%|████▉     | 230/471 [05:09<05:25,  1.35s/it] 49%|████▉     | 231/471 [05:10<05:24,  1.35s/it] 49%|████▉     | 232/471 [05:11<05:22,  1.35s/it] 49%|████▉     | 233/471 [05:13<05:21,  1.35s/it] 50%|████▉     | 234/471 [05:14<05:20,  1.35s/it] 50%|████▉     | 235/471 [05:15<05:19,  1.35s/it] 50%|█████     | 236/471 [05:17<05:16,  1.35s/it] 50%|█████     | 237/471 [05:18<05:15,  1.35s/it] 51%|█████     | 238/471 [05:20<05:14,  1.35s/it] 51%|█████     | 239/471 [05:21<05:13,  1.35s/it] 51%|█████     | 240/471 [05:22<05:11,  1.35s/it] 51%|█████     | 241/471 [05:24<05:10,  1.35s/it] 51%|█████▏    | 242/471 [05:25<05:09,  1.35s/it] 52%|█████▏    | 243/471 [05:26<05:08,  1.35s/it] 52%|█████▏    | 244/471 [05:28<05:06,  1.35s/it] 52%|█████▏    | 245/471 [05:29<05:05,  1.35s/it] 52%|█████▏    | 246/471 [05:30<05:03,  1.35s/it] 52%|█████▏    | 247/471 [05:32<05:02,  1.35s/it] 53%|█████▎    | 248/471 [05:33<05:01,  1.35s/it] 53%|█████▎    | 249/471 [05:34<05:00,  1.35s/it] 53%|█████▎    | 250/471 [05:36<04:58,  1.35s/it] 53%|█████▎    | 251/471 [05:37<04:57,  1.35s/it] 54%|█████▎    | 252/471 [05:38<04:56,  1.35s/it] 54%|█████▎    | 253/471 [05:40<04:55,  1.35s/it] 54%|█████▍    | 254/471 [05:41<04:53,  1.35s/it] 54%|█████▍    | 255/471 [05:43<04:52,  1.35s/it] 54%|█████▍    | 256/471 [05:44<04:51,  1.35s/it] 55%|█████▍    | 257/471 [05:45<04:49,  1.36s/it] 55%|█████▍    | 258/471 [05:47<04:48,  1.36s/it] 55%|█████▍    | 259/471 [05:48<04:47,  1.36s/it] 55%|█████▌    | 260/471 [05:49<04:46,  1.36s/it] 55%|█████▌    | 261/471 [05:51<04:44,  1.36s/it] 56%|█████▌    | 262/471 [05:52<04:43,  1.35s/it] 56%|█████▌    | 263/471 [05:53<04:42,  1.36s/it] 56%|█████▌    | 264/471 [05:55<04:40,  1.36s/it] 56%|█████▋    | 265/471 [05:56<04:39,  1.36s/it] 56%|█████▋    | 266/471 [05:57<04:38,  1.36s/it] 57%|█████▋    | 267/471 [05:59<04:36,  1.36s/it] 57%|█████▋    | 268/471 [06:00<04:35,  1.36s/it] 57%|█████▋    | 269/471 [06:01<04:33,  1.36s/it] 57%|█████▋    | 270/471 [06:03<04:32,  1.36s/it] 58%|█████▊    | 271/471 [06:04<04:31,  1.36s/it] 58%|█████▊    | 272/471 [06:06<04:29,  1.35s/it] 58%|█████▊    | 273/471 [06:07<04:28,  1.35s/it] 58%|█████▊    | 274/471 [06:08<04:26,  1.35s/it] 58%|█████▊    | 275/471 [06:10<04:24,  1.35s/it] 59%|█████▊    | 276/471 [06:11<04:23,  1.35s/it] 59%|█████▉    | 277/471 [06:12<04:22,  1.35s/it] 59%|█████▉    | 278/471 [06:14<04:21,  1.36s/it] 59%|█████▉    | 279/471 [06:15<04:19,  1.35s/it] 59%|█████▉    | 280/471 [06:16<04:18,  1.35s/it] 60%|█████▉    | 281/471 [06:18<04:16,  1.35s/it] 60%|█████▉    | 282/471 [06:19<04:15,  1.35s/it] 60%|██████    | 283/471 [06:20<04:14,  1.35s/it] 60%|██████    | 284/471 [06:22<04:12,  1.35s/it] 61%|██████    | 285/471 [06:23<04:11,  1.35s/it] 61%|██████    | 286/471 [06:24<04:10,  1.35s/it] 61%|██████    | 287/471 [06:26<04:08,  1.35s/it] 61%|██████    | 288/471 [06:27<04:07,  1.35s/it] 61%|██████▏   | 289/471 [06:29<04:05,  1.35s/it] 62%|██████▏   | 290/471 [06:30<04:04,  1.35s/it] 62%|██████▏   | 291/471 [06:31<04:02,  1.35s/it] 62%|██████▏   | 292/471 [06:33<04:01,  1.35s/it] 62%|██████▏   | 293/471 [06:34<03:59,  1.35s/it] 62%|██████▏   | 294/471 [06:35<03:58,  1.35s/it] 63%|██████▎   | 295/471 [06:37<03:56,  1.35s/it] 63%|██████▎   | 296/471 [06:38<03:55,  1.35s/it] 63%|██████▎   | 297/471 [06:39<03:54,  1.35s/it] 63%|██████▎   | 298/471 [06:41<03:53,  1.35s/it] 63%|██████▎   | 299/471 [06:42<03:51,  1.35s/it] 64%|██████▎   | 300/471 [06:43<03:50,  1.35s/it] 64%|██████▍   | 301/471 [06:45<03:49,  1.35s/it] 64%|██████▍   | 302/471 [06:46<03:47,  1.35s/it] 64%|██████▍   | 303/471 [06:47<03:46,  1.35s/it] 65%|██████▍   | 304/471 [06:49<03:44,  1.35s/it] 65%|██████▍   | 305/471 [06:50<03:43,  1.35s/it] 65%|██████▍   | 306/471 [06:51<03:42,  1.35s/it] 65%|██████▌   | 307/471 [06:53<03:41,  1.35s/it] 65%|██████▌   | 308/471 [06:54<03:40,  1.35s/it] 66%|██████▌   | 309/471 [06:56<03:38,  1.35s/it] 66%|██████▌   | 310/471 [06:57<03:37,  1.35s/it] 66%|██████▌   | 311/471 [06:58<03:36,  1.35s/it] 66%|██████▌   | 312/471 [07:00<03:34,  1.35s/it] 66%|██████▋   | 313/471 [07:01<03:33,  1.35s/it] 67%|██████▋   | 314/471 [07:02<03:31,  1.35s/it] 67%|██████▋   | 315/471 [07:04<03:30,  1.35s/it] 67%|██████▋   | 316/471 [07:05<03:28,  1.35s/it] 67%|██████▋   | 317/471 [07:06<03:27,  1.35s/it] 68%|██████▊   | 318/471 [07:08<03:26,  1.35s/it] 68%|██████▊   | 319/471 [07:09<03:24,  1.35s/it] 68%|██████▊   | 320/471 [07:10<03:23,  1.35s/it] 68%|██████▊   | 321/471 [07:12<03:22,  1.35s/it] 68%|██████▊   | 322/471 [07:13<03:21,  1.35s/it] 69%|██████▊   | 323/471 [07:14<03:19,  1.35s/it] 69%|██████▉   | 324/471 [07:16<03:18,  1.35s/it] 69%|██████▉   | 325/471 [07:17<03:17,  1.35s/it] 69%|██████▉   | 326/471 [07:18<03:15,  1.35s/it] 69%|██████▉   | 327/471 [07:20<03:14,  1.35s/it] 70%|██████▉   | 328/471 [07:21<03:13,  1.35s/it] 70%|██████▉   | 329/471 [07:22<03:11,  1.35s/it] 70%|███████   | 330/471 [07:24<03:10,  1.35s/it] 70%|███████   | 331/471 [07:25<03:08,  1.35s/it] 70%|███████   | 332/471 [07:27<03:07,  1.35s/it] 71%|███████   | 333/471 [07:28<03:06,  1.35s/it] 71%|███████   | 334/471 [07:29<03:05,  1.35s/it] 71%|███████   | 335/471 [07:31<03:04,  1.35s/it] 71%|███████▏  | 336/471 [07:32<03:02,  1.35s/it] 72%|███████▏  | 337/471 [07:33<03:00,  1.35s/it] 72%|███████▏  | 338/471 [07:35<02:59,  1.35s/it] 72%|███████▏  | 339/471 [07:36<02:58,  1.35s/it] 72%|███████▏  | 340/471 [07:37<02:57,  1.35s/it] 72%|███████▏  | 341/471 [07:39<02:55,  1.35s/it] 73%|███████▎  | 342/471 [07:40<02:54,  1.35s/it] 73%|███████▎  | 343/471 [07:41<02:53,  1.35s/it] 73%|███████▎  | 344/471 [07:43<02:51,  1.35s/it] 73%|███████▎  | 345/471 [07:44<02:50,  1.35s/it] 73%|███████▎  | 346/471 [07:45<02:48,  1.35s/it] 74%|███████▎  | 347/471 [07:47<02:47,  1.35s/it] 74%|███████▍  | 348/471 [07:48<02:46,  1.35s/it] 74%|███████▍  | 349/471 [07:49<02:44,  1.35s/it] 74%|███████▍  | 350/471 [07:51<02:43,  1.35s/it] 75%|███████▍  | 351/471 [07:52<02:42,  1.35s/it] 75%|███████▍  | 352/471 [07:54<02:40,  1.35s/it] 75%|███████▍  | 353/471 [07:55<02:39,  1.35s/it] 75%|███████▌  | 354/471 [07:56<02:38,  1.35s/it] 75%|███████▌  | 355/471 [07:58<02:37,  1.35s/it] 76%|███████▌  | 356/471 [07:59<02:35,  1.35s/it] 76%|███████▌  | 357/471 [08:00<02:34,  1.35s/it] 76%|███████▌  | 358/471 [08:02<02:32,  1.35s/it] 76%|███████▌  | 359/471 [08:03<02:31,  1.35s/it] 76%|███████▋  | 360/471 [08:04<02:30,  1.35s/it] 77%|███████▋  | 361/471 [08:06<02:28,  1.35s/it] 77%|███████▋  | 362/471 [08:07<02:27,  1.35s/it] 77%|███████▋  | 363/471 [08:08<02:25,  1.35s/it] 77%|███████▋  | 364/471 [08:10<02:24,  1.35s/it] 77%|███████▋  | 365/471 [08:11<02:23,  1.35s/it] 78%|███████▊  | 366/471 [08:13<02:22,  1.36s/it] 78%|███████▊  | 367/471 [08:14<02:20,  1.36s/it] 78%|███████▊  | 368/471 [08:15<02:19,  1.35s/it] 78%|███████▊  | 369/471 [08:17<02:17,  1.35s/it] 79%|███████▊  | 370/471 [08:18<02:16,  1.35s/it] 79%|███████▉  | 371/471 [08:19<02:15,  1.36s/it] 79%|███████▉  | 372/471 [08:21<02:14,  1.36s/it] 79%|███████▉  | 373/471 [08:22<02:12,  1.36s/it] 79%|███████▉  | 374/471 [08:23<02:11,  1.36s/it] 80%|███████▉  | 375/471 [08:25<02:10,  1.35s/it] 80%|███████▉  | 376/471 [08:26<02:08,  1.35s/it] 80%|████████  | 377/471 [08:27<02:07,  1.36s/it] 80%|████████  | 378/471 [08:29<02:05,  1.35s/it] 80%|████████  | 379/471 [08:30<02:04,  1.36s/it] 81%|████████  | 380/471 [08:31<02:03,  1.36s/it] 81%|████████  | 381/471 [08:33<02:02,  1.36s/it] 81%|████████  | 382/471 [08:34<02:00,  1.36s/it] 81%|████████▏ | 383/471 [08:36<01:59,  1.36s/it] 82%|████████▏ | 384/471 [08:37<01:58,  1.36s/it] 82%|████████▏ | 385/471 [08:38<01:56,  1.36s/it] 82%|████████▏ | 386/471 [08:40<01:55,  1.36s/it] 82%|████████▏ | 387/471 [08:41<01:53,  1.36s/it] 82%|████████▏ | 388/471 [08:42<01:52,  1.36s/it] 83%|████████▎ | 389/471 [08:44<01:51,  1.35s/it] 83%|████████▎ | 390/471 [08:45<01:49,  1.36s/it] 83%|████████▎ | 391/471 [08:46<01:48,  1.35s/it] 83%|████████▎ | 392/471 [08:48<01:47,  1.35s/it] 83%|████████▎ | 393/471 [08:49<01:45,  1.35s/it] 84%|████████▎ | 394/471 [08:50<01:44,  1.35s/it] 84%|████████▍ | 395/471 [08:52<01:42,  1.35s/it] 84%|████████▍ | 396/471 [08:53<01:41,  1.35s/it] 84%|████████▍ | 397/471 [08:55<01:40,  1.35s/it] 85%|████████▍ | 398/471 [08:56<01:38,  1.35s/it] 85%|████████▍ | 399/471 [08:57<01:37,  1.35s/it] 85%|████████▍ | 400/471 [08:59<01:36,  1.35s/it] 85%|████████▌ | 401/471 [09:00<01:34,  1.35s/it] 85%|████████▌ | 402/471 [09:01<01:33,  1.35s/it] 86%|████████▌ | 403/471 [09:03<01:31,  1.35s/it] 86%|████████▌ | 404/471 [09:04<01:30,  1.35s/it] 86%|████████▌ | 405/471 [09:05<01:29,  1.35s/it] 86%|████████▌ | 406/471 [09:07<01:27,  1.35s/it] 86%|████████▋ | 407/471 [09:08<01:26,  1.35s/it] 87%|████████▋ | 408/471 [09:09<01:25,  1.35s/it] 87%|████████▋ | 409/471 [09:11<01:23,  1.35s/it] 87%|████████▋ | 410/471 [09:12<01:22,  1.35s/it] 87%|████████▋ | 411/471 [09:13<01:20,  1.35s/it] 87%|████████▋ | 412/471 [09:15<01:19,  1.35s/it] 88%|████████▊ | 413/471 [09:16<01:18,  1.35s/it] 88%|████████▊ | 414/471 [09:17<01:16,  1.35s/it] 88%|████████▊ | 415/471 [09:19<01:15,  1.35s/it] 88%|████████▊ | 416/471 [09:20<01:14,  1.35s/it] 89%|████████▊ | 417/471 [09:22<01:12,  1.35s/it] 89%|████████▊ | 418/471 [09:23<01:11,  1.35s/it] 89%|████████▉ | 419/471 [09:24<01:10,  1.35s/it] 89%|████████▉ | 420/471 [09:26<01:08,  1.35s/it] 89%|████████▉ | 421/471 [09:27<01:07,  1.35s/it] 90%|████████▉ | 422/471 [09:28<01:05,  1.35s/it] 90%|████████▉ | 423/471 [09:30<01:04,  1.34s/it] 90%|█████████ | 424/471 [09:31<01:03,  1.35s/it] 90%|█████████ | 425/471 [09:32<01:01,  1.35s/it] 90%|█████████ | 426/471 [09:34<01:00,  1.35s/it] 91%|█████████ | 427/471 [09:35<00:59,  1.35s/it] 91%|█████████ | 428/471 [09:36<00:57,  1.35s/it] 91%|█████████ | 429/471 [09:38<00:56,  1.35s/it] 91%|█████████▏| 430/471 [09:39<00:55,  1.35s/it] 92%|█████████▏| 431/471 [09:40<00:54,  1.35s/it] 92%|█████████▏| 432/471 [09:42<00:52,  1.35s/it] 92%|█████████▏| 433/471 [09:43<00:51,  1.35s/it] 92%|█████████▏| 434/471 [09:44<00:50,  1.35s/it] 92%|█████████▏| 435/471 [09:46<00:48,  1.35s/it] 93%|█████████▎| 436/471 [09:47<00:47,  1.35s/it] 93%|█████████▎| 437/471 [09:48<00:46,  1.35s/it] 93%|█████████▎| 438/471 [09:50<00:44,  1.35s/it] 93%|█████████▎| 439/471 [09:51<00:43,  1.35s/it] 93%|█████████▎| 440/471 [09:53<00:41,  1.35s/it] 94%|█████████▎| 441/471 [09:54<00:40,  1.35s/it] 94%|█████████▍| 442/471 [09:55<00:39,  1.35s/it] 94%|█████████▍| 443/471 [09:57<00:37,  1.35s/it] 94%|█████████▍| 444/471 [09:58<00:36,  1.35s/it] 94%|█████████▍| 445/471 [09:59<00:35,  1.35s/it] 95%|█████████▍| 446/471 [10:01<00:33,  1.35s/it] 95%|█████████▍| 447/471 [10:02<00:32,  1.35s/it] 95%|█████████▌| 448/471 [10:03<00:31,  1.35s/it] 95%|█████████▌| 449/471 [10:05<00:29,  1.35s/it] 96%|█████████▌| 450/471 [10:06<00:28,  1.35s/it] 96%|█████████▌| 451/471 [10:07<00:27,  1.35s/it] 96%|█████████▌| 452/471 [10:09<00:25,  1.35s/it] 96%|█████████▌| 453/471 [10:10<00:24,  1.35s/it] 96%|█████████▋| 454/471 [10:11<00:22,  1.35s/it] 97%|█████████▋| 455/471 [10:13<00:21,  1.35s/it] 97%|█████████▋| 456/471 [10:14<00:20,  1.35s/it] 97%|█████████▋| 457/471 [10:16<00:18,  1.35s/it] 97%|█████████▋| 458/471 [10:17<00:17,  1.35s/it] 97%|█████████▋| 459/471 [10:18<00:16,  1.35s/it] 98%|█████████▊| 460/471 [10:20<00:14,  1.35s/it] 98%|█████████▊| 461/471 [10:21<00:13,  1.36s/it] 98%|█████████▊| 462/471 [10:22<00:12,  1.36s/it] 98%|█████████▊| 463/471 [10:24<00:10,  1.36s/it] 99%|█████████▊| 464/471 [10:25<00:09,  1.36s/it] 99%|█████████▊| 465/471 [10:26<00:08,  1.35s/it] 99%|█████████▉| 466/471 [10:28<00:06,  1.36s/it] 99%|█████████▉| 467/471 [10:29<00:05,  1.36s/it] 99%|█████████▉| 468/471 [10:30<00:04,  1.36s/it]100%|█████████▉| 469/471 [10:32<00:02,  1.36s/it]100%|█████████▉| 470/471 [10:33<00:01,  1.36s/it]100%|██████████| 471/471 [10:34<00:00,  1.24s/it]100%|██████████| 471/471 [10:34<00:00,  1.35s/it]
{'eval_loss': 3.984027624130249, 'eval_model_preparation_time': 0.0111, 'eval_acc': 0.19437068507700478, 'eval_runtime': 635.9185, 'eval_samples_per_second': 11.844, 'eval_steps_per_second': 0.741}
ROUND:8
CLIENT:2
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:38,  2.52s/it]                                              {'loss': 3.8586, 'grad_norm': 7.151960372924805, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:38,  2.52s/it]  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]                                              {'loss': 3.8029, 'grad_norm': 10.144914627075195, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]  8%|▊         | 3/40 [00:07<01:25,  2.31s/it]                                              {'loss': 2.3124, 'grad_norm': 11.397005081176758, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.31s/it] 10%|█         | 4/40 [00:09<01:22,  2.29s/it]                                              {'loss': 2.8922, 'grad_norm': 12.829347610473633, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.29s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.28s/it]                                              {'loss': 1.6836, 'grad_norm': 9.938485145568848, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.28s/it] 15%|█▌        | 6/40 [00:13<01:17,  2.28s/it]                                              {'loss': 2.657, 'grad_norm': 19.932435989379883, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:17,  2.28s/it] 18%|█▊        | 7/40 [00:16<01:15,  2.28s/it]                                              {'loss': 2.6938, 'grad_norm': 20.90464210510254, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:15,  2.28s/it] 20%|██        | 8/40 [00:16<00:51,  1.62s/it]                                              {'loss': 0.0569, 'grad_norm': 3.02660870552063, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.62s/it] 22%|██▎       | 9/40 [00:18<00:56,  1.82s/it]                                              {'loss': 1.7127, 'grad_norm': 15.299248695373535, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:56,  1.82s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.96s/it]                                               {'loss': 1.5826, 'grad_norm': 15.380053520202637, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.96s/it] 28%|██▊       | 11/40 [00:23<00:59,  2.06s/it]                                               {'loss': 0.5536, 'grad_norm': 6.870498180389404, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:59,  2.06s/it] 30%|███       | 12/40 [00:25<00:59,  2.12s/it]                                               {'loss': 1.0988, 'grad_norm': 7.507321357727051, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:59,  2.12s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.17s/it]                                               {'loss': 1.5731, 'grad_norm': 7.083614826202393, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.17s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.22s/it]                                               {'loss': 0.667, 'grad_norm': 7.117738246917725, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.22s/it] 38%|███▊      | 15/40 [00:32<00:56,  2.24s/it]                                               {'loss': 1.1444, 'grad_norm': 6.233010768890381, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:56,  2.24s/it] 40%|████      | 16/40 [00:32<00:39,  1.64s/it]                                               {'loss': 0.0419, 'grad_norm': 1.8337466716766357, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:39,  1.64s/it] 42%|████▎     | 17/40 [00:35<00:45,  1.96s/it]                                               {'loss': 0.1655, 'grad_norm': 3.5009589195251465, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:35<00:45,  1.96s/it] 45%|████▌     | 18/40 [00:37<00:45,  2.06s/it]                                               {'loss': 0.6585, 'grad_norm': 4.701597690582275, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:37<00:45,  2.06s/it] 48%|████▊     | 19/40 [00:39<00:44,  2.13s/it]                                               {'loss': 0.1753, 'grad_norm': 2.7772488594055176, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:44,  2.13s/it] 50%|█████     | 20/40 [00:42<00:43,  2.19s/it]                                               {'loss': 0.3893, 'grad_norm': 4.400108337402344, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:42<00:43,  2.19s/it] 52%|█████▎    | 21/40 [00:44<00:42,  2.22s/it]                                               {'loss': 0.6703, 'grad_norm': 5.461350440979004, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:44<00:42,  2.22s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.25s/it]                                               {'loss': 0.5091, 'grad_norm': 5.3097076416015625, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.25s/it] 57%|█████▊    | 23/40 [00:49<00:38,  2.28s/it]                                               {'loss': 0.1732, 'grad_norm': 2.836081027984619, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:49<00:38,  2.28s/it] 60%|██████    | 24/40 [00:49<00:26,  1.65s/it]                                               {'loss': 0.0669, 'grad_norm': 3.709460735321045, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:49<00:26,  1.65s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.85s/it]                                               {'loss': 0.21, 'grad_norm': 3.959286689758301, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.85s/it] 65%|██████▌   | 26/40 [00:53<00:28,  2.00s/it]                                               {'loss': 0.1184, 'grad_norm': 6.709843635559082, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:28,  2.00s/it] 68%|██████▊   | 27/40 [00:56<00:27,  2.10s/it]                                               {'loss': 0.0973, 'grad_norm': 2.3277480602264404, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:56<00:27,  2.10s/it] 70%|███████   | 28/40 [00:58<00:25,  2.16s/it]                                               {'loss': 0.092, 'grad_norm': 3.226811408996582, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:58<00:25,  2.16s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.20s/it]                                               {'loss': 0.1133, 'grad_norm': 2.1150550842285156, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.20s/it] 75%|███████▌  | 30/40 [01:03<00:22,  2.25s/it]                                               {'loss': 0.0696, 'grad_norm': 1.2369308471679688, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:03<00:22,  2.25s/it] 78%|███████▊  | 31/40 [01:05<00:20,  2.27s/it]                                               {'loss': 0.3018, 'grad_norm': 4.377779483795166, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:05<00:20,  2.27s/it] 80%|████████  | 32/40 [01:05<00:13,  1.65s/it]                                               {'loss': 0.0128, 'grad_norm': 0.6384387016296387, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.65s/it] 82%|████████▎ | 33/40 [01:08<00:12,  1.86s/it]                                               {'loss': 0.0291, 'grad_norm': 0.6800147294998169, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:08<00:12,  1.86s/it] 85%|████████▌ | 34/40 [01:10<00:11,  1.99s/it]                                               {'loss': 0.0931, 'grad_norm': 2.835550308227539, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:10<00:11,  1.99s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.10s/it]                                               {'loss': 0.0254, 'grad_norm': 0.7090454697608948, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.10s/it] 90%|█████████ | 36/40 [01:15<00:08,  2.17s/it]                                               {'loss': 0.0633, 'grad_norm': 1.7525999546051025, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:15<00:08,  2.17s/it] 92%|█████████▎| 37/40 [01:17<00:06,  2.21s/it]                                               {'loss': 0.0325, 'grad_norm': 0.6802695393562317, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:17<00:06,  2.21s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.25s/it]                                               {'loss': 0.0872, 'grad_norm': 3.2173147201538086, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.25s/it] 98%|█████████▊| 39/40 [01:22<00:02,  2.29s/it]                                               {'loss': 0.0253, 'grad_norm': 0.44218313694000244, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:22<00:02,  2.29s/it]100%|██████████| 40/40 [01:22<00:00,  1.65s/it]                                               {'loss': 0.9072, 'grad_norm': 74.59815216064453, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.65s/it]                                               {'train_runtime': 82.5666, 'train_samples_per_second': 6.843, 'train_steps_per_second': 0.484, 'train_loss': 0.8354435560526327, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.65s/it]100%|██████████| 40/40 [01:22<00:00,  2.06s/it]
CLIENT:49
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:45,  2.70s/it]                                              {'loss': 5.8746, 'grad_norm': 12.020076751708984, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:45,  2.70s/it]  5%|▌         | 2/40 [00:04<01:31,  2.42s/it]                                              {'loss': 3.2112, 'grad_norm': 7.461577892303467, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:31,  2.42s/it]  8%|▊         | 3/40 [00:07<01:25,  2.32s/it]                                              {'loss': 2.8022, 'grad_norm': 10.231035232543945, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.32s/it] 10%|█         | 4/40 [00:09<01:22,  2.28s/it]                                              {'loss': 1.4441, 'grad_norm': 8.986099243164062, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.28s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it]                                              {'loss': 1.9794, 'grad_norm': 10.853110313415527, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it] 15%|█▌        | 6/40 [00:13<01:17,  2.27s/it]                                              {'loss': 3.5438, 'grad_norm': 17.239315032958984, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:17,  2.27s/it] 18%|█▊        | 7/40 [00:16<01:15,  2.28s/it]                                              {'loss': 2.7367, 'grad_norm': 17.606538772583008, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:15,  2.28s/it] 20%|██        | 8/40 [00:16<00:51,  1.61s/it]                                              {'loss': 0.7375, 'grad_norm': 93.66378021240234, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.61s/it] 22%|██▎       | 9/40 [00:18<00:56,  1.82s/it]                                              {'loss': 1.2683, 'grad_norm': 9.755322456359863, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:56,  1.82s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.95s/it]                                               {'loss': 0.7483, 'grad_norm': 9.909656524658203, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.95s/it] 28%|██▊       | 11/40 [00:23<00:59,  2.04s/it]                                               {'loss': 1.0256, 'grad_norm': 18.16046905517578, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:59,  2.04s/it] 30%|███       | 12/40 [00:25<00:58,  2.11s/it]                                               {'loss': 0.5726, 'grad_norm': 9.585800170898438, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.11s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 1.4252, 'grad_norm': 16.04792022705078, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 0.9274, 'grad_norm': 7.170196056365967, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:32<00:55,  2.20s/it]                                               {'loss': 0.1891, 'grad_norm': 2.4281957149505615, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:55,  2.20s/it] 40%|████      | 16/40 [00:32<00:38,  1.60s/it]                                               {'loss': 0.0099, 'grad_norm': 0.5148059725761414, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it]                                               {'loss': 0.0984, 'grad_norm': 2.4676268100738525, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 0.5058, 'grad_norm': 2.8346283435821533, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:39<00:42,  2.03s/it]                                               {'loss': 0.9289, 'grad_norm': 3.610335111618042, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:42,  2.03s/it] 50%|█████     | 20/40 [00:41<00:42,  2.11s/it]                                               {'loss': 0.1142, 'grad_norm': 3.041123867034912, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 0.2913, 'grad_norm': 2.411966562271118, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.2154, 'grad_norm': 3.2931456565856934, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it]                                               {'loss': 0.3591, 'grad_norm': 6.547985553741455, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it] 60%|██████    | 24/40 [00:48<00:25,  1.62s/it]                                               {'loss': 0.0247, 'grad_norm': 1.394845724105835, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.6675, 'grad_norm': 5.244168758392334, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.0262, 'grad_norm': 0.8947064876556396, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.04s/it]                                               {'loss': 0.7801, 'grad_norm': 2.6284091472625732, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.04s/it] 70%|███████   | 28/40 [00:57<00:25,  2.13s/it]                                               {'loss': 0.0354, 'grad_norm': 0.8838525414466858, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.13s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.3221, 'grad_norm': 12.71254825592041, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.22s/it]                                               {'loss': 0.0674, 'grad_norm': 1.6608809232711792, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.22s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it]                                               {'loss': 0.3129, 'grad_norm': 3.670530080795288, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it] 80%|████████  | 32/40 [01:04<00:13,  1.63s/it]                                               {'loss': 0.0062, 'grad_norm': 0.3214680254459381, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it]                                               {'loss': 0.0368, 'grad_norm': 1.5398800373077393, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.98s/it]                                               {'loss': 0.3712, 'grad_norm': 5.0174336433410645, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.98s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it]                                               {'loss': 0.1023, 'grad_norm': 3.521250009536743, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it]                                               {'loss': 1.1948, 'grad_norm': 9.933023452758789, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.20s/it]                                               {'loss': 1.1896, 'grad_norm': 5.245998859405518, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.20s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.23s/it]                                               {'loss': 0.2174, 'grad_norm': 12.82709789276123, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.23s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.26s/it]                                               {'loss': 0.6324, 'grad_norm': 7.434340000152588, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.26s/it]100%|██████████| 40/40 [01:21<00:00,  1.63s/it]                                               {'loss': 0.0832, 'grad_norm': 7.938159942626953, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.63s/it]                                               {'train_runtime': 81.2868, 'train_samples_per_second': 6.951, 'train_steps_per_second': 0.492, 'train_loss': 0.926979175012093, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.63s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
CLIENT:82
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:03<01:58,  3.03s/it]                                              {'loss': 5.1466, 'grad_norm': 6.747913360595703, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:03<01:58,  3.03s/it]  5%|▌         | 2/40 [00:05<01:35,  2.52s/it]                                              {'loss': 3.4553, 'grad_norm': 7.0973639488220215, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:35,  2.52s/it]  8%|▊         | 3/40 [00:07<01:27,  2.37s/it]                                              {'loss': 2.5375, 'grad_norm': 9.627432823181152, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:27,  2.37s/it] 10%|█         | 4/40 [00:09<01:22,  2.30s/it]                                              {'loss': 3.8022, 'grad_norm': 16.696876525878906, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.30s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it]                                              {'loss': 2.4956, 'grad_norm': 16.37369155883789, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 2.6879, 'grad_norm': 25.813255310058594, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:16<01:13,  2.24s/it]                                              {'loss': 2.4393, 'grad_norm': 16.473539352416992, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:13,  2.24s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 0.1632, 'grad_norm': 10.399310111999512, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 0.7528, 'grad_norm': 8.67466926574707, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it]                                               {'loss': 0.3758, 'grad_norm': 3.7670540809631348, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:23<00:58,  2.01s/it]                                               {'loss': 0.3793, 'grad_norm': 3.4548866748809814, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:58,  2.01s/it] 30%|███       | 12/40 [00:25<00:58,  2.08s/it]                                               {'loss': 0.9599, 'grad_norm': 7.307031631469727, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it]                                               {'loss': 1.3238, 'grad_norm': 8.318249702453613, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 1.8634, 'grad_norm': 9.942468643188477, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 1.1968, 'grad_norm': 7.999842643737793, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:32<00:37,  1.58s/it]                                               {'loss': 3.8256, 'grad_norm': 11.716588020324707, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.1924, 'grad_norm': 3.118851900100708, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it]                                               {'loss': 0.244, 'grad_norm': 2.4690704345703125, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it]                                               {'loss': 0.5204, 'grad_norm': 3.324052095413208, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it] 50%|█████     | 20/40 [00:41<00:42,  2.11s/it]                                               {'loss': 0.5625, 'grad_norm': 10.384238243103027, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 1.2217, 'grad_norm': 11.623190879821777, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.6069, 'grad_norm': 6.264760494232178, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.20s/it]                                               {'loss': 0.3919, 'grad_norm': 2.692945957183838, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.20s/it] 60%|██████    | 24/40 [00:48<00:25,  1.59s/it]                                               {'loss': 0.0549, 'grad_norm': 4.940364360809326, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.78s/it]                                               {'loss': 0.4429, 'grad_norm': 4.758738994598389, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.93s/it]                                               {'loss': 0.5071, 'grad_norm': 4.005871295928955, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.0842, 'grad_norm': 1.6003503799438477, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.0512, 'grad_norm': 0.8686267733573914, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.8808, 'grad_norm': 2.4936413764953613, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.2395, 'grad_norm': 3.1672885417938232, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it]                                               {'loss': 0.1591, 'grad_norm': 3.3654279708862305, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it] 80%|████████  | 32/40 [01:04<00:12,  1.60s/it]                                               {'loss': 0.0067, 'grad_norm': 0.27559491991996765, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.0679, 'grad_norm': 2.9965405464172363, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.1221, 'grad_norm': 4.624992370605469, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it]                                               {'loss': 0.2544, 'grad_norm': 1.2436256408691406, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it]                                               {'loss': 0.0393, 'grad_norm': 1.5242184400558472, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.4948, 'grad_norm': 4.338569641113281, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.2509, 'grad_norm': 4.2782745361328125, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.21s/it]                                               {'loss': 0.6869, 'grad_norm': 4.956843376159668, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.21s/it]100%|██████████| 40/40 [01:20<00:00,  1.60s/it]                                               {'loss': 0.0118, 'grad_norm': 0.7643580436706543, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.60s/it]                                               {'train_runtime': 80.6349, 'train_samples_per_second': 7.007, 'train_steps_per_second': 0.496, 'train_loss': 1.0374767151777633, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.60s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.68s/it]                                              {'loss': 3.5319, 'grad_norm': 5.805530548095703, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.68s/it]  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]                                              {'loss': 3.2258, 'grad_norm': 7.504659175872803, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]  8%|▊         | 3/40 [00:07<01:25,  2.31s/it]                                              {'loss': 3.1402, 'grad_norm': 9.711640357971191, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.31s/it] 10%|█         | 4/40 [00:09<01:21,  2.27s/it]                                              {'loss': 4.2495, 'grad_norm': 11.392925262451172, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.27s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 4.5754, 'grad_norm': 60.11874008178711, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 3.5828, 'grad_norm': 14.58709716796875, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it]                                              {'loss': 3.2861, 'grad_norm': 13.460569381713867, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 3.1012, 'grad_norm': 28.38578224182129, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 1.193, 'grad_norm': 8.57796573638916, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 1.0405, 'grad_norm': 20.378244400024414, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.7054, 'grad_norm': 6.644864082336426, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:25<00:58,  2.09s/it]                                               {'loss': 0.8646, 'grad_norm': 11.247989654541016, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.15s/it]                                               {'loss': 0.9975, 'grad_norm': 8.571954727172852, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.15s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 1.4586, 'grad_norm': 10.78738784790039, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it]                                               {'loss': 0.9952, 'grad_norm': 7.212855339050293, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it] 40%|████      | 16/40 [00:32<00:38,  1.60s/it]                                               {'loss': 0.0053, 'grad_norm': 0.2230624109506607, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it]                                               {'loss': 0.2971, 'grad_norm': 4.044809341430664, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 1.1999, 'grad_norm': 7.775590896606445, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.5236, 'grad_norm': 8.866962432861328, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:41<00:42,  2.12s/it]                                               {'loss': 0.1575, 'grad_norm': 4.785926818847656, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 0.2375, 'grad_norm': 4.006771564483643, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 0.2019, 'grad_norm': 3.0382933616638184, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it]                                               {'loss': 0.2271, 'grad_norm': 3.265211820602417, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it] 60%|██████    | 24/40 [00:48<00:25,  1.62s/it]                                               {'loss': 0.2542, 'grad_norm': 8.03530502319336, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it]                                               {'loss': 0.1667, 'grad_norm': 3.5716617107391357, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.98s/it]                                               {'loss': 0.0358, 'grad_norm': 1.520198941230774, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.98s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.07s/it]                                               {'loss': 0.2044, 'grad_norm': 4.203206539154053, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.07s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 1.0396, 'grad_norm': 5.466055393218994, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.18s/it]                                               {'loss': 0.158, 'grad_norm': 2.780532121658325, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.18s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.22s/it]                                               {'loss': 0.232, 'grad_norm': 4.402681827545166, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.22s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it]                                               {'loss': 0.1644, 'grad_norm': 3.494056463241577, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it] 80%|████████  | 32/40 [01:04<00:13,  1.63s/it]                                               {'loss': 0.0185, 'grad_norm': 1.220226526260376, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it]                                               {'loss': 0.0358, 'grad_norm': 0.8213695287704468, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.97s/it]                                               {'loss': 0.4573, 'grad_norm': 3.966338872909546, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it]                                               {'loss': 0.0847, 'grad_norm': 2.4660444259643555, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it]                                               {'loss': 0.0753, 'grad_norm': 1.4736604690551758, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.21s/it]                                               {'loss': 0.113, 'grad_norm': 3.0503807067871094, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.21s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.24s/it]                                               {'loss': 0.1855, 'grad_norm': 3.8649730682373047, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.24s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.27s/it]                                               {'loss': 0.0487, 'grad_norm': 0.8000141382217407, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.27s/it]100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'loss': 0.2886, 'grad_norm': 11.130059242248535, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'train_runtime': 81.2782, 'train_samples_per_second': 6.951, 'train_steps_per_second': 0.492, 'train_loss': 1.0590055438457058, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.65s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:39,  2.55s/it]                                              {'loss': 3.7802, 'grad_norm': 7.994566440582275, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:39,  2.55s/it]  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]                                              {'loss': 3.4022, 'grad_norm': 8.929481506347656, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]  8%|▊         | 3/40 [00:06<01:24,  2.28s/it]                                              {'loss': 1.8408, 'grad_norm': 9.717000007629395, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 4.2114, 'grad_norm': 29.08672332763672, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 1.6589, 'grad_norm': 10.525336265563965, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.6484, 'grad_norm': 16.634830474853516, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 3.1817, 'grad_norm': 12.37529182434082, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 0.0644, 'grad_norm': 4.123204708099365, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 0.6803, 'grad_norm': 6.516198635101318, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.5459, 'grad_norm': 6.361403465270996, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 1.1698, 'grad_norm': 10.662908554077148, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.7699, 'grad_norm': 6.337396144866943, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 1.2169, 'grad_norm': 6.08077335357666, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 0.5756, 'grad_norm': 6.4576005935668945, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it]                                               {'loss': 1.0564, 'grad_norm': 8.651398658752441, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.864, 'grad_norm': 37.02633285522461, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.3006, 'grad_norm': 5.550281524658203, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it]                                               {'loss': 0.4779, 'grad_norm': 10.15568733215332, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.5995, 'grad_norm': 6.537752628326416, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.6563, 'grad_norm': 7.323139190673828, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.1921, 'grad_norm': 1.7218602895736694, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.17s/it]                                               {'loss': 0.3675, 'grad_norm': 5.943697452545166, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.2611, 'grad_norm': 4.228511333465576, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.057, 'grad_norm': 4.623320579528809, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.699, 'grad_norm': 8.501057624816895, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it]                                               {'loss': 0.0596, 'grad_norm': 1.2698743343353271, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it]                                               {'loss': 0.546, 'grad_norm': 3.625124931335449, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.044, 'grad_norm': 0.9212726354598999, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.4846, 'grad_norm': 6.2377471923828125, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.0485, 'grad_norm': 1.1940956115722656, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it]                                               {'loss': 0.0605, 'grad_norm': 2.2425124645233154, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.0715, 'grad_norm': 3.5342445373535156, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it]                                               {'loss': 0.0104, 'grad_norm': 0.18400511145591736, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.0137, 'grad_norm': 0.35197383165359497, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.0766, 'grad_norm': 0.8873150944709778, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.0117, 'grad_norm': 0.2816970646381378, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it]                                               {'loss': 0.0743, 'grad_norm': 1.3124909400939941, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.2907, 'grad_norm': 3.308720827102661, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 1.3347, 'grad_norm': 15.965095520019531, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0057, 'grad_norm': 0.3140996992588043, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.0513, 'train_samples_per_second': 7.058, 'train_steps_per_second': 0.5, 'train_loss': 0.8602643759688362, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:12
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:03<02:34,  3.97s/it]                                              {'loss': 3.436, 'grad_norm': 6.529163837432861, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:03<02:34,  3.97s/it]  5%|▌         | 2/40 [00:06<01:49,  2.88s/it]                                              {'loss': 5.3411, 'grad_norm': 11.72035026550293, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:06<01:49,  2.88s/it]  8%|▊         | 3/40 [00:08<01:35,  2.57s/it]                                              {'loss': 2.8032, 'grad_norm': 10.142192840576172, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:08<01:35,  2.57s/it] 10%|█         | 4/40 [00:10<01:27,  2.42s/it]                                              {'loss': 2.4071, 'grad_norm': 13.585086822509766, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:10<01:27,  2.42s/it] 12%|█▎        | 5/40 [00:12<01:21,  2.33s/it]                                              {'loss': 2.4796, 'grad_norm': 15.668885231018066, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:12<01:21,  2.33s/it] 15%|█▌        | 6/40 [00:14<01:17,  2.27s/it]                                              {'loss': 2.2701, 'grad_norm': 12.390896797180176, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:14<01:17,  2.27s/it] 18%|█▊        | 7/40 [00:17<01:14,  2.26s/it]                                              {'loss': 3.2516, 'grad_norm': 13.28553581237793, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:17<01:14,  2.26s/it] 20%|██        | 8/40 [00:17<00:51,  1.60s/it]                                              {'loss': 4.873, 'grad_norm': 52.181793212890625, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:17<00:51,  1.60s/it] 22%|██▎       | 9/40 [00:19<00:55,  1.78s/it]                                              {'loss': 1.0928, 'grad_norm': 14.434428215026855, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:19<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:21<00:57,  1.91s/it]                                               {'loss': 1.3144, 'grad_norm': 8.90705394744873, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:21<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:23<00:58,  2.00s/it]                                               {'loss': 0.4796, 'grad_norm': 7.146604061126709, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:58,  2.00s/it] 30%|███       | 12/40 [00:26<00:58,  2.07s/it]                                               {'loss': 0.8701, 'grad_norm': 303.9541931152344, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:26<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:28<00:57,  2.12s/it]                                               {'loss': 1.134, 'grad_norm': 6.969106674194336, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:28<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:30<00:56,  2.16s/it]                                               {'loss': 0.689, 'grad_norm': 48.788787841796875, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:30<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:32<00:54,  2.19s/it]                                               {'loss': 0.3135, 'grad_norm': 4.935286998748779, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:54,  2.19s/it] 40%|████      | 16/40 [00:32<00:38,  1.59s/it]                                               {'loss': 0.5155, 'grad_norm': 13.581670761108398, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:35<00:41,  1.78s/it]                                               {'loss': 0.4904, 'grad_norm': 4.773458003997803, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:35<00:41,  1.78s/it] 45%|████▌     | 18/40 [00:37<00:42,  1.93s/it]                                               {'loss': 0.1236, 'grad_norm': 1.9527400732040405, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:37<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:39<00:42,  2.02s/it]                                               {'loss': 0.5528, 'grad_norm': 2.3697502613067627, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:42,  2.02s/it] 50%|█████     | 20/40 [00:41<00:41,  2.08s/it]                                               {'loss': 0.7025, 'grad_norm': 4.383874416351318, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:44<00:40,  2.12s/it]                                               {'loss': 0.3253, 'grad_norm': 4.371543884277344, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:44<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:46<00:39,  2.17s/it]                                               {'loss': 0.1972, 'grad_norm': 2.4884228706359863, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.21s/it]                                               {'loss': 0.9596, 'grad_norm': 8.771730422973633, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.21s/it] 60%|██████    | 24/40 [00:48<00:25,  1.60s/it]                                               {'loss': 4.0129, 'grad_norm': 84.23246002197266, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.81s/it]                                               {'loss': 0.0952, 'grad_norm': 2.6146509647369385, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.94s/it]                                               {'loss': 0.0378, 'grad_norm': 0.7635786533355713, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.04s/it]                                               {'loss': 0.1964, 'grad_norm': 2.327860116958618, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.04s/it] 70%|███████   | 28/40 [00:57<00:25,  2.11s/it]                                               {'loss': 0.1756, 'grad_norm': 1.591005802154541, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.11s/it] 72%|███████▎  | 29/40 [01:00<00:23,  2.15s/it]                                               {'loss': 0.2487, 'grad_norm': 2.025275945663452, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:02<00:21,  2.18s/it]                                               {'loss': 0.1925, 'grad_norm': 2.37734055519104, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.22s/it]                                               {'loss': 0.2306, 'grad_norm': 6.295940399169922, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.22s/it] 80%|████████  | 32/40 [01:04<00:12,  1.61s/it]                                               {'loss': 0.458, 'grad_norm': 35.33680725097656, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:07<00:12,  1.81s/it]                                               {'loss': 0.072, 'grad_norm': 1.874485731124878, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.95s/it]                                               {'loss': 0.0122, 'grad_norm': 0.1922607421875, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it]                                               {'loss': 0.0473, 'grad_norm': 0.9172162413597107, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.14s/it]                                               {'loss': 0.1223, 'grad_norm': 3.1483328342437744, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.19s/it]                                               {'loss': 0.2305, 'grad_norm': 2.6955697536468506, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.19s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.21s/it]                                               {'loss': 0.334, 'grad_norm': 8.658520698547363, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.23s/it]                                               {'loss': 0.3027, 'grad_norm': 15.170576095581055, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.23s/it]100%|██████████| 40/40 [01:21<00:00,  1.62s/it]                                               {'loss': 0.2453, 'grad_norm': 43.055091857910156, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.62s/it]                                               {'train_runtime': 81.5123, 'train_samples_per_second': 6.931, 'train_steps_per_second': 0.491, 'train_loss': 1.0908976132515817, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.62s/it]100%|██████████| 40/40 [01:21<00:00,  2.04s/it]
CLIENT:87
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]                                              {'loss': 5.3458, 'grad_norm': 7.746842384338379, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]  5%|▌         | 2/40 [00:04<01:30,  2.39s/it]                                              {'loss': 2.5159, 'grad_norm': 6.86860466003418, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.39s/it]  8%|▊         | 3/40 [00:07<01:25,  2.31s/it]                                              {'loss': 2.1318, 'grad_norm': 9.170870780944824, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.31s/it] 10%|█         | 4/40 [00:09<01:22,  2.29s/it]                                              {'loss': 2.061, 'grad_norm': 12.382286071777344, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.29s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.26s/it]                                              {'loss': 3.1341, 'grad_norm': 24.896728515625, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.26s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it]                                              {'loss': 2.7925, 'grad_norm': 17.58598518371582, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it] 18%|█▊        | 7/40 [00:16<01:14,  2.25s/it]                                              {'loss': 2.94, 'grad_norm': 20.18638801574707, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:14,  2.25s/it] 20%|██        | 8/40 [00:16<00:50,  1.59s/it]                                              {'loss': 1.6575, 'grad_norm': 48.526187896728516, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:56,  1.81s/it]                                              {'loss': 1.1261, 'grad_norm': 8.581018447875977, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:56,  1.81s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.95s/it]                                               {'loss': 0.9177, 'grad_norm': 9.496891975402832, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.95s/it] 28%|██▊       | 11/40 [00:23<00:59,  2.04s/it]                                               {'loss': 1.1035, 'grad_norm': 7.765803337097168, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:59,  2.04s/it] 30%|███       | 12/40 [00:25<00:58,  2.09s/it]                                               {'loss': 1.0133, 'grad_norm': 5.3355913162231445, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.15s/it]                                               {'loss': 0.6898, 'grad_norm': 4.961923599243164, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.15s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 1.3294, 'grad_norm': 6.002346038818359, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:32<00:55,  2.22s/it]                                               {'loss': 0.8959, 'grad_norm': 7.2934136390686035, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:55,  2.22s/it] 40%|████      | 16/40 [00:32<00:38,  1.61s/it]                                               {'loss': 0.0407, 'grad_norm': 1.8240617513656616, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.61s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.82s/it]                                               {'loss': 0.1489, 'grad_norm': 2.8130385875701904, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.82s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it]                                               {'loss': 0.1756, 'grad_norm': 3.2993204593658447, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.05s/it]                                               {'loss': 0.33, 'grad_norm': 3.0609309673309326, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.05s/it] 50%|█████     | 20/40 [00:41<00:42,  2.13s/it]                                               {'loss': 0.0559, 'grad_norm': 0.9001967906951904, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.13s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 0.3234, 'grad_norm': 2.2608323097229004, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 0.2717, 'grad_norm': 6.660549640655518, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it]                                               {'loss': 0.2046, 'grad_norm': 3.5740907192230225, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it] 60%|██████    | 24/40 [00:48<00:25,  1.62s/it]                                               {'loss': 0.0044, 'grad_norm': 0.18831904232501984, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it]                                               {'loss': 0.0388, 'grad_norm': 0.7116460800170898, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.96s/it]                                               {'loss': 0.0215, 'grad_norm': 0.4004320502281189, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.06s/it]                                               {'loss': 0.0337, 'grad_norm': 0.6118140816688538, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.06s/it] 70%|███████   | 28/40 [00:57<00:25,  2.14s/it]                                               {'loss': 0.1344, 'grad_norm': 3.9885146617889404, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.18s/it]                                               {'loss': 0.1623, 'grad_norm': 1.0840282440185547, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.18s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.23s/it]                                               {'loss': 0.0079, 'grad_norm': 0.16306062042713165, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.23s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it]                                               {'loss': 0.1657, 'grad_norm': 1.5695726871490479, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it] 80%|████████  | 32/40 [01:04<00:13,  1.63s/it]                                               {'loss': 0.0471, 'grad_norm': 2.1623504161834717, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:07<00:12,  1.83s/it]                                               {'loss': 0.0209, 'grad_norm': 0.5484487414360046, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:12,  1.83s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.98s/it]                                               {'loss': 0.0164, 'grad_norm': 0.3678935468196869, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.98s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it]                                               {'loss': 0.0091, 'grad_norm': 0.21606700122356415, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it]                                               {'loss': 0.0323, 'grad_norm': 1.0912792682647705, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.20s/it]                                               {'loss': 0.0093, 'grad_norm': 0.2831100821495056, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.20s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.22s/it]                                               {'loss': 0.0168, 'grad_norm': 0.43181654810905457, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.22s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.26s/it]                                               {'loss': 0.0222, 'grad_norm': 0.48586568236351013, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.26s/it]100%|██████████| 40/40 [01:21<00:00,  1.64s/it]                                               {'loss': 0.0705, 'grad_norm': 3.4514973163604736, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.64s/it]                                               {'train_runtime': 81.4006, 'train_samples_per_second': 6.941, 'train_steps_per_second': 0.491, 'train_loss': 0.800463190395385, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.64s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:31,  2.36s/it]                                              {'loss': 3.0167, 'grad_norm': 7.028248310089111, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:31,  2.36s/it]  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]                                              {'loss': 2.8786, 'grad_norm': 7.943634986877441, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]  8%|▊         | 3/40 [00:06<01:22,  2.23s/it]                                              {'loss': 2.3889, 'grad_norm': 10.787154197692871, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.23s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 4.3237, 'grad_norm': 13.840096473693848, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 2.3611, 'grad_norm': 12.452223777770996, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 2.9215, 'grad_norm': 13.996475219726562, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 1.866, 'grad_norm': 13.024799346923828, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 4.0634, 'grad_norm': 57.76125717163086, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 0.9255, 'grad_norm': 10.950763702392578, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.082, 'grad_norm': 10.70763111114502, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.6093, 'grad_norm': 6.2432475090026855, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.9426, 'grad_norm': 6.804068088531494, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 1.1266, 'grad_norm': 7.517568588256836, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 0.5691, 'grad_norm': 5.083824157714844, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 1.1367, 'grad_norm': 10.90017318725586, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.2419, 'grad_norm': 11.525542259216309, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.2466, 'grad_norm': 7.369515895843506, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.3661, 'grad_norm': 4.9640278816223145, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it]                                               {'loss': 0.4649, 'grad_norm': 45.187965393066406, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.8821, 'grad_norm': 28.93017578125, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.363, 'grad_norm': 5.393344879150391, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it]                                               {'loss': 0.3649, 'grad_norm': 6.189765930175781, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.5996, 'grad_norm': 7.584764003753662, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.0126, 'grad_norm': 0.577663004398346, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.84s/it]                                               {'loss': 0.0992, 'grad_norm': 4.253846645355225, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.84s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.3771, 'grad_norm': 3.7862396240234375, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.1408, 'grad_norm': 4.798311710357666, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.2772, 'grad_norm': 12.77930736541748, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.17s/it]                                               {'loss': 0.0801, 'grad_norm': 2.667052745819092, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it]                                               {'loss': 0.117, 'grad_norm': 2.5166256427764893, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.4574, 'grad_norm': 12.686939239501953, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.0956, 'grad_norm': 4.839798927307129, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it]                                               {'loss': 0.3807, 'grad_norm': 10.233890533447266, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.3421, 'grad_norm': 11.63180923461914, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.0777, 'grad_norm': 1.576386570930481, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.1715, 'grad_norm': 2.3961117267608643, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.0402, 'grad_norm': 1.2790719270706177, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.2786, 'grad_norm': 2.511347770690918, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]                                               {'loss': 0.0876, 'grad_norm': 2.260658025741577, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.0686, 'grad_norm': 4.901613712310791, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 80.0784, 'train_samples_per_second': 7.056, 'train_steps_per_second': 0.5, 'train_loss': 0.9211245862301439, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:99
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:56,  2.98s/it]                                              {'loss': 5.0488, 'grad_norm': 7.114015579223633, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:56,  2.98s/it]  5%|▌         | 2/40 [00:05<01:34,  2.49s/it]                                              {'loss': 3.8245, 'grad_norm': 7.5416107177734375, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:34,  2.49s/it]  8%|▊         | 3/40 [00:07<01:27,  2.35s/it]                                              {'loss': 2.3591, 'grad_norm': 10.477238655090332, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:27,  2.35s/it] 10%|█         | 4/40 [00:09<01:22,  2.30s/it]                                              {'loss': 3.6458, 'grad_norm': 12.383172035217285, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.30s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it]                                              {'loss': 3.2796, 'grad_norm': 11.694014549255371, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.5647, 'grad_norm': 11.148491859436035, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:16<01:13,  2.22s/it]                                              {'loss': 2.1611, 'grad_norm': 10.924134254455566, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:13,  2.22s/it] 20%|██        | 8/40 [00:18<01:11,  2.24s/it]                                              {'loss': 2.5136, 'grad_norm': 13.53635311126709, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:18<01:11,  2.24s/it] 22%|██▎       | 9/40 [00:20<01:08,  2.22s/it]                                              {'loss': 1.5353, 'grad_norm': 9.434943199157715, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:20<01:08,  2.22s/it] 25%|██▌       | 10/40 [00:22<01:06,  2.21s/it]                                               {'loss': 0.9905, 'grad_norm': 9.469433784484863, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:22<01:06,  2.21s/it] 28%|██▊       | 11/40 [00:25<01:04,  2.23s/it]                                               {'loss': 0.4513, 'grad_norm': 4.777296543121338, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:25<01:04,  2.23s/it] 30%|███       | 12/40 [00:27<01:02,  2.23s/it]                                               {'loss': 0.4519, 'grad_norm': 6.578460216522217, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:27<01:02,  2.23s/it] 32%|███▎      | 13/40 [00:29<01:00,  2.22s/it]                                               {'loss': 1.0713, 'grad_norm': 6.055459976196289, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:29<01:00,  2.22s/it] 35%|███▌      | 14/40 [00:31<00:58,  2.24s/it]                                               {'loss': 0.6885, 'grad_norm': 5.069974422454834, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:31<00:58,  2.24s/it] 38%|███▊      | 15/40 [00:33<00:56,  2.24s/it]                                               {'loss': 1.3238, 'grad_norm': 6.581947326660156, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:33<00:56,  2.24s/it] 40%|████      | 16/40 [00:36<00:52,  2.21s/it]                                               {'loss': 0.5949, 'grad_norm': 5.704820156097412, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:36<00:52,  2.21s/it] 42%|████▎     | 17/40 [00:38<00:50,  2.21s/it]                                               {'loss': 0.1554, 'grad_norm': 2.2929131984710693, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:38<00:50,  2.21s/it] 45%|████▌     | 18/40 [00:40<00:49,  2.24s/it]                                               {'loss': 0.0917, 'grad_norm': 1.0272936820983887, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:40<00:49,  2.24s/it] 48%|████▊     | 19/40 [00:42<00:47,  2.25s/it]                                               {'loss': 0.0999, 'grad_norm': 2.448490619659424, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:42<00:47,  2.25s/it] 50%|█████     | 20/40 [00:45<00:44,  2.25s/it]                                               {'loss': 0.6672, 'grad_norm': 5.612653732299805, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:45<00:44,  2.25s/it] 52%|█████▎    | 21/40 [00:47<00:43,  2.26s/it]                                               {'loss': 0.2478, 'grad_norm': 4.5369462966918945, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:47<00:43,  2.26s/it] 55%|█████▌    | 22/40 [00:49<00:40,  2.27s/it]                                               {'loss': 0.4584, 'grad_norm': 4.095209121704102, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:49<00:40,  2.27s/it] 57%|█████▊    | 23/40 [00:52<00:38,  2.28s/it]                                               {'loss': 0.5066, 'grad_norm': 5.4315690994262695, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:52<00:38,  2.28s/it] 60%|██████    | 24/40 [00:54<00:35,  2.23s/it]                                               {'loss': 0.384, 'grad_norm': 3.7302823066711426, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:54<00:35,  2.23s/it] 62%|██████▎   | 25/40 [00:56<00:33,  2.25s/it]                                               {'loss': 0.4166, 'grad_norm': 4.808935642242432, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:56<00:33,  2.25s/it] 65%|██████▌   | 26/40 [00:58<00:31,  2.27s/it]                                               {'loss': 0.2083, 'grad_norm': 1.8006476163864136, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:58<00:31,  2.27s/it] 68%|██████▊   | 27/40 [01:01<00:29,  2.27s/it]                                               {'loss': 0.4053, 'grad_norm': 6.067351341247559, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [01:01<00:29,  2.27s/it] 70%|███████   | 28/40 [01:03<00:27,  2.27s/it]                                               {'loss': 0.3832, 'grad_norm': 6.545303821563721, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [01:03<00:27,  2.27s/it] 72%|███████▎  | 29/40 [01:05<00:25,  2.29s/it]                                               {'loss': 0.2331, 'grad_norm': 4.868465423583984, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:05<00:25,  2.29s/it] 75%|███████▌  | 30/40 [01:07<00:22,  2.29s/it]                                               {'loss': 0.2569, 'grad_norm': 5.6158576011657715, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:07<00:22,  2.29s/it] 78%|███████▊  | 31/40 [01:10<00:20,  2.28s/it]                                               {'loss': 0.0534, 'grad_norm': 2.4918742179870605, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:10<00:20,  2.28s/it] 80%|████████  | 32/40 [01:12<00:17,  2.24s/it]                                               {'loss': 0.1189, 'grad_norm': 2.3585426807403564, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:12<00:17,  2.24s/it] 82%|████████▎ | 33/40 [01:14<00:15,  2.27s/it]                                               {'loss': 0.0438, 'grad_norm': 0.9002140164375305, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:14<00:15,  2.27s/it] 85%|████████▌ | 34/40 [01:16<00:13,  2.28s/it]                                               {'loss': 0.146, 'grad_norm': 2.983938694000244, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:16<00:13,  2.28s/it] 88%|████████▊ | 35/40 [01:19<00:11,  2.29s/it]                                               {'loss': 0.022, 'grad_norm': 0.30365222692489624, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:19<00:11,  2.29s/it] 90%|█████████ | 36/40 [01:21<00:09,  2.30s/it]                                               {'loss': 0.0533, 'grad_norm': 1.1510307788848877, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:21<00:09,  2.30s/it] 92%|█████████▎| 37/40 [01:23<00:06,  2.28s/it]                                               {'loss': 0.0895, 'grad_norm': 1.1640706062316895, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:23<00:06,  2.28s/it] 95%|█████████▌| 38/40 [01:26<00:04,  2.30s/it]                                               {'loss': 0.0321, 'grad_norm': 0.891560435295105, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:26<00:04,  2.30s/it] 98%|█████████▊| 39/40 [01:28<00:02,  2.29s/it]                                               {'loss': 0.3005, 'grad_norm': 3.0944082736968994, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:28<00:02,  2.29s/it]100%|██████████| 40/40 [01:30<00:00,  2.24s/it]                                               {'loss': 0.1248, 'grad_norm': 2.8970530033111572, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:30<00:00,  2.24s/it]                                               {'train_runtime': 90.9126, 'train_samples_per_second': 6.985, 'train_steps_per_second': 0.44, 'train_loss': 0.9500858603045345, 'epoch': 5.0}
100%|██████████| 40/40 [01:30<00:00,  2.24s/it]100%|██████████| 40/40 [01:30<00:00,  2.27s/it]
CLIENT:85
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]                                              {'loss': 0.0115, 'grad_norm': 0.17316177487373352, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]                                              {'loss': 0.0513, 'grad_norm': 0.8474382162094116, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]  8%|▊         | 3/40 [00:06<01:24,  2.28s/it]                                              {'loss': 0.0324, 'grad_norm': 0.9392865896224976, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:20,  2.25s/it]                                              {'loss': 0.8692, 'grad_norm': 6.089077472686768, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 0.3155, 'grad_norm': 0.389143168926239, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 0.0073, 'grad_norm': 0.11436506360769272, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 0.382, 'grad_norm': 2.7029712200164795, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 0.0299, 'grad_norm': 0.7822480797767639, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 0.0054, 'grad_norm': 0.07019884139299393, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.2587, 'grad_norm': 7.297387599945068, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it]                                               {'loss': 0.0056, 'grad_norm': 0.04038069024682045, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.526, 'grad_norm': 4.158689022064209, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 0.0153, 'grad_norm': 0.32725054025650024, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.7804, 'grad_norm': 21.477108001708984, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.3041, 'grad_norm': 2.4935712814331055, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.0, 'grad_norm': 8.625337795820087e-05, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.0067, 'grad_norm': 0.10147377848625183, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.0061, 'grad_norm': 0.2274332195520401, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it]                                               {'loss': 0.0055, 'grad_norm': 0.12667404115200043, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it] 50%|█████     | 20/40 [00:40<00:42,  2.11s/it]                                               {'loss': 0.3709, 'grad_norm': 0.5239590406417847, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 0.6648, 'grad_norm': 1.4122116565704346, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it]                                               {'loss': 0.7427, 'grad_norm': 1.5059665441513062, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.3131, 'grad_norm': 2.757934331893921, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0017, 'grad_norm': 0.04178015887737274, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.0046, 'grad_norm': 0.14233461022377014, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.3106, 'grad_norm': 0.7753183245658875, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.6971, 'grad_norm': 33.13866424560547, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.11s/it]                                               {'loss': 0.5286, 'grad_norm': 8.048276901245117, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.4942, 'grad_norm': 1.4507064819335938, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it]                                               {'loss': 0.0026, 'grad_norm': 0.024094825610518456, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it]                                               {'loss': 0.351, 'grad_norm': 0.924292266368866, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it] 80%|████████  | 32/40 [01:04<00:12,  1.61s/it]                                               {'loss': 0.0007, 'grad_norm': 0.022696416825056076, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.2012, 'grad_norm': 8.47122573852539, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.3443, 'grad_norm': 3.2099578380584717, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.4159, 'grad_norm': 1.0208128690719604, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.10s/it]                                               {'loss': 0.009, 'grad_norm': 0.06225511059165001, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.2072, 'grad_norm': 1.027944564819336, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it]                                               {'loss': 0.0022, 'grad_norm': 0.025291819125413895, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.2464, 'grad_norm': 0.4771641194820404, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.0005, 'grad_norm': 0.013932266272604465, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.4855, 'train_samples_per_second': 7.02, 'train_steps_per_second': 0.497, 'train_loss': 0.23805987769417242, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:57,  1.58it/s]  1%|          | 3/471 [00:02<07:00,  1.11it/s]  1%|          | 4/471 [00:03<08:06,  1.04s/it]  1%|          | 5/471 [00:05<08:44,  1.13s/it]  1%|▏         | 6/471 [00:06<09:06,  1.18s/it]  1%|▏         | 7/471 [00:07<09:22,  1.21s/it]  2%|▏         | 8/471 [00:08<09:31,  1.23s/it]  2%|▏         | 9/471 [00:10<09:38,  1.25s/it]  2%|▏         | 10/471 [00:11<09:41,  1.26s/it]  2%|▏         | 11/471 [00:12<09:43,  1.27s/it]  3%|▎         | 12/471 [00:14<09:46,  1.28s/it]  3%|▎         | 13/471 [00:15<09:47,  1.28s/it]  3%|▎         | 14/471 [00:16<09:48,  1.29s/it]  3%|▎         | 15/471 [00:17<09:47,  1.29s/it]  3%|▎         | 16/471 [00:19<09:48,  1.29s/it]  4%|▎         | 17/471 [00:20<09:48,  1.30s/it]  4%|▍         | 18/471 [00:21<09:48,  1.30s/it]  4%|▍         | 19/471 [00:23<09:47,  1.30s/it]  4%|▍         | 20/471 [00:24<09:46,  1.30s/it]  4%|▍         | 21/471 [00:25<09:46,  1.30s/it]  5%|▍         | 22/471 [00:27<09:45,  1.30s/it]  5%|▍         | 23/471 [00:28<09:44,  1.31s/it]  5%|▌         | 24/471 [00:29<09:44,  1.31s/it]  5%|▌         | 25/471 [00:31<09:43,  1.31s/it]  6%|▌         | 26/471 [00:32<09:42,  1.31s/it]  6%|▌         | 27/471 [00:33<09:41,  1.31s/it]  6%|▌         | 28/471 [00:34<09:41,  1.31s/it]  6%|▌         | 29/471 [00:36<09:40,  1.31s/it]  6%|▋         | 30/471 [00:37<09:39,  1.32s/it]  7%|▋         | 31/471 [00:38<09:38,  1.32s/it]  7%|▋         | 32/471 [00:40<09:37,  1.31s/it]  7%|▋         | 33/471 [00:41<09:34,  1.31s/it]  7%|▋         | 34/471 [00:42<09:34,  1.31s/it]  7%|▋         | 35/471 [00:44<09:34,  1.32s/it]  8%|▊         | 36/471 [00:45<09:33,  1.32s/it]  8%|▊         | 37/471 [00:46<09:33,  1.32s/it]  8%|▊         | 38/471 [00:48<09:33,  1.32s/it]  8%|▊         | 39/471 [00:49<09:31,  1.32s/it]  8%|▊         | 40/471 [00:50<09:31,  1.33s/it]  9%|▊         | 41/471 [00:52<09:30,  1.33s/it]  9%|▉         | 42/471 [00:53<09:30,  1.33s/it]  9%|▉         | 43/471 [00:54<09:28,  1.33s/it]  9%|▉         | 44/471 [00:56<09:27,  1.33s/it] 10%|▉         | 45/471 [00:57<09:26,  1.33s/it] 10%|▉         | 46/471 [00:58<09:25,  1.33s/it] 10%|▉         | 47/471 [01:00<09:24,  1.33s/it] 10%|█         | 48/471 [01:01<09:23,  1.33s/it] 10%|█         | 49/471 [01:02<09:22,  1.33s/it] 11%|█         | 50/471 [01:04<09:22,  1.34s/it] 11%|█         | 51/471 [01:05<09:21,  1.34s/it] 11%|█         | 52/471 [01:06<09:20,  1.34s/it] 11%|█▏        | 53/471 [01:08<09:20,  1.34s/it] 11%|█▏        | 54/471 [01:09<09:19,  1.34s/it] 12%|█▏        | 55/471 [01:10<09:18,  1.34s/it] 12%|█▏        | 56/471 [01:12<09:18,  1.35s/it] 12%|█▏        | 57/471 [01:13<09:17,  1.35s/it] 12%|█▏        | 58/471 [01:14<09:16,  1.35s/it] 13%|█▎        | 59/471 [01:16<09:15,  1.35s/it] 13%|█▎        | 60/471 [01:17<09:13,  1.35s/it] 13%|█▎        | 61/471 [01:18<09:12,  1.35s/it] 13%|█▎        | 62/471 [01:20<09:11,  1.35s/it] 13%|█▎        | 63/471 [01:21<09:10,  1.35s/it] 14%|█▎        | 64/471 [01:23<09:09,  1.35s/it] 14%|█▍        | 65/471 [01:24<09:08,  1.35s/it] 14%|█▍        | 66/471 [01:25<09:07,  1.35s/it] 14%|█▍        | 67/471 [01:27<09:06,  1.35s/it] 14%|█▍        | 68/471 [01:28<09:04,  1.35s/it] 15%|█▍        | 69/471 [01:29<09:03,  1.35s/it] 15%|█▍        | 70/471 [01:31<09:02,  1.35s/it] 15%|█▌        | 71/471 [01:32<09:02,  1.36s/it] 15%|█▌        | 72/471 [01:33<09:00,  1.36s/it] 15%|█▌        | 73/471 [01:35<08:58,  1.35s/it] 16%|█▌        | 74/471 [01:36<08:56,  1.35s/it] 16%|█▌        | 75/471 [01:37<08:55,  1.35s/it] 16%|█▌        | 76/471 [01:39<08:54,  1.35s/it] 16%|█▋        | 77/471 [01:40<08:53,  1.35s/it] 17%|█▋        | 78/471 [01:41<08:51,  1.35s/it] 17%|█▋        | 79/471 [01:43<08:51,  1.36s/it] 17%|█▋        | 80/471 [01:44<08:50,  1.36s/it] 17%|█▋        | 81/471 [01:46<08:47,  1.35s/it] 17%|█▋        | 82/471 [01:47<08:46,  1.35s/it] 18%|█▊        | 83/471 [01:48<08:45,  1.35s/it] 18%|█▊        | 84/471 [01:50<08:43,  1.35s/it] 18%|█▊        | 85/471 [01:51<08:42,  1.35s/it] 18%|█▊        | 86/471 [01:52<08:40,  1.35s/it] 18%|█▊        | 87/471 [01:54<08:39,  1.35s/it] 19%|█▊        | 88/471 [01:55<08:37,  1.35s/it] 19%|█▉        | 89/471 [01:56<08:35,  1.35s/it] 19%|█▉        | 90/471 [01:58<08:35,  1.35s/it] 19%|█▉        | 91/471 [01:59<08:32,  1.35s/it] 20%|█▉        | 92/471 [02:00<08:31,  1.35s/it] 20%|█▉        | 93/471 [02:02<08:30,  1.35s/it] 20%|█▉        | 94/471 [02:03<08:29,  1.35s/it] 20%|██        | 95/471 [02:04<08:27,  1.35s/it] 20%|██        | 96/471 [02:06<08:26,  1.35s/it] 21%|██        | 97/471 [02:07<08:25,  1.35s/it] 21%|██        | 98/471 [02:09<08:23,  1.35s/it] 21%|██        | 99/471 [02:10<08:21,  1.35s/it] 21%|██        | 100/471 [02:11<08:20,  1.35s/it] 21%|██▏       | 101/471 [02:13<08:19,  1.35s/it] 22%|██▏       | 102/471 [02:14<08:18,  1.35s/it] 22%|██▏       | 103/471 [02:15<08:16,  1.35s/it] 22%|██▏       | 104/471 [02:17<08:16,  1.35s/it] 22%|██▏       | 105/471 [02:18<08:15,  1.35s/it] 23%|██▎       | 106/471 [02:19<08:13,  1.35s/it] 23%|██▎       | 107/471 [02:21<08:11,  1.35s/it] 23%|██▎       | 108/471 [02:22<08:09,  1.35s/it] 23%|██▎       | 109/471 [02:23<08:07,  1.35s/it] 23%|██▎       | 110/471 [02:25<08:05,  1.34s/it] 24%|██▎       | 111/471 [02:26<08:04,  1.35s/it] 24%|██▍       | 112/471 [02:27<08:03,  1.35s/it] 24%|██▍       | 113/471 [02:29<08:01,  1.35s/it] 24%|██▍       | 114/471 [02:30<08:01,  1.35s/it] 24%|██▍       | 115/471 [02:31<08:00,  1.35s/it] 25%|██▍       | 116/471 [02:33<07:58,  1.35s/it] 25%|██▍       | 117/471 [02:34<07:57,  1.35s/it] 25%|██▌       | 118/471 [02:35<07:56,  1.35s/it] 25%|██▌       | 119/471 [02:37<07:54,  1.35s/it] 25%|██▌       | 120/471 [02:38<07:53,  1.35s/it] 26%|██▌       | 121/471 [02:40<07:51,  1.35s/it] 26%|██▌       | 122/471 [02:41<07:50,  1.35s/it] 26%|██▌       | 123/471 [02:42<07:49,  1.35s/it] 26%|██▋       | 124/471 [02:44<07:47,  1.35s/it] 27%|██▋       | 125/471 [02:45<07:46,  1.35s/it] 27%|██▋       | 126/471 [02:46<07:45,  1.35s/it] 27%|██▋       | 127/471 [02:48<07:43,  1.35s/it] 27%|██▋       | 128/471 [02:49<07:42,  1.35s/it] 27%|██▋       | 129/471 [02:50<07:40,  1.35s/it] 28%|██▊       | 130/471 [02:52<07:39,  1.35s/it] 28%|██▊       | 131/471 [02:53<07:38,  1.35s/it] 28%|██▊       | 132/471 [02:54<07:36,  1.35s/it] 28%|██▊       | 133/471 [02:56<07:35,  1.35s/it] 28%|██▊       | 134/471 [02:57<07:34,  1.35s/it] 29%|██▊       | 135/471 [02:58<07:32,  1.35s/it] 29%|██▉       | 136/471 [03:00<07:30,  1.35s/it] 29%|██▉       | 137/471 [03:01<07:29,  1.35s/it] 29%|██▉       | 138/471 [03:02<07:27,  1.35s/it] 30%|██▉       | 139/471 [03:04<07:26,  1.34s/it] 30%|██▉       | 140/471 [03:05<07:24,  1.34s/it] 30%|██▉       | 141/471 [03:06<07:22,  1.34s/it] 30%|███       | 142/471 [03:08<07:21,  1.34s/it] 30%|███       | 143/471 [03:09<07:19,  1.34s/it] 31%|███       | 144/471 [03:10<07:18,  1.34s/it] 31%|███       | 145/471 [03:12<07:16,  1.34s/it] 31%|███       | 146/471 [03:13<07:16,  1.34s/it] 31%|███       | 147/471 [03:14<07:15,  1.34s/it] 31%|███▏      | 148/471 [03:16<07:13,  1.34s/it] 32%|███▏      | 149/471 [03:17<07:12,  1.34s/it] 32%|███▏      | 150/471 [03:19<07:11,  1.34s/it] 32%|███▏      | 151/471 [03:20<07:10,  1.34s/it] 32%|███▏      | 152/471 [03:21<07:08,  1.34s/it] 32%|███▏      | 153/471 [03:23<07:07,  1.34s/it] 33%|███▎      | 154/471 [03:24<07:05,  1.34s/it] 33%|███▎      | 155/471 [03:25<07:03,  1.34s/it] 33%|███▎      | 156/471 [03:27<07:02,  1.34s/it] 33%|███▎      | 157/471 [03:28<06:59,  1.34s/it] 34%|███▎      | 158/471 [03:29<06:58,  1.34s/it] 34%|███▍      | 159/471 [03:31<06:56,  1.34s/it] 34%|███▍      | 160/471 [03:32<06:55,  1.34s/it] 34%|███▍      | 161/471 [03:33<06:54,  1.34s/it] 34%|███▍      | 162/471 [03:35<06:53,  1.34s/it] 35%|███▍      | 163/471 [03:36<06:52,  1.34s/it] 35%|███▍      | 164/471 [03:37<06:50,  1.34s/it] 35%|███▌      | 165/471 [03:39<06:49,  1.34s/it] 35%|███▌      | 166/471 [03:40<06:48,  1.34s/it] 35%|███▌      | 167/471 [03:41<06:46,  1.34s/it] 36%|███▌      | 168/471 [03:43<06:44,  1.34s/it] 36%|███▌      | 169/471 [03:44<06:43,  1.34s/it] 36%|███▌      | 170/471 [03:45<06:42,  1.34s/it] 36%|███▋      | 171/471 [03:47<06:40,  1.33s/it] 37%|███▋      | 172/471 [03:48<06:38,  1.33s/it] 37%|███▋      | 173/471 [03:49<06:37,  1.33s/it] 37%|███▋      | 174/471 [03:51<06:36,  1.33s/it] 37%|███▋      | 175/471 [03:52<06:34,  1.33s/it] 37%|███▋      | 176/471 [03:53<06:33,  1.33s/it] 38%|███▊      | 177/471 [03:55<06:31,  1.33s/it] 38%|███▊      | 178/471 [03:56<06:30,  1.33s/it] 38%|███▊      | 179/471 [03:57<06:28,  1.33s/it] 38%|███▊      | 180/471 [03:59<06:27,  1.33s/it] 38%|███▊      | 181/471 [04:00<06:25,  1.33s/it] 39%|███▊      | 182/471 [04:01<06:24,  1.33s/it] 39%|███▉      | 183/471 [04:03<06:23,  1.33s/it] 39%|███▉      | 184/471 [04:04<06:21,  1.33s/it] 39%|███▉      | 185/471 [04:05<06:20,  1.33s/it] 39%|███▉      | 186/471 [04:07<06:19,  1.33s/it] 40%|███▉      | 187/471 [04:08<06:18,  1.33s/it] 40%|███▉      | 188/471 [04:09<06:17,  1.33s/it] 40%|████      | 189/471 [04:11<06:15,  1.33s/it] 40%|████      | 190/471 [04:12<06:14,  1.33s/it] 41%|████      | 191/471 [04:13<06:13,  1.33s/it] 41%|████      | 192/471 [04:15<06:11,  1.33s/it] 41%|████      | 193/471 [04:16<06:09,  1.33s/it] 41%|████      | 194/471 [04:17<06:08,  1.33s/it] 41%|████▏     | 195/471 [04:19<06:07,  1.33s/it] 42%|████▏     | 196/471 [04:20<06:06,  1.33s/it] 42%|████▏     | 197/471 [04:21<06:03,  1.33s/it] 42%|████▏     | 198/471 [04:23<06:02,  1.33s/it] 42%|████▏     | 199/471 [04:24<06:01,  1.33s/it] 42%|████▏     | 200/471 [04:25<06:00,  1.33s/it] 43%|████▎     | 201/471 [04:27<05:57,  1.32s/it] 43%|████▎     | 202/471 [04:28<05:56,  1.33s/it] 43%|████▎     | 203/471 [04:29<05:55,  1.33s/it] 43%|████▎     | 204/471 [04:31<05:54,  1.33s/it] 44%|████▎     | 205/471 [04:32<05:52,  1.33s/it] 44%|████▎     | 206/471 [04:33<05:50,  1.32s/it] 44%|████▍     | 207/471 [04:34<05:49,  1.33s/it] 44%|████▍     | 208/471 [04:36<05:47,  1.32s/it] 44%|████▍     | 209/471 [04:37<05:46,  1.32s/it] 45%|████▍     | 210/471 [04:38<05:45,  1.32s/it] 45%|████▍     | 211/471 [04:40<05:44,  1.32s/it] 45%|████▌     | 212/471 [04:41<05:42,  1.32s/it] 45%|████▌     | 213/471 [04:42<05:41,  1.32s/it] 45%|████▌     | 214/471 [04:44<05:40,  1.32s/it] 46%|████▌     | 215/471 [04:45<05:38,  1.32s/it] 46%|████▌     | 216/471 [04:46<05:37,  1.32s/it] 46%|████▌     | 217/471 [04:48<05:36,  1.33s/it] 46%|████▋     | 218/471 [04:49<05:35,  1.33s/it] 46%|████▋     | 219/471 [04:50<05:34,  1.33s/it] 47%|████▋     | 220/471 [04:52<05:33,  1.33s/it] 47%|████▋     | 221/471 [04:53<05:32,  1.33s/it] 47%|████▋     | 222/471 [04:54<05:30,  1.33s/it] 47%|████▋     | 223/471 [04:56<05:28,  1.33s/it] 48%|████▊     | 224/471 [04:57<05:27,  1.33s/it] 48%|████▊     | 225/471 [04:58<05:26,  1.33s/it] 48%|████▊     | 226/471 [05:00<05:25,  1.33s/it] 48%|████▊     | 227/471 [05:01<05:24,  1.33s/it] 48%|████▊     | 228/471 [05:02<05:22,  1.33s/it] 49%|████▊     | 229/471 [05:04<05:21,  1.33s/it] 49%|████▉     | 230/471 [05:05<05:20,  1.33s/it] 49%|████▉     | 231/471 [05:06<05:18,  1.33s/it] 49%|████▉     | 232/471 [05:08<05:16,  1.32s/it] 49%|████▉     | 233/471 [05:09<05:15,  1.32s/it] 50%|████▉     | 234/471 [05:10<05:14,  1.33s/it] 50%|████▉     | 235/471 [05:12<05:13,  1.33s/it] 50%|█████     | 236/471 [05:13<05:11,  1.33s/it] 50%|█████     | 237/471 [05:14<05:10,  1.33s/it] 51%|█████     | 238/471 [05:16<05:08,  1.33s/it] 51%|█████     | 239/471 [05:17<05:07,  1.33s/it] 51%|█████     | 240/471 [05:18<05:06,  1.33s/it] 51%|█████     | 241/471 [05:20<05:05,  1.33s/it] 51%|█████▏    | 242/471 [05:21<05:03,  1.33s/it] 52%|█████▏    | 243/471 [05:22<05:02,  1.33s/it] 52%|█████▏    | 244/471 [05:24<05:01,  1.33s/it] 52%|█████▏    | 245/471 [05:25<04:59,  1.33s/it] 52%|█████▏    | 246/471 [05:26<04:58,  1.33s/it] 52%|█████▏    | 247/471 [05:28<04:56,  1.32s/it] 53%|█████▎    | 248/471 [05:29<04:55,  1.33s/it] 53%|█████▎    | 249/471 [05:30<04:54,  1.33s/it] 53%|█████▎    | 250/471 [05:32<04:53,  1.33s/it] 53%|█████▎    | 251/471 [05:33<04:51,  1.33s/it] 54%|█████▎    | 252/471 [05:34<04:50,  1.33s/it] 54%|█████▎    | 253/471 [05:35<04:49,  1.33s/it] 54%|█████▍    | 254/471 [05:37<04:48,  1.33s/it] 54%|█████▍    | 255/471 [05:38<04:46,  1.33s/it] 54%|█████▍    | 256/471 [05:39<04:45,  1.33s/it] 55%|█████▍    | 257/471 [05:41<04:44,  1.33s/it] 55%|█████▍    | 258/471 [05:42<04:43,  1.33s/it] 55%|█████▍    | 259/471 [05:43<04:42,  1.33s/it] 55%|█████▌    | 260/471 [05:45<04:40,  1.33s/it] 55%|█████▌    | 261/471 [05:46<04:39,  1.33s/it] 56%|█████▌    | 262/471 [05:47<04:37,  1.33s/it] 56%|█████▌    | 263/471 [05:49<04:36,  1.33s/it] 56%|█████▌    | 264/471 [05:50<04:35,  1.33s/it] 56%|█████▋    | 265/471 [05:51<04:34,  1.33s/it] 56%|█████▋    | 266/471 [05:53<04:33,  1.33s/it] 57%|█████▋    | 267/471 [05:54<04:31,  1.33s/it] 57%|█████▋    | 268/471 [05:55<04:30,  1.33s/it] 57%|█████▋    | 269/471 [05:57<04:29,  1.33s/it] 57%|█████▋    | 270/471 [05:58<04:27,  1.33s/it] 58%|█████▊    | 271/471 [05:59<04:26,  1.33s/it] 58%|█████▊    | 272/471 [06:01<04:24,  1.33s/it] 58%|█████▊    | 273/471 [06:02<04:23,  1.33s/it] 58%|█████▊    | 274/471 [06:03<04:22,  1.33s/it] 58%|█████▊    | 275/471 [06:05<04:20,  1.33s/it] 59%|█████▊    | 276/471 [06:06<04:19,  1.33s/it] 59%|█████▉    | 277/471 [06:07<04:18,  1.33s/it] 59%|█████▉    | 278/471 [06:09<04:17,  1.34s/it] 59%|█████▉    | 279/471 [06:10<04:16,  1.33s/it] 59%|█████▉    | 280/471 [06:11<04:14,  1.33s/it] 60%|█████▉    | 281/471 [06:13<04:13,  1.33s/it] 60%|█████▉    | 282/471 [06:14<04:11,  1.33s/it] 60%|██████    | 283/471 [06:15<04:10,  1.33s/it] 60%|██████    | 284/471 [06:17<04:09,  1.34s/it] 61%|██████    | 285/471 [06:18<04:08,  1.34s/it] 61%|██████    | 286/471 [06:19<04:07,  1.34s/it] 61%|██████    | 287/471 [06:21<04:06,  1.34s/it] 61%|██████    | 288/471 [06:22<04:05,  1.34s/it] 61%|██████▏   | 289/471 [06:23<04:03,  1.34s/it] 62%|██████▏   | 290/471 [06:25<04:02,  1.34s/it] 62%|██████▏   | 291/471 [06:26<04:01,  1.34s/it] 62%|██████▏   | 292/471 [06:28<03:59,  1.34s/it] 62%|██████▏   | 293/471 [06:29<03:58,  1.34s/it] 62%|██████▏   | 294/471 [06:30<03:57,  1.34s/it] 63%|██████▎   | 295/471 [06:32<03:55,  1.34s/it] 63%|██████▎   | 296/471 [06:33<03:54,  1.34s/it] 63%|██████▎   | 297/471 [06:34<03:53,  1.34s/it] 63%|██████▎   | 298/471 [06:36<03:52,  1.34s/it] 63%|██████▎   | 299/471 [06:37<03:50,  1.34s/it] 64%|██████▎   | 300/471 [06:38<03:49,  1.34s/it] 64%|██████▍   | 301/471 [06:40<03:48,  1.34s/it] 64%|██████▍   | 302/471 [06:41<03:46,  1.34s/it] 64%|██████▍   | 303/471 [06:42<03:45,  1.34s/it] 65%|██████▍   | 304/471 [06:44<03:43,  1.34s/it] 65%|██████▍   | 305/471 [06:45<03:42,  1.34s/it] 65%|██████▍   | 306/471 [06:46<03:41,  1.34s/it] 65%|██████▌   | 307/471 [06:48<03:40,  1.34s/it] 65%|██████▌   | 308/471 [06:49<03:38,  1.34s/it] 66%|██████▌   | 309/471 [06:50<03:37,  1.34s/it] 66%|██████▌   | 310/471 [06:52<03:36,  1.34s/it] 66%|██████▌   | 311/471 [06:53<03:34,  1.34s/it] 66%|██████▌   | 312/471 [06:54<03:32,  1.34s/it] 66%|██████▋   | 313/471 [06:56<03:31,  1.34s/it] 67%|██████▋   | 314/471 [06:57<03:30,  1.34s/it] 67%|██████▋   | 315/471 [06:58<03:28,  1.34s/it] 67%|██████▋   | 316/471 [07:00<03:27,  1.34s/it] 67%|██████▋   | 317/471 [07:01<03:26,  1.34s/it] 68%|██████▊   | 318/471 [07:02<03:24,  1.34s/it] 68%|██████▊   | 319/471 [07:04<03:23,  1.34s/it] 68%|██████▊   | 320/471 [07:05<03:22,  1.34s/it] 68%|██████▊   | 321/471 [07:06<03:21,  1.34s/it] 68%|██████▊   | 322/471 [07:08<03:19,  1.34s/it] 69%|██████▊   | 323/471 [07:09<03:18,  1.34s/it] 69%|██████▉   | 324/471 [07:10<03:17,  1.34s/it] 69%|██████▉   | 325/471 [07:12<03:16,  1.34s/it] 69%|██████▉   | 326/471 [07:13<03:14,  1.34s/it] 69%|██████▉   | 327/471 [07:14<03:12,  1.34s/it] 70%|██████▉   | 328/471 [07:16<03:11,  1.34s/it] 70%|██████▉   | 329/471 [07:17<03:10,  1.34s/it] 70%|███████   | 330/471 [07:18<03:08,  1.34s/it] 70%|███████   | 331/471 [07:20<03:07,  1.34s/it] 70%|███████   | 332/471 [07:21<03:06,  1.34s/it] 71%|███████   | 333/471 [07:22<03:04,  1.34s/it] 71%|███████   | 334/471 [07:24<03:03,  1.34s/it] 71%|███████   | 335/471 [07:25<03:02,  1.34s/it] 71%|███████▏  | 336/471 [07:26<03:00,  1.34s/it] 72%|███████▏  | 337/471 [07:28<02:59,  1.34s/it] 72%|███████▏  | 338/471 [07:29<02:57,  1.34s/it] 72%|███████▏  | 339/471 [07:30<02:56,  1.34s/it] 72%|███████▏  | 340/471 [07:32<02:55,  1.34s/it] 72%|███████▏  | 341/471 [07:33<02:53,  1.34s/it] 73%|███████▎  | 342/471 [07:35<02:52,  1.34s/it] 73%|███████▎  | 343/471 [07:36<02:51,  1.34s/it] 73%|███████▎  | 344/471 [07:37<02:49,  1.34s/it] 73%|███████▎  | 345/471 [07:39<02:48,  1.34s/it] 73%|███████▎  | 346/471 [07:40<02:47,  1.34s/it] 74%|███████▎  | 347/471 [07:41<02:45,  1.34s/it] 74%|███████▍  | 348/471 [07:43<02:44,  1.34s/it] 74%|███████▍  | 349/471 [07:44<02:43,  1.34s/it] 74%|███████▍  | 350/471 [07:45<02:41,  1.34s/it] 75%|███████▍  | 351/471 [07:47<02:40,  1.33s/it] 75%|███████▍  | 352/471 [07:48<02:38,  1.34s/it] 75%|███████▍  | 353/471 [07:49<02:37,  1.34s/it] 75%|███████▌  | 354/471 [07:51<02:36,  1.34s/it] 75%|███████▌  | 355/471 [07:52<02:35,  1.34s/it] 76%|███████▌  | 356/471 [07:53<02:33,  1.34s/it] 76%|███████▌  | 357/471 [07:55<02:32,  1.34s/it] 76%|███████▌  | 358/471 [07:56<02:30,  1.34s/it] 76%|███████▌  | 359/471 [07:57<02:29,  1.34s/it] 76%|███████▋  | 360/471 [07:59<02:28,  1.33s/it] 77%|███████▋  | 361/471 [08:00<02:26,  1.34s/it] 77%|███████▋  | 362/471 [08:01<02:25,  1.34s/it] 77%|███████▋  | 363/471 [08:03<02:23,  1.33s/it] 77%|███████▋  | 364/471 [08:04<02:22,  1.33s/it] 77%|███████▋  | 365/471 [08:05<02:21,  1.34s/it] 78%|███████▊  | 366/471 [08:07<02:20,  1.34s/it] 78%|███████▊  | 367/471 [08:08<02:18,  1.33s/it] 78%|███████▊  | 368/471 [08:09<02:17,  1.33s/it] 78%|███████▊  | 369/471 [08:11<02:15,  1.33s/it] 79%|███████▊  | 370/471 [08:12<02:14,  1.33s/it] 79%|███████▉  | 371/471 [08:13<02:13,  1.33s/it] 79%|███████▉  | 372/471 [08:15<02:11,  1.33s/it] 79%|███████▉  | 373/471 [08:16<02:10,  1.33s/it] 79%|███████▉  | 374/471 [08:17<02:09,  1.33s/it] 80%|███████▉  | 375/471 [08:19<02:07,  1.33s/it] 80%|███████▉  | 376/471 [08:20<02:06,  1.33s/it] 80%|████████  | 377/471 [08:21<02:04,  1.33s/it] 80%|████████  | 378/471 [08:23<02:03,  1.33s/it] 80%|████████  | 379/471 [08:24<02:02,  1.33s/it] 81%|████████  | 380/471 [08:25<02:01,  1.33s/it] 81%|████████  | 381/471 [08:27<01:59,  1.33s/it] 81%|████████  | 382/471 [08:28<01:58,  1.33s/it] 81%|████████▏ | 383/471 [08:29<01:57,  1.33s/it] 82%|████████▏ | 384/471 [08:31<01:56,  1.33s/it] 82%|████████▏ | 385/471 [08:32<01:54,  1.33s/it] 82%|████████▏ | 386/471 [08:33<01:53,  1.33s/it] 82%|████████▏ | 387/471 [08:35<01:51,  1.33s/it] 82%|████████▏ | 388/471 [08:36<01:50,  1.33s/it] 83%|████████▎ | 389/471 [08:37<01:49,  1.33s/it] 83%|████████▎ | 390/471 [08:38<01:47,  1.33s/it] 83%|████████▎ | 391/471 [08:40<01:46,  1.33s/it] 83%|████████▎ | 392/471 [08:41<01:44,  1.33s/it] 83%|████████▎ | 393/471 [08:42<01:43,  1.33s/it] 84%|████████▎ | 394/471 [08:44<01:42,  1.33s/it] 84%|████████▍ | 395/471 [08:45<01:40,  1.33s/it] 84%|████████▍ | 396/471 [08:46<01:39,  1.33s/it] 84%|████████▍ | 397/471 [08:48<01:38,  1.33s/it] 85%|████████▍ | 398/471 [08:49<01:36,  1.33s/it] 85%|████████▍ | 399/471 [08:50<01:35,  1.33s/it] 85%|████████▍ | 400/471 [08:52<01:34,  1.33s/it] 85%|████████▌ | 401/471 [08:53<01:32,  1.33s/it] 85%|████████▌ | 402/471 [08:54<01:31,  1.33s/it] 86%|████████▌ | 403/471 [08:56<01:30,  1.33s/it] 86%|████████▌ | 404/471 [08:57<01:28,  1.33s/it] 86%|████████▌ | 405/471 [08:58<01:27,  1.33s/it] 86%|████████▌ | 406/471 [09:00<01:26,  1.33s/it] 86%|████████▋ | 407/471 [09:01<01:24,  1.32s/it] 87%|████████▋ | 408/471 [09:02<01:23,  1.33s/it] 87%|████████▋ | 409/471 [09:04<01:22,  1.33s/it] 87%|████████▋ | 410/471 [09:05<01:20,  1.32s/it] 87%|████████▋ | 411/471 [09:06<01:19,  1.32s/it] 87%|████████▋ | 412/471 [09:08<01:18,  1.32s/it] 88%|████████▊ | 413/471 [09:09<01:16,  1.33s/it] 88%|████████▊ | 414/471 [09:10<01:15,  1.33s/it] 88%|████████▊ | 415/471 [09:12<01:14,  1.32s/it] 88%|████████▊ | 416/471 [09:13<01:12,  1.33s/it] 89%|████████▊ | 417/471 [09:14<01:11,  1.33s/it] 89%|████████▊ | 418/471 [09:16<01:10,  1.33s/it] 89%|████████▉ | 419/471 [09:17<01:09,  1.33s/it] 89%|████████▉ | 420/471 [09:18<01:07,  1.33s/it] 89%|████████▉ | 421/471 [09:20<01:06,  1.33s/it] 90%|████████▉ | 422/471 [09:21<01:04,  1.32s/it] 90%|████████▉ | 423/471 [09:22<01:03,  1.32s/it] 90%|█████████ | 424/471 [09:24<01:02,  1.32s/it] 90%|█████████ | 425/471 [09:25<01:00,  1.32s/it] 90%|█████████ | 426/471 [09:26<00:59,  1.33s/it] 91%|█████████ | 427/471 [09:28<00:58,  1.33s/it] 91%|█████████ | 428/471 [09:29<00:57,  1.33s/it] 91%|█████████ | 429/471 [09:30<00:55,  1.33s/it] 91%|█████████▏| 430/471 [09:32<00:54,  1.33s/it] 92%|█████████▏| 431/471 [09:33<00:53,  1.33s/it] 92%|█████████▏| 432/471 [09:34<00:51,  1.33s/it] 92%|█████████▏| 433/471 [09:36<00:50,  1.33s/it] 92%|█████████▏| 434/471 [09:37<00:49,  1.33s/it] 92%|█████████▏| 435/471 [09:38<00:47,  1.33s/it] 93%|█████████▎| 436/471 [09:40<00:46,  1.33s/it] 93%|█████████▎| 437/471 [09:41<00:45,  1.33s/it] 93%|█████████▎| 438/471 [09:42<00:43,  1.33s/it] 93%|█████████▎| 439/471 [09:43<00:42,  1.33s/it] 93%|█████████▎| 440/471 [09:45<00:41,  1.32s/it] 94%|█████████▎| 441/471 [09:46<00:39,  1.32s/it] 94%|█████████▍| 442/471 [09:47<00:38,  1.33s/it] 94%|█████████▍| 443/471 [09:49<00:37,  1.32s/it] 94%|█████████▍| 444/471 [09:50<00:35,  1.33s/it] 94%|█████████▍| 445/471 [09:51<00:34,  1.33s/it] 95%|█████████▍| 446/471 [09:53<00:33,  1.33s/it] 95%|█████████▍| 447/471 [09:54<00:31,  1.33s/it] 95%|█████████▌| 448/471 [09:55<00:30,  1.32s/it] 95%|█████████▌| 449/471 [09:57<00:29,  1.33s/it] 96%|█████████▌| 450/471 [09:58<00:27,  1.33s/it] 96%|█████████▌| 451/471 [09:59<00:26,  1.33s/it] 96%|█████████▌| 452/471 [10:01<00:25,  1.33s/it] 96%|█████████▌| 453/471 [10:02<00:23,  1.33s/it] 96%|█████████▋| 454/471 [10:03<00:22,  1.33s/it] 97%|█████████▋| 455/471 [10:05<00:21,  1.33s/it] 97%|█████████▋| 456/471 [10:06<00:19,  1.33s/it] 97%|█████████▋| 457/471 [10:07<00:18,  1.33s/it] 97%|█████████▋| 458/471 [10:09<00:17,  1.33s/it] 97%|█████████▋| 459/471 [10:10<00:15,  1.33s/it] 98%|█████████▊| 460/471 [10:11<00:14,  1.33s/it] 98%|█████████▊| 461/471 [10:13<00:13,  1.33s/it] 98%|█████████▊| 462/471 [10:14<00:11,  1.33s/it] 98%|█████████▊| 463/471 [10:15<00:10,  1.33s/it] 99%|█████████▊| 464/471 [10:17<00:09,  1.33s/it] 99%|█████████▊| 465/471 [10:18<00:07,  1.32s/it] 99%|█████████▉| 466/471 [10:19<00:06,  1.33s/it] 99%|█████████▉| 467/471 [10:21<00:05,  1.33s/it] 99%|█████████▉| 468/471 [10:22<00:03,  1.33s/it]100%|█████████▉| 469/471 [10:23<00:02,  1.33s/it]100%|█████████▉| 470/471 [10:25<00:01,  1.33s/it]100%|██████████| 471/471 [10:26<00:00,  1.22s/it]100%|██████████| 471/471 [10:26<00:00,  1.33s/it]
{'eval_loss': 3.8168716430664062, 'eval_model_preparation_time': 0.0194, 'eval_acc': 0.20884227296866703, 'eval_runtime': 627.3267, 'eval_samples_per_second': 12.007, 'eval_steps_per_second': 0.751}
ROUND:9
CLIENT:8
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:27,  2.24s/it]                                              {'loss': 1.7147, 'grad_norm': 5.7542243003845215, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:27,  2.24s/it]  5%|▌         | 2/40 [00:04<01:24,  2.21s/it]                                              {'loss': 3.3197, 'grad_norm': 8.882264137268066, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.21s/it]  8%|▊         | 3/40 [00:06<01:21,  2.20s/it]                                              {'loss': 1.7831, 'grad_norm': 10.103558540344238, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.20s/it] 10%|█         | 4/40 [00:08<01:18,  2.18s/it]                                              {'loss': 3.2867, 'grad_norm': 16.48819351196289, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.18s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it]                                              {'loss': 3.4116, 'grad_norm': 19.26844596862793, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 2.2118, 'grad_norm': 13.053889274597168, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 2.1295, 'grad_norm': 12.790268898010254, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 1.7906, 'grad_norm': 48.1549072265625, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it]                                              {'loss': 0.4924, 'grad_norm': 6.967107772827148, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.0394, 'grad_norm': 9.535527229309082, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.4515, 'grad_norm': 5.189647197723389, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.6309, 'grad_norm': 5.121980667114258, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 0.5065, 'grad_norm': 5.532228469848633, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it]                                               {'loss': 1.0966, 'grad_norm': 8.942887306213379, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.7961, 'grad_norm': 7.907324314117432, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0208, 'grad_norm': 1.0618398189544678, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.3516, 'grad_norm': 8.471431732177734, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it]                                               {'loss': 0.258, 'grad_norm': 3.8941731452941895, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.3414, 'grad_norm': 3.572904586791992, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.4271, 'grad_norm': 4.82219934463501, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.3197, 'grad_norm': 4.598082065582275, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it]                                               {'loss': 0.1793, 'grad_norm': 2.12412166595459, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.7751, 'grad_norm': 10.978271484375, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.1193, 'grad_norm': 3.372453451156616, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0892, 'grad_norm': 1.1367177963256836, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.0725, 'grad_norm': 2.2738709449768066, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.0806, 'grad_norm': 1.639210820198059, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.0828, 'grad_norm': 2.0983705520629883, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.1314, 'grad_norm': 2.195328712463379, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.0754, 'grad_norm': 1.5199588537216187, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.1661, 'grad_norm': 3.5869271755218506, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0194, 'grad_norm': 1.0379492044448853, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0939, 'grad_norm': 2.1850264072418213, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.0707, 'grad_norm': 3.856485605239868, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.0619, 'grad_norm': 2.0897376537323, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.0239, 'grad_norm': 0.5948024988174438, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it]                                               {'loss': 0.0649, 'grad_norm': 2.0429813861846924, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.5682, 'grad_norm': 4.829626083374023, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.0357, 'grad_norm': 0.9826779961585999, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0004, 'grad_norm': 0.030321545898914337, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.6226, 'train_samples_per_second': 7.096, 'train_steps_per_second': 0.502, 'train_loss': 0.7272602906545217, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:93
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:53,  2.92s/it]                                              {'loss': 3.9291, 'grad_norm': 44.480464935302734, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:53,  2.92s/it]  5%|▌         | 2/40 [00:05<01:33,  2.45s/it]                                              {'loss': 4.5388, 'grad_norm': 9.368194580078125, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:33,  2.45s/it]  8%|▊         | 3/40 [00:07<01:25,  2.30s/it]                                              {'loss': 2.8775, 'grad_norm': 11.633360862731934, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.30s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 3.3457, 'grad_norm': 10.4246187210083, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 1.9513, 'grad_norm': 11.643887519836426, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 3.5162, 'grad_norm': 11.437685012817383, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.8978, 'grad_norm': 13.077032089233398, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:16<00:49,  1.56s/it]                                              {'loss': 0.6095, 'grad_norm': 29.311542510986328, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.74s/it]                                              {'loss': 1.3765, 'grad_norm': 6.80159330368042, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.74s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it]                                               {'loss': 1.9704, 'grad_norm': 13.901253700256348, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.9455, 'grad_norm': 5.413764953613281, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 0.7434, 'grad_norm': 5.3698835372924805, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.09s/it]                                               {'loss': 1.5678, 'grad_norm': 6.264674663543701, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it]                                               {'loss': 1.172, 'grad_norm': 11.509607315063477, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 1.2392, 'grad_norm': 12.060935020446777, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 0.0769, 'grad_norm': 2.436356782913208, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.3491, 'grad_norm': 2.9330482482910156, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it]                                               {'loss': 0.8744, 'grad_norm': 16.601869583129883, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it]                                               {'loss': 0.7087, 'grad_norm': 5.2328972816467285, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.2977, 'grad_norm': 7.447585582733154, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.2427, 'grad_norm': 6.85634708404541, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.17s/it]                                               {'loss': 0.5861, 'grad_norm': 16.96135711669922, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 1.1524, 'grad_norm': 26.312923431396484, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.2001, 'grad_norm': 94.25332641601562, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.3175, 'grad_norm': 8.49843692779541, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it]                                               {'loss': 0.8441, 'grad_norm': 31.759180068969727, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.1722, 'grad_norm': 29.182392120361328, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 1.1752, 'grad_norm': 87.24163055419922, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.6373, 'grad_norm': 13.370406150817871, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 1.5114, 'grad_norm': 45.191925048828125, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 1.14, 'grad_norm': 19.614269256591797, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.1306, 'grad_norm': 17.376100540161133, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.3269, 'grad_norm': 66.7149658203125, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.1372, 'grad_norm': 3.8470070362091064, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it]                                               {'loss': 0.5493, 'grad_norm': 5.1487860679626465, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.8016, 'grad_norm': 59.00830078125, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 1.0252, 'grad_norm': 15.928118705749512, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.3529, 'grad_norm': 8.664931297302246, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.7132, 'grad_norm': 18.842317581176758, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 7.4874, 'grad_norm': 144.0946502685547, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.7065, 'train_samples_per_second': 7.089, 'train_steps_per_second': 0.502, 'train_loss': 1.3372671904042364, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:4
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:41,  2.59s/it]                                              {'loss': 3.8852, 'grad_norm': 7.424129486083984, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:41,  2.59s/it]  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]                                              {'loss': 3.513, 'grad_norm': 8.198773384094238, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 2.4283, 'grad_norm': 12.141828536987305, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:19,  2.21s/it]                                              {'loss': 2.5643, 'grad_norm': 14.223664283752441, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it]                                              {'loss': 3.4779, 'grad_norm': 17.389144897460938, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:13,  2.17s/it]                                              {'loss': 3.0605, 'grad_norm': 17.270105361938477, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:13,  2.17s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it]                                              {'loss': 3.8997, 'grad_norm': 18.16011619567871, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 5.8832, 'grad_norm': 51.221412658691406, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it]                                              {'loss': 1.2183, 'grad_norm': 12.31822395324707, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it]                                               {'loss': 1.6098, 'grad_norm': 13.057881355285645, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 1.2193, 'grad_norm': 9.31080150604248, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 0.8658, 'grad_norm': 6.685701847076416, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it]                                               {'loss': 0.4888, 'grad_norm': 5.173326015472412, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 0.7931, 'grad_norm': 8.629054069519043, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.13s/it]                                               {'loss': 0.772, 'grad_norm': 4.861843109130859, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.13s/it] 40%|████      | 16/40 [00:31<00:37,  1.55s/it]                                               {'loss': 0.1656, 'grad_norm': 8.501184463500977, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.55s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.2698, 'grad_norm': 2.3980982303619385, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.313, 'grad_norm': 3.41200852394104, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it]                                               {'loss': 0.3958, 'grad_norm': 4.193545818328857, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.298, 'grad_norm': 5.164275646209717, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.507, 'grad_norm': 11.097830772399902, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 0.2303, 'grad_norm': 4.273531913757324, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it]                                               {'loss': 0.4837, 'grad_norm': 5.7170729637146, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it] 60%|██████    | 24/40 [00:46<00:25,  1.56s/it]                                               {'loss': 2.6712, 'grad_norm': 13.094088554382324, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.56s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.75s/it]                                               {'loss': 0.2584, 'grad_norm': 3.586036205291748, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.75s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.88s/it]                                               {'loss': 0.1556, 'grad_norm': 4.589663505554199, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.88s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it]                                               {'loss': 0.6375, 'grad_norm': 7.354780673980713, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it] 70%|███████   | 28/40 [00:55<00:24,  2.07s/it]                                               {'loss': 0.4242, 'grad_norm': 3.390028476715088, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.5836, 'grad_norm': 6.84544563293457, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.6061, 'grad_norm': 2.8686227798461914, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.21s/it]                                               {'loss': 0.1816, 'grad_norm': 2.740885019302368, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.21s/it] 80%|████████  | 32/40 [01:02<00:12,  1.60s/it]                                               {'loss': 0.1048, 'grad_norm': 3.759122133255005, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.1887, 'grad_norm': 0.6774064898490906, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it]                                               {'loss': 0.2716, 'grad_norm': 2.339387893676758, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it]                                               {'loss': 0.2448, 'grad_norm': 1.8556013107299805, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.12s/it]                                               {'loss': 0.3499, 'grad_norm': 5.339802265167236, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it]                                               {'loss': 0.2421, 'grad_norm': 1.9187278747558594, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.3339, 'grad_norm': 2.637681245803833, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]                                               {'loss': 0.0578, 'grad_norm': 1.2556524276733398, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 0.008, 'grad_norm': 0.6572906970977783, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 79.1716, 'train_samples_per_second': 7.136, 'train_steps_per_second': 0.505, 'train_loss': 1.141550055402331, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:5
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:41,  2.61s/it]                                              {'loss': 4.297, 'grad_norm': 7.955029010772705, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:41,  2.61s/it]  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]                                              {'loss': 2.4439, 'grad_norm': 9.153302192687988, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]  8%|▊         | 3/40 [00:07<01:24,  2.29s/it]                                              {'loss': 2.4693, 'grad_norm': 9.861766815185547, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 1.972, 'grad_norm': 10.395294189453125, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 2.9439, 'grad_norm': 12.285469055175781, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 2.298, 'grad_norm': 12.275911331176758, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it]                                              {'loss': 3.0435, 'grad_norm': 12.546704292297363, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 0.2278, 'grad_norm': 12.704452514648438, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 0.7386, 'grad_norm': 6.443567752838135, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.3376, 'grad_norm': 5.081061363220215, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 0.5335, 'grad_norm': 4.895481109619141, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 1.1117, 'grad_norm': 4.780580520629883, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 1.686, 'grad_norm': 7.834157943725586, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 0.3989, 'grad_norm': 34.68117904663086, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it]                                               {'loss': 0.9106, 'grad_norm': 5.301633834838867, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it] 40%|████      | 16/40 [00:31<00:38,  1.60s/it]                                               {'loss': 0.6666, 'grad_norm': 25.880399703979492, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.80s/it]                                               {'loss': 0.1897, 'grad_norm': 3.9351966381073, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.3506, 'grad_norm': 3.130049705505371, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.2615, 'grad_norm': 4.060243606567383, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:41<00:42,  2.11s/it]                                               {'loss': 0.2333, 'grad_norm': 2.9194276332855225, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 0.6915, 'grad_norm': 14.80941104888916, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 1.7144, 'grad_norm': 162.7502899169922, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 1.6462, 'grad_norm': 174.98284912109375, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:48<00:25,  1.60s/it]                                               {'loss': 0.0104, 'grad_norm': 0.4160960912704468, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it]                                               {'loss': 0.362, 'grad_norm': 4.929177284240723, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.1126, 'grad_norm': 3.215998411178589, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.6792, 'grad_norm': 8.147619247436523, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.2066, 'grad_norm': 4.407040596008301, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.3571, 'grad_norm': 3.4456887245178223, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.2238, 'grad_norm': 3.4761834144592285, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.2667, 'grad_norm': 3.5659427642822266, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.041, 'grad_norm': 1.5496997833251953, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.0624, 'grad_norm': 1.3564465045928955, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it]                                               {'loss': 0.1629, 'grad_norm': 2.2503886222839355, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it]                                               {'loss': 0.0234, 'grad_norm': 0.4291854798793793, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.10s/it]                                               {'loss': 0.38, 'grad_norm': 2.450577735900879, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.1598, 'grad_norm': 3.9192864894866943, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.2163, 'grad_norm': 2.515190601348877, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]                                               {'loss': 0.144, 'grad_norm': 3.5972702503204346, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.0317, 'grad_norm': 1.481428623199463, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.6526, 'train_samples_per_second': 7.005, 'train_steps_per_second': 0.496, 'train_loss': 0.8651545824017376, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:52
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:43,  2.66s/it]                                              {'loss': 3.6698, 'grad_norm': 7.4427170753479, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:43,  2.66s/it]  5%|▌         | 2/40 [00:04<01:30,  2.39s/it]                                              {'loss': 3.0019, 'grad_norm': 8.295626640319824, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.39s/it]  8%|▊         | 3/40 [00:07<01:25,  2.30s/it]                                              {'loss': 2.6255, 'grad_norm': 9.092684745788574, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.30s/it] 10%|█         | 4/40 [00:09<01:22,  2.28s/it]                                              {'loss': 2.6166, 'grad_norm': 11.474392890930176, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.28s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 4.989, 'grad_norm': 24.099084854125977, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 3.2566, 'grad_norm': 16.62565803527832, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 1.3965, 'grad_norm': 11.598310470581055, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 2.1572, 'grad_norm': 33.08888244628906, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 0.7122, 'grad_norm': 6.912129878997803, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 1.1945, 'grad_norm': 6.841032028198242, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 1.8589, 'grad_norm': 7.218455791473389, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:25<00:58,  2.09s/it]                                               {'loss': 1.0824, 'grad_norm': 7.502398490905762, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 1.2509, 'grad_norm': 6.822956085205078, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 2.2065, 'grad_norm': 10.91814136505127, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.9747, 'grad_norm': 5.097967624664307, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:32<00:38,  1.59s/it]                                               {'loss': 1.0716, 'grad_norm': 19.563013076782227, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.78s/it]                                               {'loss': 0.3383, 'grad_norm': 5.160829067230225, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.7493, 'grad_norm': 7.829256057739258, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it]                                               {'loss': 0.4351, 'grad_norm': 6.021307468414307, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it] 50%|█████     | 20/40 [00:41<00:42,  2.10s/it]                                               {'loss': 0.6998, 'grad_norm': 70.13043975830078, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 0.2415, 'grad_norm': 5.571847438812256, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 0.5285, 'grad_norm': 5.726911544799805, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.5329, 'grad_norm': 5.6812238693237305, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:48<00:25,  1.61s/it]                                               {'loss': 0.6041, 'grad_norm': 28.258447647094727, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it]                                               {'loss': 0.6388, 'grad_norm': 13.938389778137207, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it]                                               {'loss': 0.2398, 'grad_norm': 7.051980972290039, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.1741, 'grad_norm': 2.615919589996338, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.1785, 'grad_norm': 2.2282700538635254, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.3197, 'grad_norm': 2.531324863433838, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it]                                               {'loss': 0.4723, 'grad_norm': 1.7845847606658936, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.24s/it]                                               {'loss': 0.1474, 'grad_norm': 2.8407721519470215, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.24s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.0471, 'grad_norm': 1.631131887435913, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.1052, 'grad_norm': 1.9537220001220703, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.0569, 'grad_norm': 0.9510939717292786, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.06s/it]                                               {'loss': 0.3102, 'grad_norm': 2.5459136962890625, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it]                                               {'loss': 0.0718, 'grad_norm': 1.6010167598724365, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it]                                               {'loss': 0.0283, 'grad_norm': 0.563109278678894, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.6847, 'grad_norm': 5.495633602142334, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.0511, 'grad_norm': 0.7790146470069885, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 1.1322, 'grad_norm': 46.83436965942383, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.6853, 'train_samples_per_second': 7.003, 'train_steps_per_second': 0.496, 'train_loss': 1.0713100417517125, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:41
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]                                              {'loss': 3.9823, 'grad_norm': 9.043662071228027, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]                                              {'loss': 3.5063, 'grad_norm': 11.176346778869629, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]  8%|▊         | 3/40 [00:06<01:22,  2.24s/it]                                              {'loss': 2.6844, 'grad_norm': 13.554713249206543, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.24s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 2.8408, 'grad_norm': 14.573538780212402, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it]                                              {'loss': 2.8212, 'grad_norm': 20.02765655517578, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 4.4324, 'grad_norm': 25.772687911987305, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 2.4029, 'grad_norm': 13.53358268737793, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 8.4188, 'grad_norm': 103.9725570678711, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.77s/it]                                              {'loss': 1.5658, 'grad_norm': 12.290061950683594, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.5892, 'grad_norm': 5.638147830963135, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.4728, 'grad_norm': 15.72793197631836, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.10s/it]                                               {'loss': 1.0781, 'grad_norm': 8.527129173278809, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.10s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.15s/it]                                               {'loss': 1.1472, 'grad_norm': 11.281872749328613, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.15s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 0.8553, 'grad_norm': 7.8134765625, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.9751, 'grad_norm': 4.883975505828857, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.0108, 'grad_norm': 0.6185901165008545, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.4413, 'grad_norm': 3.6764626502990723, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.2532, 'grad_norm': 3.490854501724243, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.647, 'grad_norm': 6.382769584655762, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.8036, 'grad_norm': 4.791559219360352, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.1087, 'grad_norm': 2.110788345336914, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.1416, 'grad_norm': 4.6772780418396, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.1735, 'grad_norm': 3.673356294631958, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.072, 'grad_norm': 3.5235257148742676, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it]                                               {'loss': 0.6474, 'grad_norm': 3.1441874504089355, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it]                                               {'loss': 0.1804, 'grad_norm': 1.7209744453430176, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.1526, 'grad_norm': 11.222241401672363, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.12s/it]                                               {'loss': 0.3208, 'grad_norm': 63.412845611572266, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.18s/it]                                               {'loss': 0.2971, 'grad_norm': 16.25849723815918, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.18s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.22s/it]                                               {'loss': 0.409, 'grad_norm': 11.685348510742188, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.22s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.4864, 'grad_norm': 47.03863525390625, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 5.6099, 'grad_norm': 62.02430725097656, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.06, 'grad_norm': 2.259483814239502, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.2717, 'grad_norm': 14.935833930969238, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it]                                               {'loss': 0.0722, 'grad_norm': 4.073925018310547, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it]                                               {'loss': 0.1923, 'grad_norm': 6.244747638702393, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it]                                               {'loss': 0.1313, 'grad_norm': 2.9161484241485596, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.4759, 'grad_norm': 3.8080296516418457, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.267, 'grad_norm': 2.759927749633789, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 1.6956, 'grad_norm': 52.06595230102539, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 80.2315, 'train_samples_per_second': 7.042, 'train_steps_per_second': 0.499, 'train_loss': 1.3173480725148692, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:0
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:43,  2.66s/it]                                              {'loss': 3.3368, 'grad_norm': 6.768348693847656, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:43,  2.66s/it]  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]                                              {'loss': 3.7229, 'grad_norm': 10.990416526794434, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]  8%|▊         | 3/40 [00:07<01:24,  2.29s/it]                                              {'loss': 2.4836, 'grad_norm': 13.690217018127441, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 3.7428, 'grad_norm': 19.386754989624023, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 2.6493, 'grad_norm': 19.319650650024414, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 2.0527, 'grad_norm': 15.433832168579102, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it]                                              {'loss': 1.52, 'grad_norm': 13.809720039367676, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 0.746, 'grad_norm': 37.42619323730469, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 0.4477, 'grad_norm': 6.939547538757324, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it]                                               {'loss': 1.5774, 'grad_norm': 16.18866539001465, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.4667, 'grad_norm': 9.447088241577148, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.3349, 'grad_norm': 4.711551189422607, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 1.0018, 'grad_norm': 8.29510498046875, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 0.7178, 'grad_norm': 6.644418239593506, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.9647, 'grad_norm': 5.799715995788574, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.951, 'grad_norm': 31.380422592163086, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.2267, 'grad_norm': 2.4158995151519775, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it]                                               {'loss': 0.4629, 'grad_norm': 10.765003204345703, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it]                                               {'loss': 0.1798, 'grad_norm': 3.473879814147949, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.4927, 'grad_norm': 7.299706935882568, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.2969, 'grad_norm': 3.4440903663635254, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.6159, 'grad_norm': 10.584260940551758, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.2126, 'grad_norm': 4.304959297180176, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0111, 'grad_norm': 1.293605923652649, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.2648, 'grad_norm': 11.355592727661133, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it]                                               {'loss': 0.1098, 'grad_norm': 3.4181292057037354, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.00s/it]                                               {'loss': 0.134, 'grad_norm': 5.522486686706543, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.00s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.0722, 'grad_norm': 1.7627003192901611, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.1933, 'grad_norm': 4.089269638061523, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.3039, 'grad_norm': 2.577223300933838, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.1987, 'grad_norm': 1.644665241241455, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0076, 'grad_norm': 0.4362281262874603, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.1015, 'grad_norm': 2.756699800491333, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.1683, 'grad_norm': 3.2307262420654297, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.3278, 'grad_norm': 5.392650127410889, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.08s/it]                                               {'loss': 0.3033, 'grad_norm': 4.628911018371582, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.08s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.13s/it]                                               {'loss': 0.1748, 'grad_norm': 3.630049705505371, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.13s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.16s/it]                                               {'loss': 0.0912, 'grad_norm': 2.1079301834106445, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.16s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]                                               {'loss': 0.0791, 'grad_norm': 2.3040859699249268, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'loss': 0.0226, 'grad_norm': 1.294689655303955, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'train_runtime': 79.4795, 'train_samples_per_second': 7.109, 'train_steps_per_second': 0.503, 'train_loss': 0.7941909281769768, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:73
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:33,  2.39s/it]                                              {'loss': 4.2935, 'grad_norm': 7.459324836730957, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:33,  2.39s/it]  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]                                              {'loss': 2.7978, 'grad_norm': 10.98713493347168, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 1.7118, 'grad_norm': 8.870174407958984, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 1.7304, 'grad_norm': 11.278376579284668, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 2.0745, 'grad_norm': 13.530793190002441, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 1.6502, 'grad_norm': 12.931017875671387, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it]                                              {'loss': 1.3323, 'grad_norm': 8.379840850830078, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 7.1703, 'grad_norm': 98.91061401367188, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 1.7797, 'grad_norm': 26.825536727905273, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 1.2074, 'grad_norm': 14.412179946899414, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 1.1387, 'grad_norm': 11.682939529418945, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.8844, 'grad_norm': 9.983142852783203, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 0.2418, 'grad_norm': 3.2885868549346924, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.7653, 'grad_norm': 7.072091102600098, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.615, 'grad_norm': 5.827179908752441, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0818, 'grad_norm': 3.1919498443603516, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.6893, 'grad_norm': 8.70757007598877, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.2404, 'grad_norm': 3.5398991107940674, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.1422, 'grad_norm': 2.3162753582000732, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.5034, 'grad_norm': 4.903311729431152, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.1644, 'grad_norm': 3.0898211002349854, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it]                                               {'loss': 0.2815, 'grad_norm': 3.1240079402923584, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.3708, 'grad_norm': 5.201395034790039, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.1606, 'grad_norm': 9.637036323547363, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.0188, 'grad_norm': 0.2564060389995575, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.1141, 'grad_norm': 1.7688571214675903, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.0737, 'grad_norm': 1.297852635383606, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.1789, 'grad_norm': 4.64481258392334, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.0962, 'grad_norm': 1.3610233068466187, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.1203, 'grad_norm': 2.09659743309021, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.044, 'grad_norm': 0.9157580733299255, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0807, 'grad_norm': 4.282853126525879, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0336, 'grad_norm': 1.2225689888000488, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it]                                               {'loss': 0.1929, 'grad_norm': 5.012526035308838, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.0197, 'grad_norm': 0.6517816781997681, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.013, 'grad_norm': 0.3313935697078705, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.0162, 'grad_norm': 0.4136699140071869, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0284, 'grad_norm': 0.5321475267410278, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.1608, 'grad_norm': 4.401880264282227, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.0046, 'grad_norm': 0.20784741640090942, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 79.9296, 'train_samples_per_second': 7.069, 'train_steps_per_second': 0.5, 'train_loss': 0.8305905655259267, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]100%|██████████| 40/40 [01:19<00:00,  2.00s/it]
CLIENT:88
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:40,  2.57s/it]                                              {'loss': 3.8748, 'grad_norm': 7.626030921936035, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:40,  2.57s/it]  5%|▌         | 2/40 [00:04<01:28,  2.33s/it]                                              {'loss': 2.0716, 'grad_norm': 7.435730457305908, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.33s/it]  8%|▊         | 3/40 [00:06<01:24,  2.29s/it]                                              {'loss': 2.7099, 'grad_norm': 15.376907348632812, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 2.9449, 'grad_norm': 13.768253326416016, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 2.4926, 'grad_norm': 12.044878959655762, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 2.0439, 'grad_norm': 20.073488235473633, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.8147, 'grad_norm': 16.713409423828125, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 1.2617, 'grad_norm': 44.32914352416992, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 0.8902, 'grad_norm': 9.927553176879883, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.8515, 'grad_norm': 18.044986724853516, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.6631, 'grad_norm': 10.31843090057373, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 1.0797, 'grad_norm': 10.397685050964355, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 0.9124, 'grad_norm': 7.4126105308532715, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.7374, 'grad_norm': 10.501420021057129, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.6441, 'grad_norm': 8.06524658203125, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.018, 'grad_norm': 0.9676467180252075, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.76s/it]                                               {'loss': 0.5794, 'grad_norm': 15.7003812789917, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it]                                               {'loss': 0.4754, 'grad_norm': 7.881540775299072, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.2457, 'grad_norm': 5.371562480926514, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:42,  2.11s/it]                                               {'loss': 0.3669, 'grad_norm': 4.172857761383057, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it]                                               {'loss': 0.1267, 'grad_norm': 1.9105740785598755, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 0.2856, 'grad_norm': 4.314909934997559, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.385, 'grad_norm': 2.762516975402832, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 1.0135, 'grad_norm': 47.66905975341797, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it]                                               {'loss': 0.2649, 'grad_norm': 5.534940242767334, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.0845, 'grad_norm': 2.382922649383545, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.3361, 'grad_norm': 5.692071914672852, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.12s/it]                                               {'loss': 0.1109, 'grad_norm': 2.221120595932007, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it]                                               {'loss': 0.0414, 'grad_norm': 1.3911610841751099, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.2619, 'grad_norm': 2.581486940383911, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.0503, 'grad_norm': 1.136661171913147, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0178, 'grad_norm': 1.181666374206543, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.78s/it]                                               {'loss': 0.0113, 'grad_norm': 0.2912062704563141, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.0227, 'grad_norm': 0.5150536298751831, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.0387, 'grad_norm': 1.7135720252990723, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it]                                               {'loss': 0.0578, 'grad_norm': 1.96733558177948, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 1.5408, 'grad_norm': 9.667359352111816, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0776, 'grad_norm': 2.39076828956604, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.0961, 'grad_norm': 5.086323261260986, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:20<00:00,  1.61s/it]                                               {'loss': 0.0148, 'grad_norm': 0.5213220119476318, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]                                               {'train_runtime': 80.3269, 'train_samples_per_second': 7.034, 'train_steps_per_second': 0.498, 'train_loss': 0.8129004382295534, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:68
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.20s/it]                                              {'loss': 2.5839, 'grad_norm': 6.290358066558838, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.20s/it]  5%|▌         | 2/40 [00:04<01:23,  2.19s/it]                                              {'loss': 3.5004, 'grad_norm': 8.364933967590332, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.19s/it]  8%|▊         | 3/40 [00:06<01:22,  2.22s/it]                                              {'loss': 2.3724, 'grad_norm': 11.468517303466797, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.22s/it] 10%|█         | 4/40 [00:08<01:19,  2.22s/it]                                              {'loss': 4.138, 'grad_norm': 12.142858505249023, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.22s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 2.4216, 'grad_norm': 20.857688903808594, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 3.1228, 'grad_norm': 11.21525764465332, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.9366, 'grad_norm': 13.173638343811035, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 1.7353, 'grad_norm': 52.40948486328125, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.79s/it]                                              {'loss': 1.1658, 'grad_norm': 11.960471153259277, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 0.7597, 'grad_norm': 5.237339019775391, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 1.6797, 'grad_norm': 10.998541831970215, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.07s/it]                                               {'loss': 0.6711, 'grad_norm': 6.844638347625732, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 0.3511, 'grad_norm': 3.6868221759796143, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 1.5502, 'grad_norm': 9.198413848876953, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it]                                               {'loss': 0.429, 'grad_norm': 4.175978660583496, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it] 40%|████      | 16/40 [00:31<00:38,  1.60s/it]                                               {'loss': 0.0192, 'grad_norm': 0.7326018214225769, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it]                                               {'loss': 0.2203, 'grad_norm': 14.634190559387207, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 0.5428, 'grad_norm': 6.6977458000183105, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it]                                               {'loss': 0.2655, 'grad_norm': 4.3861308097839355, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it] 50%|█████     | 20/40 [00:40<00:42,  2.12s/it]                                               {'loss': 0.1565, 'grad_norm': 2.9288740158081055, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 0.1453, 'grad_norm': 2.0229406356811523, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it]                                               {'loss': 0.1992, 'grad_norm': 2.656435489654541, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.2867, 'grad_norm': 3.610949754714966, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 4.4485, 'grad_norm': 86.55756378173828, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.0454, 'grad_norm': 0.7957944273948669, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.1082, 'grad_norm': 4.692112922668457, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it]                                               {'loss': 0.0617, 'grad_norm': 1.354027509689331, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it] 70%|███████   | 28/40 [00:56<00:25,  2.15s/it]                                               {'loss': 0.0926, 'grad_norm': 5.635338306427002, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.15s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.20s/it]                                               {'loss': 0.0541, 'grad_norm': 2.325085401535034, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.20s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it]                                               {'loss': 0.2799, 'grad_norm': 5.690406322479248, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.25s/it]                                               {'loss': 0.2482, 'grad_norm': 3.626129627227783, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.25s/it] 80%|████████  | 32/40 [01:04<00:13,  1.63s/it]                                               {'loss': 0.2396, 'grad_norm': 9.527915954589844, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it]                                               {'loss': 0.0249, 'grad_norm': 0.37624919414520264, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it] 85%|████████▌ | 34/40 [01:08<00:12,  2.01s/it]                                               {'loss': 0.0284, 'grad_norm': 1.6531121730804443, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:12,  2.01s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.11s/it]                                               {'loss': 0.0599, 'grad_norm': 1.3717267513275146, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.11s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.18s/it]                                               {'loss': 0.0502, 'grad_norm': 1.5455418825149536, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.18s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.21s/it]                                               {'loss': 0.0991, 'grad_norm': 2.89284348487854, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.21s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.24s/it]                                               {'loss': 0.049, 'grad_norm': 1.189663290977478, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.24s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.27s/it]                                               {'loss': 0.045, 'grad_norm': 0.7724015712738037, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.27s/it]100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'loss': 0.0322, 'grad_norm': 1.229382872581482, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'train_runtime': 80.9257, 'train_samples_per_second': 6.982, 'train_steps_per_second': 0.494, 'train_loss': 0.9304953854065389, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.65s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:59,  1.57it/s]  1%|          | 3/471 [00:02<07:02,  1.11it/s]  1%|          | 4/471 [00:03<08:09,  1.05s/it]  1%|          | 5/471 [00:05<08:47,  1.13s/it]  1%|▏         | 6/471 [00:06<09:10,  1.18s/it]  1%|▏         | 7/471 [00:07<09:25,  1.22s/it]  2%|▏         | 8/471 [00:09<09:36,  1.24s/it]  2%|▏         | 9/471 [00:10<09:42,  1.26s/it]  2%|▏         | 10/471 [00:11<09:46,  1.27s/it]  2%|▏         | 11/471 [00:12<09:48,  1.28s/it]  3%|▎         | 12/471 [00:14<09:51,  1.29s/it]  3%|▎         | 13/471 [00:15<09:52,  1.29s/it]  3%|▎         | 14/471 [00:16<09:53,  1.30s/it]  3%|▎         | 15/471 [00:18<09:53,  1.30s/it]  3%|▎         | 16/471 [00:19<09:53,  1.31s/it]  4%|▎         | 17/471 [00:20<09:53,  1.31s/it]  4%|▍         | 18/471 [00:22<09:54,  1.31s/it]  4%|▍         | 19/471 [00:23<09:53,  1.31s/it]  4%|▍         | 20/471 [00:24<09:53,  1.32s/it]  4%|▍         | 21/471 [00:26<09:52,  1.32s/it]  5%|▍         | 22/471 [00:27<09:52,  1.32s/it]  5%|▍         | 23/471 [00:28<09:51,  1.32s/it]  5%|▌         | 24/471 [00:30<09:51,  1.32s/it]  5%|▌         | 25/471 [00:31<09:50,  1.32s/it]  6%|▌         | 26/471 [00:32<09:50,  1.33s/it]  6%|▌         | 27/471 [00:34<09:49,  1.33s/it]  6%|▌         | 28/471 [00:35<09:48,  1.33s/it]  6%|▌         | 29/471 [00:36<09:47,  1.33s/it]  6%|▋         | 30/471 [00:38<09:47,  1.33s/it]  7%|▋         | 31/471 [00:39<09:46,  1.33s/it]  7%|▋         | 32/471 [00:40<09:45,  1.33s/it]  7%|▋         | 33/471 [00:42<09:43,  1.33s/it]  7%|▋         | 34/471 [00:43<09:41,  1.33s/it]  7%|▋         | 35/471 [00:44<09:42,  1.34s/it]  8%|▊         | 36/471 [00:46<09:41,  1.34s/it]  8%|▊         | 37/471 [00:47<09:40,  1.34s/it]  8%|▊         | 38/471 [00:48<09:40,  1.34s/it]  8%|▊         | 39/471 [00:50<09:39,  1.34s/it]  8%|▊         | 40/471 [00:51<09:39,  1.34s/it]  9%|▊         | 41/471 [00:52<09:38,  1.35s/it]  9%|▉         | 42/471 [00:54<09:38,  1.35s/it]  9%|▉         | 43/471 [00:55<09:34,  1.34s/it]  9%|▉         | 44/471 [00:56<09:34,  1.34s/it] 10%|▉         | 45/471 [00:58<09:33,  1.35s/it] 10%|▉         | 46/471 [00:59<09:31,  1.35s/it] 10%|▉         | 47/471 [01:00<09:30,  1.35s/it] 10%|█         | 48/471 [01:02<09:29,  1.35s/it] 10%|█         | 49/471 [01:03<09:28,  1.35s/it] 11%|█         | 50/471 [01:04<09:27,  1.35s/it] 11%|█         | 51/471 [01:06<09:27,  1.35s/it] 11%|█         | 52/471 [01:07<09:26,  1.35s/it] 11%|█▏        | 53/471 [01:08<09:25,  1.35s/it] 11%|█▏        | 54/471 [01:10<09:24,  1.35s/it] 12%|█▏        | 55/471 [01:11<09:23,  1.35s/it] 12%|█▏        | 56/471 [01:13<09:22,  1.36s/it] 12%|█▏        | 57/471 [01:14<09:20,  1.35s/it] 12%|█▏        | 58/471 [01:15<09:20,  1.36s/it] 13%|█▎        | 59/471 [01:17<09:18,  1.36s/it] 13%|█▎        | 60/471 [01:18<09:17,  1.36s/it] 13%|█▎        | 61/471 [01:19<09:15,  1.36s/it] 13%|█▎        | 62/471 [01:21<09:14,  1.36s/it] 13%|█▎        | 63/471 [01:22<09:12,  1.35s/it] 14%|█▎        | 64/471 [01:23<09:11,  1.35s/it] 14%|█▍        | 65/471 [01:25<09:09,  1.35s/it] 14%|█▍        | 66/471 [01:26<09:08,  1.35s/it] 14%|█▍        | 67/471 [01:27<09:07,  1.35s/it] 14%|█▍        | 68/471 [01:29<09:05,  1.35s/it] 15%|█▍        | 69/471 [01:30<09:04,  1.35s/it] 15%|█▍        | 70/471 [01:31<09:03,  1.35s/it] 15%|█▌        | 71/471 [01:33<09:02,  1.36s/it] 15%|█▌        | 72/471 [01:34<09:00,  1.35s/it] 15%|█▌        | 73/471 [01:36<08:58,  1.35s/it] 16%|█▌        | 74/471 [01:37<08:56,  1.35s/it] 16%|█▌        | 75/471 [01:38<08:55,  1.35s/it] 16%|█▌        | 76/471 [01:40<08:54,  1.35s/it] 16%|█▋        | 77/471 [01:41<08:53,  1.35s/it] 17%|█▋        | 78/471 [01:42<08:52,  1.35s/it] 17%|█▋        | 79/471 [01:44<08:50,  1.35s/it] 17%|█▋        | 80/471 [01:45<08:48,  1.35s/it] 17%|█▋        | 81/471 [01:46<08:46,  1.35s/it] 17%|█▋        | 82/471 [01:48<08:45,  1.35s/it] 18%|█▊        | 83/471 [01:49<08:44,  1.35s/it] 18%|█▊        | 84/471 [01:50<08:42,  1.35s/it] 18%|█▊        | 85/471 [01:52<08:41,  1.35s/it] 18%|█▊        | 86/471 [01:53<08:39,  1.35s/it] 18%|█▊        | 87/471 [01:54<08:38,  1.35s/it] 19%|█▊        | 88/471 [01:56<08:35,  1.35s/it] 19%|█▉        | 89/471 [01:57<08:34,  1.35s/it] 19%|█▉        | 90/471 [01:58<08:33,  1.35s/it] 19%|█▉        | 91/471 [02:00<08:31,  1.35s/it] 20%|█▉        | 92/471 [02:01<08:30,  1.35s/it] 20%|█▉        | 93/471 [02:03<08:29,  1.35s/it] 20%|█▉        | 94/471 [02:04<08:28,  1.35s/it] 20%|██        | 95/471 [02:05<08:26,  1.35s/it] 20%|██        | 96/471 [02:07<08:25,  1.35s/it] 21%|██        | 97/471 [02:08<08:24,  1.35s/it] 21%|██        | 98/471 [02:09<08:22,  1.35s/it] 21%|██        | 99/471 [02:11<08:20,  1.35s/it] 21%|██        | 100/471 [02:12<08:18,  1.34s/it] 21%|██▏       | 101/471 [02:13<08:17,  1.34s/it] 22%|██▏       | 102/471 [02:15<08:16,  1.34s/it] 22%|██▏       | 103/471 [02:16<08:14,  1.34s/it] 22%|██▏       | 104/471 [02:17<08:13,  1.34s/it] 22%|██▏       | 105/471 [02:19<08:12,  1.35s/it] 23%|██▎       | 106/471 [02:20<08:10,  1.34s/it] 23%|██▎       | 107/471 [02:21<08:08,  1.34s/it] 23%|██▎       | 108/471 [02:23<08:07,  1.34s/it] 23%|██▎       | 109/471 [02:24<08:05,  1.34s/it] 23%|██▎       | 110/471 [02:25<08:03,  1.34s/it] 24%|██▎       | 111/471 [02:27<08:02,  1.34s/it] 24%|██▍       | 112/471 [02:28<08:01,  1.34s/it] 24%|██▍       | 113/471 [02:29<07:59,  1.34s/it] 24%|██▍       | 114/471 [02:31<07:58,  1.34s/it] 24%|██▍       | 115/471 [02:32<07:57,  1.34s/it] 25%|██▍       | 116/471 [02:33<07:55,  1.34s/it] 25%|██▍       | 117/471 [02:35<07:54,  1.34s/it] 25%|██▌       | 118/471 [02:36<07:53,  1.34s/it] 25%|██▌       | 119/471 [02:37<07:51,  1.34s/it] 25%|██▌       | 120/471 [02:39<07:51,  1.34s/it] 26%|██▌       | 121/471 [02:40<07:49,  1.34s/it] 26%|██▌       | 122/471 [02:41<07:48,  1.34s/it] 26%|██▌       | 123/471 [02:43<07:46,  1.34s/it] 26%|██▋       | 124/471 [02:44<07:45,  1.34s/it] 27%|██▋       | 125/471 [02:46<07:44,  1.34s/it] 27%|██▋       | 126/471 [02:47<07:42,  1.34s/it] 27%|██▋       | 127/471 [02:48<07:41,  1.34s/it] 27%|██▋       | 128/471 [02:50<07:39,  1.34s/it] 27%|██▋       | 129/471 [02:51<07:37,  1.34s/it] 28%|██▊       | 130/471 [02:52<07:36,  1.34s/it] 28%|██▊       | 131/471 [02:54<07:35,  1.34s/it] 28%|██▊       | 132/471 [02:55<07:33,  1.34s/it] 28%|██▊       | 133/471 [02:56<07:32,  1.34s/it] 28%|██▊       | 134/471 [02:58<07:31,  1.34s/it] 29%|██▊       | 135/471 [02:59<07:29,  1.34s/it] 29%|██▉       | 136/471 [03:00<07:27,  1.34s/it] 29%|██▉       | 137/471 [03:02<07:26,  1.34s/it] 29%|██▉       | 138/471 [03:03<07:25,  1.34s/it] 30%|██▉       | 139/471 [03:04<07:24,  1.34s/it] 30%|██▉       | 140/471 [03:06<07:22,  1.34s/it] 30%|██▉       | 141/471 [03:07<07:20,  1.34s/it] 30%|███       | 142/471 [03:08<07:19,  1.34s/it] 30%|███       | 143/471 [03:10<07:17,  1.33s/it] 31%|███       | 144/471 [03:11<07:16,  1.34s/it] 31%|███       | 145/471 [03:12<07:14,  1.33s/it] 31%|███       | 146/471 [03:14<07:13,  1.33s/it] 31%|███       | 147/471 [03:15<07:12,  1.33s/it] 31%|███▏      | 148/471 [03:16<07:10,  1.33s/it] 32%|███▏      | 149/471 [03:18<07:10,  1.34s/it] 32%|███▏      | 150/471 [03:19<07:08,  1.34s/it] 32%|███▏      | 151/471 [03:20<07:07,  1.34s/it] 32%|███▏      | 152/471 [03:22<07:05,  1.33s/it] 32%|███▏      | 153/471 [03:23<07:04,  1.34s/it] 33%|███▎      | 154/471 [03:24<07:02,  1.33s/it] 33%|███▎      | 155/471 [03:26<07:02,  1.34s/it] 33%|███▎      | 156/471 [03:27<07:00,  1.33s/it] 33%|███▎      | 157/471 [03:28<06:58,  1.33s/it] 34%|███▎      | 158/471 [03:30<06:56,  1.33s/it] 34%|███▍      | 159/471 [03:31<06:54,  1.33s/it] 34%|███▍      | 160/471 [03:32<06:53,  1.33s/it] 34%|███▍      | 161/471 [03:34<06:52,  1.33s/it] 34%|███▍      | 162/471 [03:35<06:51,  1.33s/it] 35%|███▍      | 163/471 [03:36<06:49,  1.33s/it] 35%|███▍      | 164/471 [03:38<06:47,  1.33s/it] 35%|███▌      | 165/471 [03:39<06:46,  1.33s/it] 35%|███▌      | 166/471 [03:40<06:45,  1.33s/it] 35%|███▌      | 167/471 [03:42<06:44,  1.33s/it] 36%|███▌      | 168/471 [03:43<06:42,  1.33s/it] 36%|███▌      | 169/471 [03:44<06:41,  1.33s/it] 36%|███▌      | 170/471 [03:46<06:40,  1.33s/it] 36%|███▋      | 171/471 [03:47<06:38,  1.33s/it] 37%|███▋      | 172/471 [03:48<06:36,  1.33s/it] 37%|███▋      | 173/471 [03:50<06:35,  1.33s/it] 37%|███▋      | 174/471 [03:51<06:34,  1.33s/it] 37%|███▋      | 175/471 [03:52<06:33,  1.33s/it] 37%|███▋      | 176/471 [03:53<06:31,  1.33s/it] 38%|███▊      | 177/471 [03:55<06:30,  1.33s/it] 38%|███▊      | 178/471 [03:56<06:28,  1.33s/it] 38%|███▊      | 179/471 [03:57<06:27,  1.33s/it] 38%|███▊      | 180/471 [03:59<06:25,  1.33s/it] 38%|███▊      | 181/471 [04:00<06:24,  1.33s/it] 39%|███▊      | 182/471 [04:01<06:22,  1.33s/it] 39%|███▉      | 183/471 [04:03<06:21,  1.32s/it] 39%|███▉      | 184/471 [04:04<06:19,  1.32s/it] 39%|███▉      | 185/471 [04:05<06:18,  1.32s/it] 39%|███▉      | 186/471 [04:07<06:17,  1.33s/it] 40%|███▉      | 187/471 [04:08<06:16,  1.33s/it] 40%|███▉      | 188/471 [04:09<06:15,  1.33s/it] 40%|████      | 189/471 [04:11<06:13,  1.32s/it] 40%|████      | 190/471 [04:12<06:12,  1.32s/it] 41%|████      | 191/471 [04:13<06:10,  1.32s/it] 41%|████      | 192/471 [04:15<06:09,  1.32s/it] 41%|████      | 193/471 [04:16<06:07,  1.32s/it] 41%|████      | 194/471 [04:17<06:06,  1.32s/it] 41%|████▏     | 195/471 [04:19<06:05,  1.32s/it] 42%|████▏     | 196/471 [04:20<06:03,  1.32s/it] 42%|████▏     | 197/471 [04:21<06:01,  1.32s/it] 42%|████▏     | 198/471 [04:23<06:00,  1.32s/it] 42%|████▏     | 199/471 [04:24<05:59,  1.32s/it] 42%|████▏     | 200/471 [04:25<05:58,  1.32s/it] 43%|████▎     | 201/471 [04:27<05:56,  1.32s/it] 43%|████▎     | 202/471 [04:28<05:55,  1.32s/it] 43%|████▎     | 203/471 [04:29<05:53,  1.32s/it] 43%|████▎     | 204/471 [04:31<05:52,  1.32s/it] 44%|████▎     | 205/471 [04:32<05:50,  1.32s/it] 44%|████▎     | 206/471 [04:33<05:49,  1.32s/it] 44%|████▍     | 207/471 [04:34<05:48,  1.32s/it] 44%|████▍     | 208/471 [04:36<05:46,  1.32s/it] 44%|████▍     | 209/471 [04:37<05:44,  1.32s/it] 45%|████▍     | 210/471 [04:38<05:43,  1.32s/it] 45%|████▍     | 211/471 [04:40<05:42,  1.32s/it] 45%|████▌     | 212/471 [04:41<05:41,  1.32s/it] 45%|████▌     | 213/471 [04:42<05:40,  1.32s/it] 45%|████▌     | 214/471 [04:44<05:38,  1.32s/it] 46%|████▌     | 215/471 [04:45<05:37,  1.32s/it] 46%|████▌     | 216/471 [04:46<05:36,  1.32s/it] 46%|████▌     | 217/471 [04:48<05:35,  1.32s/it] 46%|████▋     | 218/471 [04:49<05:34,  1.32s/it] 46%|████▋     | 219/471 [04:50<05:33,  1.32s/it] 47%|████▋     | 220/471 [04:52<05:32,  1.32s/it] 47%|████▋     | 221/471 [04:53<05:30,  1.32s/it] 47%|████▋     | 222/471 [04:54<05:28,  1.32s/it] 47%|████▋     | 223/471 [04:56<05:27,  1.32s/it] 48%|████▊     | 224/471 [04:57<05:26,  1.32s/it] 48%|████▊     | 225/471 [04:58<05:25,  1.32s/it] 48%|████▊     | 226/471 [05:00<05:23,  1.32s/it] 48%|████▊     | 227/471 [05:01<05:22,  1.32s/it] 48%|████▊     | 228/471 [05:02<05:21,  1.32s/it] 49%|████▊     | 229/471 [05:04<05:20,  1.32s/it] 49%|████▉     | 230/471 [05:05<05:19,  1.32s/it] 49%|████▉     | 231/471 [05:06<05:17,  1.32s/it] 49%|████▉     | 232/471 [05:07<05:15,  1.32s/it] 49%|████▉     | 233/471 [05:09<05:14,  1.32s/it] 50%|████▉     | 234/471 [05:10<05:13,  1.32s/it] 50%|████▉     | 235/471 [05:11<05:12,  1.32s/it] 50%|█████     | 236/471 [05:13<05:10,  1.32s/it] 50%|█████     | 237/471 [05:14<05:09,  1.32s/it] 51%|█████     | 238/471 [05:15<05:08,  1.32s/it] 51%|█████     | 239/471 [05:17<05:07,  1.32s/it] 51%|█████     | 240/471 [05:18<05:06,  1.33s/it] 51%|█████     | 241/471 [05:19<05:05,  1.33s/it] 51%|█████▏    | 242/471 [05:21<05:03,  1.33s/it] 52%|█████▏    | 243/471 [05:22<05:02,  1.33s/it] 52%|█████▏    | 244/471 [05:23<05:01,  1.33s/it] 52%|█████▏    | 245/471 [05:25<05:00,  1.33s/it] 52%|█████▏    | 246/471 [05:26<04:58,  1.33s/it] 52%|█████▏    | 247/471 [05:27<04:57,  1.33s/it] 53%|█████▎    | 248/471 [05:29<04:56,  1.33s/it] 53%|█████▎    | 249/471 [05:30<04:55,  1.33s/it] 53%|█████▎    | 250/471 [05:31<04:54,  1.33s/it] 53%|█████▎    | 251/471 [05:33<04:52,  1.33s/it] 54%|█████▎    | 252/471 [05:34<04:51,  1.33s/it] 54%|█████▎    | 253/471 [05:35<04:50,  1.33s/it] 54%|█████▍    | 254/471 [05:37<04:48,  1.33s/it] 54%|█████▍    | 255/471 [05:38<04:47,  1.33s/it] 54%|█████▍    | 256/471 [05:39<04:46,  1.33s/it] 55%|█████▍    | 257/471 [05:41<04:45,  1.34s/it] 55%|█████▍    | 258/471 [05:42<04:44,  1.34s/it] 55%|█████▍    | 259/471 [05:43<04:43,  1.34s/it] 55%|█████▌    | 260/471 [05:45<04:42,  1.34s/it] 55%|█████▌    | 261/471 [05:46<04:40,  1.34s/it] 56%|█████▌    | 262/471 [05:47<04:39,  1.34s/it] 56%|█████▌    | 263/471 [05:49<04:38,  1.34s/it] 56%|█████▌    | 264/471 [05:50<04:36,  1.34s/it] 56%|█████▋    | 265/471 [05:51<04:35,  1.34s/it] 56%|█████▋    | 266/471 [05:53<04:34,  1.34s/it] 57%|█████▋    | 267/471 [05:54<04:33,  1.34s/it] 57%|█████▋    | 268/471 [05:55<04:32,  1.34s/it] 57%|█████▋    | 269/471 [05:57<04:30,  1.34s/it] 57%|█████▋    | 270/471 [05:58<04:29,  1.34s/it] 58%|█████▊    | 271/471 [05:59<04:27,  1.34s/it] 58%|█████▊    | 272/471 [06:01<04:25,  1.34s/it] 58%|█████▊    | 273/471 [06:02<04:24,  1.34s/it] 58%|█████▊    | 274/471 [06:03<04:23,  1.34s/it] 58%|█████▊    | 275/471 [06:05<04:21,  1.34s/it] 59%|█████▊    | 276/471 [06:06<04:20,  1.34s/it] 59%|█████▉    | 277/471 [06:07<04:19,  1.34s/it] 59%|█████▉    | 278/471 [06:09<04:18,  1.34s/it] 59%|█████▉    | 279/471 [06:10<04:16,  1.34s/it] 59%|█████▉    | 280/471 [06:11<04:15,  1.34s/it] 60%|█████▉    | 281/471 [06:13<04:14,  1.34s/it] 60%|█████▉    | 282/471 [06:14<04:12,  1.34s/it] 60%|██████    | 283/471 [06:16<04:11,  1.34s/it] 60%|██████    | 284/471 [06:17<04:10,  1.34s/it] 61%|██████    | 285/471 [06:18<04:09,  1.34s/it] 61%|██████    | 286/471 [06:20<04:07,  1.34s/it] 61%|██████    | 287/471 [06:21<04:06,  1.34s/it] 61%|██████    | 288/471 [06:22<04:05,  1.34s/it] 61%|██████▏   | 289/471 [06:24<04:03,  1.34s/it] 62%|██████▏   | 290/471 [06:25<04:01,  1.34s/it] 62%|██████▏   | 291/471 [06:26<04:00,  1.34s/it] 62%|██████▏   | 292/471 [06:28<03:59,  1.34s/it] 62%|██████▏   | 293/471 [06:29<03:57,  1.33s/it] 62%|██████▏   | 294/471 [06:30<03:56,  1.34s/it] 63%|██████▎   | 295/471 [06:32<03:55,  1.34s/it] 63%|██████▎   | 296/471 [06:33<03:53,  1.33s/it] 63%|██████▎   | 297/471 [06:34<03:52,  1.33s/it] 63%|██████▎   | 298/471 [06:36<03:51,  1.34s/it] 63%|██████▎   | 299/471 [06:37<03:49,  1.34s/it] 64%|██████▎   | 300/471 [06:38<03:48,  1.34s/it] 64%|██████▍   | 301/471 [06:40<03:47,  1.34s/it] 64%|██████▍   | 302/471 [06:41<03:45,  1.33s/it] 64%|██████▍   | 303/471 [06:42<03:43,  1.33s/it] 65%|██████▍   | 304/471 [06:44<03:42,  1.33s/it] 65%|██████▍   | 305/471 [06:45<03:41,  1.33s/it] 65%|██████▍   | 306/471 [06:46<03:40,  1.33s/it] 65%|██████▌   | 307/471 [06:48<03:38,  1.33s/it] 65%|██████▌   | 308/471 [06:49<03:37,  1.34s/it] 66%|██████▌   | 309/471 [06:50<03:36,  1.33s/it] 66%|██████▌   | 310/471 [06:52<03:34,  1.33s/it] 66%|██████▌   | 311/471 [06:53<03:33,  1.33s/it] 66%|██████▌   | 312/471 [06:54<03:32,  1.33s/it] 66%|██████▋   | 313/471 [06:56<03:30,  1.33s/it] 67%|██████▋   | 314/471 [06:57<03:29,  1.33s/it] 67%|██████▋   | 315/471 [06:58<03:28,  1.33s/it] 67%|██████▋   | 316/471 [07:00<03:26,  1.33s/it] 67%|██████▋   | 317/471 [07:01<03:25,  1.33s/it] 68%|██████▊   | 318/471 [07:02<03:24,  1.33s/it] 68%|██████▊   | 319/471 [07:04<03:22,  1.33s/it] 68%|██████▊   | 320/471 [07:05<03:21,  1.33s/it] 68%|██████▊   | 321/471 [07:06<03:20,  1.33s/it] 68%|██████▊   | 322/471 [07:08<03:18,  1.33s/it] 69%|██████▊   | 323/471 [07:09<03:17,  1.34s/it] 69%|██████▉   | 324/471 [07:10<03:16,  1.34s/it] 69%|██████▉   | 325/471 [07:12<03:15,  1.34s/it] 69%|██████▉   | 326/471 [07:13<03:13,  1.34s/it] 69%|██████▉   | 327/471 [07:14<03:11,  1.33s/it] 70%|██████▉   | 328/471 [07:16<03:10,  1.33s/it] 70%|██████▉   | 329/471 [07:17<03:09,  1.33s/it] 70%|███████   | 330/471 [07:18<03:08,  1.33s/it] 70%|███████   | 331/471 [07:20<03:06,  1.33s/it] 70%|███████   | 332/471 [07:21<03:05,  1.34s/it] 71%|███████   | 333/471 [07:22<03:04,  1.33s/it] 71%|███████   | 334/471 [07:24<03:02,  1.33s/it] 71%|███████   | 335/471 [07:25<03:01,  1.34s/it] 71%|███████▏  | 336/471 [07:26<03:00,  1.33s/it] 72%|███████▏  | 337/471 [07:28<02:58,  1.33s/it] 72%|███████▏  | 338/471 [07:29<02:56,  1.33s/it] 72%|███████▏  | 339/471 [07:30<02:55,  1.33s/it] 72%|███████▏  | 340/471 [07:32<02:54,  1.33s/it] 72%|███████▏  | 341/471 [07:33<02:52,  1.33s/it] 73%|███████▎  | 342/471 [07:34<02:51,  1.33s/it] 73%|███████▎  | 343/471 [07:36<02:50,  1.33s/it] 73%|███████▎  | 344/471 [07:37<02:48,  1.33s/it] 73%|███████▎  | 345/471 [07:38<02:47,  1.33s/it] 73%|███████▎  | 346/471 [07:40<02:46,  1.33s/it] 74%|███████▎  | 347/471 [07:41<02:44,  1.33s/it] 74%|███████▍  | 348/471 [07:42<02:43,  1.33s/it] 74%|███████▍  | 349/471 [07:44<02:42,  1.33s/it] 74%|███████▍  | 350/471 [07:45<02:40,  1.33s/it] 75%|███████▍  | 351/471 [07:46<02:39,  1.33s/it] 75%|███████▍  | 352/471 [07:48<02:38,  1.33s/it] 75%|███████▍  | 353/471 [07:49<02:37,  1.33s/it] 75%|███████▌  | 354/471 [07:50<02:35,  1.33s/it] 75%|███████▌  | 355/471 [07:52<02:34,  1.33s/it] 76%|███████▌  | 356/471 [07:53<02:32,  1.33s/it] 76%|███████▌  | 357/471 [07:54<02:31,  1.33s/it] 76%|███████▌  | 358/471 [07:56<02:30,  1.33s/it] 76%|███████▌  | 359/471 [07:57<02:28,  1.33s/it] 76%|███████▋  | 360/471 [07:58<02:27,  1.33s/it] 77%|███████▋  | 361/471 [07:59<02:26,  1.33s/it] 77%|███████▋  | 362/471 [08:01<02:24,  1.33s/it] 77%|███████▋  | 363/471 [08:02<02:23,  1.33s/it] 77%|███████▋  | 364/471 [08:03<02:22,  1.33s/it] 77%|███████▋  | 365/471 [08:05<02:21,  1.33s/it] 78%|███████▊  | 366/471 [08:06<02:19,  1.33s/it] 78%|███████▊  | 367/471 [08:07<02:18,  1.33s/it] 78%|███████▊  | 368/471 [08:09<02:17,  1.33s/it] 78%|███████▊  | 369/471 [08:10<02:15,  1.33s/it] 79%|███████▊  | 370/471 [08:11<02:14,  1.33s/it] 79%|███████▉  | 371/471 [08:13<02:13,  1.33s/it] 79%|███████▉  | 372/471 [08:14<02:11,  1.33s/it] 79%|███████▉  | 373/471 [08:15<02:10,  1.33s/it] 79%|███████▉  | 374/471 [08:17<02:08,  1.33s/it] 80%|███████▉  | 375/471 [08:18<02:07,  1.33s/it] 80%|███████▉  | 376/471 [08:19<02:06,  1.33s/it] 80%|████████  | 377/471 [08:21<02:04,  1.33s/it] 80%|████████  | 378/471 [08:22<02:03,  1.33s/it] 80%|████████  | 379/471 [08:23<02:02,  1.33s/it] 81%|████████  | 380/471 [08:25<02:00,  1.33s/it] 81%|████████  | 381/471 [08:26<01:59,  1.33s/it] 81%|████████  | 382/471 [08:27<01:58,  1.33s/it] 81%|████████▏ | 383/471 [08:29<01:57,  1.33s/it] 82%|████████▏ | 384/471 [08:30<01:56,  1.33s/it] 82%|████████▏ | 385/471 [08:31<01:54,  1.33s/it] 82%|████████▏ | 386/471 [08:33<01:53,  1.33s/it] 82%|████████▏ | 387/471 [08:34<01:51,  1.33s/it] 82%|████████▏ | 388/471 [08:35<01:50,  1.33s/it] 83%|████████▎ | 389/471 [08:37<01:49,  1.33s/it] 83%|████████▎ | 390/471 [08:38<01:47,  1.33s/it] 83%|████████▎ | 391/471 [08:39<01:46,  1.33s/it] 83%|████████▎ | 392/471 [08:41<01:45,  1.33s/it] 83%|████████▎ | 393/471 [08:42<01:43,  1.33s/it] 84%|████████▎ | 394/471 [08:43<01:42,  1.33s/it] 84%|████████▍ | 395/471 [08:45<01:41,  1.33s/it] 84%|████████▍ | 396/471 [08:46<01:39,  1.33s/it] 84%|████████▍ | 397/471 [08:47<01:38,  1.33s/it] 85%|████████▍ | 398/471 [08:49<01:37,  1.33s/it] 85%|████████▍ | 399/471 [08:50<01:35,  1.33s/it] 85%|████████▍ | 400/471 [08:51<01:34,  1.33s/it] 85%|████████▌ | 401/471 [08:53<01:33,  1.33s/it] 85%|████████▌ | 402/471 [08:54<01:31,  1.33s/it] 86%|████████▌ | 403/471 [08:55<01:30,  1.33s/it] 86%|████████▌ | 404/471 [08:57<01:28,  1.33s/it] 86%|████████▌ | 405/471 [08:58<01:27,  1.33s/it] 86%|████████▌ | 406/471 [08:59<01:26,  1.33s/it] 86%|████████▋ | 407/471 [09:01<01:24,  1.32s/it] 87%|████████▋ | 408/471 [09:02<01:23,  1.33s/it] 87%|████████▋ | 409/471 [09:03<01:22,  1.33s/it] 87%|████████▋ | 410/471 [09:05<01:20,  1.33s/it] 87%|████████▋ | 411/471 [09:06<01:19,  1.32s/it] 87%|████████▋ | 412/471 [09:07<01:18,  1.33s/it] 88%|████████▊ | 413/471 [09:09<01:16,  1.33s/it] 88%|████████▊ | 414/471 [09:10<01:15,  1.33s/it] 88%|████████▊ | 415/471 [09:11<01:14,  1.32s/it] 88%|████████▊ | 416/471 [09:13<01:13,  1.33s/it] 89%|████████▊ | 417/471 [09:14<01:11,  1.33s/it] 89%|████████▊ | 418/471 [09:15<01:10,  1.33s/it] 89%|████████▉ | 419/471 [09:17<01:08,  1.33s/it] 89%|████████▉ | 420/471 [09:18<01:07,  1.32s/it] 89%|████████▉ | 421/471 [09:19<01:06,  1.32s/it] 90%|████████▉ | 422/471 [09:21<01:04,  1.32s/it] 90%|████████▉ | 423/471 [09:22<01:03,  1.32s/it] 90%|█████████ | 424/471 [09:23<01:02,  1.32s/it] 90%|█████████ | 425/471 [09:24<01:00,  1.32s/it] 90%|█████████ | 426/471 [09:26<00:59,  1.32s/it] 91%|█████████ | 427/471 [09:27<00:58,  1.32s/it] 91%|█████████ | 428/471 [09:28<00:56,  1.32s/it] 91%|█████████ | 429/471 [09:30<00:55,  1.32s/it] 91%|█████████▏| 430/471 [09:31<00:54,  1.32s/it] 92%|█████████▏| 431/471 [09:32<00:53,  1.33s/it] 92%|█████████▏| 432/471 [09:34<00:51,  1.32s/it] 92%|█████████▏| 433/471 [09:35<00:50,  1.32s/it] 92%|█████████▏| 434/471 [09:36<00:49,  1.33s/it] 92%|█████████▏| 435/471 [09:38<00:47,  1.33s/it] 93%|█████████▎| 436/471 [09:39<00:46,  1.33s/it] 93%|█████████▎| 437/471 [09:40<00:45,  1.33s/it] 93%|█████████▎| 438/471 [09:42<00:43,  1.33s/it] 93%|█████████▎| 439/471 [09:43<00:42,  1.32s/it] 93%|█████████▎| 440/471 [09:44<00:41,  1.32s/it] 94%|█████████▎| 441/471 [09:46<00:39,  1.32s/it] 94%|█████████▍| 442/471 [09:47<00:38,  1.32s/it] 94%|█████████▍| 443/471 [09:48<00:37,  1.32s/it] 94%|█████████▍| 444/471 [09:50<00:35,  1.32s/it] 94%|█████████▍| 445/471 [09:51<00:34,  1.32s/it] 95%|█████████▍| 446/471 [09:52<00:33,  1.32s/it] 95%|█████████▍| 447/471 [09:54<00:31,  1.32s/it] 95%|█████████▌| 448/471 [09:55<00:30,  1.32s/it] 95%|█████████▌| 449/471 [09:56<00:29,  1.32s/it] 96%|█████████▌| 450/471 [09:58<00:27,  1.32s/it] 96%|█████████▌| 451/471 [09:59<00:26,  1.32s/it] 96%|█████████▌| 452/471 [10:00<00:25,  1.32s/it] 96%|█████████▌| 453/471 [10:02<00:23,  1.33s/it] 96%|█████████▋| 454/471 [10:03<00:22,  1.33s/it] 97%|█████████▋| 455/471 [10:04<00:21,  1.33s/it] 97%|█████████▋| 456/471 [10:06<00:19,  1.33s/it] 97%|█████████▋| 457/471 [10:07<00:18,  1.33s/it] 97%|█████████▋| 458/471 [10:08<00:17,  1.33s/it] 97%|█████████▋| 459/471 [10:10<00:15,  1.33s/it] 98%|█████████▊| 460/471 [10:11<00:14,  1.33s/it] 98%|█████████▊| 461/471 [10:12<00:13,  1.33s/it] 98%|█████████▊| 462/471 [10:14<00:11,  1.33s/it] 98%|█████████▊| 463/471 [10:15<00:10,  1.33s/it] 99%|█████████▊| 464/471 [10:16<00:09,  1.33s/it] 99%|█████████▊| 465/471 [10:18<00:07,  1.33s/it] 99%|█████████▉| 466/471 [10:19<00:06,  1.33s/it] 99%|█████████▉| 467/471 [10:20<00:05,  1.33s/it] 99%|█████████▉| 468/471 [10:22<00:04,  1.33s/it]100%|█████████▉| 469/471 [10:23<00:02,  1.33s/it]100%|█████████▉| 470/471 [10:24<00:01,  1.34s/it]100%|██████████| 471/471 [10:25<00:00,  1.22s/it]100%|██████████| 471/471 [10:25<00:00,  1.33s/it]
{'eval_loss': 3.615696430206299, 'eval_model_preparation_time': 0.0137, 'eval_acc': 0.2254381306425916, 'eval_runtime': 626.9351, 'eval_samples_per_second': 12.014, 'eval_steps_per_second': 0.751}
ROUND:10
CLIENT:26
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:29,  2.29s/it]                                              {'loss': 2.827, 'grad_norm': 6.680347442626953, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:29,  2.29s/it]  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]                                              {'loss': 3.2912, 'grad_norm': 10.762677192687988, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 3.4682, 'grad_norm': 15.888894081115723, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 1.8096, 'grad_norm': 22.8033504486084, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it]                                              {'loss': 4.621, 'grad_norm': 20.582969665527344, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 1.8085, 'grad_norm': 15.138023376464844, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 2.302, 'grad_norm': 16.618532180786133, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 5.2712, 'grad_norm': 51.67198181152344, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 1.3372, 'grad_norm': 16.930822372436523, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 1.2639, 'grad_norm': 12.51466178894043, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.04s/it]                                               {'loss': 0.7012, 'grad_norm': 9.462565422058105, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.04s/it] 30%|███       | 12/40 [00:24<00:58,  2.10s/it]                                               {'loss': 0.9641, 'grad_norm': 8.124557495117188, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.10s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 1.1503, 'grad_norm': 5.616444110870361, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 1.0672, 'grad_norm': 7.126889228820801, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 1.2564, 'grad_norm': 10.767017364501953, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.0807, 'grad_norm': 5.700789451599121, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it]                                               {'loss': 0.4579, 'grad_norm': 6.32415771484375, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.5877, 'grad_norm': 7.003879070281982, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.317, 'grad_norm': 4.577205657958984, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.5658, 'grad_norm': 9.313434600830078, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it]                                               {'loss': 0.4558, 'grad_norm': 4.989093780517578, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.3544, 'grad_norm': 3.4026498794555664, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.4164, 'grad_norm': 4.517055511474609, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.1066, 'grad_norm': 5.314397811889648, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it]                                               {'loss': 0.5368, 'grad_norm': 5.931619644165039, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.1762, 'grad_norm': 3.7481374740600586, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it]                                               {'loss': 0.168, 'grad_norm': 4.755359649658203, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.0896, 'grad_norm': 2.313462972640991, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.14s/it]                                               {'loss': 0.1816, 'grad_norm': 4.076265811920166, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.0754, 'grad_norm': 1.3221720457077026, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.1493, 'grad_norm': 2.9465160369873047, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.0167, 'grad_norm': 1.0941696166992188, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.0472, 'grad_norm': 0.8180450201034546, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it]                                               {'loss': 0.1549, 'grad_norm': 3.347013473510742, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it]                                               {'loss': 0.0621, 'grad_norm': 1.904334306716919, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.3471, 'grad_norm': 5.232540607452393, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.0835, 'grad_norm': 4.119001388549805, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.0944, 'grad_norm': 1.864954948425293, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.25s/it]                                               {'loss': 0.098, 'grad_norm': 1.6477992534637451, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.25s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.0022, 'grad_norm': 0.16309630870819092, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.3494, 'train_samples_per_second': 7.032, 'train_steps_per_second': 0.498, 'train_loss': 0.9691042529302649, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:40,  2.59s/it]                                              {'loss': 3.1321, 'grad_norm': 7.2876667976379395, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:40,  2.59s/it]  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]                                              {'loss': 2.9556, 'grad_norm': 9.722976684570312, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]  8%|▊         | 3/40 [00:07<01:25,  2.30s/it]                                              {'loss': 2.7553, 'grad_norm': 11.314756393432617, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.30s/it] 10%|█         | 4/40 [00:09<01:21,  2.27s/it]                                              {'loss': 3.7425, 'grad_norm': 15.935500144958496, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.27s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 3.6964, 'grad_norm': 19.42150115966797, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 3.3972, 'grad_norm': 18.349889755249023, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it]                                              {'loss': 2.6724, 'grad_norm': 16.37701988220215, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it] 20%|██        | 8/40 [00:16<00:50,  1.59s/it]                                              {'loss': 2.1421, 'grad_norm': 30.92192268371582, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 1.0269, 'grad_norm': 10.784025192260742, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 1.0666, 'grad_norm': 9.605411529541016, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it]                                               {'loss': 0.5583, 'grad_norm': 8.552629470825195, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it] 30%|███       | 12/40 [00:25<00:58,  2.10s/it]                                               {'loss': 0.338, 'grad_norm': 3.872724771499634, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.10s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.15s/it]                                               {'loss': 1.2079, 'grad_norm': 11.684429168701172, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.15s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 0.9745, 'grad_norm': 10.616628646850586, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it]                                               {'loss': 0.9433, 'grad_norm': 7.074609279632568, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it] 40%|████      | 16/40 [00:32<00:38,  1.59s/it]                                               {'loss': 0.0293, 'grad_norm': 1.420951247215271, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.80s/it]                                               {'loss': 0.1227, 'grad_norm': 2.2010183334350586, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 0.5682, 'grad_norm': 5.41053581237793, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.3226, 'grad_norm': 1.98154616355896, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:41<00:42,  2.10s/it]                                               {'loss': 0.1938, 'grad_norm': 4.160346031188965, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 0.3074, 'grad_norm': 7.65837287902832, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.16, 'grad_norm': 4.929883003234863, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.1622, 'grad_norm': 1.1076384782791138, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:48<00:25,  1.61s/it]                                               {'loss': 0.2311, 'grad_norm': 7.159298896789551, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.0555, 'grad_norm': 0.8535773158073425, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.145, 'grad_norm': 12.751931190490723, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.0545, 'grad_norm': 0.6820175647735596, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.1513, 'grad_norm': 2.152500629425049, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it]                                               {'loss': 0.1199, 'grad_norm': 3.6050333976745605, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.0282, 'grad_norm': 0.5731700658798218, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.23s/it]                                               {'loss': 0.0535, 'grad_norm': 1.4211355447769165, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.23s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.017, 'grad_norm': 1.0757083892822266, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.0195, 'grad_norm': 0.46112334728240967, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.1833, 'grad_norm': 4.471362113952637, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it]                                               {'loss': 0.0183, 'grad_norm': 0.48463693261146545, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it]                                               {'loss': 0.0555, 'grad_norm': 1.2879087924957275, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it]                                               {'loss': 0.0322, 'grad_norm': 0.9247168302536011, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.027, 'grad_norm': 1.3214255571365356, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]                                               {'loss': 0.0217, 'grad_norm': 0.6535476446151733, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.0589, 'grad_norm': 3.0476443767547607, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.6669, 'train_samples_per_second': 7.004, 'train_steps_per_second': 0.496, 'train_loss': 0.8437016594689339, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:45,  2.71s/it]                                              {'loss': 3.1177, 'grad_norm': 9.253117561340332, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:45,  2.71s/it]  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]                                              {'loss': 2.862, 'grad_norm': 9.883235931396484, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]  8%|▊         | 3/40 [00:07<01:25,  2.31s/it]                                              {'loss': 1.6039, 'grad_norm': 10.163310050964355, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.31s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 4.3504, 'grad_norm': 30.204326629638672, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 1.7099, 'grad_norm': 13.747093200683594, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 1.7371, 'grad_norm': 15.401827812194824, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 2.8096, 'grad_norm': 12.484167098999023, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 0.1158, 'grad_norm': 7.416870594024658, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 0.5759, 'grad_norm': 4.302176475524902, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it]                                               {'loss': 0.6455, 'grad_norm': 7.798817157745361, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 0.8734, 'grad_norm': 9.528249740600586, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.662, 'grad_norm': 6.376965522766113, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 0.9076, 'grad_norm': 6.363945007324219, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 0.4673, 'grad_norm': 5.6043806076049805, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 1.0408, 'grad_norm': 7.770002365112305, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.8248, 'grad_norm': 37.13166809082031, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.5003, 'grad_norm': 5.5210771560668945, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it]                                               {'loss': 0.1269, 'grad_norm': 3.461785078048706, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.3228, 'grad_norm': 4.198576927185059, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.3825, 'grad_norm': 4.02047061920166, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.2824, 'grad_norm': 1.0826512575149536, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it]                                               {'loss': 0.9771, 'grad_norm': 4.9052252769470215, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.2998, 'grad_norm': 5.797584533691406, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.1799, 'grad_norm': 13.810205459594727, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it]                                               {'loss': 0.4022, 'grad_norm': 2.1935763359069824, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.04, 'grad_norm': 0.9363553524017334, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 1.1376, 'grad_norm': 19.56822967529297, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.1276, 'grad_norm': 5.458493232727051, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.6479, 'grad_norm': 4.922170162200928, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it]                                               {'loss': 0.064, 'grad_norm': 1.6477808952331543, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.22s/it]                                               {'loss': 0.0862, 'grad_norm': 2.354322671890259, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.0509, 'grad_norm': 2.831094264984131, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.0129, 'grad_norm': 0.2970001697540283, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it]                                               {'loss': 0.0156, 'grad_norm': 0.41294971108436584, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.2197, 'grad_norm': 2.754457950592041, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.0275, 'grad_norm': 0.6521264910697937, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.0439, 'grad_norm': 2.4176626205444336, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.2397, 'grad_norm': 3.138762950897217, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.4181, 'grad_norm': 1.9579734802246094, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.01, 'grad_norm': 0.8263393640518188, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 80.253, 'train_samples_per_second': 7.04, 'train_steps_per_second': 0.498, 'train_loss': 0.7729784917784854, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:86
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:43,  2.65s/it]                                              {'loss': 3.1278, 'grad_norm': 5.745880603790283, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:43,  2.65s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 2.5939, 'grad_norm': 11.17653751373291, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:23,  2.27s/it]                                              {'loss': 2.6288, 'grad_norm': 12.824743270874023, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.27s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 1.7572, 'grad_norm': 13.329280853271484, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 3.0162, 'grad_norm': 22.08602523803711, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 3.6394, 'grad_norm': 34.367401123046875, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it]                                              {'loss': 3.2128, 'grad_norm': 31.857776641845703, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 5.2552, 'grad_norm': 67.5986557006836, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 0.7416, 'grad_norm': 9.772290229797363, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.7135, 'grad_norm': 4.967580318450928, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 1.6299, 'grad_norm': 13.520695686340332, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.4262, 'grad_norm': 4.381904125213623, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 1.6038, 'grad_norm': 8.955429077148438, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 1.4485, 'grad_norm': 10.38716983795166, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 1.5293, 'grad_norm': 16.49738883972168, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.1042, 'grad_norm': 4.294524192810059, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.1382, 'grad_norm': 3.076388120651245, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.91s/it]                                               {'loss': 0.1442, 'grad_norm': 5.410574913024902, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it]                                               {'loss': 0.9341, 'grad_norm': 2.332470417022705, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.3943, 'grad_norm': 2.2535393238067627, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.1112, 'grad_norm': 2.3756370544433594, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it]                                               {'loss': 0.1265, 'grad_norm': 2.736360788345337, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.4043, 'grad_norm': 4.892054557800293, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0491, 'grad_norm': 2.5977001190185547, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.027, 'grad_norm': 0.582131564617157, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it]                                               {'loss': 0.4832, 'grad_norm': 2.1984262466430664, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.0636, 'grad_norm': 1.1501715183258057, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.0849, 'grad_norm': 1.3942216634750366, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.4114, 'grad_norm': 5.297090530395508, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.2509, 'grad_norm': 1.9866557121276855, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.0489, 'grad_norm': 1.0166540145874023, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.4261, 'grad_norm': 24.030492782592773, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it]                                               {'loss': 0.0236, 'grad_norm': 0.8461471796035767, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it]                                               {'loss': 0.2341, 'grad_norm': 1.391434669494629, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.1772, 'grad_norm': 1.0065524578094482, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.0264, 'grad_norm': 0.7529999613761902, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.1597, 'grad_norm': 2.616591691970825, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it]                                               {'loss': 0.0214, 'grad_norm': 0.6605598330497742, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.0286, 'grad_norm': 0.9978061318397522, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0002, 'grad_norm': 0.012756282463669777, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.8937, 'train_samples_per_second': 7.072, 'train_steps_per_second': 0.501, 'train_loss': 0.9549360337507096, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  2.00s/it]
CLIENT:76
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.63s/it]                                              {'loss': 4.8073, 'grad_norm': 7.728133201599121, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.63s/it]  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]                                              {'loss': 2.6472, 'grad_norm': 11.603914260864258, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]  8%|▊         | 3/40 [00:06<01:23,  2.25s/it]                                              {'loss': 2.9034, 'grad_norm': 10.770942687988281, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.25s/it] 10%|█         | 4/40 [00:09<01:19,  2.22s/it]                                              {'loss': 2.4935, 'grad_norm': 13.652698516845703, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:19,  2.22s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 2.4992, 'grad_norm': 25.032962799072266, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 2.3528, 'grad_norm': 15.363658905029297, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 1.7236, 'grad_norm': 17.04376983642578, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 1.7596, 'grad_norm': 53.87271499633789, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 1.5199, 'grad_norm': 23.048696517944336, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 1.1066, 'grad_norm': 11.613649368286133, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 0.8141, 'grad_norm': 8.448929786682129, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.9618, 'grad_norm': 6.146169185638428, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 0.5701, 'grad_norm': 8.316827774047852, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it]                                               {'loss': 1.0038, 'grad_norm': 6.2539777755737305, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.9667, 'grad_norm': 8.012130737304688, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.0451, 'grad_norm': 1.820277452468872, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.1431, 'grad_norm': 2.3272705078125, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it]                                               {'loss': 0.2444, 'grad_norm': 3.135939598083496, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.08s/it]                                               {'loss': 0.1816, 'grad_norm': 2.534121036529541, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.08s/it] 50%|█████     | 20/40 [00:40<00:42,  2.12s/it]                                               {'loss': 0.3515, 'grad_norm': 4.372682094573975, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it]                                               {'loss': 0.0617, 'grad_norm': 0.8645312190055847, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.7562, 'grad_norm': 17.754899978637695, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.8807, 'grad_norm': 8.45117473602295, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0034, 'grad_norm': 0.15125031769275665, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0922, 'grad_norm': 1.6327255964279175, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it]                                               {'loss': 0.0708, 'grad_norm': 1.184017300605774, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.0555, 'grad_norm': 1.0281916856765747, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.1212, 'grad_norm': 1.9493331909179688, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.3356, 'grad_norm': 6.308967113494873, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.0826, 'grad_norm': 1.6272902488708496, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.6133, 'grad_norm': 21.207857131958008, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0687, 'grad_norm': 4.1568098068237305, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0345, 'grad_norm': 0.803250253200531, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it]                                               {'loss': 0.3235, 'grad_norm': 9.174817085266113, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.3274, 'grad_norm': 18.309797286987305, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.0587, 'grad_norm': 1.6970323324203491, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it]                                               {'loss': 0.0567, 'grad_norm': 1.1948370933532715, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.1194, 'grad_norm': 2.6296839714050293, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]                                               {'loss': 0.0122, 'grad_norm': 0.2153320610523224, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.0011, 'grad_norm': 0.06488370150327682, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 80.0289, 'train_samples_per_second': 7.06, 'train_steps_per_second': 0.5, 'train_loss': 0.8292714251700091, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:14
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:35,  2.45s/it]                                              {'loss': 2.8539, 'grad_norm': 9.432840347290039, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:35,  2.45s/it]  5%|▌         | 2/40 [00:04<01:27,  2.30s/it]                                              {'loss': 1.54, 'grad_norm': 7.3874831199646, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:27,  2.30s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 2.5374, 'grad_norm': 12.766317367553711, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 3.3828, 'grad_norm': 18.5260066986084, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 3.1373, 'grad_norm': 20.7613582611084, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 2.4133, 'grad_norm': 14.784524917602539, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it]                                              {'loss': 3.1206, 'grad_norm': 21.6697998046875, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 1.4092, 'grad_norm': 86.97232818603516, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 1.5059, 'grad_norm': 9.625499725341797, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it]                                               {'loss': 1.2185, 'grad_norm': 7.716531753540039, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.932, 'grad_norm': 9.185790061950684, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.07s/it]                                               {'loss': 0.8564, 'grad_norm': 3.6472408771514893, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 2.0369, 'grad_norm': 12.292617797851562, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 0.5754, 'grad_norm': 5.225111484527588, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it]                                               {'loss': 1.0003, 'grad_norm': 8.030077934265137, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it] 40%|████      | 16/40 [00:31<00:38,  1.60s/it]                                               {'loss': 0.0134, 'grad_norm': 0.7779549360275269, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.471, 'grad_norm': 5.692951679229736, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.2204, 'grad_norm': 1.859536051750183, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.05s/it]                                               {'loss': 0.5395, 'grad_norm': 5.015802383422852, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.05s/it] 50%|█████     | 20/40 [00:40<00:42,  2.12s/it]                                               {'loss': 0.2347, 'grad_norm': 2.9371533393859863, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 0.3814, 'grad_norm': 15.844437599182129, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it]                                               {'loss': 0.8496, 'grad_norm': 4.70216178894043, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.5399, 'grad_norm': 5.354978084564209, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.0137, 'grad_norm': 0.8155320882797241, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it]                                               {'loss': 0.0704, 'grad_norm': 1.0909162759780884, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.1017, 'grad_norm': 1.6161962747573853, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it]                                               {'loss': 0.2246, 'grad_norm': 3.8141157627105713, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it] 70%|███████   | 28/40 [00:57<00:25,  2.14s/it]                                               {'loss': 0.1476, 'grad_norm': 2.9524831771850586, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it]                                               {'loss': 0.152, 'grad_norm': 1.0113065242767334, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.22s/it]                                               {'loss': 0.0894, 'grad_norm': 1.3676315546035767, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.22s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it]                                               {'loss': 0.0596, 'grad_norm': 1.2926756143569946, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it] 80%|████████  | 32/40 [01:04<00:13,  1.65s/it]                                               {'loss': 0.9736, 'grad_norm': 33.02409744262695, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.65s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.85s/it]                                               {'loss': 0.0395, 'grad_norm': 0.870872437953949, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.85s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.99s/it]                                               {'loss': 0.0346, 'grad_norm': 1.3342245817184448, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.99s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it]                                               {'loss': 0.0389, 'grad_norm': 1.0612916946411133, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it]                                               {'loss': 0.0582, 'grad_norm': 1.4764834642410278, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.0486, 'grad_norm': 1.2343205213546753, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.21s/it]                                               {'loss': 0.3554, 'grad_norm': 2.6350760459899902, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]                                               {'loss': 0.0411, 'grad_norm': 1.441853404045105, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.0454, 'grad_norm': 3.2216720581054688, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.8012, 'train_samples_per_second': 6.992, 'train_steps_per_second': 0.495, 'train_loss': 0.8566050721099601, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:88
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:41,  2.59s/it]                                              {'loss': 3.6786, 'grad_norm': 8.070982933044434, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:41,  2.59s/it]  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]                                              {'loss': 1.8767, 'grad_norm': 8.00650691986084, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]  8%|▊         | 3/40 [00:06<01:24,  2.28s/it]                                              {'loss': 2.2804, 'grad_norm': 14.686366081237793, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:21,  2.25s/it]                                              {'loss': 2.642, 'grad_norm': 14.70259952545166, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 2.3677, 'grad_norm': 14.714034080505371, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 1.6196, 'grad_norm': 14.530686378479004, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it]                                              {'loss': 2.2036, 'grad_norm': 18.414466857910156, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.7242, 'grad_norm': 38.30472946166992, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 0.984, 'grad_norm': 9.187411308288574, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.6452, 'grad_norm': 8.072206497192383, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 0.4698, 'grad_norm': 6.576623439788818, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 1.0004, 'grad_norm': 15.818648338317871, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 0.9843, 'grad_norm': 6.1295366287231445, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 0.6654, 'grad_norm': 4.923435211181641, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.5552, 'grad_norm': 7.668181896209717, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0488, 'grad_norm': 2.945209264755249, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.8674, 'grad_norm': 7.982945442199707, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it]                                               {'loss': 0.7863, 'grad_norm': 13.17129898071289, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.1807, 'grad_norm': 4.780516147613525, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.1347, 'grad_norm': 1.7554717063903809, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.1926, 'grad_norm': 2.9494004249572754, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.3083, 'grad_norm': 5.521473407745361, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.4069, 'grad_norm': 4.118072032928467, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0792, 'grad_norm': 5.908020496368408, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.1307, 'grad_norm': 1.6060833930969238, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.93s/it]                                               {'loss': 0.1469, 'grad_norm': 2.652353286743164, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.2029, 'grad_norm': 1.7111319303512573, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.046, 'grad_norm': 5.36728048324585, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.0557, 'grad_norm': 1.5764108896255493, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.17s/it]                                               {'loss': 0.3535, 'grad_norm': 17.467336654663086, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.0242, 'grad_norm': 0.6372665762901306, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0014, 'grad_norm': 0.09652213007211685, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.76s/it]                                               {'loss': 0.0284, 'grad_norm': 0.6175134181976318, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.76s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it]                                               {'loss': 0.0874, 'grad_norm': 1.6961239576339722, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.013, 'grad_norm': 0.4480917453765869, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.5155, 'grad_norm': 4.230081558227539, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.3866, 'grad_norm': 3.80964994430542, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it]                                               {'loss': 0.1639, 'grad_norm': 5.111392974853516, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.0895, 'grad_norm': 2.867377996444702, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.9798, 'grad_norm': 24.449188232421875, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.7775, 'train_samples_per_second': 7.082, 'train_steps_per_second': 0.501, 'train_loss': 0.7231824334972771, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:48
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:47,  2.75s/it]                                              {'loss': 3.1713, 'grad_norm': 6.921006202697754, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:47,  2.75s/it]  5%|▌         | 2/40 [00:04<01:31,  2.41s/it]                                              {'loss': 3.3744, 'grad_norm': 7.678565979003906, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:31,  2.41s/it]  8%|▊         | 3/40 [00:07<01:24,  2.28s/it]                                              {'loss': 3.4761, 'grad_norm': 10.652605056762695, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:20,  2.25s/it]                                              {'loss': 2.6706, 'grad_norm': 12.256919860839844, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 2.504, 'grad_norm': 13.470717430114746, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 3.6816, 'grad_norm': 23.335582733154297, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.8236, 'grad_norm': 25.691722869873047, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 4.2081, 'grad_norm': 87.10795593261719, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 1.0259, 'grad_norm': 9.431682586669922, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.9223, 'grad_norm': 10.696587562561035, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.4896, 'grad_norm': 12.879607200622559, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:25<00:58,  2.08s/it]                                               {'loss': 0.6619, 'grad_norm': 5.8221845626831055, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 0.9396, 'grad_norm': 5.683765888214111, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 1.2742, 'grad_norm': 6.493582248687744, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 1.2687, 'grad_norm': 7.599370956420898, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.9688, 'grad_norm': 23.02955436706543, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it]                                               {'loss': 0.3047, 'grad_norm': 3.556349754333496, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.136, 'grad_norm': 3.0522964000701904, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:44,  2.12s/it]                                               {'loss': 0.4306, 'grad_norm': 5.76268196105957, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:44,  2.12s/it] 50%|█████     | 20/40 [00:41<00:43,  2.16s/it]                                               {'loss': 0.4079, 'grad_norm': 5.22221565246582, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:43,  2.16s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it]                                               {'loss': 0.2431, 'grad_norm': 2.8764171600341797, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.22s/it]                                               {'loss': 0.3183, 'grad_norm': 3.298511028289795, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.22s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.22s/it]                                               {'loss': 0.605, 'grad_norm': 5.2746758460998535, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.22s/it] 60%|██████    | 24/40 [00:48<00:25,  1.61s/it]                                               {'loss': 0.0132, 'grad_norm': 0.6185488104820251, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.0604, 'grad_norm': 2.137108564376831, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.1454, 'grad_norm': 2.8959178924560547, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it]                                               {'loss': 0.0656, 'grad_norm': 1.7966084480285645, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.11s/it]                                               {'loss': 0.1356, 'grad_norm': 1.5517196655273438, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it]                                               {'loss': 0.0807, 'grad_norm': 1.6998143196105957, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.1226, 'grad_norm': 2.0171608924865723, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.23s/it]                                               {'loss': 0.3274, 'grad_norm': 5.534204483032227, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.23s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.0052, 'grad_norm': 0.23518306016921997, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.0586, 'grad_norm': 0.8698951601982117, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.0269, 'grad_norm': 0.7577740550041199, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it]                                               {'loss': 0.0307, 'grad_norm': 0.566963791847229, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it]                                               {'loss': 0.0285, 'grad_norm': 0.8017516136169434, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it]                                               {'loss': 0.0164, 'grad_norm': 0.3487142324447632, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.21s/it]                                               {'loss': 0.139, 'grad_norm': 5.233426094055176, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.0505, 'grad_norm': 1.9733378887176514, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.0019, 'grad_norm': 0.10568616539239883, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.8633, 'train_samples_per_second': 6.987, 'train_steps_per_second': 0.495, 'train_loss': 0.9553754944528918, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:71
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:31,  2.34s/it]                                              {'loss': 2.7197, 'grad_norm': 6.7039475440979, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:31,  2.34s/it]  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]                                              {'loss': 2.6439, 'grad_norm': 9.109803199768066, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]  8%|▊         | 3/40 [00:06<01:22,  2.22s/it]                                              {'loss': 2.4366, 'grad_norm': 12.342455863952637, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.22s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 2.1311, 'grad_norm': 17.737995147705078, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it]                                              {'loss': 1.4369, 'grad_norm': 14.950472831726074, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 2.3213, 'grad_norm': 12.776008605957031, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 1.9756, 'grad_norm': 15.8533353805542, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.3596, 'grad_norm': 15.737752914428711, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.77s/it]                                              {'loss': 1.2947, 'grad_norm': 9.732978820800781, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 0.7382, 'grad_norm': 5.623111724853516, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.3585, 'grad_norm': 3.71083927154541, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.8731, 'grad_norm': 9.930537223815918, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 0.8025, 'grad_norm': 5.4504852294921875, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.4756, 'grad_norm': 5.612494945526123, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.3484, 'grad_norm': 4.7537126541137695, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.2143, 'grad_norm': 10.517062187194824, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it]                                               {'loss': 0.2755, 'grad_norm': 7.5843119621276855, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 0.2334, 'grad_norm': 5.498730182647705, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.1255, 'grad_norm': 3.459937572479248, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.3957, 'grad_norm': 8.98730754852295, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.2841, 'grad_norm': 3.0675480365753174, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it]                                               {'loss': 0.4404, 'grad_norm': 3.256052255630493, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.1429, 'grad_norm': 2.4234189987182617, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0983, 'grad_norm': 4.084689140319824, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it]                                               {'loss': 0.0361, 'grad_norm': 0.7624984979629517, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.0825, 'grad_norm': 1.5148605108261108, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.0434, 'grad_norm': 1.4386738538742065, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.0458, 'grad_norm': 1.4263672828674316, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.1705, 'grad_norm': 2.8024230003356934, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.3718, 'grad_norm': 3.7636966705322266, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.0548, 'grad_norm': 1.1712214946746826, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 1.3842, 'grad_norm': 28.920503616333008, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it]                                               {'loss': 0.0206, 'grad_norm': 0.44213342666625977, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.0418, 'grad_norm': 1.3804744482040405, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.0205, 'grad_norm': 0.5701581239700317, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.5757, 'grad_norm': 26.778074264526367, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.0744, 'grad_norm': 1.0269535779953003, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0415, 'grad_norm': 0.8853527307510376, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.1197, 'grad_norm': 3.238227367401123, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0202, 'grad_norm': 0.7515832781791687, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.0028, 'train_samples_per_second': 7.062, 'train_steps_per_second': 0.5, 'train_loss': 0.6557282106019556, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:67
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]                                              {'loss': 3.5548, 'grad_norm': 8.302948951721191, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]  5%|▌         | 2/40 [00:04<01:30,  2.38s/it]                                              {'loss': 1.9193, 'grad_norm': 9.472240447998047, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.38s/it]  8%|▊         | 3/40 [00:07<01:25,  2.31s/it]                                              {'loss': 1.5729, 'grad_norm': 9.075627326965332, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.31s/it] 10%|█         | 4/40 [00:09<01:21,  2.25s/it]                                              {'loss': 3.043, 'grad_norm': 15.386019706726074, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 2.6228, 'grad_norm': 18.095935821533203, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 1.5675, 'grad_norm': 16.25918960571289, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.4713, 'grad_norm': 19.722362518310547, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 1.254, 'grad_norm': 44.50013732910156, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 1.76, 'grad_norm': 19.06690788269043, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 0.8997, 'grad_norm': 11.187302589416504, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.5011, 'grad_norm': 7.761084079742432, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.6778, 'grad_norm': 6.699617862701416, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it]                                               {'loss': 1.5849, 'grad_norm': 14.33630657196045, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.6887, 'grad_norm': 5.911483287811279, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.5006, 'grad_norm': 4.651303291320801, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 1.5145, 'grad_norm': 46.22026062011719, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it]                                               {'loss': 0.3956, 'grad_norm': 12.562264442443848, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.3907, 'grad_norm': 5.875359535217285, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:44,  2.14s/it]                                               {'loss': 0.403, 'grad_norm': 7.006686210632324, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:44,  2.14s/it] 50%|█████     | 20/40 [00:41<00:43,  2.18s/it]                                               {'loss': 0.1651, 'grad_norm': 3.7090823650360107, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:43,  2.18s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it]                                               {'loss': 0.1316, 'grad_norm': 2.895569324493408, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.22s/it]                                               {'loss': 0.9331, 'grad_norm': 5.343231201171875, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.22s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it]                                               {'loss': 0.4213, 'grad_norm': 5.778599262237549, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it] 60%|██████    | 24/40 [00:48<00:25,  1.62s/it]                                               {'loss': 0.0384, 'grad_norm': 1.7876993417739868, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.1112, 'grad_norm': 3.9861040115356445, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.5147, 'grad_norm': 6.922013282775879, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it]                                               {'loss': 0.1941, 'grad_norm': 4.4002366065979, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.13s/it]                                               {'loss': 0.3472, 'grad_norm': 6.57839298248291, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.13s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.1221, 'grad_norm': 2.71520733833313, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.2027, 'grad_norm': 3.5281214714050293, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it]                                               {'loss': 0.1693, 'grad_norm': 54.81010437011719, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it] 80%|████████  | 32/40 [01:04<00:12,  1.61s/it]                                               {'loss': 0.4624, 'grad_norm': 40.48981475830078, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it]                                               {'loss': 0.1072, 'grad_norm': 5.5642852783203125, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.0796, 'grad_norm': 2.2154905796051025, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.06s/it]                                               {'loss': 0.0676, 'grad_norm': 1.2608293294906616, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it]                                               {'loss': 0.2262, 'grad_norm': 8.634232521057129, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it]                                               {'loss': 0.2418, 'grad_norm': 4.777626991271973, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.23s/it]                                               {'loss': 0.0685, 'grad_norm': 2.0942089557647705, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.23s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]                                               {'loss': 0.1742, 'grad_norm': 3.649764060974121, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 2.6401, 'grad_norm': 9675.7236328125, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.7896, 'train_samples_per_second': 6.993, 'train_steps_per_second': 0.495, 'train_loss': 0.8685139850713313, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:58,  1.57it/s]  1%|          | 3/471 [00:02<07:03,  1.10it/s]  1%|          | 4/471 [00:03<08:10,  1.05s/it]  1%|          | 5/471 [00:05<08:47,  1.13s/it]  1%|▏         | 6/471 [00:06<09:10,  1.18s/it]  1%|▏         | 7/471 [00:07<09:26,  1.22s/it]  2%|▏         | 8/471 [00:09<09:35,  1.24s/it]  2%|▏         | 9/471 [00:10<09:41,  1.26s/it]  2%|▏         | 10/471 [00:11<09:45,  1.27s/it]  2%|▏         | 11/471 [00:12<09:47,  1.28s/it]  3%|▎         | 12/471 [00:14<09:49,  1.28s/it]  3%|▎         | 13/471 [00:15<09:51,  1.29s/it]  3%|▎         | 14/471 [00:16<09:51,  1.29s/it]  3%|▎         | 15/471 [00:18<09:51,  1.30s/it]  3%|▎         | 16/471 [00:19<09:52,  1.30s/it]  4%|▎         | 17/471 [00:20<09:52,  1.30s/it]  4%|▍         | 18/471 [00:22<09:51,  1.31s/it]  4%|▍         | 19/471 [00:23<09:50,  1.31s/it]  4%|▍         | 20/471 [00:24<09:50,  1.31s/it]  4%|▍         | 21/471 [00:25<09:49,  1.31s/it]  5%|▍         | 22/471 [00:27<09:49,  1.31s/it]  5%|▍         | 23/471 [00:28<09:48,  1.31s/it]  5%|▌         | 24/471 [00:29<09:47,  1.31s/it]  5%|▌         | 25/471 [00:31<09:46,  1.31s/it]  6%|▌         | 26/471 [00:32<09:45,  1.32s/it]  6%|▌         | 27/471 [00:33<09:44,  1.32s/it]  6%|▌         | 28/471 [00:35<09:43,  1.32s/it]  6%|▌         | 29/471 [00:36<09:42,  1.32s/it]  6%|▋         | 30/471 [00:37<09:42,  1.32s/it]  7%|▋         | 31/471 [00:39<09:40,  1.32s/it]  7%|▋         | 32/471 [00:40<09:39,  1.32s/it]  7%|▋         | 33/471 [00:41<09:36,  1.32s/it]  7%|▋         | 34/471 [00:43<09:35,  1.32s/it]  7%|▋         | 35/471 [00:44<09:35,  1.32s/it]  8%|▊         | 36/471 [00:45<09:33,  1.32s/it]  8%|▊         | 37/471 [00:47<09:33,  1.32s/it]  8%|▊         | 38/471 [00:48<09:33,  1.32s/it]  8%|▊         | 39/471 [00:49<09:31,  1.32s/it]  8%|▊         | 40/471 [00:51<09:30,  1.32s/it]  9%|▊         | 41/471 [00:52<09:29,  1.32s/it]  9%|▉         | 42/471 [00:53<09:28,  1.33s/it]  9%|▉         | 43/471 [00:55<09:27,  1.32s/it]  9%|▉         | 44/471 [00:56<09:25,  1.33s/it] 10%|▉         | 45/471 [00:57<09:25,  1.33s/it] 10%|▉         | 46/471 [00:59<09:23,  1.33s/it] 10%|▉         | 47/471 [01:00<09:22,  1.33s/it] 10%|█         | 48/471 [01:01<09:21,  1.33s/it] 10%|█         | 49/471 [01:02<09:20,  1.33s/it] 11%|█         | 50/471 [01:04<09:19,  1.33s/it] 11%|█         | 51/471 [01:05<09:18,  1.33s/it] 11%|█         | 52/471 [01:06<09:17,  1.33s/it] 11%|█▏        | 53/471 [01:08<09:17,  1.33s/it] 11%|█▏        | 54/471 [01:09<09:15,  1.33s/it] 12%|█▏        | 55/471 [01:10<09:13,  1.33s/it] 12%|█▏        | 56/471 [01:12<09:13,  1.33s/it] 12%|█▏        | 57/471 [01:13<09:11,  1.33s/it] 12%|█▏        | 58/471 [01:14<09:10,  1.33s/it] 13%|█▎        | 59/471 [01:16<09:09,  1.33s/it] 13%|█▎        | 60/471 [01:17<09:07,  1.33s/it] 13%|█▎        | 61/471 [01:18<09:06,  1.33s/it] 13%|█▎        | 62/471 [01:20<09:04,  1.33s/it] 13%|█▎        | 63/471 [01:21<09:03,  1.33s/it] 14%|█▎        | 64/471 [01:22<09:02,  1.33s/it] 14%|█▍        | 65/471 [01:24<09:00,  1.33s/it] 14%|█▍        | 66/471 [01:25<08:59,  1.33s/it] 14%|█▍        | 67/471 [01:26<08:56,  1.33s/it] 14%|█▍        | 68/471 [01:28<08:55,  1.33s/it] 15%|█▍        | 69/471 [01:29<08:54,  1.33s/it] 15%|█▍        | 70/471 [01:30<08:54,  1.33s/it] 15%|█▌        | 71/471 [01:32<08:53,  1.33s/it] 15%|█▌        | 72/471 [01:33<08:51,  1.33s/it] 15%|█▌        | 73/471 [01:34<08:50,  1.33s/it] 16%|█▌        | 74/471 [01:36<08:48,  1.33s/it] 16%|█▌        | 75/471 [01:37<08:47,  1.33s/it] 16%|█▌        | 76/471 [01:38<08:45,  1.33s/it] 16%|█▋        | 77/471 [01:40<08:44,  1.33s/it] 17%|█▋        | 78/471 [01:41<08:42,  1.33s/it] 17%|█▋        | 79/471 [01:42<08:41,  1.33s/it] 17%|█▋        | 80/471 [01:44<08:40,  1.33s/it] 17%|█▋        | 81/471 [01:45<08:38,  1.33s/it] 17%|█▋        | 82/471 [01:46<08:36,  1.33s/it] 18%|█▊        | 83/471 [01:48<08:36,  1.33s/it] 18%|█▊        | 84/471 [01:49<08:34,  1.33s/it] 18%|█▊        | 85/471 [01:50<08:33,  1.33s/it] 18%|█▊        | 86/471 [01:52<08:32,  1.33s/it] 18%|█▊        | 87/471 [01:53<08:30,  1.33s/it] 19%|█▊        | 88/471 [01:54<08:29,  1.33s/it] 19%|█▉        | 89/471 [01:56<08:27,  1.33s/it] 19%|█▉        | 90/471 [01:57<08:27,  1.33s/it] 19%|█▉        | 91/471 [01:58<08:25,  1.33s/it] 20%|█▉        | 92/471 [02:00<08:24,  1.33s/it] 20%|█▉        | 93/471 [02:01<08:22,  1.33s/it] 20%|█▉        | 94/471 [02:02<08:21,  1.33s/it] 20%|██        | 95/471 [02:04<08:20,  1.33s/it] 20%|██        | 96/471 [02:05<08:18,  1.33s/it] 21%|██        | 97/471 [02:06<08:18,  1.33s/it] 21%|██        | 98/471 [02:08<08:16,  1.33s/it] 21%|██        | 99/471 [02:09<08:14,  1.33s/it] 21%|██        | 100/471 [02:10<08:13,  1.33s/it] 21%|██▏       | 101/471 [02:12<08:12,  1.33s/it] 22%|██▏       | 102/471 [02:13<08:11,  1.33s/it] 22%|██▏       | 103/471 [02:14<08:10,  1.33s/it] 22%|██▏       | 104/471 [02:16<08:10,  1.34s/it] 22%|██▏       | 105/471 [02:17<08:08,  1.34s/it] 23%|██▎       | 106/471 [02:18<08:06,  1.33s/it] 23%|██▎       | 107/471 [02:20<08:05,  1.33s/it] 23%|██▎       | 108/471 [02:21<08:03,  1.33s/it] 23%|██▎       | 109/471 [02:22<08:01,  1.33s/it] 23%|██▎       | 110/471 [02:24<07:59,  1.33s/it] 24%|██▎       | 111/471 [02:25<07:58,  1.33s/it] 24%|██▍       | 112/471 [02:26<07:57,  1.33s/it] 24%|██▍       | 113/471 [02:28<07:55,  1.33s/it] 24%|██▍       | 114/471 [02:29<07:55,  1.33s/it] 24%|██▍       | 115/471 [02:30<07:54,  1.33s/it] 25%|██▍       | 116/471 [02:32<07:52,  1.33s/it] 25%|██▍       | 117/471 [02:33<07:51,  1.33s/it] 25%|██▌       | 118/471 [02:34<07:50,  1.33s/it] 25%|██▌       | 119/471 [02:36<07:48,  1.33s/it] 25%|██▌       | 120/471 [02:37<07:48,  1.33s/it] 26%|██▌       | 121/471 [02:38<07:46,  1.33s/it] 26%|██▌       | 122/471 [02:40<07:44,  1.33s/it] 26%|██▌       | 123/471 [02:41<07:43,  1.33s/it] 26%|██▋       | 124/471 [02:42<07:42,  1.33s/it] 27%|██▋       | 125/471 [02:44<07:40,  1.33s/it] 27%|██▋       | 126/471 [02:45<07:39,  1.33s/it] 27%|██▋       | 127/471 [02:46<07:38,  1.33s/it] 27%|██▋       | 128/471 [02:48<07:36,  1.33s/it] 27%|██▋       | 129/471 [02:49<07:34,  1.33s/it] 28%|██▊       | 130/471 [02:50<07:33,  1.33s/it] 28%|██▊       | 131/471 [02:52<07:32,  1.33s/it] 28%|██▊       | 132/471 [02:53<07:31,  1.33s/it] 28%|██▊       | 133/471 [02:54<07:29,  1.33s/it] 28%|██▊       | 134/471 [02:56<07:29,  1.33s/it] 29%|██▊       | 135/471 [02:57<07:27,  1.33s/it] 29%|██▉       | 136/471 [02:58<07:26,  1.33s/it] 29%|██▉       | 137/471 [03:00<07:25,  1.33s/it] 29%|██▉       | 138/471 [03:01<07:23,  1.33s/it] 30%|██▉       | 139/471 [03:02<07:22,  1.33s/it] 30%|██▉       | 140/471 [03:04<07:20,  1.33s/it] 30%|██▉       | 141/471 [03:05<07:18,  1.33s/it] 30%|███       | 142/471 [03:06<07:17,  1.33s/it] 30%|███       | 143/471 [03:08<07:15,  1.33s/it] 31%|███       | 144/471 [03:09<07:14,  1.33s/it] 31%|███       | 145/471 [03:10<07:12,  1.33s/it] 31%|███       | 146/471 [03:12<07:12,  1.33s/it] 31%|███       | 147/471 [03:13<07:11,  1.33s/it] 31%|███▏      | 148/471 [03:14<07:10,  1.33s/it] 32%|███▏      | 149/471 [03:16<07:09,  1.33s/it] 32%|███▏      | 150/471 [03:17<07:08,  1.33s/it] 32%|███▏      | 151/471 [03:18<07:06,  1.33s/it] 32%|███▏      | 152/471 [03:20<07:05,  1.33s/it] 32%|███▏      | 153/471 [03:21<07:03,  1.33s/it] 33%|███▎      | 154/471 [03:22<07:01,  1.33s/it] 33%|███▎      | 155/471 [03:24<07:00,  1.33s/it] 33%|███▎      | 156/471 [03:25<06:58,  1.33s/it] 33%|███▎      | 157/471 [03:26<06:57,  1.33s/it] 34%|███▎      | 158/471 [03:28<06:55,  1.33s/it] 34%|███▍      | 159/471 [03:29<06:54,  1.33s/it] 34%|███▍      | 160/471 [03:30<06:53,  1.33s/it] 34%|███▍      | 161/471 [03:32<06:52,  1.33s/it] 34%|███▍      | 162/471 [03:33<06:51,  1.33s/it] 35%|███▍      | 163/471 [03:34<06:50,  1.33s/it] 35%|███▍      | 164/471 [03:36<06:48,  1.33s/it] 35%|███▌      | 165/471 [03:37<06:47,  1.33s/it] 35%|███▌      | 166/471 [03:38<06:46,  1.33s/it] 35%|███▌      | 167/471 [03:40<06:45,  1.33s/it] 36%|███▌      | 168/471 [03:41<06:44,  1.33s/it] 36%|███▌      | 169/471 [03:42<06:43,  1.34s/it] 36%|███▌      | 170/471 [03:44<06:41,  1.33s/it] 36%|███▋      | 171/471 [03:45<06:39,  1.33s/it] 37%|███▋      | 172/471 [03:46<06:38,  1.33s/it] 37%|███▋      | 173/471 [03:48<06:37,  1.33s/it] 37%|███▋      | 174/471 [03:49<06:36,  1.33s/it] 37%|███▋      | 175/471 [03:50<06:35,  1.34s/it] 37%|███▋      | 176/471 [03:52<06:33,  1.33s/it] 38%|███▊      | 177/471 [03:53<06:32,  1.34s/it] 38%|███▊      | 178/471 [03:54<06:31,  1.34s/it] 38%|███▊      | 179/471 [03:56<06:29,  1.34s/it] 38%|███▊      | 180/471 [03:57<06:28,  1.34s/it] 38%|███▊      | 181/471 [03:58<06:27,  1.34s/it] 39%|███▊      | 182/471 [04:00<06:26,  1.34s/it] 39%|███▉      | 183/471 [04:01<06:25,  1.34s/it] 39%|███▉      | 184/471 [04:02<06:23,  1.34s/it] 39%|███▉      | 185/471 [04:04<06:22,  1.34s/it] 39%|███▉      | 186/471 [04:05<06:21,  1.34s/it] 40%|███▉      | 187/471 [04:06<06:20,  1.34s/it] 40%|███▉      | 188/471 [04:08<06:19,  1.34s/it] 40%|████      | 189/471 [04:09<06:17,  1.34s/it] 40%|████      | 190/471 [04:10<06:15,  1.34s/it] 41%|████      | 191/471 [04:12<06:15,  1.34s/it] 41%|████      | 192/471 [04:13<06:13,  1.34s/it] 41%|████      | 193/471 [04:14<06:11,  1.34s/it] 41%|████      | 194/471 [04:16<06:10,  1.34s/it] 41%|████▏     | 195/471 [04:17<06:10,  1.34s/it] 42%|████▏     | 196/471 [04:18<06:08,  1.34s/it] 42%|████▏     | 197/471 [04:20<06:06,  1.34s/it] 42%|████▏     | 198/471 [04:21<06:05,  1.34s/it] 42%|████▏     | 199/471 [04:22<06:04,  1.34s/it] 42%|████▏     | 200/471 [04:24<06:03,  1.34s/it] 43%|████▎     | 201/471 [04:25<06:00,  1.34s/it] 43%|████▎     | 202/471 [04:26<06:00,  1.34s/it] 43%|████▎     | 203/471 [04:28<05:59,  1.34s/it] 43%|████▎     | 204/471 [04:29<05:57,  1.34s/it] 44%|████▎     | 205/471 [04:30<05:56,  1.34s/it] 44%|████▎     | 206/471 [04:32<05:54,  1.34s/it] 44%|████▍     | 207/471 [04:33<05:53,  1.34s/it] 44%|████▍     | 208/471 [04:34<05:51,  1.34s/it] 44%|████▍     | 209/471 [04:36<05:50,  1.34s/it] 45%|████▍     | 210/471 [04:37<05:49,  1.34s/it] 45%|████▍     | 211/471 [04:38<05:48,  1.34s/it] 45%|████▌     | 212/471 [04:40<05:46,  1.34s/it] 45%|████▌     | 213/471 [04:41<05:45,  1.34s/it] 45%|████▌     | 214/471 [04:42<05:44,  1.34s/it] 46%|████▌     | 215/471 [04:44<05:42,  1.34s/it] 46%|████▌     | 216/471 [04:45<05:41,  1.34s/it] 46%|████▌     | 217/471 [04:47<05:41,  1.34s/it] 46%|████▋     | 218/471 [04:48<05:39,  1.34s/it] 46%|████▋     | 219/471 [04:49<05:38,  1.34s/it] 47%|████▋     | 220/471 [04:51<05:37,  1.34s/it] 47%|████▋     | 221/471 [04:52<05:36,  1.34s/it] 47%|████▋     | 222/471 [04:53<05:34,  1.34s/it] 47%|████▋     | 223/471 [04:55<05:32,  1.34s/it] 48%|████▊     | 224/471 [04:56<05:32,  1.34s/it] 48%|████▊     | 225/471 [04:57<05:30,  1.34s/it] 48%|████▊     | 226/471 [04:59<05:29,  1.35s/it] 48%|████▊     | 227/471 [05:00<05:28,  1.34s/it] 48%|████▊     | 228/471 [05:01<05:26,  1.34s/it] 49%|████▊     | 229/471 [05:03<05:25,  1.35s/it] 49%|████▉     | 230/471 [05:04<05:24,  1.35s/it] 49%|████▉     | 231/471 [05:05<05:22,  1.34s/it] 49%|████▉     | 232/471 [05:07<05:20,  1.34s/it] 49%|████▉     | 233/471 [05:08<05:19,  1.34s/it] 50%|████▉     | 234/471 [05:09<05:18,  1.34s/it] 50%|████▉     | 235/471 [05:11<05:17,  1.34s/it] 50%|█████     | 236/471 [05:12<05:15,  1.34s/it] 50%|█████     | 237/471 [05:13<05:13,  1.34s/it] 51%|█████     | 238/471 [05:15<05:12,  1.34s/it] 51%|█████     | 239/471 [05:16<05:11,  1.34s/it] 51%|█████     | 240/471 [05:17<05:10,  1.34s/it] 51%|█████     | 241/471 [05:19<05:08,  1.34s/it] 51%|█████▏    | 242/471 [05:20<05:07,  1.34s/it] 52%|█████▏    | 243/471 [05:21<05:05,  1.34s/it] 52%|█████▏    | 244/471 [05:23<05:04,  1.34s/it] 52%|█████▏    | 245/471 [05:24<05:03,  1.34s/it] 52%|█████▏    | 246/471 [05:25<05:01,  1.34s/it] 52%|█████▏    | 247/471 [05:27<04:59,  1.34s/it] 53%|█████▎    | 248/471 [05:28<04:58,  1.34s/it] 53%|█████▎    | 249/471 [05:29<04:57,  1.34s/it] 53%|█████▎    | 250/471 [05:31<04:55,  1.34s/it] 53%|█████▎    | 251/471 [05:32<04:54,  1.34s/it] 54%|█████▎    | 252/471 [05:33<04:53,  1.34s/it] 54%|█████▎    | 253/471 [05:35<04:52,  1.34s/it] 54%|█████▍    | 254/471 [05:36<04:51,  1.34s/it] 54%|█████▍    | 255/471 [05:38<04:49,  1.34s/it] 54%|█████▍    | 256/471 [05:39<04:48,  1.34s/it] 55%|█████▍    | 257/471 [05:40<04:47,  1.34s/it] 55%|█████▍    | 258/471 [05:42<04:46,  1.34s/it] 55%|█████▍    | 259/471 [05:43<04:44,  1.34s/it] 55%|█████▌    | 260/471 [05:44<04:43,  1.34s/it] 55%|█████▌    | 261/471 [05:46<04:41,  1.34s/it] 56%|█████▌    | 262/471 [05:47<04:39,  1.34s/it] 56%|█████▌    | 263/471 [05:48<04:38,  1.34s/it] 56%|█████▌    | 264/471 [05:50<04:37,  1.34s/it] 56%|█████▋    | 265/471 [05:51<04:35,  1.34s/it] 56%|█████▋    | 266/471 [05:52<04:34,  1.34s/it] 57%|█████▋    | 267/471 [05:54<04:33,  1.34s/it] 57%|█████▋    | 268/471 [05:55<04:32,  1.34s/it] 57%|█████▋    | 269/471 [05:56<04:30,  1.34s/it] 57%|█████▋    | 270/471 [05:58<04:29,  1.34s/it] 58%|█████▊    | 271/471 [05:59<04:27,  1.34s/it] 58%|█████▊    | 272/471 [06:00<04:26,  1.34s/it] 58%|█████▊    | 273/471 [06:02<04:25,  1.34s/it] 58%|█████▊    | 274/471 [06:03<04:23,  1.34s/it] 58%|█████▊    | 275/471 [06:04<04:21,  1.34s/it] 59%|█████▊    | 276/471 [06:06<04:20,  1.34s/it] 59%|█████▉    | 277/471 [06:07<04:19,  1.34s/it] 59%|█████▉    | 278/471 [06:08<04:18,  1.34s/it] 59%|█████▉    | 279/471 [06:10<04:16,  1.34s/it] 59%|█████▉    | 280/471 [06:11<04:15,  1.34s/it] 60%|█████▉    | 281/471 [06:12<04:13,  1.34s/it] 60%|█████▉    | 282/471 [06:14<04:12,  1.34s/it] 60%|██████    | 283/471 [06:15<04:11,  1.34s/it] 60%|██████    | 284/471 [06:16<04:09,  1.34s/it] 61%|██████    | 285/471 [06:18<04:08,  1.34s/it] 61%|██████    | 286/471 [06:19<04:07,  1.34s/it] 61%|██████    | 287/471 [06:20<04:05,  1.34s/it] 61%|██████    | 288/471 [06:22<04:04,  1.34s/it] 61%|██████▏   | 289/471 [06:23<04:02,  1.33s/it] 62%|██████▏   | 290/471 [06:24<04:01,  1.33s/it] 62%|██████▏   | 291/471 [06:26<04:00,  1.33s/it] 62%|██████▏   | 292/471 [06:27<03:58,  1.33s/it] 62%|██████▏   | 293/471 [06:28<03:56,  1.33s/it] 62%|██████▏   | 294/471 [06:30<03:55,  1.33s/it] 63%|██████▎   | 295/471 [06:31<03:54,  1.33s/it] 63%|██████▎   | 296/471 [06:32<03:52,  1.33s/it] 63%|██████▎   | 297/471 [06:34<03:51,  1.33s/it] 63%|██████▎   | 298/471 [06:35<03:50,  1.33s/it] 63%|██████▎   | 299/471 [06:36<03:49,  1.33s/it] 64%|██████▎   | 300/471 [06:38<03:47,  1.33s/it] 64%|██████▍   | 301/471 [06:39<03:46,  1.33s/it] 64%|██████▍   | 302/471 [06:40<03:44,  1.33s/it] 64%|██████▍   | 303/471 [06:42<03:43,  1.33s/it] 65%|██████▍   | 304/471 [06:43<03:41,  1.33s/it] 65%|██████▍   | 305/471 [06:44<03:40,  1.33s/it] 65%|██████▍   | 306/471 [06:46<03:39,  1.33s/it] 65%|██████▌   | 307/471 [06:47<03:38,  1.33s/it] 65%|██████▌   | 308/471 [06:48<03:37,  1.33s/it] 66%|██████▌   | 309/471 [06:50<03:36,  1.33s/it] 66%|██████▌   | 310/471 [06:51<03:34,  1.33s/it] 66%|██████▌   | 311/471 [06:52<03:33,  1.33s/it] 66%|██████▌   | 312/471 [06:54<03:31,  1.33s/it] 66%|██████▋   | 313/471 [06:55<03:30,  1.33s/it] 67%|██████▋   | 314/471 [06:56<03:28,  1.33s/it] 67%|██████▋   | 315/471 [06:58<03:27,  1.33s/it] 67%|██████▋   | 316/471 [06:59<03:26,  1.33s/it] 67%|██████▋   | 317/471 [07:00<03:25,  1.33s/it] 68%|██████▊   | 318/471 [07:02<03:24,  1.33s/it] 68%|██████▊   | 319/471 [07:03<03:22,  1.34s/it] 68%|██████▊   | 320/471 [07:04<03:21,  1.34s/it] 68%|██████▊   | 321/471 [07:06<03:20,  1.34s/it] 68%|██████▊   | 322/471 [07:07<03:19,  1.34s/it] 69%|██████▊   | 323/471 [07:08<03:17,  1.34s/it] 69%|██████▉   | 324/471 [07:10<03:16,  1.34s/it] 69%|██████▉   | 325/471 [07:11<03:15,  1.34s/it] 69%|██████▉   | 326/471 [07:12<03:13,  1.34s/it] 69%|██████▉   | 327/471 [07:14<03:12,  1.33s/it] 70%|██████▉   | 328/471 [07:15<03:10,  1.34s/it] 70%|██████▉   | 329/471 [07:16<03:09,  1.34s/it] 70%|███████   | 330/471 [07:18<03:08,  1.33s/it] 70%|███████   | 331/471 [07:19<03:06,  1.33s/it] 70%|███████   | 332/471 [07:20<03:05,  1.34s/it] 71%|███████   | 333/471 [07:22<03:04,  1.33s/it] 71%|███████   | 334/471 [07:23<03:02,  1.33s/it] 71%|███████   | 335/471 [07:24<03:01,  1.34s/it] 71%|███████▏  | 336/471 [07:26<03:00,  1.33s/it] 72%|███████▏  | 337/471 [07:27<02:58,  1.33s/it] 72%|███████▏  | 338/471 [07:28<02:56,  1.33s/it] 72%|███████▏  | 339/471 [07:30<02:55,  1.33s/it] 72%|███████▏  | 340/471 [07:31<02:54,  1.33s/it] 72%|███████▏  | 341/471 [07:32<02:52,  1.33s/it] 73%|███████▎  | 342/471 [07:34<02:51,  1.33s/it] 73%|███████▎  | 343/471 [07:35<02:50,  1.33s/it] 73%|███████▎  | 344/471 [07:36<02:48,  1.33s/it] 73%|███████▎  | 345/471 [07:38<02:47,  1.33s/it] 73%|███████▎  | 346/471 [07:39<02:46,  1.33s/it] 74%|███████▎  | 347/471 [07:40<02:44,  1.33s/it] 74%|███████▍  | 348/471 [07:42<02:43,  1.33s/it] 74%|███████▍  | 349/471 [07:43<02:42,  1.33s/it] 74%|███████▍  | 350/471 [07:44<02:40,  1.33s/it] 75%|███████▍  | 351/471 [07:46<02:39,  1.33s/it] 75%|███████▍  | 352/471 [07:47<02:38,  1.33s/it] 75%|███████▍  | 353/471 [07:48<02:37,  1.33s/it] 75%|███████▌  | 354/471 [07:50<02:35,  1.33s/it] 75%|███████▌  | 355/471 [07:51<02:34,  1.33s/it] 76%|███████▌  | 356/471 [07:52<02:32,  1.33s/it] 76%|███████▌  | 357/471 [07:54<02:31,  1.33s/it] 76%|███████▌  | 358/471 [07:55<02:30,  1.33s/it] 76%|███████▌  | 359/471 [07:56<02:29,  1.33s/it] 76%|███████▋  | 360/471 [07:58<02:27,  1.33s/it] 77%|███████▋  | 361/471 [07:59<02:26,  1.33s/it] 77%|███████▋  | 362/471 [08:00<02:25,  1.33s/it] 77%|███████▋  | 363/471 [08:02<02:23,  1.33s/it] 77%|███████▋  | 364/471 [08:03<02:22,  1.33s/it] 77%|███████▋  | 365/471 [08:04<02:21,  1.33s/it] 78%|███████▊  | 366/471 [08:06<02:19,  1.33s/it] 78%|███████▊  | 367/471 [08:07<02:18,  1.33s/it] 78%|███████▊  | 368/471 [08:08<02:17,  1.33s/it] 78%|███████▊  | 369/471 [08:10<02:15,  1.33s/it] 79%|███████▊  | 370/471 [08:11<02:14,  1.33s/it] 79%|███████▉  | 371/471 [08:12<02:13,  1.33s/it] 79%|███████▉  | 372/471 [08:14<02:11,  1.33s/it] 79%|███████▉  | 373/471 [08:15<02:10,  1.33s/it] 79%|███████▉  | 374/471 [08:16<02:09,  1.33s/it] 80%|███████▉  | 375/471 [08:18<02:07,  1.33s/it] 80%|███████▉  | 376/471 [08:19<02:06,  1.33s/it] 80%|████████  | 377/471 [08:20<02:04,  1.33s/it] 80%|████████  | 378/471 [08:22<02:03,  1.33s/it] 80%|████████  | 379/471 [08:23<02:02,  1.33s/it] 81%|████████  | 380/471 [08:24<02:01,  1.33s/it] 81%|████████  | 381/471 [08:26<01:59,  1.33s/it] 81%|████████  | 382/471 [08:27<01:58,  1.33s/it] 81%|████████▏ | 383/471 [08:28<01:57,  1.33s/it] 82%|████████▏ | 384/471 [08:30<01:55,  1.33s/it] 82%|████████▏ | 385/471 [08:31<01:54,  1.33s/it] 82%|████████▏ | 386/471 [08:32<01:53,  1.33s/it] 82%|████████▏ | 387/471 [08:34<01:51,  1.33s/it] 82%|████████▏ | 388/471 [08:35<01:50,  1.33s/it] 83%|████████▎ | 389/471 [08:36<01:49,  1.33s/it] 83%|████████▎ | 390/471 [08:38<01:47,  1.33s/it] 83%|████████▎ | 391/471 [08:39<01:46,  1.33s/it] 83%|████████▎ | 392/471 [08:40<01:45,  1.33s/it] 83%|████████▎ | 393/471 [08:42<01:43,  1.33s/it] 84%|████████▎ | 394/471 [08:43<01:42,  1.33s/it] 84%|████████▍ | 395/471 [08:44<01:41,  1.33s/it] 84%|████████▍ | 396/471 [08:46<01:39,  1.33s/it] 84%|████████▍ | 397/471 [08:47<01:38,  1.33s/it] 85%|████████▍ | 398/471 [08:48<01:37,  1.33s/it] 85%|████████▍ | 399/471 [08:50<01:35,  1.33s/it] 85%|████████▍ | 400/471 [08:51<01:34,  1.33s/it] 85%|████████▌ | 401/471 [08:52<01:33,  1.33s/it] 85%|████████▌ | 402/471 [08:54<01:31,  1.33s/it] 86%|████████▌ | 403/471 [08:55<01:30,  1.33s/it] 86%|████████▌ | 404/471 [08:56<01:29,  1.33s/it] 86%|████████▌ | 405/471 [08:57<01:27,  1.33s/it] 86%|████████▌ | 406/471 [08:59<01:26,  1.33s/it] 86%|████████▋ | 407/471 [09:00<01:25,  1.33s/it] 87%|████████▋ | 408/471 [09:01<01:23,  1.33s/it] 87%|████████▋ | 409/471 [09:03<01:22,  1.33s/it] 87%|████████▋ | 410/471 [09:04<01:21,  1.33s/it] 87%|████████▋ | 411/471 [09:05<01:19,  1.33s/it] 87%|████████▋ | 412/471 [09:07<01:18,  1.33s/it] 88%|████████▊ | 413/471 [09:08<01:17,  1.33s/it] 88%|████████▊ | 414/471 [09:09<01:16,  1.33s/it] 88%|████████▊ | 415/471 [09:11<01:14,  1.33s/it] 88%|████████▊ | 416/471 [09:12<01:13,  1.33s/it] 89%|████████▊ | 417/471 [09:13<01:11,  1.33s/it] 89%|████████▊ | 418/471 [09:15<01:10,  1.33s/it] 89%|████████▉ | 419/471 [09:16<01:09,  1.33s/it] 89%|████████▉ | 420/471 [09:17<01:07,  1.33s/it] 89%|████████▉ | 421/471 [09:19<01:06,  1.33s/it] 90%|████████▉ | 422/471 [09:20<01:05,  1.33s/it] 90%|████████▉ | 423/471 [09:21<01:03,  1.33s/it] 90%|█████████ | 424/471 [09:23<01:02,  1.33s/it] 90%|█████████ | 425/471 [09:24<01:01,  1.33s/it] 90%|█████████ | 426/471 [09:25<01:00,  1.34s/it] 91%|█████████ | 427/471 [09:27<00:58,  1.34s/it] 91%|█████████ | 428/471 [09:28<00:57,  1.34s/it] 91%|█████████ | 429/471 [09:30<00:56,  1.34s/it] 91%|█████████▏| 430/471 [09:31<00:54,  1.34s/it] 92%|█████████▏| 431/471 [09:32<00:53,  1.34s/it] 92%|█████████▏| 432/471 [09:34<00:52,  1.34s/it] 92%|█████████▏| 433/471 [09:35<00:50,  1.34s/it] 92%|█████████▏| 434/471 [09:36<00:49,  1.34s/it] 92%|█████████▏| 435/471 [09:38<00:48,  1.34s/it] 93%|█████████▎| 436/471 [09:39<00:46,  1.34s/it] 93%|█████████▎| 437/471 [09:40<00:45,  1.34s/it] 93%|█████████▎| 438/471 [09:42<00:44,  1.34s/it] 93%|█████████▎| 439/471 [09:43<00:43,  1.34s/it] 93%|█████████▎| 440/471 [09:44<00:41,  1.34s/it] 94%|█████████▎| 441/471 [09:46<00:40,  1.34s/it] 94%|█████████▍| 442/471 [09:47<00:38,  1.34s/it] 94%|█████████▍| 443/471 [09:48<00:37,  1.34s/it] 94%|█████████▍| 444/471 [09:50<00:36,  1.34s/it] 94%|█████████▍| 445/471 [09:51<00:34,  1.34s/it] 95%|█████████▍| 446/471 [09:52<00:33,  1.34s/it] 95%|█████████▍| 447/471 [09:54<00:32,  1.34s/it] 95%|█████████▌| 448/471 [09:55<00:30,  1.34s/it] 95%|█████████▌| 449/471 [09:56<00:29,  1.34s/it] 96%|█████████▌| 450/471 [09:58<00:28,  1.34s/it] 96%|█████████▌| 451/471 [09:59<00:26,  1.34s/it] 96%|█████████▌| 452/471 [10:00<00:25,  1.34s/it] 96%|█████████▌| 453/471 [10:02<00:24,  1.34s/it] 96%|█████████▋| 454/471 [10:03<00:22,  1.35s/it] 97%|█████████▋| 455/471 [10:04<00:21,  1.35s/it] 97%|█████████▋| 456/471 [10:06<00:20,  1.34s/it] 97%|█████████▋| 457/471 [10:07<00:18,  1.34s/it] 97%|█████████▋| 458/471 [10:08<00:17,  1.35s/it] 97%|█████████▋| 459/471 [10:10<00:16,  1.34s/it] 98%|█████████▊| 460/471 [10:11<00:14,  1.34s/it] 98%|█████████▊| 461/471 [10:13<00:13,  1.34s/it] 98%|█████████▊| 462/471 [10:14<00:12,  1.34s/it] 98%|█████████▊| 463/471 [10:15<00:10,  1.34s/it] 99%|█████████▊| 464/471 [10:17<00:09,  1.34s/it] 99%|█████████▊| 465/471 [10:18<00:08,  1.34s/it] 99%|█████████▉| 466/471 [10:19<00:06,  1.34s/it] 99%|█████████▉| 467/471 [10:21<00:05,  1.34s/it] 99%|█████████▉| 468/471 [10:22<00:04,  1.34s/it]100%|█████████▉| 469/471 [10:23<00:02,  1.34s/it]100%|█████████▉| 470/471 [10:25<00:01,  1.34s/it]100%|██████████| 471/471 [10:26<00:00,  1.23s/it]100%|██████████| 471/471 [10:26<00:00,  1.33s/it]
{'eval_loss': 3.3712799549102783, 'eval_model_preparation_time': 0.0153, 'eval_acc': 0.24787573021773765, 'eval_runtime': 627.3115, 'eval_samples_per_second': 12.007, 'eval_steps_per_second': 0.751}
ROUND:11
CLIENT:23
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:34,  2.41s/it]                                              {'loss': 2.8087, 'grad_norm': 8.292403221130371, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:34,  2.41s/it]  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]                                              {'loss': 2.8994, 'grad_norm': 22.41680335998535, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 2.726, 'grad_norm': 11.343652725219727, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 3.5149, 'grad_norm': 15.093148231506348, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it]                                              {'loss': 3.0233, 'grad_norm': 14.379011154174805, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 2.3382, 'grad_norm': 12.671563148498535, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 2.5048, 'grad_norm': 11.129807472229004, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 0.3971, 'grad_norm': 24.411453247070312, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 2.895, 'grad_norm': 32.42919158935547, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.87s/it]                                               {'loss': 1.2839, 'grad_norm': 16.964637756347656, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.87s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.97s/it]                                               {'loss': 1.2151, 'grad_norm': 17.56089210510254, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.97s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.7766, 'grad_norm': 13.144086837768555, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 1.1547, 'grad_norm': 8.428704261779785, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it]                                               {'loss': 0.4071, 'grad_norm': 4.292789936065674, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 1.0159, 'grad_norm': 5.371649265289307, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.007, 'grad_norm': 0.3205099403858185, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.2759, 'grad_norm': 2.9742236137390137, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.91s/it]                                               {'loss': 0.1053, 'grad_norm': 2.021000623703003, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it]                                               {'loss': 0.3816, 'grad_norm': 136.52755737304688, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.05s/it]                                               {'loss': 0.3522, 'grad_norm': 2.8134915828704834, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.05s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.5496, 'grad_norm': 6.362316131591797, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.5613, 'grad_norm': 5.261164665222168, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it]                                               {'loss': 0.4629, 'grad_norm': 6.144674301147461, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 2.2321, 'grad_norm': 50.7364501953125, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.4466, 'grad_norm': 3.715034246444702, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.1092, 'grad_norm': 2.1975975036621094, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it]                                               {'loss': 1.2629, 'grad_norm': 10.484463691711426, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.2163, 'grad_norm': 2.9687581062316895, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.365, 'grad_norm': 4.931338787078857, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it]                                               {'loss': 0.3999, 'grad_norm': 3.2500805854797363, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it]                                               {'loss': 0.447, 'grad_norm': 5.910603046417236, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 1.7002, 'grad_norm': 93.37640380859375, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 2.1465, 'grad_norm': 43.11033248901367, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 1.429, 'grad_norm': 93.83905792236328, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 1.4407, 'grad_norm': 23.81818389892578, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.3566, 'grad_norm': 14.533432960510254, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.1696, 'grad_norm': 5.68471622467041, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.6093, 'grad_norm': 13.558707237243652, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]                                               {'loss': 0.3343, 'grad_norm': 9.69706916809082, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'loss': 0.0071, 'grad_norm': 0.9582852721214294, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'train_runtime': 79.3117, 'train_samples_per_second': 7.124, 'train_steps_per_second': 0.504, 'train_loss': 1.1332198550342583, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:81
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:03<02:02,  3.14s/it]                                              {'loss': 3.2787, 'grad_norm': 9.174766540527344, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:03<02:02,  3.14s/it]  5%|▌         | 2/40 [00:05<01:37,  2.56s/it]                                              {'loss': 2.6793, 'grad_norm': 12.328903198242188, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:37,  2.56s/it]  8%|▊         | 3/40 [00:07<01:27,  2.37s/it]                                              {'loss': 3.0835, 'grad_norm': 13.9204683303833, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:27,  2.37s/it] 10%|█         | 4/40 [00:09<01:22,  2.30s/it]                                              {'loss': 2.9657, 'grad_norm': 13.050736427307129, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.30s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 3.1239, 'grad_norm': 14.072315216064453, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 3.8552, 'grad_norm': 14.308752059936523, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:16<01:13,  2.22s/it]                                              {'loss': 2.2277, 'grad_norm': 62.78600311279297, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 2.1396, 'grad_norm': 54.194461822509766, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 2.7563, 'grad_norm': 21.08989143371582, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it]                                               {'loss': 2.2262, 'grad_norm': 18.865798950195312, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.5791, 'grad_norm': 15.52039623260498, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:25<00:57,  2.04s/it]                                               {'loss': 0.5078, 'grad_norm': 5.953747272491455, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.09s/it]                                               {'loss': 1.2897, 'grad_norm': 7.699896812438965, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:29<00:54,  2.11s/it]                                               {'loss': 1.7387, 'grad_norm': 10.200467109680176, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:54,  2.11s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.6429, 'grad_norm': 5.558561325073242, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.0429, 'grad_norm': 1.9073868989944458, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it]                                               {'loss': 0.6525, 'grad_norm': 4.736155033111572, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:43,  2.00s/it]                                               {'loss': 0.5656, 'grad_norm': 3.325331687927246, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  2.00s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it]                                               {'loss': 0.8161, 'grad_norm': 4.8527116775512695, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it] 50%|█████     | 20/40 [00:41<00:41,  2.09s/it]                                               {'loss': 0.6564, 'grad_norm': 6.327083110809326, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 0.0985, 'grad_norm': 1.8273776769638062, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it]                                               {'loss': 0.2824, 'grad_norm': 6.386117458343506, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.6561, 'grad_norm': 4.899387359619141, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.009, 'grad_norm': 0.6164388060569763, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.77s/it]                                               {'loss': 0.6387, 'grad_norm': 7.727622985839844, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.90s/it]                                               {'loss': 0.2866, 'grad_norm': 3.9729676246643066, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it]                                               {'loss': 0.1824, 'grad_norm': 3.8331520557403564, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:24,  2.07s/it]                                               {'loss': 0.5057, 'grad_norm': 3.4630019664764404, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.12s/it]                                               {'loss': 0.1279, 'grad_norm': 2.569491147994995, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.12s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.16s/it]                                               {'loss': 0.4096, 'grad_norm': 5.235274314880371, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.0428, 'grad_norm': 0.8156558871269226, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.551, 'grad_norm': 26.724706649780273, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.79s/it]                                               {'loss': 0.4709, 'grad_norm': 6.183403015136719, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it]                                               {'loss': 0.066, 'grad_norm': 2.887070417404175, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it]                                               {'loss': 0.0439, 'grad_norm': 1.1215356588363647, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.0576, 'grad_norm': 1.2002360820770264, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.14s/it]                                               {'loss': 0.3431, 'grad_norm': 1.4808529615402222, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.17s/it]                                               {'loss': 0.1847, 'grad_norm': 3.0037336349487305, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]                                               {'loss': 0.1572, 'grad_norm': 7.111993312835693, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0565, 'grad_norm': 6.103325366973877, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 80.1062, 'train_samples_per_second': 7.053, 'train_steps_per_second': 0.499, 'train_loss': 1.0499597667949274, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.60s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:85
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]                                              {'loss': 0.0561, 'grad_norm': 1.6668848991394043, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]  5%|▌         | 2/40 [00:04<01:29,  2.34s/it]                                              {'loss': 0.1515, 'grad_norm': 3.1497137546539307, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.34s/it]  8%|▊         | 3/40 [00:06<01:23,  2.25s/it]                                              {'loss': 0.0276, 'grad_norm': 0.6267576813697815, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.25s/it] 10%|█         | 4/40 [00:09<01:19,  2.21s/it]                                              {'loss': 0.6206, 'grad_norm': 1.179903268814087, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 0.3171, 'grad_norm': 0.43484967947006226, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 0.0124, 'grad_norm': 0.22395408153533936, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 0.6617, 'grad_norm': 0.9380951523780823, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 0.0195, 'grad_norm': 0.42050549387931824, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 0.004, 'grad_norm': 0.04675544425845146, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 0.205, 'grad_norm': 0.4567089378833771, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.005, 'grad_norm': 0.04299864172935486, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:56,  2.03s/it]                                               {'loss': 0.42, 'grad_norm': 4.507280349731445, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:56,  2.03s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 0.004, 'grad_norm': 0.09130922704935074, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 0.5609, 'grad_norm': 1.969078540802002, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 0.0559, 'grad_norm': 2.499467611312866, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 0.0, 'grad_norm': 0.00019097547919955105, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.0045, 'grad_norm': 0.036887988448143005, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.002, 'grad_norm': 0.023260224610567093, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.0073, 'grad_norm': 0.376462459564209, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.0871, 'grad_norm': 0.26044848561286926, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.2925, 'grad_norm': 12.979687690734863, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.6016, 'grad_norm': 1.3480383157730103, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.4776, 'grad_norm': 0.8431928753852844, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0057, 'grad_norm': 0.273399293422699, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.1694, 'grad_norm': 2.8438220024108887, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it]                                               {'loss': 0.0045, 'grad_norm': 0.06621912866830826, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.2506, 'grad_norm': 2.4333646297454834, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.1407, 'grad_norm': 1.5082981586456299, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.2409, 'grad_norm': 1.99410080909729, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it]                                               {'loss': 0.0057, 'grad_norm': 0.11681313067674637, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.6573, 'grad_norm': 3.451723575592041, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0001, 'grad_norm': 0.0035641631111502647, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it]                                               {'loss': 0.193, 'grad_norm': 0.38377121090888977, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it]                                               {'loss': 0.3136, 'grad_norm': 1.1307939291000366, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.4518, 'grad_norm': 3.0665085315704346, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.0149, 'grad_norm': 0.14327725768089294, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.1422, 'grad_norm': 0.8000831604003906, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.22s/it]                                               {'loss': 0.0017, 'grad_norm': 0.014474877156317234, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.22s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]                                               {'loss': 0.2533, 'grad_norm': 2.0369036197662354, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]100%|██████████| 40/40 [01:19<00:00,  1.63s/it]                                               {'loss': 0.0005, 'grad_norm': 0.01589556224644184, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.63s/it]                                               {'train_runtime': 79.7628, 'train_samples_per_second': 7.084, 'train_steps_per_second': 0.501, 'train_loss': 0.18599639343116223, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.63s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:34
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:30,  2.32s/it]                                              {'loss': 4.8648, 'grad_norm': 6.939120769500732, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:30,  2.32s/it]  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]                                              {'loss': 2.8387, 'grad_norm': 10.026787757873535, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 2.2922, 'grad_norm': 13.078911781311035, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:20,  2.22s/it]                                              {'loss': 2.463, 'grad_norm': 17.139799118041992, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:20,  2.22s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 3.7637, 'grad_norm': 16.531116485595703, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 1.8128, 'grad_norm': 14.39224624633789, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:15<01:14,  2.26s/it]                                              {'loss': 1.4586, 'grad_norm': 12.566727638244629, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:14,  2.26s/it] 20%|██        | 8/40 [00:15<00:51,  1.60s/it]                                              {'loss': 1.6345, 'grad_norm': 60.99043273925781, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:51,  1.60s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.80s/it]                                              {'loss': 0.7912, 'grad_norm': 9.593498229980469, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.80s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.95s/it]                                               {'loss': 0.5869, 'grad_norm': 6.614831447601318, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.95s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it]                                               {'loss': 0.3295, 'grad_norm': 2.8600659370422363, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 0.5655, 'grad_norm': 6.2898335456848145, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.15s/it]                                               {'loss': 0.5261, 'grad_norm': 8.025795936584473, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.15s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.4749, 'grad_norm': 7.610308647155762, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.5842, 'grad_norm': 6.725256443023682, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.58s/it]                                               {'loss': 3.1428, 'grad_norm': 69.98567962646484, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.58s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.0681, 'grad_norm': 1.58357572555542, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 0.1042, 'grad_norm': 1.56470787525177, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.2695, 'grad_norm': 3.4075965881347656, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:42,  2.11s/it]                                               {'loss': 0.2321, 'grad_norm': 3.412468433380127, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it]                                               {'loss': 0.0799, 'grad_norm': 2.2020649909973145, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.3951, 'grad_norm': 6.3366498947143555, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.084, 'grad_norm': 2.065797805786133, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0358, 'grad_norm': 2.5924620628356934, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it]                                               {'loss': 0.0793, 'grad_norm': 1.647734522819519, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.1233, 'grad_norm': 1.9584017992019653, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it]                                               {'loss': 0.079, 'grad_norm': 1.8326600790023804, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it] 70%|███████   | 28/40 [00:57<00:25,  2.14s/it]                                               {'loss': 0.0365, 'grad_norm': 0.9571573734283447, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it]                                               {'loss': 0.3071, 'grad_norm': 5.527933597564697, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.0381, 'grad_norm': 0.9407390356063843, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.0617, 'grad_norm': 1.4732608795166016, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.2273, 'grad_norm': 14.626017570495605, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.0126, 'grad_norm': 0.36969709396362305, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it]                                               {'loss': 0.0087, 'grad_norm': 0.268478125333786, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.03, 'grad_norm': 0.5889134407043457, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it]                                               {'loss': 0.0563, 'grad_norm': 1.6563571691513062, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it]                                               {'loss': 0.0831, 'grad_norm': 2.8270063400268555, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.0384, 'grad_norm': 1.179121971130371, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.0073, 'grad_norm': 0.21057440340518951, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.0291, 'grad_norm': 2.346003293991089, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.5345, 'train_samples_per_second': 7.016, 'train_steps_per_second': 0.497, 'train_loss': 0.7653983456548303, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:62
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.20s/it]                                              {'loss': 3.0223, 'grad_norm': 9.379977226257324, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.20s/it]  5%|▌         | 2/40 [00:04<01:23,  2.20s/it]                                              {'loss': 2.4977, 'grad_norm': 24.258913040161133, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.20s/it]  8%|▊         | 3/40 [00:06<01:21,  2.20s/it]                                              {'loss': 2.1413, 'grad_norm': 10.3446044921875, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.20s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 1.498, 'grad_norm': 13.189924240112305, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 1.4126, 'grad_norm': 12.817926406860352, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 3.0792, 'grad_norm': 20.568967819213867, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it]                                              {'loss': 2.3163, 'grad_norm': 15.359325408935547, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 5.3912, 'grad_norm': 68.74823760986328, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.80s/it]                                              {'loss': 1.0092, 'grad_norm': 8.658317565917969, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.80s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 1.123, 'grad_norm': 9.560532569885254, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it]                                               {'loss': 0.8911, 'grad_norm': 10.323139190673828, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.4746, 'grad_norm': 8.962788581848145, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it]                                               {'loss': 0.5297, 'grad_norm': 5.69898796081543, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.19s/it]                                               {'loss': 0.2277, 'grad_norm': 3.464935302734375, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.19s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it]                                               {'loss': 0.6393, 'grad_norm': 8.61570930480957, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it] 40%|████      | 16/40 [00:31<00:38,  1.60s/it]                                               {'loss': 0.0071, 'grad_norm': 0.16171985864639282, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it]                                               {'loss': 0.3514, 'grad_norm': 6.034083366394043, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.0837, 'grad_norm': 2.0573642253875732, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it]                                               {'loss': 0.1923, 'grad_norm': 3.9849328994750977, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it] 50%|█████     | 20/40 [00:40<00:42,  2.12s/it]                                               {'loss': 0.1033, 'grad_norm': 1.8707432746887207, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 0.1122, 'grad_norm': 2.3171226978302, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it]                                               {'loss': 0.1498, 'grad_norm': 4.948788642883301, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it]                                               {'loss': 0.1254, 'grad_norm': 2.8818647861480713, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it] 60%|██████    | 24/40 [00:47<00:25,  1.62s/it]                                               {'loss': 0.1033, 'grad_norm': 7.527863502502441, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.0466, 'grad_norm': 1.3825300931930542, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it]                                               {'loss': 0.174, 'grad_norm': 4.933651924133301, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it]                                               {'loss': 0.0751, 'grad_norm': 2.201796770095825, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it] 70%|███████   | 28/40 [00:57<00:25,  2.15s/it]                                               {'loss': 0.1645, 'grad_norm': 6.562614440917969, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.15s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it]                                               {'loss': 0.2935, 'grad_norm': 5.706143856048584, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it]                                               {'loss': 0.1261, 'grad_norm': 5.99014949798584, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it]                                               {'loss': 0.0237, 'grad_norm': 0.7006534934043884, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it] 80%|████████  | 32/40 [01:04<00:13,  1.63s/it]                                               {'loss': 0.1856, 'grad_norm': 11.048285484313965, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it]                                               {'loss': 0.0275, 'grad_norm': 0.8862264752388, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.0729, 'grad_norm': 3.7163782119750977, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.09s/it]                                               {'loss': 0.1055, 'grad_norm': 4.609825611114502, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.09s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.16s/it]                                               {'loss': 0.1881, 'grad_norm': 6.501829624176025, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.16s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it]                                               {'loss': 0.0538, 'grad_norm': 1.4387493133544922, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.23s/it]                                               {'loss': 0.0461, 'grad_norm': 1.2033239603042603, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.23s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]                                               {'loss': 0.0949, 'grad_norm': 3.5346782207489014, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.0435, 'grad_norm': 2.4904234409332275, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.8315, 'train_samples_per_second': 6.99, 'train_steps_per_second': 0.495, 'train_loss': 0.7300797625444829, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:46
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]                                              {'loss': 2.705, 'grad_norm': 7.193746566772461, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]                                              {'loss': 3.1721, 'grad_norm': 16.206680297851562, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]  8%|▊         | 3/40 [00:07<01:24,  2.29s/it]                                              {'loss': 2.5313, 'grad_norm': 11.988123893737793, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:21,  2.25s/it]                                              {'loss': 3.0091, 'grad_norm': 12.621084213256836, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 1.7632, 'grad_norm': 14.566636085510254, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 2.2879, 'grad_norm': 10.8814058303833, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 1.7617, 'grad_norm': 11.59838581085205, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 0.9548, 'grad_norm': 26.290040969848633, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 0.4426, 'grad_norm': 7.081414699554443, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 0.7509, 'grad_norm': 8.182698249816895, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 0.6863, 'grad_norm': 8.298676490783691, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.6351, 'grad_norm': 6.2104692459106445, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 0.7588, 'grad_norm': 7.262496471405029, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.7245, 'grad_norm': 6.6326470375061035, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it]                                               {'loss': 0.9405, 'grad_norm': 13.30504322052002, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 1.3999, 'grad_norm': 37.33237075805664, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it]                                               {'loss': 0.2879, 'grad_norm': 11.961471557617188, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.4739, 'grad_norm': 22.110172271728516, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.3218, 'grad_norm': 4.478260040283203, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.1862, 'grad_norm': 2.8813765048980713, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 0.0825, 'grad_norm': 3.939896583557129, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.1099, 'grad_norm': 1.4608367681503296, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.2856, 'grad_norm': 3.999096632003784, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.0393, 'grad_norm': 1.7002689838409424, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it]                                               {'loss': 0.0624, 'grad_norm': 1.2294318675994873, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.0575, 'grad_norm': 0.9912184476852417, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.2425, 'grad_norm': 3.7288079261779785, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.11s/it]                                               {'loss': 0.3947, 'grad_norm': 3.698272705078125, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.234, 'grad_norm': 2.3685410022735596, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.1218, 'grad_norm': 1.9155774116516113, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it]                                               {'loss': 0.2498, 'grad_norm': 36.5505256652832, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it] 80%|████████  | 32/40 [01:04<00:12,  1.61s/it]                                               {'loss': 0.0166, 'grad_norm': 0.8697289824485779, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.1255, 'grad_norm': 1.8614344596862793, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.1039, 'grad_norm': 2.247295379638672, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.4904, 'grad_norm': 3.4683518409729004, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.11s/it]                                               {'loss': 0.1001, 'grad_norm': 3.2664101123809814, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.0658, 'grad_norm': 2.2426295280456543, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.1047, 'grad_norm': 4.04052734375, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.1909, 'grad_norm': 5.515002250671387, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 3.9543, 'grad_norm': 78.441162109375, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.5089, 'train_samples_per_second': 7.018, 'train_steps_per_second': 0.497, 'train_loss': 0.8206500060390681, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.17s/it]                                              {'loss': 2.4123, 'grad_norm': 7.699484825134277, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.17s/it]  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]                                              {'loss': 2.253, 'grad_norm': 8.153412818908691, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.16s/it]  8%|▊         | 3/40 [00:06<01:20,  2.17s/it]                                              {'loss': 1.9906, 'grad_norm': 11.25613784790039, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.17s/it] 10%|█         | 4/40 [00:08<01:17,  2.17s/it]                                              {'loss': 3.524, 'grad_norm': 19.04168701171875, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.17s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it]                                              {'loss': 1.8501, 'grad_norm': 12.405006408691406, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 2.2306, 'grad_norm': 12.68624210357666, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.7575, 'grad_norm': 15.880398750305176, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 3.1073, 'grad_norm': 57.26915740966797, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 1.7613, 'grad_norm': 16.97475242614746, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:19<00:57,  1.90s/it]                                               {'loss': 0.8882, 'grad_norm': 10.495858192443848, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.8923, 'grad_norm': 6.258576393127441, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 1.0168, 'grad_norm': 19.86618995666504, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 1.8163, 'grad_norm': 14.198569297790527, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it]                                               {'loss': 0.89, 'grad_norm': 8.554271697998047, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it]                                               {'loss': 1.2289, 'grad_norm': 9.471593856811523, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 1.5834, 'grad_norm': 77.22504425048828, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.5694, 'grad_norm': 9.674232482910156, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.3947, 'grad_norm': 2.1654393672943115, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it]                                               {'loss': 0.5716, 'grad_norm': 5.721442699432373, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.4172, 'grad_norm': 11.854453086853027, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.3418, 'grad_norm': 6.343478202819824, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it]                                               {'loss': 0.4557, 'grad_norm': 8.321393013000488, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.21s/it]                                               {'loss': 0.6377, 'grad_norm': 23.597192764282227, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0933, 'grad_norm': 4.020055770874023, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.157, 'grad_norm': 3.8264739513397217, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.5169, 'grad_norm': 11.338107109069824, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.03s/it]                                               {'loss': 0.3385, 'grad_norm': 162.33880615234375, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.5027, 'grad_norm': 8.001830101013184, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.1925, 'grad_norm': 9.758562088012695, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.20s/it]                                               {'loss': 0.1576, 'grad_norm': 2.9797863960266113, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.2662, 'grad_norm': 3.2166976928710938, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.2184, 'grad_norm': 11.961142539978027, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it]                                               {'loss': 0.0685, 'grad_norm': 1.7530455589294434, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.2826, 'grad_norm': 8.047008514404297, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.3676, 'grad_norm': 6.850471019744873, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.185, 'grad_norm': 1.7840265035629272, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.18s/it]                                               {'loss': 0.5092, 'grad_norm': 9.067264556884766, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.22s/it]                                               {'loss': 0.4294, 'grad_norm': 5.118241310119629, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.22s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.26s/it]                                               {'loss': 0.179, 'grad_norm': 4.182572841644287, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.26s/it]100%|██████████| 40/40 [01:19<00:00,  1.64s/it]                                               {'loss': 0.2308, 'grad_norm': 13.150308609008789, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.64s/it]                                               {'train_runtime': 79.7373, 'train_samples_per_second': 7.086, 'train_steps_per_second': 0.502, 'train_loss': 0.9321452230215073, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.64s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:46,  2.73s/it]                                              {'loss': 2.7265, 'grad_norm': 9.18493366241455, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:46,  2.73s/it]  5%|▌         | 2/40 [00:04<01:32,  2.44s/it]                                              {'loss': 2.614, 'grad_norm': 13.371891021728516, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:32,  2.44s/it]  8%|▊         | 3/40 [00:07<01:26,  2.34s/it]                                              {'loss': 2.3639, 'grad_norm': 13.475578308105469, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:26,  2.34s/it] 10%|█         | 4/40 [00:09<01:22,  2.29s/it]                                              {'loss': 3.5834, 'grad_norm': 19.28213882446289, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.29s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it]                                              {'loss': 3.2957, 'grad_norm': 23.543479919433594, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 3.4684, 'grad_norm': 23.417583465576172, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:16<01:14,  2.25s/it]                                              {'loss': 2.3967, 'grad_norm': 19.432146072387695, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:14,  2.25s/it] 20%|██        | 8/40 [00:16<00:50,  1.59s/it]                                              {'loss': 1.6712, 'grad_norm': 42.08835983276367, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 0.7194, 'grad_norm': 11.828561782836914, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 0.6341, 'grad_norm': 10.638545989990234, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:23<00:58,  2.03s/it]                                               {'loss': 0.4162, 'grad_norm': 7.288039207458496, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:58,  2.03s/it] 30%|███       | 12/40 [00:25<00:58,  2.10s/it]                                               {'loss': 0.4446, 'grad_norm': 5.160763263702393, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.10s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it]                                               {'loss': 0.7985, 'grad_norm': 9.985250473022461, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it]                                               {'loss': 1.0128, 'grad_norm': 12.69200611114502, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it] 38%|███▊      | 15/40 [00:32<00:55,  2.23s/it]                                               {'loss': 1.5752, 'grad_norm': 29.097915649414062, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:55,  2.23s/it] 40%|████      | 16/40 [00:32<00:38,  1.62s/it]                                               {'loss': 0.3211, 'grad_norm': 21.853656768798828, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.62s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.82s/it]                                               {'loss': 0.2166, 'grad_norm': 7.013360977172852, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.82s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.8913, 'grad_norm': 5.731586456298828, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:39<00:42,  2.03s/it]                                               {'loss': 0.7097, 'grad_norm': 15.436356544494629, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:42,  2.03s/it] 50%|█████     | 20/40 [00:41<00:42,  2.12s/it]                                               {'loss': 0.0614, 'grad_norm': 2.0945382118225098, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 0.2567, 'grad_norm': 13.832784652709961, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:46<00:39,  2.21s/it]                                               {'loss': 0.184, 'grad_norm': 7.188573837280273, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it]                                               {'loss': 0.1674, 'grad_norm': 1.3487063646316528, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it] 60%|██████    | 24/40 [00:48<00:25,  1.62s/it]                                               {'loss': 0.0108, 'grad_norm': 0.41641300916671753, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it]                                               {'loss': 0.1946, 'grad_norm': 6.544612407684326, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.98s/it]                                               {'loss': 0.0801, 'grad_norm': 3.5561535358428955, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.98s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.06s/it]                                               {'loss': 0.2851, 'grad_norm': 1.4908671379089355, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.06s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.502, 'grad_norm': 17.810937881469727, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.18s/it]                                               {'loss': 0.0487, 'grad_norm': 1.5922856330871582, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.18s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.21s/it]                                               {'loss': 0.0824, 'grad_norm': 1.7640836238861084, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.24s/it]                                               {'loss': 0.1242, 'grad_norm': 3.9409093856811523, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.24s/it] 80%|████████  | 32/40 [01:04<00:13,  1.63s/it]                                               {'loss': 0.0061, 'grad_norm': 0.4162137508392334, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:07<00:12,  1.83s/it]                                               {'loss': 0.0626, 'grad_norm': 2.1810059547424316, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:12,  1.83s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.96s/it]                                               {'loss': 0.2476, 'grad_norm': 2.3467257022857666, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it]                                               {'loss': 0.0601, 'grad_norm': 1.4077759981155396, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it]                                               {'loss': 0.1227, 'grad_norm': 2.752502918243408, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.20s/it]                                               {'loss': 0.0803, 'grad_norm': 2.8019156455993652, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.20s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.23s/it]                                               {'loss': 0.0824, 'grad_norm': 1.9810433387756348, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.23s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.26s/it]                                               {'loss': 0.0612, 'grad_norm': 1.947422742843628, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.26s/it]100%|██████████| 40/40 [01:21<00:00,  1.64s/it]                                               {'loss': 0.0686, 'grad_norm': 3.508345365524292, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.64s/it]                                               {'train_runtime': 81.4211, 'train_samples_per_second': 6.939, 'train_steps_per_second': 0.491, 'train_loss': 0.816202018619515, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.64s/it]100%|██████████| 40/40 [01:21<00:00,  2.04s/it]
CLIENT:93
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:46,  2.73s/it]                                              {'loss': 3.4032, 'grad_norm': 15.682668685913086, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:46,  2.73s/it]  5%|▌         | 2/40 [00:04<01:30,  2.39s/it]                                              {'loss': 3.4671, 'grad_norm': 15.768238067626953, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.39s/it]  8%|▊         | 3/40 [00:07<01:24,  2.28s/it]                                              {'loss': 2.3878, 'grad_norm': 55.95126724243164, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 2.6589, 'grad_norm': 16.118581771850586, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 1.0566, 'grad_norm': 10.739895820617676, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it]                                              {'loss': 3.2201, 'grad_norm': 17.41739845275879, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 1.7946, 'grad_norm': 16.30638885498047, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 1.6567, 'grad_norm': 70.17572784423828, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 1.7812, 'grad_norm': 16.967145919799805, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it]                                               {'loss': 2.2815, 'grad_norm': 18.172109603881836, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.0325, 'grad_norm': 8.390140533447266, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.07s/it]                                               {'loss': 0.5998, 'grad_norm': 7.562160015106201, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.11s/it]                                               {'loss': 1.3204, 'grad_norm': 8.868045806884766, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 0.7399, 'grad_norm': 8.38621711730957, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.9842, 'grad_norm': 44.998504638671875, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.5482, 'grad_norm': 47.24626541137695, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it]                                               {'loss': 0.4706, 'grad_norm': 8.14596939086914, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.9249, 'grad_norm': 9.142598152160645, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.8574, 'grad_norm': 13.61137580871582, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.5032, 'grad_norm': 6.154418468475342, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 0.2179, 'grad_norm': 4.29233980178833, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.3027, 'grad_norm': 3.8200747966766357, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.621, 'grad_norm': 5.272554874420166, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 1.2643, 'grad_norm': 47.770660400390625, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.1657, 'grad_norm': 4.328968048095703, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it]                                               {'loss': 0.1918, 'grad_norm': 4.7632527351379395, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.119, 'grad_norm': 3.074629068374634, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.3033, 'grad_norm': 3.751269578933716, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.4418, 'grad_norm': 31.70850944519043, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.17s/it]                                               {'loss': 0.3343, 'grad_norm': 3.8470473289489746, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.2646, 'grad_norm': 6.958897113800049, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.3618, 'grad_norm': 17.634319305419922, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0644, 'grad_norm': 1.3481839895248413, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it]                                               {'loss': 0.029, 'grad_norm': 0.6337218880653381, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it]                                               {'loss': 0.2634, 'grad_norm': 7.577600955963135, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.3691, 'grad_norm': 3.8443455696105957, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.4445, 'grad_norm': 4.859236717224121, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.321, 'grad_norm': 8.143158912658691, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.0592, 'grad_norm': 1.6279839277267456, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.3949, 'grad_norm': 53.484066009521484, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.9446, 'train_samples_per_second': 7.067, 'train_steps_per_second': 0.5, 'train_loss': 0.9555625181645155, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  2.00s/it]
CLIENT:11
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]                                              {'loss': 3.4342, 'grad_norm': 7.510717868804932, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.19s/it]  5%|▌         | 2/40 [00:04<01:23,  2.19s/it]                                              {'loss': 1.6302, 'grad_norm': 10.086272239685059, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.19s/it]  8%|▊         | 3/40 [00:06<01:20,  2.19s/it]                                              {'loss': 3.0078, 'grad_norm': 21.521142959594727, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.19s/it] 10%|█         | 4/40 [00:08<01:18,  2.19s/it]                                              {'loss': 1.2412, 'grad_norm': 10.157999992370605, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.19s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it]                                              {'loss': 3.7347, 'grad_norm': 45.49913787841797, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 2.718, 'grad_norm': 22.35257911682129, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 2.4833, 'grad_norm': 20.989776611328125, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 0.0459, 'grad_norm': 2.341893434524536, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.74s/it]                                              {'loss': 0.9569, 'grad_norm': 8.717362403869629, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.74s/it] 25%|██▌       | 10/40 [00:19<00:57,  1.91s/it]                                               {'loss': 0.9153, 'grad_norm': 10.084826469421387, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 1.9961, 'grad_norm': 10.10472583770752, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.6937, 'grad_norm': 6.174633979797363, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 0.7877, 'grad_norm': 6.638995170593262, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it]                                               {'loss': 1.1755, 'grad_norm': 7.334354400634766, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.8949, 'grad_norm': 6.100950241088867, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0191, 'grad_norm': 0.755469560623169, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.3702, 'grad_norm': 3.336944818496704, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.2238, 'grad_norm': 3.357163429260254, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.2325, 'grad_norm': 4.014688968658447, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.3849, 'grad_norm': 4.12346076965332, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it]                                               {'loss': 0.398, 'grad_norm': 8.040128707885742, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it]                                               {'loss': 0.194, 'grad_norm': 3.4380271434783936, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.3321, 'grad_norm': 1.6976745128631592, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0329, 'grad_norm': 1.3050850629806519, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.3708, 'grad_norm': 1.8015296459197998, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.0946, 'grad_norm': 1.8396066427230835, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.0854, 'grad_norm': 1.6746037006378174, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.0494, 'grad_norm': 1.4730727672576904, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.0463, 'grad_norm': 0.7889725565910339, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:00<00:22,  2.20s/it]                                               {'loss': 0.0493, 'grad_norm': 1.2093825340270996, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:22,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.22s/it]                                               {'loss': 0.0347, 'grad_norm': 0.7326884269714355, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.0062, 'grad_norm': 0.27849024534225464, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it]                                               {'loss': 0.0219, 'grad_norm': 0.42694494128227234, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it]                                               {'loss': 0.0133, 'grad_norm': 0.6420725584030151, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.015, 'grad_norm': 0.33883705735206604, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.14s/it]                                               {'loss': 0.0116, 'grad_norm': 0.21401625871658325, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.8258, 'grad_norm': 19.390033721923828, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.922, 'grad_norm': 3.9616057872772217, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.0626, 'grad_norm': 2.4950859546661377, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.1029, 'grad_norm': 6.621267318725586, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.808, 'train_samples_per_second': 7.079, 'train_steps_per_second': 0.501, 'train_loss': 0.7653638304327615, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  2.00s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  do_eval=True, seed=self.args.random_seed)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:55,  1.59it/s]  1%|          | 3/471 [00:02<06:56,  1.12it/s]  1%|          | 4/471 [00:03<08:02,  1.03s/it]  1%|          | 5/471 [00:05<08:39,  1.11s/it]  1%|▏         | 6/471 [00:06<09:01,  1.17s/it]  1%|▏         | 7/471 [00:07<09:16,  1.20s/it]  2%|▏         | 8/471 [00:08<09:25,  1.22s/it]  2%|▏         | 9/471 [00:10<09:32,  1.24s/it]  2%|▏         | 10/471 [00:11<09:35,  1.25s/it]  2%|▏         | 11/471 [00:12<09:38,  1.26s/it]  3%|▎         | 12/471 [00:13<09:40,  1.26s/it]  3%|▎         | 13/471 [00:15<09:41,  1.27s/it]  3%|▎         | 14/471 [00:16<09:42,  1.27s/it]  3%|▎         | 15/471 [00:17<09:41,  1.28s/it]  3%|▎         | 16/471 [00:19<09:42,  1.28s/it]  4%|▎         | 17/471 [00:20<09:42,  1.28s/it]  4%|▍         | 18/471 [00:21<09:41,  1.28s/it]  4%|▍         | 19/471 [00:22<09:40,  1.28s/it]  4%|▍         | 20/471 [00:24<09:40,  1.29s/it]  4%|▍         | 21/471 [00:25<09:39,  1.29s/it]  5%|▍         | 22/471 [00:26<09:39,  1.29s/it]  5%|▍         | 23/471 [00:28<09:38,  1.29s/it]  5%|▌         | 24/471 [00:29<09:37,  1.29s/it]  5%|▌         | 25/471 [00:30<09:36,  1.29s/it]  6%|▌         | 26/471 [00:32<09:36,  1.29s/it]  6%|▌         | 27/471 [00:33<09:34,  1.29s/it]  6%|▌         | 28/471 [00:34<09:34,  1.30s/it]  6%|▌         | 29/471 [00:35<09:33,  1.30s/it]  6%|▋         | 30/471 [00:37<09:32,  1.30s/it]  7%|▋         | 31/471 [00:38<09:31,  1.30s/it]  7%|▋         | 32/471 [00:39<09:30,  1.30s/it]  7%|▋         | 33/471 [00:41<09:28,  1.30s/it]  7%|▋         | 34/471 [00:42<09:27,  1.30s/it]  7%|▋         | 35/471 [00:43<09:27,  1.30s/it]  8%|▊         | 36/471 [00:45<09:26,  1.30s/it]  8%|▊         | 37/471 [00:46<09:25,  1.30s/it]  8%|▊         | 38/471 [00:47<09:25,  1.31s/it]  8%|▊         | 39/471 [00:48<09:23,  1.30s/it]  8%|▊         | 40/471 [00:50<09:22,  1.30s/it]  9%|▊         | 41/471 [00:51<09:21,  1.31s/it]  9%|▉         | 42/471 [00:52<09:21,  1.31s/it]  9%|▉         | 43/471 [00:54<09:19,  1.31s/it]  9%|▉         | 44/471 [00:55<09:18,  1.31s/it] 10%|▉         | 45/471 [00:56<09:18,  1.31s/it] 10%|▉         | 46/471 [00:58<09:16,  1.31s/it] 10%|▉         | 47/471 [00:59<09:15,  1.31s/it] 10%|█         | 48/471 [01:00<09:14,  1.31s/it] 10%|█         | 49/471 [01:02<09:13,  1.31s/it] 11%|█         | 50/471 [01:03<09:12,  1.31s/it] 11%|█         | 51/471 [01:04<09:11,  1.31s/it] 11%|█         | 52/471 [01:05<09:10,  1.31s/it] 11%|█▏        | 53/471 [01:07<09:09,  1.32s/it] 11%|█▏        | 54/471 [01:08<09:08,  1.32s/it] 12%|█▏        | 55/471 [01:09<09:07,  1.32s/it] 12%|█▏        | 56/471 [01:11<09:06,  1.32s/it] 12%|█▏        | 57/471 [01:12<09:05,  1.32s/it] 12%|█▏        | 58/471 [01:13<09:04,  1.32s/it] 13%|█▎        | 59/471 [01:15<09:03,  1.32s/it] 13%|█▎        | 60/471 [01:16<09:02,  1.32s/it] 13%|█▎        | 61/471 [01:17<09:01,  1.32s/it] 13%|█▎        | 62/471 [01:19<08:59,  1.32s/it] 13%|█▎        | 63/471 [01:20<08:58,  1.32s/it] 14%|█▎        | 64/471 [01:21<08:57,  1.32s/it] 14%|█▍        | 65/471 [01:23<08:55,  1.32s/it] 14%|█▍        | 66/471 [01:24<08:55,  1.32s/it] 14%|█▍        | 67/471 [01:25<08:54,  1.32s/it] 14%|█▍        | 68/471 [01:27<08:52,  1.32s/it] 15%|█▍        | 69/471 [01:28<08:50,  1.32s/it] 15%|█▍        | 70/471 [01:29<08:50,  1.32s/it] 15%|█▌        | 71/471 [01:31<08:49,  1.32s/it] 15%|█▌        | 72/471 [01:32<08:47,  1.32s/it] 15%|█▌        | 73/471 [01:33<08:46,  1.32s/it] 16%|█▌        | 74/471 [01:35<08:43,  1.32s/it] 16%|█▌        | 75/471 [01:36<08:43,  1.32s/it] 16%|█▌        | 76/471 [01:37<08:41,  1.32s/it] 16%|█▋        | 77/471 [01:39<08:40,  1.32s/it] 17%|█▋        | 78/471 [01:40<08:39,  1.32s/it] 17%|█▋        | 79/471 [01:41<08:38,  1.32s/it] 17%|█▋        | 80/471 [01:42<08:37,  1.32s/it] 17%|█▋        | 81/471 [01:44<08:35,  1.32s/it] 17%|█▋        | 82/471 [01:45<08:34,  1.32s/it] 18%|█▊        | 83/471 [01:46<08:33,  1.32s/it] 18%|█▊        | 84/471 [01:48<08:31,  1.32s/it] 18%|█▊        | 85/471 [01:49<08:31,  1.32s/it] 18%|█▊        | 86/471 [01:50<08:29,  1.32s/it] 18%|█▊        | 87/471 [01:52<08:28,  1.32s/it] 19%|█▊        | 88/471 [01:53<08:26,  1.32s/it] 19%|█▉        | 89/471 [01:54<08:24,  1.32s/it] 19%|█▉        | 90/471 [01:56<08:24,  1.32s/it] 19%|█▉        | 91/471 [01:57<08:22,  1.32s/it] 20%|█▉        | 92/471 [01:58<08:21,  1.32s/it] 20%|█▉        | 93/471 [02:00<08:20,  1.32s/it] 20%|█▉        | 94/471 [02:01<08:19,  1.32s/it] 20%|██        | 95/471 [02:02<08:17,  1.32s/it] 20%|██        | 96/471 [02:04<08:16,  1.32s/it] 21%|██        | 97/471 [02:05<08:16,  1.33s/it] 21%|██        | 98/471 [02:06<08:14,  1.33s/it] 21%|██        | 99/471 [02:08<08:12,  1.32s/it] 21%|██        | 100/471 [02:09<08:11,  1.32s/it] 21%|██▏       | 101/471 [02:10<08:10,  1.32s/it] 22%|██▏       | 102/471 [02:12<08:09,  1.33s/it] 22%|██▏       | 103/471 [02:13<08:08,  1.33s/it] 22%|██▏       | 104/471 [02:14<08:07,  1.33s/it] 22%|██▏       | 105/471 [02:16<08:07,  1.33s/it] 23%|██▎       | 106/471 [02:17<08:04,  1.33s/it] 23%|██▎       | 107/471 [02:18<08:03,  1.33s/it] 23%|██▎       | 108/471 [02:20<08:01,  1.33s/it] 23%|██▎       | 109/471 [02:21<07:59,  1.32s/it] 23%|██▎       | 110/471 [02:22<07:57,  1.32s/it] 24%|██▎       | 111/471 [02:24<07:56,  1.32s/it] 24%|██▍       | 112/471 [02:25<07:55,  1.32s/it] 24%|██▍       | 113/471 [02:26<07:53,  1.32s/it] 24%|██▍       | 114/471 [02:28<07:52,  1.32s/it] 24%|██▍       | 115/471 [02:29<07:51,  1.32s/it] 25%|██▍       | 116/471 [02:30<07:50,  1.33s/it] 25%|██▍       | 117/471 [02:32<07:49,  1.33s/it] 25%|██▌       | 118/471 [02:33<07:48,  1.33s/it] 25%|██▌       | 119/471 [02:34<07:46,  1.33s/it] 25%|██▌       | 120/471 [02:35<07:45,  1.33s/it] 26%|██▌       | 121/471 [02:37<07:44,  1.33s/it] 26%|██▌       | 122/471 [02:38<07:44,  1.33s/it] 26%|██▌       | 123/471 [02:39<07:42,  1.33s/it] 26%|██▋       | 124/471 [02:41<07:41,  1.33s/it] 27%|██▋       | 125/471 [02:42<07:40,  1.33s/it] 27%|██▋       | 126/471 [02:43<07:39,  1.33s/it] 27%|██▋       | 127/471 [02:45<07:38,  1.33s/it] 27%|██▋       | 128/471 [02:46<07:36,  1.33s/it] 27%|██▋       | 129/471 [02:47<07:34,  1.33s/it] 28%|██▊       | 130/471 [02:49<07:34,  1.33s/it] 28%|██▊       | 131/471 [02:50<07:33,  1.33s/it] 28%|██▊       | 132/471 [02:51<07:31,  1.33s/it] 28%|██▊       | 133/471 [02:53<07:30,  1.33s/it] 28%|██▊       | 134/471 [02:54<07:29,  1.33s/it] 29%|██▊       | 135/471 [02:55<07:28,  1.33s/it] 29%|██▉       | 136/471 [02:57<07:26,  1.33s/it] 29%|██▉       | 137/471 [02:58<07:25,  1.33s/it] 29%|██▉       | 138/471 [02:59<07:24,  1.33s/it] 30%|██▉       | 139/471 [03:01<07:23,  1.33s/it] 30%|██▉       | 140/471 [03:02<07:21,  1.33s/it] 30%|██▉       | 141/471 [03:03<07:20,  1.33s/it] 30%|███       | 142/471 [03:05<07:18,  1.33s/it] 30%|███       | 143/471 [03:06<07:17,  1.33s/it] 31%|███       | 144/471 [03:07<07:16,  1.34s/it] 31%|███       | 145/471 [03:09<07:14,  1.33s/it] 31%|███       | 146/471 [03:10<07:13,  1.33s/it] 31%|███       | 147/471 [03:11<07:12,  1.33s/it] 31%|███▏      | 148/471 [03:13<07:11,  1.33s/it] 32%|███▏      | 149/471 [03:14<07:10,  1.34s/it] 32%|███▏      | 150/471 [03:16<07:09,  1.34s/it] 32%|███▏      | 151/471 [03:17<07:08,  1.34s/it] 32%|███▏      | 152/471 [03:18<07:06,  1.34s/it] 32%|███▏      | 153/471 [03:20<07:06,  1.34s/it] 33%|███▎      | 154/471 [03:21<07:03,  1.34s/it] 33%|███▎      | 155/471 [03:22<07:02,  1.34s/it] 33%|███▎      | 156/471 [03:24<07:01,  1.34s/it] 33%|███▎      | 157/471 [03:25<06:59,  1.34s/it] 34%|███▎      | 158/471 [03:26<06:57,  1.34s/it] 34%|███▍      | 159/471 [03:28<06:56,  1.33s/it] 34%|███▍      | 160/471 [03:29<06:56,  1.34s/it] 34%|███▍      | 161/471 [03:30<06:55,  1.34s/it] 34%|███▍      | 162/471 [03:32<06:54,  1.34s/it] 35%|███▍      | 163/471 [03:33<06:53,  1.34s/it] 35%|███▍      | 164/471 [03:34<06:51,  1.34s/it] 35%|███▌      | 165/471 [03:36<06:50,  1.34s/it] 35%|███▌      | 166/471 [03:37<06:49,  1.34s/it] 35%|███▌      | 167/471 [03:38<06:48,  1.34s/it] 36%|███▌      | 168/471 [03:40<06:46,  1.34s/it] 36%|███▌      | 169/471 [03:41<06:46,  1.34s/it] 36%|███▌      | 170/471 [03:42<06:44,  1.34s/it] 36%|███▋      | 171/471 [03:44<06:42,  1.34s/it] 37%|███▋      | 172/471 [03:45<06:40,  1.34s/it] 37%|███▋      | 173/471 [03:46<06:39,  1.34s/it] 37%|███▋      | 174/471 [03:48<06:38,  1.34s/it] 37%|███▋      | 175/471 [03:49<06:37,  1.34s/it] 37%|███▋      | 176/471 [03:50<06:35,  1.34s/it] 38%|███▊      | 177/471 [03:52<06:34,  1.34s/it] 38%|███▊      | 178/471 [03:53<06:32,  1.34s/it] 38%|███▊      | 179/471 [03:54<06:31,  1.34s/it] 38%|███▊      | 180/471 [03:56<06:30,  1.34s/it] 38%|███▊      | 181/471 [03:57<06:29,  1.34s/it] 39%|███▊      | 182/471 [03:58<06:27,  1.34s/it] 39%|███▉      | 183/471 [04:00<06:26,  1.34s/it] 39%|███▉      | 184/471 [04:01<06:25,  1.34s/it] 39%|███▉      | 185/471 [04:02<06:23,  1.34s/it] 39%|███▉      | 186/471 [04:04<06:22,  1.34s/it] 40%|███▉      | 187/471 [04:05<06:21,  1.34s/it] 40%|███▉      | 188/471 [04:06<06:20,  1.34s/it] 40%|████      | 189/471 [04:08<06:18,  1.34s/it] 40%|████      | 190/471 [04:09<06:16,  1.34s/it] 41%|████      | 191/471 [04:10<06:15,  1.34s/it] 41%|████      | 192/471 [04:12<06:14,  1.34s/it] 41%|████      | 193/471 [04:13<06:12,  1.34s/it] 41%|████      | 194/471 [04:14<06:11,  1.34s/it] 41%|████▏     | 195/471 [04:16<06:10,  1.34s/it] 42%|████▏     | 196/471 [04:17<06:08,  1.34s/it] 42%|████▏     | 197/471 [04:19<06:06,  1.34s/it] 42%|████▏     | 198/471 [04:20<06:05,  1.34s/it] 42%|████▏     | 199/471 [04:21<06:04,  1.34s/it] 42%|████▏     | 200/471 [04:23<06:03,  1.34s/it] 43%|████▎     | 201/471 [04:24<06:00,  1.34s/it] 43%|████▎     | 202/471 [04:25<05:59,  1.34s/it] 43%|████▎     | 203/471 [04:27<05:58,  1.34s/it] 43%|████▎     | 204/471 [04:28<05:57,  1.34s/it] 44%|████▎     | 205/471 [04:29<05:55,  1.34s/it] 44%|████▎     | 206/471 [04:31<05:53,  1.34s/it] 44%|████▍     | 207/471 [04:32<05:52,  1.34s/it] 44%|████▍     | 208/471 [04:33<05:50,  1.33s/it] 44%|████▍     | 209/471 [04:35<05:49,  1.33s/it] 45%|████▍     | 210/471 [04:36<05:47,  1.33s/it] 45%|████▍     | 211/471 [04:37<05:46,  1.33s/it] 45%|████▌     | 212/471 [04:39<05:45,  1.33s/it] 45%|████▌     | 213/471 [04:40<05:44,  1.34s/it] 45%|████▌     | 214/471 [04:41<05:42,  1.33s/it] 46%|████▌     | 215/471 [04:43<05:41,  1.33s/it] 46%|████▌     | 216/471 [04:44<05:40,  1.34s/it] 46%|████▌     | 217/471 [04:45<05:39,  1.34s/it] 46%|████▋     | 218/471 [04:47<05:37,  1.34s/it] 46%|████▋     | 219/471 [04:48<05:36,  1.33s/it] 47%|████▋     | 220/471 [04:49<05:35,  1.34s/it] 47%|████▋     | 221/471 [04:51<05:34,  1.34s/it] 47%|████▋     | 222/471 [04:52<05:31,  1.33s/it] 47%|████▋     | 223/471 [04:53<05:30,  1.33s/it] 48%|████▊     | 224/471 [04:55<05:29,  1.33s/it] 48%|████▊     | 225/471 [04:56<05:28,  1.33s/it] 48%|████▊     | 226/471 [04:57<05:26,  1.33s/it] 48%|████▊     | 227/471 [04:59<05:25,  1.33s/it] 48%|████▊     | 228/471 [05:00<05:24,  1.33s/it] 49%|████▊     | 229/471 [05:01<05:23,  1.34s/it] 49%|████▉     | 230/471 [05:03<05:21,  1.34s/it] 49%|████▉     | 231/471 [05:04<05:20,  1.33s/it] 49%|████▉     | 232/471 [05:05<05:18,  1.33s/it] 49%|████▉     | 233/471 [05:07<05:16,  1.33s/it] 50%|████▉     | 234/471 [05:08<05:15,  1.33s/it] 50%|████▉     | 235/471 [05:09<05:14,  1.33s/it] 50%|█████     | 236/471 [05:11<05:12,  1.33s/it] 50%|█████     | 237/471 [05:12<05:11,  1.33s/it] 51%|█████     | 238/471 [05:13<05:10,  1.33s/it] 51%|█████     | 239/471 [05:15<05:09,  1.33s/it] 51%|█████     | 240/471 [05:16<05:07,  1.33s/it] 51%|█████     | 241/471 [05:17<05:06,  1.33s/it] 51%|█████▏    | 242/471 [05:19<05:05,  1.33s/it] 52%|█████▏    | 243/471 [05:20<05:04,  1.33s/it] 52%|█████▏    | 244/471 [05:21<05:02,  1.33s/it] 52%|█████▏    | 245/471 [05:23<05:01,  1.33s/it] 52%|█████▏    | 246/471 [05:24<04:59,  1.33s/it] 52%|█████▏    | 247/471 [05:25<04:58,  1.33s/it] 53%|█████▎    | 248/471 [05:27<04:57,  1.33s/it] 53%|█████▎    | 249/471 [05:28<04:56,  1.33s/it] 53%|█████▎    | 250/471 [05:29<04:54,  1.33s/it] 53%|█████▎    | 251/471 [05:31<04:53,  1.33s/it] 54%|█████▎    | 252/471 [05:32<04:51,  1.33s/it] 54%|█████▎    | 253/471 [05:33<04:50,  1.33s/it] 54%|█████▍    | 254/471 [05:35<04:49,  1.33s/it] 54%|█████▍    | 255/471 [05:36<04:47,  1.33s/it] 54%|█████▍    | 256/471 [05:37<04:46,  1.33s/it] 55%|█████▍    | 257/471 [05:39<04:45,  1.33s/it] 55%|█████▍    | 258/471 [05:40<04:43,  1.33s/it] 55%|█████▍    | 259/471 [05:41<04:42,  1.33s/it] 55%|█████▌    | 260/471 [05:43<04:41,  1.33s/it] 55%|█████▌    | 261/471 [05:44<04:39,  1.33s/it] 56%|█████▌    | 262/471 [05:45<04:38,  1.33s/it] 56%|█████▌    | 263/471 [05:47<04:36,  1.33s/it] 56%|█████▌    | 264/471 [05:48<04:35,  1.33s/it] 56%|█████▋    | 265/471 [05:49<04:34,  1.33s/it] 56%|█████▋    | 266/471 [05:51<04:32,  1.33s/it] 57%|█████▋    | 267/471 [05:52<04:31,  1.33s/it] 57%|█████▋    | 268/471 [05:53<04:30,  1.33s/it] 57%|█████▋    | 269/471 [05:55<04:28,  1.33s/it] 57%|█████▋    | 270/471 [05:56<04:27,  1.33s/it] 58%|█████▊    | 271/471 [05:57<04:26,  1.33s/it] 58%|█████▊    | 272/471 [05:59<04:24,  1.33s/it] 58%|█████▊    | 273/471 [06:00<04:23,  1.33s/it] 58%|█████▊    | 274/471 [06:01<04:21,  1.33s/it] 58%|█████▊    | 275/471 [06:03<04:20,  1.33s/it] 59%|█████▊    | 276/471 [06:04<04:19,  1.33s/it] 59%|█████▉    | 277/471 [06:05<04:17,  1.33s/it] 59%|█████▉    | 278/471 [06:07<04:16,  1.33s/it] 59%|█████▉    | 279/471 [06:08<04:15,  1.33s/it] 59%|█████▉    | 280/471 [06:09<04:13,  1.33s/it] 60%|█████▉    | 281/471 [06:10<04:12,  1.33s/it] 60%|█████▉    | 282/471 [06:12<04:11,  1.33s/it] 60%|██████    | 283/471 [06:13<04:09,  1.33s/it] 60%|██████    | 284/471 [06:14<04:08,  1.33s/it] 61%|██████    | 285/471 [06:16<04:07,  1.33s/it] 61%|██████    | 286/471 [06:17<04:05,  1.33s/it] 61%|██████    | 287/471 [06:18<04:04,  1.33s/it] 61%|██████    | 288/471 [06:20<04:03,  1.33s/it] 61%|██████▏   | 289/471 [06:21<04:01,  1.33s/it] 62%|██████▏   | 290/471 [06:22<04:00,  1.33s/it] 62%|██████▏   | 291/471 [06:24<03:58,  1.33s/it] 62%|██████▏   | 292/471 [06:25<03:57,  1.33s/it] 62%|██████▏   | 293/471 [06:26<03:56,  1.33s/it] 62%|██████▏   | 294/471 [06:28<03:54,  1.33s/it] 63%|██████▎   | 295/471 [06:29<03:53,  1.33s/it] 63%|██████▎   | 296/471 [06:30<03:52,  1.33s/it] 63%|██████▎   | 297/471 [06:32<03:50,  1.33s/it] 63%|██████▎   | 298/471 [06:33<03:49,  1.33s/it] 63%|██████▎   | 299/471 [06:34<03:48,  1.33s/it] 64%|██████▎   | 300/471 [06:36<03:47,  1.33s/it] 64%|██████▍   | 301/471 [06:37<03:45,  1.33s/it] 64%|██████▍   | 302/471 [06:38<03:44,  1.33s/it] 64%|██████▍   | 303/471 [06:40<03:42,  1.33s/it] 65%|██████▍   | 304/471 [06:41<03:41,  1.33s/it] 65%|██████▍   | 305/471 [06:42<03:40,  1.33s/it] 65%|██████▍   | 306/471 [06:44<03:39,  1.33s/it] 65%|██████▌   | 307/471 [06:45<03:37,  1.33s/it] 65%|██████▌   | 308/471 [06:46<03:36,  1.33s/it] 66%|██████▌   | 309/471 [06:48<03:35,  1.33s/it] 66%|██████▌   | 310/471 [06:49<03:34,  1.33s/it] 66%|██████▌   | 311/471 [06:50<03:32,  1.33s/it] 66%|██████▌   | 312/471 [06:52<03:31,  1.33s/it] 66%|██████▋   | 313/471 [06:53<03:29,  1.33s/it] 67%|██████▋   | 314/471 [06:54<03:28,  1.33s/it] 67%|██████▋   | 315/471 [06:56<03:27,  1.33s/it] 67%|██████▋   | 316/471 [06:57<03:25,  1.33s/it] 67%|██████▋   | 317/471 [06:58<03:24,  1.33s/it] 68%|██████▊   | 318/471 [07:00<03:23,  1.33s/it] 68%|██████▊   | 319/471 [07:01<03:22,  1.33s/it] 68%|██████▊   | 320/471 [07:02<03:20,  1.33s/it] 68%|██████▊   | 321/471 [07:04<03:19,  1.33s/it] 68%|██████▊   | 322/471 [07:05<03:18,  1.33s/it] 69%|██████▊   | 323/471 [07:06<03:17,  1.33s/it] 69%|██████▉   | 324/471 [07:08<03:16,  1.33s/it] 69%|██████▉   | 325/471 [07:09<03:14,  1.33s/it] 69%|██████▉   | 326/471 [07:10<03:12,  1.33s/it] 69%|██████▉   | 327/471 [07:12<03:11,  1.33s/it] 70%|██████▉   | 328/471 [07:13<03:10,  1.33s/it] 70%|██████▉   | 329/471 [07:14<03:09,  1.33s/it] 70%|███████   | 330/471 [07:16<03:07,  1.33s/it] 70%|███████   | 331/471 [07:17<03:06,  1.33s/it] 70%|███████   | 332/471 [07:18<03:05,  1.33s/it] 71%|███████   | 333/471 [07:20<03:03,  1.33s/it] 71%|███████   | 334/471 [07:21<03:02,  1.33s/it] 71%|███████   | 335/471 [07:22<03:01,  1.33s/it] 71%|███████▏  | 336/471 [07:24<02:59,  1.33s/it] 72%|███████▏  | 337/471 [07:25<02:58,  1.33s/it] 72%|███████▏  | 338/471 [07:26<02:56,  1.33s/it] 72%|███████▏  | 339/471 [07:28<02:55,  1.33s/it] 72%|███████▏  | 340/471 [07:29<02:54,  1.33s/it] 72%|███████▏  | 341/471 [07:30<02:52,  1.33s/it] 73%|███████▎  | 342/471 [07:32<02:51,  1.33s/it] 73%|███████▎  | 343/471 [07:33<02:50,  1.33s/it] 73%|███████▎  | 344/471 [07:34<02:48,  1.33s/it] 73%|███████▎  | 345/471 [07:36<02:47,  1.33s/it] 73%|███████▎  | 346/471 [07:37<02:46,  1.33s/it] 74%|███████▎  | 347/471 [07:38<02:44,  1.33s/it] 74%|███████▍  | 348/471 [07:40<02:43,  1.33s/it] 74%|███████▍  | 349/471 [07:41<02:42,  1.33s/it] 74%|███████▍  | 350/471 [07:42<02:41,  1.33s/it] 75%|███████▍  | 351/471 [07:44<02:39,  1.33s/it] 75%|███████▍  | 352/471 [07:45<02:38,  1.33s/it] 75%|███████▍  | 353/471 [07:46<02:37,  1.34s/it] 75%|███████▌  | 354/471 [07:48<02:36,  1.34s/it] 75%|███████▌  | 355/471 [07:49<02:35,  1.34s/it] 76%|███████▌  | 356/471 [07:50<02:33,  1.34s/it] 76%|███████▌  | 357/471 [07:52<02:32,  1.34s/it] 76%|███████▌  | 358/471 [07:53<02:31,  1.34s/it] 76%|███████▌  | 359/471 [07:54<02:29,  1.34s/it] 76%|███████▋  | 360/471 [07:56<02:28,  1.34s/it] 77%|███████▋  | 361/471 [07:57<02:26,  1.34s/it] 77%|███████▋  | 362/471 [07:58<02:25,  1.34s/it] 77%|███████▋  | 363/471 [08:00<02:24,  1.33s/it] 77%|███████▋  | 364/471 [08:01<02:22,  1.34s/it] 77%|███████▋  | 365/471 [08:02<02:21,  1.34s/it] 78%|███████▊  | 366/471 [08:04<02:20,  1.34s/it] 78%|███████▊  | 367/471 [08:05<02:19,  1.34s/it] 78%|███████▊  | 368/471 [08:06<02:17,  1.34s/it] 78%|███████▊  | 369/471 [08:08<02:16,  1.34s/it] 79%|███████▊  | 370/471 [08:09<02:15,  1.34s/it] 79%|███████▉  | 371/471 [08:10<02:13,  1.34s/it] 79%|███████▉  | 372/471 [08:12<02:12,  1.34s/it] 79%|███████▉  | 373/471 [08:13<02:11,  1.34s/it] 79%|███████▉  | 374/471 [08:14<02:09,  1.34s/it] 80%|███████▉  | 375/471 [08:16<02:08,  1.34s/it] 80%|███████▉  | 376/471 [08:17<02:07,  1.34s/it] 80%|████████  | 377/471 [08:18<02:06,  1.34s/it] 80%|████████  | 378/471 [08:20<02:04,  1.34s/it] 80%|████████  | 379/471 [08:21<02:03,  1.34s/it] 81%|████████  | 380/471 [08:22<02:02,  1.34s/it] 81%|████████  | 381/471 [08:24<02:00,  1.34s/it] 81%|████████  | 382/471 [08:25<01:59,  1.34s/it] 81%|████████▏ | 383/471 [08:26<01:58,  1.34s/it] 82%|████████▏ | 384/471 [08:28<01:56,  1.34s/it] 82%|████████▏ | 385/471 [08:29<01:55,  1.35s/it] 82%|████████▏ | 386/471 [08:30<01:54,  1.35s/it] 82%|████████▏ | 387/471 [08:32<01:53,  1.35s/it] 82%|████████▏ | 388/471 [08:33<01:51,  1.35s/it] 83%|████████▎ | 389/471 [08:34<01:50,  1.35s/it] 83%|████████▎ | 390/471 [08:36<01:49,  1.35s/it] 83%|████████▎ | 391/471 [08:37<01:47,  1.35s/it] 83%|████████▎ | 392/471 [08:39<01:46,  1.35s/it] 83%|████████▎ | 393/471 [08:40<01:45,  1.35s/it] 84%|████████▎ | 394/471 [08:41<01:43,  1.35s/it] 84%|████████▍ | 395/471 [08:43<01:42,  1.34s/it] 84%|████████▍ | 396/471 [08:44<01:40,  1.34s/it] 84%|████████▍ | 397/471 [08:45<01:39,  1.34s/it] 85%|████████▍ | 398/471 [08:47<01:38,  1.34s/it] 85%|████████▍ | 399/471 [08:48<01:36,  1.34s/it] 85%|████████▍ | 400/471 [08:49<01:35,  1.34s/it] 85%|████████▌ | 401/471 [08:51<01:33,  1.34s/it] 85%|████████▌ | 402/471 [08:52<01:32,  1.34s/it] 86%|████████▌ | 403/471 [08:53<01:31,  1.34s/it] 86%|████████▌ | 404/471 [08:55<01:29,  1.34s/it] 86%|████████▌ | 405/471 [08:56<01:28,  1.34s/it] 86%|████████▌ | 406/471 [08:57<01:26,  1.34s/it] 86%|████████▋ | 407/471 [08:59<01:25,  1.34s/it] 87%|████████▋ | 408/471 [09:00<01:24,  1.34s/it] 87%|████████▋ | 409/471 [09:01<01:23,  1.34s/it] 87%|████████▋ | 410/471 [09:03<01:21,  1.34s/it] 87%|████████▋ | 411/471 [09:04<01:20,  1.34s/it] 87%|████████▋ | 412/471 [09:05<01:19,  1.34s/it] 88%|████████▊ | 413/471 [09:07<01:17,  1.34s/it] 88%|████████▊ | 414/471 [09:08<01:16,  1.34s/it] 88%|████████▊ | 415/471 [09:09<01:14,  1.34s/it] 88%|████████▊ | 416/471 [09:11<01:13,  1.34s/it] 89%|████████▊ | 417/471 [09:12<01:12,  1.34s/it] 89%|████████▊ | 418/471 [09:13<01:10,  1.34s/it] 89%|████████▉ | 419/471 [09:15<01:09,  1.34s/it] 89%|████████▉ | 420/471 [09:16<01:08,  1.34s/it] 89%|████████▉ | 421/471 [09:17<01:06,  1.34s/it] 90%|████████▉ | 422/471 [09:19<01:05,  1.34s/it] 90%|████████▉ | 423/471 [09:20<01:04,  1.34s/it] 90%|█████████ | 424/471 [09:21<01:02,  1.34s/it] 90%|█████████ | 425/471 [09:23<01:01,  1.34s/it] 90%|█████████ | 426/471 [09:24<01:00,  1.34s/it] 91%|█████████ | 427/471 [09:25<00:58,  1.34s/it] 91%|█████████ | 428/471 [09:27<00:57,  1.34s/it] 91%|█████████ | 429/471 [09:28<00:56,  1.34s/it] 91%|█████████▏| 430/471 [09:29<00:54,  1.34s/it] 92%|█████████▏| 431/471 [09:31<00:53,  1.34s/it] 92%|█████████▏| 432/471 [09:32<00:52,  1.34s/it] 92%|█████████▏| 433/471 [09:33<00:50,  1.34s/it] 92%|█████████▏| 434/471 [09:35<00:49,  1.34s/it] 92%|█████████▏| 435/471 [09:36<00:48,  1.34s/it] 93%|█████████▎| 436/471 [09:37<00:46,  1.34s/it] 93%|█████████▎| 437/471 [09:39<00:45,  1.34s/it] 93%|█████████▎| 438/471 [09:40<00:44,  1.34s/it] 93%|█████████▎| 439/471 [09:41<00:42,  1.34s/it] 93%|█████████▎| 440/471 [09:43<00:41,  1.34s/it] 94%|█████████▎| 441/471 [09:44<00:40,  1.34s/it] 94%|█████████▍| 442/471 [09:45<00:38,  1.34s/it] 94%|█████████▍| 443/471 [09:47<00:37,  1.33s/it] 94%|█████████▍| 444/471 [09:48<00:36,  1.33s/it] 94%|█████████▍| 445/471 [09:49<00:34,  1.34s/it] 95%|█████████▍| 446/471 [09:51<00:33,  1.34s/it] 95%|█████████▍| 447/471 [09:52<00:32,  1.33s/it] 95%|█████████▌| 448/471 [09:53<00:30,  1.33s/it] 95%|█████████▌| 449/471 [09:55<00:29,  1.33s/it] 96%|█████████▌| 450/471 [09:56<00:28,  1.33s/it] 96%|█████████▌| 451/471 [09:57<00:26,  1.33s/it] 96%|█████████▌| 452/471 [09:59<00:25,  1.33s/it] 96%|█████████▌| 453/471 [10:00<00:23,  1.33s/it] 96%|█████████▋| 454/471 [10:01<00:22,  1.33s/it] 97%|█████████▋| 455/471 [10:03<00:21,  1.33s/it] 97%|█████████▋| 456/471 [10:04<00:19,  1.33s/it] 97%|█████████▋| 457/471 [10:05<00:18,  1.33s/it] 97%|█████████▋| 458/471 [10:07<00:17,  1.33s/it] 97%|█████████▋| 459/471 [10:08<00:15,  1.33s/it] 98%|█████████▊| 460/471 [10:09<00:14,  1.33s/it] 98%|█████████▊| 461/471 [10:11<00:13,  1.33s/it] 98%|█████████▊| 462/471 [10:12<00:11,  1.33s/it] 98%|█████████▊| 463/471 [10:13<00:10,  1.33s/it] 99%|█████████▊| 464/471 [10:15<00:09,  1.33s/it] 99%|█████████▊| 465/471 [10:16<00:07,  1.33s/it] 99%|█████████▉| 466/471 [10:17<00:06,  1.33s/it] 99%|█████████▉| 467/471 [10:19<00:05,  1.33s/it] 99%|█████████▉| 468/471 [10:20<00:03,  1.33s/it]100%|█████████▉| 469/471 [10:21<00:02,  1.33s/it]100%|█████████▉| 470/471 [10:23<00:01,  1.33s/it]100%|██████████| 471/471 [10:24<00:00,  1.22s/it]100%|██████████| 471/471 [10:24<00:00,  1.33s/it]
{'eval_loss': 3.2464616298675537, 'eval_model_preparation_time': 0.0112, 'eval_acc': 0.2575677110993096, 'eval_runtime': 625.4445, 'eval_samples_per_second': 12.043, 'eval_steps_per_second': 0.753}
ROUND:12
CLIENT:80
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]                                              {'loss': 3.7877, 'grad_norm': 11.017671585083008, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]                                              {'loss': 2.2048, 'grad_norm': 14.150638580322266, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 2.1427, 'grad_norm': 12.824520111083984, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 2.282, 'grad_norm': 13.294986724853516, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it]                                              {'loss': 2.6449, 'grad_norm': 21.229928970336914, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 2.3707, 'grad_norm': 16.982131958007812, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 3.0941, 'grad_norm': 22.898700714111328, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 1.0283, 'grad_norm': 59.88279342651367, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 2.0732, 'grad_norm': 21.91048812866211, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 0.8921, 'grad_norm': 10.327248573303223, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.7883, 'grad_norm': 9.503522872924805, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.7845, 'grad_norm': 6.9713969230651855, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 1.1988, 'grad_norm': 7.655145645141602, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it]                                               {'loss': 1.333, 'grad_norm': 9.071372985839844, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 1.1714, 'grad_norm': 7.373983383178711, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 0.6301, 'grad_norm': 36.032745361328125, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.2738, 'grad_norm': 5.69036865234375, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it]                                               {'loss': 0.3825, 'grad_norm': 10.024396896362305, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:38<00:44,  2.12s/it]                                               {'loss': 0.5664, 'grad_norm': 5.7059831619262695, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:44,  2.12s/it] 50%|█████     | 20/40 [00:40<00:42,  2.13s/it]                                               {'loss': 0.3411, 'grad_norm': 4.0107421875, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.13s/it] 52%|█████▎    | 21/40 [00:42<00:41,  2.18s/it]                                               {'loss': 0.1745, 'grad_norm': 3.392472982406616, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:41,  2.18s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.4832, 'grad_norm': 6.4717559814453125, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.2932, 'grad_norm': 4.856224060058594, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.0732, 'grad_norm': 4.072018146514893, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it]                                               {'loss': 0.4449, 'grad_norm': 2.4939091205596924, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.0269, 'grad_norm': 0.8010314702987671, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.1087, 'grad_norm': 2.2659592628479004, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.304, 'grad_norm': 3.4746334552764893, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.0857, 'grad_norm': 1.9264711141586304, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.0619, 'grad_norm': 1.3084665536880493, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.2012, 'grad_norm': 6.681362628936768, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 6.15, 'grad_norm': 91.48462677001953, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0506, 'grad_norm': 0.9369276165962219, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.2942, 'grad_norm': 2.835211992263794, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.09s/it]                                               {'loss': 0.1351, 'grad_norm': 2.6665337085723877, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.09s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.14s/it]                                               {'loss': 0.3633, 'grad_norm': 8.517056465148926, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.18s/it]                                               {'loss': 0.0697, 'grad_norm': 1.7106512784957886, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.0249, 'grad_norm': 0.5734854340553284, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.3854, 'grad_norm': 1.4814382791519165, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.0262, 'grad_norm': 1.384285569190979, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 79.9883, 'train_samples_per_second': 7.064, 'train_steps_per_second': 0.5, 'train_loss': 0.993680169666186, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]100%|██████████| 40/40 [01:19<00:00,  2.00s/it]
CLIENT:84
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:27,  2.24s/it]                                              {'loss': 2.4573, 'grad_norm': 9.270730972290039, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:27,  2.24s/it]  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]                                              {'loss': 3.3891, 'grad_norm': 9.582103729248047, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]  8%|▊         | 3/40 [00:06<01:20,  2.17s/it]                                              {'loss': 1.5842, 'grad_norm': 10.192695617675781, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.17s/it] 10%|█         | 4/40 [00:08<01:18,  2.18s/it]                                              {'loss': 2.4073, 'grad_norm': 19.961380004882812, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.18s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it]                                              {'loss': 0.8437, 'grad_norm': 10.863518714904785, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it] 15%|█▌        | 6/40 [00:13<01:13,  2.16s/it]                                              {'loss': 3.1453, 'grad_norm': 21.650409698486328, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:13,  2.16s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it]                                              {'loss': 2.6737, 'grad_norm': 20.02626609802246, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it] 20%|██        | 8/40 [00:15<00:49,  1.53s/it]                                              {'loss': 0.0342, 'grad_norm': 1.5754398107528687, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.53s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it]                                              {'loss': 1.0397, 'grad_norm': 8.271795272827148, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it] 25%|██▌       | 10/40 [00:19<00:55,  1.87s/it]                                               {'loss': 1.0836, 'grad_norm': 11.122804641723633, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:55,  1.87s/it] 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it]                                               {'loss': 0.7774, 'grad_norm': 9.735006332397461, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:21<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 0.5988, 'grad_norm': 5.089011192321777, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 0.7647, 'grad_norm': 6.209067344665527, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it]                                               {'loss': 1.0333, 'grad_norm': 6.640906810760498, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:30<00:54,  2.16s/it]                                               {'loss': 0.9542, 'grad_norm': 7.005919456481934, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:54,  2.16s/it] 40%|████      | 16/40 [00:30<00:37,  1.57s/it]                                               {'loss': 0.2204, 'grad_norm': 13.698644638061523, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:30<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.1984, 'grad_norm': 3.5127944946289062, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.3362, 'grad_norm': 2.87626314163208, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it]                                               {'loss': 0.0504, 'grad_norm': 1.3378483057022095, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it] 50%|█████     | 20/40 [00:39<00:41,  2.07s/it]                                               {'loss': 0.2864, 'grad_norm': 4.485776424407959, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.394, 'grad_norm': 4.482573986053467, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.6785, 'grad_norm': 7.940074443817139, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 0.4433, 'grad_norm': 4.447803497314453, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:46<00:25,  1.58s/it]                                               {'loss': 0.0473, 'grad_norm': 2.2193033695220947, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:48<00:26,  1.78s/it]                                               {'loss': 0.0389, 'grad_norm': 0.6394475698471069, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:48<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.5158, 'grad_norm': 4.1822075843811035, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.99s/it]                                               {'loss': 0.8981, 'grad_norm': 114.76854705810547, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.99s/it] 70%|███████   | 28/40 [00:55<00:24,  2.07s/it]                                               {'loss': 0.8704, 'grad_norm': 171.73239135742188, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.12s/it]                                               {'loss': 0.505, 'grad_norm': 10.001296043395996, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.12s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.1413, 'grad_norm': 2.250537157058716, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it]                                               {'loss': 0.0549, 'grad_norm': 0.9673382639884949, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it] 80%|████████  | 32/40 [01:02<00:12,  1.59s/it]                                               {'loss': 0.0984, 'grad_norm': 4.129914283752441, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.79s/it]                                               {'loss': 0.0445, 'grad_norm': 1.114989161491394, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it]                                               {'loss': 0.0389, 'grad_norm': 0.8435205221176147, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.05s/it]                                               {'loss': 0.0167, 'grad_norm': 0.3571523129940033, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it]                                               {'loss': 0.6743, 'grad_norm': 6.524430274963379, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.13s/it]                                               {'loss': 0.0544, 'grad_norm': 1.4425536394119263, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.13s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it]                                               {'loss': 0.2036, 'grad_norm': 7.391544342041016, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.18s/it]                                               {'loss': 0.0504, 'grad_norm': 1.3813625574111938, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.18s/it]100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'loss': 0.0043, 'grad_norm': 0.24100014567375183, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'train_runtime': 78.8246, 'train_samples_per_second': 7.168, 'train_steps_per_second': 0.507, 'train_loss': 0.7412854877533391, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]100%|██████████| 40/40 [01:18<00:00,  1.97s/it]
CLIENT:33
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:27,  2.24s/it]                                              {'loss': 3.3545, 'grad_norm': 9.197319984436035, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:27,  2.24s/it]  5%|▌         | 2/40 [00:04<01:23,  2.20s/it]                                              {'loss': 3.2185, 'grad_norm': 14.015819549560547, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.20s/it]  8%|▊         | 3/40 [00:06<01:21,  2.20s/it]                                              {'loss': 2.0488, 'grad_norm': 19.924819946289062, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.20s/it] 10%|█         | 4/40 [00:08<01:18,  2.17s/it]                                              {'loss': 2.3295, 'grad_norm': 12.932900428771973, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.17s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.17s/it]                                              {'loss': 3.0355, 'grad_norm': 14.890274047851562, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.17s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 1.3788, 'grad_norm': 10.597676277160645, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it]                                              {'loss': 2.4693, 'grad_norm': 16.46209716796875, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 0.4613, 'grad_norm': 22.51401710510254, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 0.8445, 'grad_norm': 8.59022045135498, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.90s/it]                                               {'loss': 1.3471, 'grad_norm': 17.2211971282959, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.3144, 'grad_norm': 7.464913368225098, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 1.2757, 'grad_norm': 21.992393493652344, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:55,  2.07s/it]                                               {'loss': 1.7971, 'grad_norm': 75.64774322509766, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:55,  2.07s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it]                                               {'loss': 1.0712, 'grad_norm': 19.473520278930664, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.16s/it]                                               {'loss': 0.9504, 'grad_norm': 17.622474670410156, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 1.0033, 'grad_norm': 24.99614143371582, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.8566, 'grad_norm': 18.065866470336914, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.6879, 'grad_norm': 21.840227127075195, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it]                                               {'loss': 0.7028, 'grad_norm': 7.258745193481445, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.4908, 'grad_norm': 8.239042282104492, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.5249, 'grad_norm': 7.19948673248291, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it]                                               {'loss': 0.5852, 'grad_norm': 7.043015480041504, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it]                                               {'loss': 0.8865, 'grad_norm': 26.894115447998047, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it] 60%|██████    | 24/40 [00:46<00:25,  1.58s/it]                                               {'loss': 4.2409, 'grad_norm': 103.73348999023438, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.2234, 'grad_norm': 5.565055847167969, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it]                                               {'loss': 0.9171, 'grad_norm': 20.261659622192383, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it]                                               {'loss': 0.3039, 'grad_norm': 4.62553071975708, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it] 70%|███████   | 28/40 [00:55<00:24,  2.08s/it]                                               {'loss': 0.3815, 'grad_norm': 4.855003356933594, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.1478, 'grad_norm': 3.5454399585723877, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.2394, 'grad_norm': 4.069891452789307, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.6902, 'grad_norm': 7.412220478057861, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:02<00:12,  1.59s/it]                                               {'loss': 0.5264, 'grad_norm': 27.7100887298584, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.1919, 'grad_norm': 3.7259938716888428, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.2264, 'grad_norm': 7.047461032867432, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it]                                               {'loss': 0.0778, 'grad_norm': 1.3618481159210205, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it]                                               {'loss': 0.5604, 'grad_norm': 11.521955490112305, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.1324, 'grad_norm': 3.230705499649048, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 1.0039, 'grad_norm': 7.017850875854492, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.3195, 'grad_norm': 4.946443557739258, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 0.0182, 'grad_norm': 0.9822178483009338, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 79.1226, 'train_samples_per_second': 7.141, 'train_steps_per_second': 0.506, 'train_loss': 1.0708941348828376, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:81
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:03<02:02,  3.14s/it]                                              {'loss': 3.044, 'grad_norm': 9.919991493225098, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:03<02:02,  3.14s/it]  5%|▌         | 2/40 [00:05<01:36,  2.55s/it]                                              {'loss': 2.4956, 'grad_norm': 10.768378257751465, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:36,  2.55s/it]  8%|▊         | 3/40 [00:07<01:27,  2.36s/it]                                              {'loss': 2.789, 'grad_norm': 14.15829849243164, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:27,  2.36s/it] 10%|█         | 4/40 [00:09<01:22,  2.29s/it]                                              {'loss': 2.4899, 'grad_norm': 12.180813789367676, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.29s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 3.0587, 'grad_norm': 17.692380905151367, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 3.1044, 'grad_norm': 28.302385330200195, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:16<01:13,  2.22s/it]                                              {'loss': 1.3244, 'grad_norm': 11.707782745361328, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 2.9501, 'grad_norm': 55.451942443847656, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 0.7858, 'grad_norm': 8.47412109375, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it]                                               {'loss': 1.0874, 'grad_norm': 43.87539291381836, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.7941, 'grad_norm': 8.267565727233887, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:25<00:57,  2.05s/it]                                               {'loss': 0.4073, 'grad_norm': 4.737579345703125, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.10s/it]                                               {'loss': 1.1174, 'grad_norm': 6.895618915557861, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it]                                               {'loss': 2.0566, 'grad_norm': 19.648056030273438, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.4158, 'grad_norm': 4.743756294250488, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.0536, 'grad_norm': 2.784323215484619, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it]                                               {'loss': 0.3383, 'grad_norm': 3.7604153156280518, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it]                                               {'loss': 0.661, 'grad_norm': 5.123604774475098, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it]                                               {'loss': 0.6053, 'grad_norm': 4.217000961303711, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it] 50%|█████     | 20/40 [00:41<00:41,  2.09s/it]                                               {'loss': 0.5409, 'grad_norm': 5.5758137702941895, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.16s/it]                                               {'loss': 0.2898, 'grad_norm': 5.243187427520752, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.2279, 'grad_norm': 4.520169734954834, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.5608, 'grad_norm': 5.0298333168029785, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:48<00:25,  1.60s/it]                                               {'loss': 0.0016, 'grad_norm': 0.12132271379232407, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.80s/it]                                               {'loss': 0.439, 'grad_norm': 20.83260154724121, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it]                                               {'loss': 0.1872, 'grad_norm': 1.8727165460586548, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.1485, 'grad_norm': 4.439891815185547, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:57<00:25,  2.11s/it]                                               {'loss': 0.5475, 'grad_norm': 6.77723503112793, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it]                                               {'loss': 0.1165, 'grad_norm': 2.672043800354004, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.3872, 'grad_norm': 3.647533416748047, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it]                                               {'loss': 0.0807, 'grad_norm': 1.8620574474334717, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it] 80%|████████  | 32/40 [01:04<00:13,  1.63s/it]                                               {'loss': 0.0789, 'grad_norm': 3.8385815620422363, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it]                                               {'loss': 0.5538, 'grad_norm': 3.4753947257995605, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.98s/it]                                               {'loss': 0.0106, 'grad_norm': 0.2523668110370636, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.98s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it]                                               {'loss': 0.038, 'grad_norm': 1.2220158576965332, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it]                                               {'loss': 0.0544, 'grad_norm': 1.1013495922088623, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it]                                               {'loss': 0.4557, 'grad_norm': 4.566380023956299, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.21s/it]                                               {'loss': 0.0851, 'grad_norm': 2.207369089126587, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]                                               {'loss': 0.0894, 'grad_norm': 2.5351510047912598, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.2747, 'grad_norm': 12.505388259887695, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.8034, 'train_samples_per_second': 6.992, 'train_steps_per_second': 0.495, 'train_loss': 0.8686682601168286, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:93
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:33,  2.39s/it]                                              {'loss': 2.9999, 'grad_norm': 10.858189582824707, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:33,  2.39s/it]  5%|▌         | 2/40 [00:04<01:26,  2.28s/it]                                              {'loss': 3.3821, 'grad_norm': 13.257312774658203, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.28s/it]  8%|▊         | 3/40 [00:06<01:22,  2.24s/it]                                              {'loss': 2.1332, 'grad_norm': 16.805767059326172, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.24s/it] 10%|█         | 4/40 [00:09<01:20,  2.25s/it]                                              {'loss': 2.3193, 'grad_norm': 23.59856605529785, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it]                                              {'loss': 1.0196, 'grad_norm': 11.349191665649414, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it] 15%|█▌        | 6/40 [00:13<01:17,  2.27s/it]                                              {'loss': 2.9092, 'grad_norm': 21.91779899597168, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:17,  2.27s/it] 18%|█▊        | 7/40 [00:15<01:14,  2.25s/it]                                              {'loss': 1.9352, 'grad_norm': 16.277698516845703, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:14,  2.25s/it] 20%|██        | 8/40 [00:16<00:51,  1.59s/it]                                              {'loss': 0.4216, 'grad_norm': 24.649606704711914, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.80s/it]                                              {'loss': 1.5994, 'grad_norm': 13.6892728805542, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.80s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 1.3825, 'grad_norm': 18.018606185913086, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.07s/it]                                               {'loss': 1.2997, 'grad_norm': 9.599653244018555, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.07s/it] 30%|███       | 12/40 [00:25<00:59,  2.13s/it]                                               {'loss': 0.6392, 'grad_norm': 5.3129096031188965, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:59,  2.13s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it]                                               {'loss': 1.5014, 'grad_norm': 9.288949012756348, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it]                                               {'loss': 0.9095, 'grad_norm': 7.138983726501465, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.23s/it]                                               {'loss': 1.0003, 'grad_norm': 11.8624906539917, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.23s/it] 40%|████      | 16/40 [00:32<00:38,  1.61s/it]                                               {'loss': 0.6804, 'grad_norm': 25.404253005981445, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.61s/it] 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it]                                               {'loss': 0.1779, 'grad_norm': 4.29672384262085, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it]                                               {'loss': 0.7205, 'grad_norm': 42.47985076904297, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.06s/it]                                               {'loss': 0.8714, 'grad_norm': 19.265941619873047, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.06s/it] 50%|█████     | 20/40 [00:41<00:42,  2.13s/it]                                               {'loss': 0.3202, 'grad_norm': 5.6796770095825195, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.13s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it]                                               {'loss': 0.0548, 'grad_norm': 0.8136584162712097, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.24s/it]                                               {'loss': 0.3202, 'grad_norm': 5.558774948120117, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.24s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.25s/it]                                               {'loss': 0.7168, 'grad_norm': 6.461138725280762, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.25s/it] 60%|██████    | 24/40 [00:48<00:26,  1.63s/it]                                               {'loss': 0.1433, 'grad_norm': 12.380016326904297, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.63s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.84s/it]                                               {'loss': 0.0945, 'grad_norm': 2.0534746646881104, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.84s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.98s/it]                                               {'loss': 0.032, 'grad_norm': 0.5957552790641785, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.98s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.08s/it]                                               {'loss': 0.1035, 'grad_norm': 2.3814096450805664, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.08s/it] 70%|███████   | 28/40 [00:57<00:25,  2.15s/it]                                               {'loss': 0.2976, 'grad_norm': 2.5728025436401367, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.15s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.20s/it]                                               {'loss': 0.18, 'grad_norm': 2.331756830215454, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.20s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.23s/it]                                               {'loss': 0.2134, 'grad_norm': 2.1632909774780273, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.23s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it]                                               {'loss': 0.1288, 'grad_norm': 3.5220704078674316, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.25s/it] 80%|████████  | 32/40 [01:04<00:13,  1.66s/it]                                               {'loss': 0.0566, 'grad_norm': 3.0237879753112793, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.66s/it] 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it]                                               {'loss': 0.0277, 'grad_norm': 0.5553938746452332, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it] 85%|████████▌ | 34/40 [01:09<00:11,  2.00s/it]                                               {'loss': 0.2073, 'grad_norm': 5.331538677215576, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  2.00s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.10s/it]                                               {'loss': 0.3389, 'grad_norm': 25.767166137695312, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.10s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.17s/it]                                               {'loss': 0.3811, 'grad_norm': 5.011989593505859, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.17s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.22s/it]                                               {'loss': 0.0649, 'grad_norm': 1.634621262550354, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.22s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it]                                               {'loss': 0.0642, 'grad_norm': 1.6448514461517334, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]                                               {'loss': 0.0418, 'grad_norm': 0.8023881316184998, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]100%|██████████| 40/40 [01:21<00:00,  1.67s/it]                                               {'loss': 0.6883, 'grad_norm': 56.26203155517578, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.67s/it]                                               {'train_runtime': 81.9527, 'train_samples_per_second': 6.894, 'train_steps_per_second': 0.488, 'train_loss': 0.8094570667482912, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.67s/it]100%|██████████| 40/40 [01:21<00:00,  2.05s/it]
CLIENT:17
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:34,  2.43s/it]                                              {'loss': 3.3527, 'grad_norm': 11.04606819152832, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:34,  2.43s/it]  5%|▌         | 2/40 [00:04<01:26,  2.29s/it]                                              {'loss': 2.1533, 'grad_norm': 13.81497573852539, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.29s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 1.6928, 'grad_norm': 15.393872261047363, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 2.4569, 'grad_norm': 15.416030883789062, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 2.6983, 'grad_norm': 23.550739288330078, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 3.3847, 'grad_norm': 24.586360931396484, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 3.0046, 'grad_norm': 24.47380828857422, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.1888, 'grad_norm': 19.88937759399414, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 2.0123, 'grad_norm': 19.6726131439209, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.596, 'grad_norm': 4.549807071685791, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 1.8261, 'grad_norm': 10.583641052246094, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 1.1209, 'grad_norm': 6.869369983673096, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.15s/it]                                               {'loss': 1.8716, 'grad_norm': 8.931265830993652, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.15s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it]                                               {'loss': 1.6988, 'grad_norm': 8.946037292480469, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it]                                               {'loss': 1.9736, 'grad_norm': 10.28886890411377, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it] 40%|████      | 16/40 [00:31<00:38,  1.60s/it]                                               {'loss': 0.0323, 'grad_norm': 1.6499769687652588, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it]                                               {'loss': 0.5112, 'grad_norm': 3.7325196266174316, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it]                                               {'loss': 0.3882, 'grad_norm': 5.305843830108643, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.05s/it]                                               {'loss': 0.6962, 'grad_norm': 9.722636222839355, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.05s/it] 50%|█████     | 20/40 [00:40<00:42,  2.13s/it]                                               {'loss': 0.7773, 'grad_norm': 8.58147144317627, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.13s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 0.2147, 'grad_norm': 7.434093475341797, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 0.6799, 'grad_norm': 5.620957851409912, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it]                                               {'loss': 0.6876, 'grad_norm': 5.992161750793457, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.066, 'grad_norm': 2.601945400238037, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.2093, 'grad_norm': 2.4963364601135254, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.5684, 'grad_norm': 3.4576528072357178, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it]                                               {'loss': 0.1796, 'grad_norm': 3.2043399810791016, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it] 70%|███████   | 28/40 [00:57<00:25,  2.13s/it]                                               {'loss': 0.6509, 'grad_norm': 2.1469638347625732, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.13s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it]                                               {'loss': 0.3415, 'grad_norm': 4.264420509338379, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it]                                               {'loss': 0.867, 'grad_norm': 5.608458042144775, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.27s/it]                                               {'loss': 0.2941, 'grad_norm': 4.407382488250732, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.27s/it] 80%|████████  | 32/40 [01:04<00:13,  1.64s/it]                                               {'loss': 0.0314, 'grad_norm': 2.0456318855285645, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.64s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.85s/it]                                               {'loss': 0.0853, 'grad_norm': 1.759944200515747, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.85s/it] 85%|████████▌ | 34/40 [01:09<00:12,  2.00s/it]                                               {'loss': 0.3012, 'grad_norm': 6.418771266937256, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:12,  2.00s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.11s/it]                                               {'loss': 0.179, 'grad_norm': 5.232491493225098, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.11s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.17s/it]                                               {'loss': 1.5294, 'grad_norm': 56.83660125732422, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.17s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.22s/it]                                               {'loss': 1.4244, 'grad_norm': 8.722505569458008, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.22s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.25s/it]                                               {'loss': 0.1267, 'grad_norm': 4.36024284362793, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.25s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.30s/it]                                               {'loss': 0.0539, 'grad_norm': 1.3114510774612427, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.30s/it]100%|██████████| 40/40 [01:21<00:00,  1.68s/it]                                               {'loss': 0.0574, 'grad_norm': 1.9679350852966309, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.68s/it]                                               {'train_runtime': 81.5394, 'train_samples_per_second': 6.929, 'train_steps_per_second': 0.491, 'train_loss': 1.0246020906604827, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.68s/it]100%|██████████| 40/40 [01:21<00:00,  2.04s/it]
CLIENT:36
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:52,  2.90s/it]                                              {'loss': 3.8865, 'grad_norm': 10.652261734008789, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:52,  2.90s/it]  5%|▌         | 2/40 [00:05<01:35,  2.51s/it]                                              {'loss': 2.3876, 'grad_norm': 12.553472518920898, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:35,  2.51s/it]  8%|▊         | 3/40 [00:07<01:27,  2.37s/it]                                              {'loss': 1.952, 'grad_norm': 12.688051223754883, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:27,  2.37s/it] 10%|█         | 4/40 [00:09<01:22,  2.29s/it]                                              {'loss': 2.9252, 'grad_norm': 14.962563514709473, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.29s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it]                                              {'loss': 2.8165, 'grad_norm': 21.234960556030273, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it]                                              {'loss': 2.3417, 'grad_norm': 15.1844482421875, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it] 18%|█▊        | 7/40 [00:16<01:14,  2.25s/it]                                              {'loss': 2.5112, 'grad_norm': 16.795413970947266, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:14,  2.25s/it] 20%|██        | 8/40 [00:16<00:50,  1.59s/it]                                              {'loss': 5.9287, 'grad_norm': 55.80457305908203, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 1.891, 'grad_norm': 11.184187889099121, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 0.8691, 'grad_norm': 67.02687072753906, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:23<00:59,  2.04s/it]                                               {'loss': 1.3275, 'grad_norm': 8.221474647521973, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:59,  2.04s/it] 30%|███       | 12/40 [00:25<00:58,  2.10s/it]                                               {'loss': 1.5002, 'grad_norm': 8.804144859313965, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.10s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it]                                               {'loss': 0.6376, 'grad_norm': 7.39841365814209, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 0.9804, 'grad_norm': 9.163308143615723, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:32<00:54,  2.20s/it]                                               {'loss': 1.9308, 'grad_norm': 13.0714111328125, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:54,  2.20s/it] 40%|████      | 16/40 [00:32<00:38,  1.59s/it]                                               {'loss': 0.2155, 'grad_norm': 12.325177192687988, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.8992, 'grad_norm': 4.051905632019043, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.2138, 'grad_norm': 4.72482442855835, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:39<00:42,  2.03s/it]                                               {'loss': 0.5998, 'grad_norm': 18.22353744506836, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:42,  2.03s/it] 50%|█████     | 20/40 [00:41<00:42,  2.12s/it]                                               {'loss': 0.7916, 'grad_norm': 9.32492733001709, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 0.4439, 'grad_norm': 5.173972129821777, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:46<00:39,  2.21s/it]                                               {'loss': 0.5206, 'grad_norm': 5.332070827484131, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.24s/it]                                               {'loss': 0.2349, 'grad_norm': 3.4464662075042725, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.24s/it] 60%|██████    | 24/40 [00:48<00:26,  1.63s/it]                                               {'loss': 0.0449, 'grad_norm': 2.326889991760254, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.63s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.77, 'grad_norm': 6.120424270629883, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.97s/it]                                               {'loss': 0.4243, 'grad_norm': 2.171510696411133, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.97s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.06s/it]                                               {'loss': 0.3079, 'grad_norm': 5.853207111358643, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.06s/it] 70%|███████   | 28/40 [00:57<00:25,  2.13s/it]                                               {'loss': 0.2689, 'grad_norm': 5.9029951095581055, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.13s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.20s/it]                                               {'loss': 0.1166, 'grad_norm': 2.153561592102051, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.20s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.23s/it]                                               {'loss': 0.1019, 'grad_norm': 2.0637435913085938, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.23s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.27s/it]                                               {'loss': 0.1249, 'grad_norm': 2.49924373626709, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.27s/it] 80%|████████  | 32/40 [01:04<00:13,  1.65s/it]                                               {'loss': 0.148, 'grad_norm': 6.58872127532959, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.65s/it] 82%|████████▎ | 33/40 [01:07<00:12,  1.85s/it]                                               {'loss': 0.0394, 'grad_norm': 1.5273689031600952, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:12,  1.85s/it] 85%|████████▌ | 34/40 [01:09<00:11,  2.00s/it]                                               {'loss': 0.0331, 'grad_norm': 0.8803377151489258, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  2.00s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.11s/it]                                               {'loss': 0.0309, 'grad_norm': 0.8385909199714661, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.11s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it]                                               {'loss': 0.067, 'grad_norm': 1.624487042427063, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.23s/it]                                               {'loss': 0.055, 'grad_norm': 1.2977036237716675, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.23s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it]                                               {'loss': 0.7617, 'grad_norm': 18.636560440063477, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.27s/it]                                               {'loss': 0.1726, 'grad_norm': 2.4190797805786133, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.27s/it]100%|██████████| 40/40 [01:21<00:00,  1.64s/it]                                               {'loss': 1.1751, 'grad_norm': 37.63371658325195, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.64s/it]                                               {'train_runtime': 81.7332, 'train_samples_per_second': 6.913, 'train_steps_per_second': 0.489, 'train_loss': 1.0611788376700133, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.64s/it]100%|██████████| 40/40 [01:21<00:00,  2.04s/it]
CLIENT:82
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:28,  2.26s/it]                                              {'loss': 4.3485, 'grad_norm': 11.119786262512207, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:28,  2.26s/it]  5%|▌         | 2/40 [00:04<01:24,  2.23s/it]                                              {'loss': 2.7221, 'grad_norm': 8.558138847351074, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.23s/it]  8%|▊         | 3/40 [00:06<01:22,  2.23s/it]                                              {'loss': 1.8501, 'grad_norm': 8.994482040405273, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.23s/it] 10%|█         | 4/40 [00:08<01:20,  2.22s/it]                                              {'loss': 2.7101, 'grad_norm': 15.142334938049316, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:20,  2.22s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it]                                              {'loss': 2.1225, 'grad_norm': 13.953513145446777, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 2.316, 'grad_norm': 17.803281784057617, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.4504, 'grad_norm': 14.249101638793945, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.0732, 'grad_norm': 3.579390048980713, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it]                                              {'loss': 0.5261, 'grad_norm': 6.302855014801025, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it]                                               {'loss': 0.2923, 'grad_norm': 3.1656410694122314, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 0.5035, 'grad_norm': 6.737687110900879, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 0.8389, 'grad_norm': 9.134708404541016, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 1.2783, 'grad_norm': 10.9290132522583, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 2.1017, 'grad_norm': 13.528470993041992, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it]                                               {'loss': 0.8775, 'grad_norm': 9.685478210449219, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it] 40%|████      | 16/40 [00:31<00:38,  1.62s/it]                                               {'loss': 4.7534, 'grad_norm': 5.378297805786133, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.62s/it] 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it]                                               {'loss': 0.297, 'grad_norm': 4.059598445892334, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.593, 'grad_norm': 4.1826558113098145, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it]                                               {'loss': 0.4627, 'grad_norm': 4.882050514221191, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it] 50%|█████     | 20/40 [00:40<00:42,  2.12s/it]                                               {'loss': 0.304, 'grad_norm': 2.38346266746521, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 0.4095, 'grad_norm': 2.5696229934692383, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it]                                               {'loss': 0.494, 'grad_norm': 3.7865607738494873, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.5357, 'grad_norm': 5.130465984344482, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0005, 'grad_norm': 0.03467614948749542, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it]                                               {'loss': 0.3606, 'grad_norm': 3.819415807723999, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.1699, 'grad_norm': 4.1169114112854, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.0416, 'grad_norm': 1.213735580444336, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:56<00:25,  2.14s/it]                                               {'loss': 0.0228, 'grad_norm': 0.4550549387931824, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.20s/it]                                               {'loss': 0.7287, 'grad_norm': 32.515384674072266, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.20s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it]                                               {'loss': 0.4105, 'grad_norm': 1.3151978254318237, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.1055, 'grad_norm': 2.28633451461792, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:04<00:12,  1.61s/it]                                               {'loss': 0.0416, 'grad_norm': 2.4315876960754395, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.0266, 'grad_norm': 0.6399539113044739, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it]                                               {'loss': 0.0404, 'grad_norm': 1.5101984739303589, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it]                                               {'loss': 0.1921, 'grad_norm': 1.5084939002990723, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it]                                               {'loss': 0.0154, 'grad_norm': 0.45130014419555664, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.2806, 'grad_norm': 0.7862361073493958, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it]                                               {'loss': 0.1635, 'grad_norm': 0.7340928316116333, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]                                               {'loss': 0.4111, 'grad_norm': 2.9301071166992188, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.0032, 'grad_norm': 0.19256658852100372, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.5549, 'train_samples_per_second': 7.014, 'train_steps_per_second': 0.497, 'train_loss': 0.8968734785637935, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:69
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:54,  2.95s/it]                                              {'loss': 3.0142, 'grad_norm': 8.120291709899902, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:54,  2.95s/it]  5%|▌         | 2/40 [00:05<01:34,  2.49s/it]                                              {'loss': 2.1628, 'grad_norm': 9.004110336303711, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:34,  2.49s/it]  8%|▊         | 3/40 [00:07<01:27,  2.36s/it]                                              {'loss': 2.8641, 'grad_norm': 13.315753936767578, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:27,  2.36s/it] 10%|█         | 4/40 [00:09<01:22,  2.28s/it]                                              {'loss': 2.2464, 'grad_norm': 15.477873802185059, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.28s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it]                                              {'loss': 1.3606, 'grad_norm': 13.918290138244629, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.27s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 2.9066, 'grad_norm': 31.2065486907959, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:16<01:13,  2.23s/it]                                              {'loss': 0.9692, 'grad_norm': 12.924226760864258, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:13,  2.23s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 0.0629, 'grad_norm': 4.235846519470215, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 2.5046, 'grad_norm': 21.44642448425293, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.8585, 'grad_norm': 12.209322929382324, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.5311, 'grad_norm': 8.264620780944824, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:25<00:58,  2.07s/it]                                               {'loss': 0.9113, 'grad_norm': 8.248435020446777, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 0.652, 'grad_norm': 7.003546237945557, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.9861, 'grad_norm': 10.246297836303711, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.7518, 'grad_norm': 6.614788055419922, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:32<00:38,  1.59s/it]                                               {'loss': 0.023, 'grad_norm': 1.11175537109375, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.78s/it]                                               {'loss': 0.0752, 'grad_norm': 1.491134762763977, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.1232, 'grad_norm': 2.6514341831207275, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.4191, 'grad_norm': 4.11344051361084, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:41<00:41,  2.08s/it]                                               {'loss': 0.1392, 'grad_norm': 3.002946615219116, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 0.0701, 'grad_norm': 1.6859209537506104, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.1962, 'grad_norm': 3.206453800201416, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.4405, 'grad_norm': 4.973205089569092, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:48<00:25,  1.61s/it]                                               {'loss': 0.0181, 'grad_norm': 0.941434919834137, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.1123, 'grad_norm': 2.783777952194214, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.1657, 'grad_norm': 5.111613750457764, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.0924, 'grad_norm': 4.909022808074951, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.0747, 'grad_norm': 1.8269104957580566, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it]                                               {'loss': 0.1982, 'grad_norm': 6.661357879638672, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.0662, 'grad_norm': 2.0243616104125977, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it]                                               {'loss': 0.0617, 'grad_norm': 1.97652268409729, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it] 80%|████████  | 32/40 [01:04<00:12,  1.60s/it]                                               {'loss': 0.0872, 'grad_norm': 6.123654365539551, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.0149, 'grad_norm': 0.4218399226665497, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.019, 'grad_norm': 0.6768926382064819, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it]                                               {'loss': 0.0404, 'grad_norm': 1.9054423570632935, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it]                                               {'loss': 0.0406, 'grad_norm': 1.5173219442367554, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.0244, 'grad_norm': 0.7421128749847412, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.0502, 'grad_norm': 2.127943277359009, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.22s/it]                                               {'loss': 0.0263, 'grad_norm': 0.916405200958252, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.22s/it]100%|██████████| 40/40 [01:20<00:00,  1.61s/it]                                               {'loss': 0.0161, 'grad_norm': 3.531033992767334, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]                                               {'train_runtime': 80.5803, 'train_samples_per_second': 7.012, 'train_steps_per_second': 0.496, 'train_loss': 0.6344276774441824, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:65
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]                                              {'loss': 3.4353, 'grad_norm': 10.67854118347168, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 2.9335, 'grad_norm': 12.001788139343262, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 3.4779, 'grad_norm': 13.479931831359863, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 1.5013, 'grad_norm': 12.206731796264648, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 2.5819, 'grad_norm': 15.229621887207031, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.2414, 'grad_norm': 12.412109375, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 1.7974, 'grad_norm': 15.003573417663574, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:51,  1.61s/it]                                              {'loss': 0.5992, 'grad_norm': 31.12681770324707, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.61s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 1.9904, 'grad_norm': 24.582433700561523, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 1.7004, 'grad_norm': 17.852922439575195, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.29, 'grad_norm': 4.584534168243408, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.285, 'grad_norm': 2.1886510848999023, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 0.8283, 'grad_norm': 4.912232398986816, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.8851, 'grad_norm': 7.17385196685791, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.5644, 'grad_norm': 3.8556759357452393, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0791, 'grad_norm': 3.037297248840332, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.0932, 'grad_norm': 1.9362295866012573, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.89s/it]                                               {'loss': 0.1983, 'grad_norm': 6.036693096160889, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:38<00:44,  2.13s/it]                                               {'loss': 0.1194, 'grad_norm': 2.942272186279297, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:44,  2.13s/it] 50%|█████     | 20/40 [00:41<00:43,  2.17s/it]                                               {'loss': 0.496, 'grad_norm': 4.562666893005371, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:43,  2.17s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.20s/it]                                               {'loss': 0.052, 'grad_norm': 1.0751111507415771, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.20s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.22s/it]                                               {'loss': 0.1694, 'grad_norm': 2.8202149868011475, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.22s/it] 57%|█████▊    | 23/40 [00:47<00:38,  2.24s/it]                                               {'loss': 0.0659, 'grad_norm': 1.2835127115249634, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:38,  2.24s/it] 60%|██████    | 24/40 [00:48<00:26,  1.63s/it]                                               {'loss': 0.3147, 'grad_norm': 21.47875213623047, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.63s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.0983, 'grad_norm': 1.7459540367126465, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it]                                               {'loss': 0.036, 'grad_norm': 0.8558573722839355, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.06s/it]                                               {'loss': 0.0366, 'grad_norm': 0.8046194911003113, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.06s/it] 70%|███████   | 28/40 [00:57<00:25,  2.14s/it]                                               {'loss': 0.0388, 'grad_norm': 1.5139662027359009, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.18s/it]                                               {'loss': 0.0608, 'grad_norm': 15.44715690612793, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.18s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.0731, 'grad_norm': 3.02345871925354, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it]                                               {'loss': 0.0353, 'grad_norm': 0.8976895809173584, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it] 80%|████████  | 32/40 [01:04<00:12,  1.60s/it]                                               {'loss': 0.0367, 'grad_norm': 1.9018137454986572, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.1723, 'grad_norm': 8.055139541625977, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.1003, 'grad_norm': 4.465946674346924, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.04s/it]                                               {'loss': 0.0389, 'grad_norm': 1.3560023307800293, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it]                                               {'loss': 0.2662, 'grad_norm': 7.21358585357666, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.2128, 'grad_norm': 44.78541564941406, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.22s/it]                                               {'loss': 0.7667, 'grad_norm': 16.456661224365234, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.22s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.6935, 'grad_norm': 6.354842662811279, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.0005, 'grad_norm': 0.04239712655544281, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 81.0266, 'train_samples_per_second': 6.973, 'train_steps_per_second': 0.494, 'train_loss': 0.7341554338723654, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.63s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  do_eval=True, seed=self.args.random_seed)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:58,  1.57it/s]  1%|          | 3/471 [00:02<07:00,  1.11it/s]  1%|          | 4/471 [00:03<08:06,  1.04s/it]  1%|          | 5/471 [00:05<08:45,  1.13s/it]  1%|▏         | 6/471 [00:06<09:08,  1.18s/it]  1%|▏         | 7/471 [00:07<09:24,  1.22s/it]  2%|▏         | 8/471 [00:08<09:34,  1.24s/it]  2%|▏         | 9/471 [00:10<09:41,  1.26s/it]  2%|▏         | 10/471 [00:11<09:45,  1.27s/it]  2%|▏         | 11/471 [00:12<09:48,  1.28s/it]  3%|▎         | 12/471 [00:14<09:51,  1.29s/it]  3%|▎         | 13/471 [00:15<09:53,  1.30s/it]  3%|▎         | 14/471 [00:16<09:54,  1.30s/it]  3%|▎         | 15/471 [00:18<09:54,  1.30s/it]  3%|▎         | 16/471 [00:19<09:55,  1.31s/it]  4%|▎         | 17/471 [00:20<09:55,  1.31s/it]  4%|▍         | 18/471 [00:22<09:55,  1.32s/it]  4%|▍         | 19/471 [00:23<09:55,  1.32s/it]  4%|▍         | 20/471 [00:24<09:55,  1.32s/it]  4%|▍         | 21/471 [00:26<09:54,  1.32s/it]  5%|▍         | 22/471 [00:27<09:54,  1.32s/it]  5%|▍         | 23/471 [00:28<09:53,  1.33s/it]  5%|▌         | 24/471 [00:30<09:54,  1.33s/it]  5%|▌         | 25/471 [00:31<09:53,  1.33s/it]  6%|▌         | 26/471 [00:32<09:53,  1.33s/it]  6%|▌         | 27/471 [00:34<09:53,  1.34s/it]  6%|▌         | 28/471 [00:35<09:51,  1.34s/it]  6%|▌         | 29/471 [00:36<09:51,  1.34s/it]  6%|▋         | 30/471 [00:38<09:51,  1.34s/it]  7%|▋         | 31/471 [00:39<09:51,  1.34s/it]  7%|▋         | 32/471 [00:40<09:48,  1.34s/it]  7%|▋         | 33/471 [00:42<09:46,  1.34s/it]  7%|▋         | 34/471 [00:43<09:46,  1.34s/it]  7%|▋         | 35/471 [00:44<09:47,  1.35s/it]  8%|▊         | 36/471 [00:46<09:45,  1.35s/it]  8%|▊         | 37/471 [00:47<09:46,  1.35s/it]  8%|▊         | 38/471 [00:48<09:46,  1.35s/it]  8%|▊         | 39/471 [00:50<09:43,  1.35s/it]  8%|▊         | 40/471 [00:51<09:43,  1.35s/it]  9%|▊         | 41/471 [00:52<09:42,  1.35s/it]  9%|▉         | 42/471 [00:54<09:41,  1.36s/it]  9%|▉         | 43/471 [00:55<09:40,  1.36s/it]  9%|▉         | 44/471 [00:57<09:38,  1.36s/it] 10%|▉         | 45/471 [00:58<09:38,  1.36s/it] 10%|▉         | 46/471 [00:59<09:37,  1.36s/it] 10%|▉         | 47/471 [01:01<09:35,  1.36s/it] 10%|█         | 48/471 [01:02<09:34,  1.36s/it] 10%|█         | 49/471 [01:03<09:35,  1.36s/it] 11%|█         | 50/471 [01:05<09:33,  1.36s/it] 11%|█         | 51/471 [01:06<09:32,  1.36s/it] 11%|█         | 52/471 [01:07<09:31,  1.36s/it] 11%|█▏        | 53/471 [01:09<09:31,  1.37s/it] 11%|█▏        | 54/471 [01:10<09:30,  1.37s/it] 12%|█▏        | 55/471 [01:12<09:29,  1.37s/it] 12%|█▏        | 56/471 [01:13<09:29,  1.37s/it] 12%|█▏        | 57/471 [01:14<09:27,  1.37s/it] 12%|█▏        | 58/471 [01:16<09:26,  1.37s/it] 13%|█▎        | 59/471 [01:17<09:25,  1.37s/it] 13%|█▎        | 60/471 [01:18<09:23,  1.37s/it] 13%|█▎        | 61/471 [01:20<09:22,  1.37s/it] 13%|█▎        | 62/471 [01:21<09:21,  1.37s/it] 13%|█▎        | 63/471 [01:23<09:19,  1.37s/it] 14%|█▎        | 64/471 [01:24<09:18,  1.37s/it] 14%|█▍        | 65/471 [01:25<09:17,  1.37s/it] 14%|█▍        | 66/471 [01:27<09:15,  1.37s/it] 14%|█▍        | 67/471 [01:28<09:14,  1.37s/it] 14%|█▍        | 68/471 [01:29<09:12,  1.37s/it] 15%|█▍        | 69/471 [01:31<09:10,  1.37s/it] 15%|█▍        | 70/471 [01:32<09:10,  1.37s/it] 15%|█▌        | 71/471 [01:34<09:09,  1.37s/it] 15%|█▌        | 72/471 [01:35<09:07,  1.37s/it] 15%|█▌        | 73/471 [01:36<09:06,  1.37s/it] 16%|█▌        | 74/471 [01:38<09:04,  1.37s/it] 16%|█▌        | 75/471 [01:39<09:04,  1.37s/it] 16%|█▌        | 76/471 [01:40<09:02,  1.37s/it] 16%|█▋        | 77/471 [01:42<09:01,  1.37s/it] 17%|█▋        | 78/471 [01:43<09:00,  1.37s/it] 17%|█▋        | 79/471 [01:45<08:59,  1.38s/it] 17%|█▋        | 80/471 [01:46<08:58,  1.38s/it] 17%|█▋        | 81/471 [01:47<08:56,  1.38s/it] 17%|█▋        | 82/471 [01:49<08:54,  1.37s/it] 18%|█▊        | 83/471 [01:50<08:53,  1.38s/it] 18%|█▊        | 84/471 [01:51<08:51,  1.37s/it] 18%|█▊        | 85/471 [01:53<08:50,  1.37s/it] 18%|█▊        | 86/471 [01:54<08:48,  1.37s/it] 18%|█▊        | 87/471 [01:55<08:47,  1.37s/it] 19%|█▊        | 88/471 [01:57<08:45,  1.37s/it] 19%|█▉        | 89/471 [01:58<08:43,  1.37s/it] 19%|█▉        | 90/471 [02:00<08:42,  1.37s/it] 19%|█▉        | 91/471 [02:01<08:40,  1.37s/it] 20%|█▉        | 92/471 [02:02<08:38,  1.37s/it] 20%|█▉        | 93/471 [02:04<08:37,  1.37s/it] 20%|█▉        | 94/471 [02:05<08:36,  1.37s/it] 20%|██        | 95/471 [02:06<08:34,  1.37s/it] 20%|██        | 96/471 [02:08<08:32,  1.37s/it] 21%|██        | 97/471 [02:09<08:32,  1.37s/it] 21%|██        | 98/471 [02:11<08:29,  1.37s/it] 21%|██        | 99/471 [02:12<08:27,  1.36s/it] 21%|██        | 100/471 [02:13<08:26,  1.37s/it] 21%|██▏       | 101/471 [02:15<08:24,  1.36s/it] 22%|██▏       | 102/471 [02:16<08:23,  1.37s/it] 22%|██▏       | 103/471 [02:17<08:22,  1.37s/it] 22%|██▏       | 104/471 [02:19<08:21,  1.37s/it] 22%|██▏       | 105/471 [02:20<08:20,  1.37s/it] 23%|██▎       | 106/471 [02:21<08:18,  1.36s/it] 23%|██▎       | 107/471 [02:23<08:17,  1.37s/it] 23%|██▎       | 108/471 [02:24<08:14,  1.36s/it] 23%|██▎       | 109/471 [02:26<08:12,  1.36s/it] 23%|██▎       | 110/471 [02:27<08:10,  1.36s/it] 24%|██▎       | 111/471 [02:28<08:10,  1.36s/it] 24%|██▍       | 112/471 [02:30<08:08,  1.36s/it] 24%|██▍       | 113/471 [02:31<08:06,  1.36s/it] 24%|██▍       | 114/471 [02:32<08:06,  1.36s/it] 24%|██▍       | 115/471 [02:34<08:05,  1.36s/it] 25%|██▍       | 116/471 [02:35<08:03,  1.36s/it] 25%|██▍       | 117/471 [02:36<08:01,  1.36s/it] 25%|██▌       | 118/471 [02:38<08:00,  1.36s/it] 25%|██▌       | 119/471 [02:39<07:58,  1.36s/it] 25%|██▌       | 120/471 [02:41<07:58,  1.36s/it] 26%|██▌       | 121/471 [02:42<07:56,  1.36s/it] 26%|██▌       | 122/471 [02:43<07:54,  1.36s/it] 26%|██▌       | 123/471 [02:45<07:53,  1.36s/it] 26%|██▋       | 124/471 [02:46<07:52,  1.36s/it] 27%|██▋       | 125/471 [02:47<07:50,  1.36s/it] 27%|██▋       | 126/471 [02:49<07:49,  1.36s/it] 27%|██▋       | 127/471 [02:50<07:47,  1.36s/it] 27%|██▋       | 128/471 [02:51<07:45,  1.36s/it] 27%|██▋       | 129/471 [02:53<07:44,  1.36s/it] 28%|██▊       | 130/471 [02:54<07:42,  1.36s/it] 28%|██▊       | 131/471 [02:55<07:40,  1.36s/it] 28%|██▊       | 132/471 [02:57<07:39,  1.36s/it] 28%|██▊       | 133/471 [02:58<07:38,  1.36s/it] 28%|██▊       | 134/471 [03:00<07:36,  1.36s/it] 29%|██▊       | 135/471 [03:01<07:35,  1.35s/it] 29%|██▉       | 136/471 [03:02<07:33,  1.35s/it] 29%|██▉       | 137/471 [03:04<07:31,  1.35s/it] 29%|██▉       | 138/471 [03:05<07:30,  1.35s/it] 30%|██▉       | 139/471 [03:06<07:29,  1.35s/it] 30%|██▉       | 140/471 [03:08<07:27,  1.35s/it] 30%|██▉       | 141/471 [03:09<07:25,  1.35s/it] 30%|███       | 142/471 [03:10<07:23,  1.35s/it] 30%|███       | 143/471 [03:12<07:21,  1.35s/it] 31%|███       | 144/471 [03:13<07:21,  1.35s/it] 31%|███       | 145/471 [03:14<07:19,  1.35s/it] 31%|███       | 146/471 [03:16<07:18,  1.35s/it] 31%|███       | 147/471 [03:17<07:17,  1.35s/it] 31%|███▏      | 148/471 [03:18<07:16,  1.35s/it] 32%|███▏      | 149/471 [03:20<07:14,  1.35s/it] 32%|███▏      | 150/471 [03:21<07:14,  1.35s/it] 32%|███▏      | 151/471 [03:22<07:12,  1.35s/it] 32%|███▏      | 152/471 [03:24<07:10,  1.35s/it] 32%|███▏      | 153/471 [03:25<07:08,  1.35s/it] 33%|███▎      | 154/471 [03:27<07:06,  1.35s/it] 33%|███▎      | 155/471 [03:28<07:05,  1.35s/it] 33%|███▎      | 156/471 [03:29<07:03,  1.35s/it] 33%|███▎      | 157/471 [03:31<07:02,  1.34s/it] 34%|███▎      | 158/471 [03:32<07:00,  1.34s/it] 34%|███▍      | 159/471 [03:33<06:59,  1.34s/it] 34%|███▍      | 160/471 [03:35<06:58,  1.35s/it] 34%|███▍      | 161/471 [03:36<06:57,  1.35s/it] 34%|███▍      | 162/471 [03:37<06:55,  1.35s/it] 35%|███▍      | 163/471 [03:39<06:54,  1.35s/it] 35%|███▍      | 164/471 [03:40<06:53,  1.35s/it] 35%|███▌      | 165/471 [03:41<06:51,  1.35s/it] 35%|███▌      | 166/471 [03:43<06:50,  1.35s/it] 35%|███▌      | 167/471 [03:44<06:49,  1.35s/it] 36%|███▌      | 168/471 [03:45<06:47,  1.35s/it] 36%|███▌      | 169/471 [03:47<06:46,  1.35s/it] 36%|███▌      | 170/471 [03:48<06:44,  1.34s/it] 36%|███▋      | 171/471 [03:49<06:43,  1.34s/it] 37%|███▋      | 172/471 [03:51<06:40,  1.34s/it] 37%|███▋      | 173/471 [03:52<06:40,  1.34s/it] 37%|███▋      | 174/471 [03:53<06:38,  1.34s/it] 37%|███▋      | 175/471 [03:55<06:36,  1.34s/it] 37%|███▋      | 176/471 [03:56<06:35,  1.34s/it] 38%|███▊      | 177/471 [03:57<06:33,  1.34s/it] 38%|███▊      | 178/471 [03:59<06:32,  1.34s/it] 38%|███▊      | 179/471 [04:00<06:30,  1.34s/it] 38%|███▊      | 180/471 [04:01<06:29,  1.34s/it] 38%|███▊      | 181/471 [04:03<06:27,  1.34s/it] 39%|███▊      | 182/471 [04:04<06:26,  1.34s/it] 39%|███▉      | 183/471 [04:05<06:25,  1.34s/it] 39%|███▉      | 184/471 [04:07<06:23,  1.34s/it] 39%|███▉      | 185/471 [04:08<06:22,  1.34s/it] 39%|███▉      | 186/471 [04:09<06:21,  1.34s/it] 40%|███▉      | 187/471 [04:11<06:20,  1.34s/it] 40%|███▉      | 188/471 [04:12<06:19,  1.34s/it] 40%|████      | 189/471 [04:13<06:16,  1.34s/it] 40%|████      | 190/471 [04:15<06:15,  1.34s/it] 41%|████      | 191/471 [04:16<06:14,  1.34s/it] 41%|████      | 192/471 [04:17<06:12,  1.34s/it] 41%|████      | 193/471 [04:19<06:11,  1.34s/it] 41%|████      | 194/471 [04:20<06:10,  1.34s/it] 41%|████▏     | 195/471 [04:21<06:08,  1.34s/it] 42%|████▏     | 196/471 [04:23<06:07,  1.34s/it] 42%|████▏     | 197/471 [04:24<06:05,  1.33s/it] 42%|████▏     | 198/471 [04:25<06:03,  1.33s/it] 42%|████▏     | 199/471 [04:27<06:02,  1.33s/it] 42%|████▏     | 200/471 [04:28<06:02,  1.34s/it] 43%|████▎     | 201/471 [04:29<05:59,  1.33s/it] 43%|████▎     | 202/471 [04:31<05:58,  1.33s/it] 43%|████▎     | 203/471 [04:32<05:57,  1.33s/it] 43%|████▎     | 204/471 [04:33<05:55,  1.33s/it] 44%|████▎     | 205/471 [04:35<05:53,  1.33s/it] 44%|████▎     | 206/471 [04:36<05:52,  1.33s/it] 44%|████▍     | 207/471 [04:37<05:51,  1.33s/it] 44%|████▍     | 208/471 [04:39<05:49,  1.33s/it] 44%|████▍     | 209/471 [04:40<05:48,  1.33s/it] 45%|████▍     | 210/471 [04:41<05:47,  1.33s/it] 45%|████▍     | 211/471 [04:43<05:46,  1.33s/it] 45%|████▌     | 212/471 [04:44<05:45,  1.33s/it] 45%|████▌     | 213/471 [04:45<05:44,  1.33s/it] 45%|████▌     | 214/471 [04:47<05:42,  1.33s/it] 46%|████▌     | 215/471 [04:48<05:41,  1.33s/it] 46%|████▌     | 216/471 [04:49<05:40,  1.34s/it] 46%|████▌     | 217/471 [04:51<05:39,  1.34s/it] 46%|████▋     | 218/471 [04:52<05:37,  1.34s/it] 46%|████▋     | 219/471 [04:53<05:36,  1.33s/it] 47%|████▋     | 220/471 [04:55<05:35,  1.34s/it] 47%|████▋     | 221/471 [04:56<05:34,  1.34s/it] 47%|████▋     | 222/471 [04:57<05:31,  1.33s/it] 47%|████▋     | 223/471 [04:59<05:30,  1.33s/it] 48%|████▊     | 224/471 [05:00<05:29,  1.33s/it] 48%|████▊     | 225/471 [05:01<05:28,  1.33s/it] 48%|████▊     | 226/471 [05:03<05:27,  1.34s/it] 48%|████▊     | 227/471 [05:04<05:25,  1.33s/it] 48%|████▊     | 228/471 [05:05<05:24,  1.34s/it] 49%|████▊     | 229/471 [05:07<05:23,  1.34s/it] 49%|████▉     | 230/471 [05:08<05:22,  1.34s/it] 49%|████▉     | 231/471 [05:09<05:20,  1.34s/it] 49%|████▉     | 232/471 [05:11<05:18,  1.33s/it] 49%|████▉     | 233/471 [05:12<05:17,  1.33s/it] 50%|████▉     | 234/471 [05:13<05:16,  1.34s/it] 50%|████▉     | 235/471 [05:15<05:15,  1.34s/it] 50%|█████     | 236/471 [05:16<05:14,  1.34s/it] 50%|█████     | 237/471 [05:17<05:12,  1.33s/it] 51%|█████     | 238/471 [05:19<05:10,  1.33s/it] 51%|█████     | 239/471 [05:20<05:09,  1.34s/it] 51%|█████     | 240/471 [05:22<05:08,  1.34s/it] 51%|█████     | 241/471 [05:23<05:07,  1.34s/it] 51%|█████▏    | 242/471 [05:24<05:06,  1.34s/it] 52%|█████▏    | 243/471 [05:26<05:04,  1.34s/it] 52%|█████▏    | 244/471 [05:27<05:03,  1.34s/it] 52%|█████▏    | 245/471 [05:28<05:02,  1.34s/it] 52%|█████▏    | 246/471 [05:30<05:00,  1.34s/it] 52%|█████▏    | 247/471 [05:31<04:59,  1.34s/it] 53%|█████▎    | 248/471 [05:32<04:58,  1.34s/it] 53%|█████▎    | 249/471 [05:34<04:57,  1.34s/it] 53%|█████▎    | 250/471 [05:35<04:55,  1.34s/it] 53%|█████▎    | 251/471 [05:36<04:54,  1.34s/it] 54%|█████▎    | 252/471 [05:38<04:53,  1.34s/it] 54%|█████▎    | 253/471 [05:39<04:52,  1.34s/it] 54%|█████▍    | 254/471 [05:40<04:51,  1.34s/it] 54%|█████▍    | 255/471 [05:42<04:49,  1.34s/it] 54%|█████▍    | 256/471 [05:43<04:48,  1.34s/it] 55%|█████▍    | 257/471 [05:44<04:47,  1.34s/it] 55%|█████▍    | 258/471 [05:46<04:45,  1.34s/it] 55%|█████▍    | 259/471 [05:47<04:44,  1.34s/it] 55%|█████▌    | 260/471 [05:48<04:43,  1.34s/it] 55%|█████▌    | 261/471 [05:50<04:41,  1.34s/it] 56%|█████▌    | 262/471 [05:51<04:39,  1.34s/it] 56%|█████▌    | 263/471 [05:52<04:38,  1.34s/it] 56%|█████▌    | 264/471 [05:54<04:37,  1.34s/it] 56%|█████▋    | 265/471 [05:55<04:35,  1.34s/it] 56%|█████▋    | 266/471 [05:56<04:34,  1.34s/it] 57%|█████▋    | 267/471 [05:58<04:33,  1.34s/it] 57%|█████▋    | 268/471 [05:59<04:31,  1.34s/it] 57%|█████▋    | 269/471 [06:00<04:30,  1.34s/it] 57%|█████▋    | 270/471 [06:02<04:28,  1.34s/it] 58%|█████▊    | 271/471 [06:03<04:27,  1.34s/it] 58%|█████▊    | 272/471 [06:04<04:25,  1.33s/it] 58%|█████▊    | 273/471 [06:06<04:24,  1.34s/it] 58%|█████▊    | 274/471 [06:07<04:23,  1.34s/it] 58%|█████▊    | 275/471 [06:08<04:21,  1.33s/it] 59%|█████▊    | 276/471 [06:10<04:20,  1.34s/it] 59%|█████▉    | 277/471 [06:11<04:19,  1.34s/it] 59%|█████▉    | 278/471 [06:12<04:18,  1.34s/it] 59%|█████▉    | 279/471 [06:14<04:16,  1.34s/it] 59%|█████▉    | 280/471 [06:15<04:15,  1.34s/it] 60%|█████▉    | 281/471 [06:16<04:13,  1.34s/it] 60%|█████▉    | 282/471 [06:18<04:12,  1.34s/it] 60%|██████    | 283/471 [06:19<04:11,  1.34s/it] 60%|██████    | 284/471 [06:20<04:09,  1.34s/it] 61%|██████    | 285/471 [06:22<04:08,  1.34s/it] 61%|██████    | 286/471 [06:23<04:07,  1.34s/it] 61%|██████    | 287/471 [06:24<04:06,  1.34s/it] 61%|██████    | 288/471 [06:26<04:05,  1.34s/it] 61%|██████▏   | 289/471 [06:27<04:03,  1.34s/it] 62%|██████▏   | 290/471 [06:28<04:02,  1.34s/it] 62%|██████▏   | 291/471 [06:30<04:00,  1.33s/it] 62%|██████▏   | 292/471 [06:31<03:58,  1.33s/it] 62%|██████▏   | 293/471 [06:32<03:57,  1.33s/it] 62%|██████▏   | 294/471 [06:34<03:55,  1.33s/it] 63%|██████▎   | 295/471 [06:35<03:54,  1.33s/it] 63%|██████▎   | 296/471 [06:36<03:53,  1.33s/it] 63%|██████▎   | 297/471 [06:38<03:51,  1.33s/it] 63%|██████▎   | 298/471 [06:39<03:50,  1.33s/it] 63%|██████▎   | 299/471 [06:40<03:49,  1.34s/it] 64%|██████▎   | 300/471 [06:42<03:48,  1.34s/it] 64%|██████▍   | 301/471 [06:43<03:47,  1.34s/it] 64%|██████▍   | 302/471 [06:44<03:45,  1.33s/it] 64%|██████▍   | 303/471 [06:46<03:43,  1.33s/it] 65%|██████▍   | 304/471 [06:47<03:42,  1.33s/it] 65%|██████▍   | 305/471 [06:48<03:41,  1.33s/it] 65%|██████▍   | 306/471 [06:50<03:40,  1.33s/it] 65%|██████▌   | 307/471 [06:51<03:38,  1.33s/it] 65%|██████▌   | 308/471 [06:52<03:37,  1.34s/it] 66%|██████▌   | 309/471 [06:54<03:36,  1.33s/it] 66%|██████▌   | 310/471 [06:55<03:34,  1.33s/it] 66%|██████▌   | 311/471 [06:56<03:33,  1.33s/it] 66%|██████▌   | 312/471 [06:58<03:31,  1.33s/it] 66%|██████▋   | 313/471 [06:59<03:30,  1.33s/it] 67%|██████▋   | 314/471 [07:00<03:28,  1.33s/it] 67%|██████▋   | 315/471 [07:02<03:27,  1.33s/it] 67%|██████▋   | 316/471 [07:03<03:26,  1.33s/it] 67%|██████▋   | 317/471 [07:04<03:24,  1.33s/it] 68%|██████▊   | 318/471 [07:06<03:23,  1.33s/it] 68%|██████▊   | 319/471 [07:07<03:22,  1.33s/it] 68%|██████▊   | 320/471 [07:08<03:21,  1.33s/it] 68%|██████▊   | 321/471 [07:10<03:19,  1.33s/it] 68%|██████▊   | 322/471 [07:11<03:18,  1.33s/it] 69%|██████▊   | 323/471 [07:12<03:17,  1.34s/it] 69%|██████▉   | 324/471 [07:14<03:16,  1.34s/it] 69%|██████▉   | 325/471 [07:15<03:15,  1.34s/it] 69%|██████▉   | 326/471 [07:16<03:13,  1.33s/it] 69%|██████▉   | 327/471 [07:18<03:11,  1.33s/it] 70%|██████▉   | 328/471 [07:19<03:10,  1.33s/it] 70%|██████▉   | 329/471 [07:20<03:09,  1.33s/it] 70%|███████   | 330/471 [07:22<03:08,  1.33s/it] 70%|███████   | 331/471 [07:23<03:06,  1.33s/it] 70%|███████   | 332/471 [07:24<03:05,  1.33s/it] 71%|███████   | 333/471 [07:26<03:03,  1.33s/it] 71%|███████   | 334/471 [07:27<03:02,  1.33s/it] 71%|███████   | 335/471 [07:28<03:01,  1.33s/it] 71%|███████▏  | 336/471 [07:30<03:00,  1.33s/it] 72%|███████▏  | 337/471 [07:31<02:58,  1.33s/it] 72%|███████▏  | 338/471 [07:32<02:57,  1.33s/it] 72%|███████▏  | 339/471 [07:34<02:56,  1.34s/it] 72%|███████▏  | 340/471 [07:35<02:54,  1.33s/it] 72%|███████▏  | 341/471 [07:36<02:53,  1.33s/it] 73%|███████▎  | 342/471 [07:38<02:51,  1.33s/it] 73%|███████▎  | 343/471 [07:39<02:50,  1.33s/it] 73%|███████▎  | 344/471 [07:40<02:49,  1.33s/it] 73%|███████▎  | 345/471 [07:42<02:47,  1.33s/it] 73%|███████▎  | 346/471 [07:43<02:46,  1.33s/it] 74%|███████▎  | 347/471 [07:44<02:44,  1.33s/it] 74%|███████▍  | 348/471 [07:46<02:43,  1.33s/it] 74%|███████▍  | 349/471 [07:47<02:42,  1.33s/it] 74%|███████▍  | 350/471 [07:48<02:41,  1.33s/it] 75%|███████▍  | 351/471 [07:50<02:39,  1.33s/it] 75%|███████▍  | 352/471 [07:51<02:38,  1.33s/it] 75%|███████▍  | 353/471 [07:52<02:37,  1.33s/it] 75%|███████▌  | 354/471 [07:54<02:35,  1.33s/it] 75%|███████▌  | 355/471 [07:55<02:34,  1.33s/it] 76%|███████▌  | 356/471 [07:56<02:33,  1.33s/it] 76%|███████▌  | 357/471 [07:58<02:31,  1.33s/it] 76%|███████▌  | 358/471 [07:59<02:30,  1.33s/it] 76%|███████▌  | 359/471 [08:00<02:29,  1.33s/it] 76%|███████▋  | 360/471 [08:02<02:27,  1.33s/it] 77%|███████▋  | 361/471 [08:03<02:26,  1.33s/it] 77%|███████▋  | 362/471 [08:04<02:25,  1.33s/it] 77%|███████▋  | 363/471 [08:06<02:23,  1.33s/it] 77%|███████▋  | 364/471 [08:07<02:22,  1.33s/it] 77%|███████▋  | 365/471 [08:08<02:21,  1.33s/it] 78%|███████▊  | 366/471 [08:10<02:19,  1.33s/it] 78%|███████▊  | 367/471 [08:11<02:18,  1.33s/it] 78%|███████▊  | 368/471 [08:12<02:16,  1.33s/it] 78%|███████▊  | 369/471 [08:14<02:15,  1.33s/it] 79%|███████▊  | 370/471 [08:15<02:14,  1.33s/it] 79%|███████▉  | 371/471 [08:16<02:12,  1.33s/it] 79%|███████▉  | 372/471 [08:18<02:11,  1.33s/it] 79%|███████▉  | 373/471 [08:19<02:10,  1.33s/it] 79%|███████▉  | 374/471 [08:20<02:08,  1.33s/it] 80%|███████▉  | 375/471 [08:22<02:07,  1.33s/it] 80%|███████▉  | 376/471 [08:23<02:06,  1.33s/it] 80%|████████  | 377/471 [08:24<02:04,  1.33s/it] 80%|████████  | 378/471 [08:26<02:03,  1.33s/it] 80%|████████  | 379/471 [08:27<02:02,  1.33s/it] 81%|████████  | 380/471 [08:28<02:00,  1.33s/it] 81%|████████  | 381/471 [08:30<01:59,  1.33s/it] 81%|████████  | 382/471 [08:31<01:58,  1.33s/it] 81%|████████▏ | 383/471 [08:32<01:56,  1.33s/it] 82%|████████▏ | 384/471 [08:34<01:55,  1.33s/it] 82%|████████▏ | 385/471 [08:35<01:54,  1.33s/it] 82%|████████▏ | 386/471 [08:36<01:52,  1.33s/it] 82%|████████▏ | 387/471 [08:38<01:51,  1.33s/it] 82%|████████▏ | 388/471 [08:39<01:50,  1.33s/it] 83%|████████▎ | 389/471 [08:40<01:48,  1.33s/it] 83%|████████▎ | 390/471 [08:42<01:47,  1.33s/it] 83%|████████▎ | 391/471 [08:43<01:46,  1.33s/it] 83%|████████▎ | 392/471 [08:44<01:44,  1.33s/it] 83%|████████▎ | 393/471 [08:46<01:43,  1.33s/it] 84%|████████▎ | 394/471 [08:47<01:42,  1.33s/it] 84%|████████▍ | 395/471 [08:48<01:40,  1.33s/it] 84%|████████▍ | 396/471 [08:50<01:39,  1.33s/it] 84%|████████▍ | 397/471 [08:51<01:38,  1.33s/it] 85%|████████▍ | 398/471 [08:52<01:36,  1.32s/it] 85%|████████▍ | 399/471 [08:54<01:35,  1.33s/it] 85%|████████▍ | 400/471 [08:55<01:34,  1.33s/it] 85%|████████▌ | 401/471 [08:56<01:32,  1.33s/it] 85%|████████▌ | 402/471 [08:57<01:31,  1.32s/it] 86%|████████▌ | 403/471 [08:59<01:30,  1.32s/it] 86%|████████▌ | 404/471 [09:00<01:28,  1.32s/it] 86%|████████▌ | 405/471 [09:01<01:27,  1.32s/it] 86%|████████▌ | 406/471 [09:03<01:26,  1.32s/it] 86%|████████▋ | 407/471 [09:04<01:24,  1.32s/it] 87%|████████▋ | 408/471 [09:05<01:23,  1.32s/it] 87%|████████▋ | 409/471 [09:07<01:22,  1.33s/it] 87%|████████▋ | 410/471 [09:08<01:20,  1.32s/it] 87%|████████▋ | 411/471 [09:09<01:19,  1.32s/it] 87%|████████▋ | 412/471 [09:11<01:17,  1.32s/it] 88%|████████▊ | 413/471 [09:12<01:16,  1.32s/it] 88%|████████▊ | 414/471 [09:13<01:15,  1.32s/it] 88%|████████▊ | 415/471 [09:15<01:14,  1.32s/it] 88%|████████▊ | 416/471 [09:16<01:12,  1.32s/it] 89%|████████▊ | 417/471 [09:17<01:11,  1.32s/it] 89%|████████▊ | 418/471 [09:19<01:10,  1.32s/it] 89%|████████▉ | 419/471 [09:20<01:08,  1.32s/it] 89%|████████▉ | 420/471 [09:21<01:07,  1.32s/it] 89%|████████▉ | 421/471 [09:23<01:06,  1.32s/it] 90%|████████▉ | 422/471 [09:24<01:04,  1.32s/it] 90%|████████▉ | 423/471 [09:25<01:03,  1.32s/it] 90%|█████████ | 424/471 [09:27<01:02,  1.32s/it] 90%|█████████ | 425/471 [09:28<01:00,  1.32s/it] 90%|█████████ | 426/471 [09:29<00:59,  1.32s/it] 91%|█████████ | 427/471 [09:31<00:58,  1.32s/it] 91%|█████████ | 428/471 [09:32<00:56,  1.32s/it] 91%|█████████ | 429/471 [09:33<00:55,  1.32s/it] 91%|█████████▏| 430/471 [09:35<00:54,  1.32s/it] 92%|█████████▏| 431/471 [09:36<00:53,  1.33s/it] 92%|█████████▏| 432/471 [09:37<00:51,  1.33s/it] 92%|█████████▏| 433/471 [09:38<00:50,  1.33s/it] 92%|█████████▏| 434/471 [09:40<00:49,  1.33s/it] 92%|█████████▏| 435/471 [09:41<00:47,  1.33s/it] 93%|█████████▎| 436/471 [09:42<00:46,  1.32s/it] 93%|█████████▎| 437/471 [09:44<00:45,  1.33s/it] 93%|█████████▎| 438/471 [09:45<00:43,  1.33s/it] 93%|█████████▎| 439/471 [09:46<00:42,  1.33s/it] 93%|█████████▎| 440/471 [09:48<00:41,  1.33s/it] 94%|█████████▎| 441/471 [09:49<00:39,  1.33s/it] 94%|█████████▍| 442/471 [09:50<00:38,  1.33s/it] 94%|█████████▍| 443/471 [09:52<00:37,  1.33s/it] 94%|█████████▍| 444/471 [09:53<00:35,  1.33s/it] 94%|█████████▍| 445/471 [09:54<00:34,  1.33s/it] 95%|█████████▍| 446/471 [09:56<00:33,  1.33s/it] 95%|█████████▍| 447/471 [09:57<00:31,  1.33s/it] 95%|█████████▌| 448/471 [09:58<00:30,  1.33s/it] 95%|█████████▌| 449/471 [10:00<00:29,  1.33s/it] 96%|█████████▌| 450/471 [10:01<00:27,  1.33s/it] 96%|█████████▌| 451/471 [10:02<00:26,  1.33s/it] 96%|█████████▌| 452/471 [10:04<00:25,  1.33s/it] 96%|█████████▌| 453/471 [10:05<00:23,  1.33s/it] 96%|█████████▋| 454/471 [10:06<00:22,  1.33s/it] 97%|█████████▋| 455/471 [10:08<00:21,  1.33s/it] 97%|█████████▋| 456/471 [10:09<00:19,  1.33s/it] 97%|█████████▋| 457/471 [10:10<00:18,  1.33s/it] 97%|█████████▋| 458/471 [10:12<00:17,  1.33s/it] 97%|█████████▋| 459/471 [10:13<00:15,  1.33s/it] 98%|█████████▊| 460/471 [10:14<00:14,  1.33s/it] 98%|█████████▊| 461/471 [10:16<00:13,  1.33s/it] 98%|█████████▊| 462/471 [10:17<00:12,  1.34s/it] 98%|█████████▊| 463/471 [10:18<00:10,  1.34s/it] 99%|█████████▊| 464/471 [10:20<00:09,  1.34s/it] 99%|█████████▊| 465/471 [10:21<00:08,  1.34s/it] 99%|█████████▉| 466/471 [10:22<00:06,  1.34s/it] 99%|█████████▉| 467/471 [10:24<00:05,  1.34s/it] 99%|█████████▉| 468/471 [10:25<00:04,  1.34s/it]100%|█████████▉| 469/471 [10:26<00:02,  1.34s/it]100%|█████████▉| 470/471 [10:28<00:01,  1.34s/it]100%|██████████| 471/471 [10:29<00:00,  1.23s/it]100%|██████████| 471/471 [10:29<00:00,  1.34s/it]
{'eval_loss': 3.0240156650543213, 'eval_model_preparation_time': 0.0154, 'eval_acc': 0.2781465746149761, 'eval_runtime': 630.4787, 'eval_samples_per_second': 11.946, 'eval_steps_per_second': 0.747}
ROUND:13
CLIENT:14
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:43,  2.65s/it]                                              {'loss': 1.9767, 'grad_norm': 10.58420467376709, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:43,  2.65s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 1.5135, 'grad_norm': 9.199748039245605, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:24,  2.27s/it]                                              {'loss': 1.7724, 'grad_norm': 10.517677307128906, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.27s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 2.2892, 'grad_norm': 15.621484756469727, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it]                                              {'loss': 2.4728, 'grad_norm': 18.06915855407715, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 1.9149, 'grad_norm': 14.807415008544922, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 3.1168, 'grad_norm': 19.051376342773438, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 0.0213, 'grad_norm': 1.102142095565796, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 1.3085, 'grad_norm': 9.266736030578613, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it]                                               {'loss': 0.76, 'grad_norm': 6.499480724334717, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 0.9296, 'grad_norm': 10.66622257232666, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.687, 'grad_norm': 3.7420594692230225, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it]                                               {'loss': 0.9464, 'grad_norm': 8.652859687805176, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 0.4344, 'grad_norm': 6.8251423835754395, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.7918, 'grad_norm': 11.621543884277344, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0269, 'grad_norm': 1.6351577043533325, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.2203, 'grad_norm': 3.3839616775512695, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it]                                               {'loss': 0.156, 'grad_norm': 4.444436550140381, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it]                                               {'loss': 0.4036, 'grad_norm': 8.517107963562012, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.2058, 'grad_norm': 3.107039451599121, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.2349, 'grad_norm': 6.339355945587158, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.7056, 'grad_norm': 4.473659515380859, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:36,  2.17s/it]                                               {'loss': 0.4525, 'grad_norm': 5.313648223876953, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:36,  2.17s/it] 60%|██████    | 24/40 [00:47<00:25,  1.57s/it]                                               {'loss': 0.0033, 'grad_norm': 0.16585324704647064, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.1005, 'grad_norm': 1.6941115856170654, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.1714, 'grad_norm': 3.309566020965576, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.2005, 'grad_norm': 4.878309726715088, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.3492, 'grad_norm': 11.201074600219727, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.1963, 'grad_norm': 2.7153162956237793, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.0788, 'grad_norm': 1.4993785619735718, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.18s/it]                                               {'loss': 0.2359, 'grad_norm': 3.5697507858276367, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.18s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0306, 'grad_norm': 1.7277441024780273, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it]                                               {'loss': 0.0562, 'grad_norm': 1.7114263772964478, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.0375, 'grad_norm': 0.9808582663536072, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.0275, 'grad_norm': 0.45349618792533875, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0371, 'grad_norm': 0.9402831792831421, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.12s/it]                                               {'loss': 0.1822, 'grad_norm': 3.7752532958984375, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.12s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.16s/it]                                               {'loss': 0.0416, 'grad_norm': 2.792691469192505, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.16s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.076, 'grad_norm': 1.9162660837173462, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'loss': 0.4985, 'grad_norm': 28.210111618041992, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'train_runtime': 79.4941, 'train_samples_per_second': 7.107, 'train_steps_per_second': 0.503, 'train_loss': 0.6415947878034786, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:74
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:47,  2.75s/it]                                              {'loss': 4.1978, 'grad_norm': 12.356294631958008, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:47,  2.75s/it]  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]                                              {'loss': 2.6932, 'grad_norm': 10.994597434997559, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]  8%|▊         | 3/40 [00:07<01:24,  2.27s/it]                                              {'loss': 1.7662, 'grad_norm': 13.35983657836914, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.27s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 2.1447, 'grad_norm': 24.54787254333496, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it]                                              {'loss': 2.5868, 'grad_norm': 19.79245948791504, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 5.0149, 'grad_norm': 27.277931213378906, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 2.7788, 'grad_norm': 16.855087280273438, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 0.5398, 'grad_norm': 19.49878692626953, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 2.3485, 'grad_norm': 10.362161636352539, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it]                                               {'loss': 1.3096, 'grad_norm': 8.15993881225586, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 1.7637, 'grad_norm': 8.799178123474121, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 2.1445, 'grad_norm': 7.289540767669678, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 1.5075, 'grad_norm': 7.96528434753418, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it]                                               {'loss': 1.8283, 'grad_norm': 9.314414978027344, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.13s/it]                                               {'loss': 1.7246, 'grad_norm': 15.391000747680664, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.13s/it] 40%|████      | 16/40 [00:31<00:37,  1.55s/it]                                               {'loss': 2.609, 'grad_norm': 22.849950790405273, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.55s/it] 42%|████▎     | 17/40 [00:33<00:39,  1.73s/it]                                               {'loss': 1.4554, 'grad_norm': 8.064909934997559, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:39,  1.73s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.7841, 'grad_norm': 7.365322589874268, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it]                                               {'loss': 0.845, 'grad_norm': 6.280612468719482, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.498, 'grad_norm': 5.33182954788208, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.464, 'grad_norm': 5.527124404907227, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.7105, 'grad_norm': 5.388339042663574, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.3235, 'grad_norm': 3.0569067001342773, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.4262, 'grad_norm': 10.105867385864258, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.6404, 'grad_norm': 2.858397960662842, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.94s/it]                                               {'loss': 0.6812, 'grad_norm': 4.742741107940674, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.0765, 'grad_norm': 1.4448354244232178, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.2535, 'grad_norm': 3.888697624206543, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.4322, 'grad_norm': 6.170727252960205, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it]                                               {'loss': 0.7698, 'grad_norm': 9.853791236877441, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.7746, 'grad_norm': 14.436493873596191, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.0199, 'grad_norm': 1.534252643585205, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.8163, 'grad_norm': 5.829672813415527, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 1.1811, 'grad_norm': 4.1431097984313965, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 1.8631, 'grad_norm': 23.944965362548828, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.9919, 'grad_norm': 41.78797149658203, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.5912, 'grad_norm': 13.277807235717773, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.169, 'grad_norm': 10.146515846252441, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.0881, 'grad_norm': 1.3112040758132935, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.1233, 'grad_norm': 5.070730686187744, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.6528, 'train_samples_per_second': 7.093, 'train_steps_per_second': 0.502, 'train_loss': 1.2984245851635934, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:15
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:03<01:57,  3.00s/it]                                              {'loss': 3.139, 'grad_norm': 9.962899208068848, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:03<01:57,  3.00s/it]  5%|▌         | 2/40 [00:05<01:33,  2.47s/it]                                              {'loss': 2.771, 'grad_norm': 12.871323585510254, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:33,  2.47s/it]  8%|▊         | 3/40 [00:07<01:26,  2.34s/it]                                              {'loss': 2.7352, 'grad_norm': 17.321069717407227, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:26,  2.34s/it] 10%|█         | 4/40 [00:09<01:22,  2.28s/it]                                              {'loss': 1.5949, 'grad_norm': 10.451303482055664, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.28s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it]                                              {'loss': 1.258, 'grad_norm': 10.636200904846191, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 2.7668, 'grad_norm': 22.396610260009766, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:16<01:13,  2.24s/it]                                              {'loss': 2.0624, 'grad_norm': 17.574462890625, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:13,  2.24s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 4.1841, 'grad_norm': 74.49948120117188, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 1.3729, 'grad_norm': 63.40409851074219, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 2.0742, 'grad_norm': 14.55038833618164, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.7251, 'grad_norm': 7.715267658233643, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:25<00:57,  2.07s/it]                                               {'loss': 0.8582, 'grad_norm': 12.838296890258789, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 0.8795, 'grad_norm': 7.759649753570557, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.6155, 'grad_norm': 8.132311820983887, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it]                                               {'loss': 0.3715, 'grad_norm': 5.320286273956299, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it] 40%|████      | 16/40 [00:32<00:38,  1.59s/it]                                               {'loss': 0.3479, 'grad_norm': 13.214850425720215, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.3741, 'grad_norm': 2.7416152954101562, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it]                                               {'loss': 0.6384, 'grad_norm': 4.0725626945495605, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.06s/it]                                               {'loss': 0.8433, 'grad_norm': 13.055386543273926, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.06s/it] 50%|█████     | 20/40 [00:41<00:42,  2.12s/it]                                               {'loss': 0.7152, 'grad_norm': 3.6003754138946533, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it]                                               {'loss': 0.6459, 'grad_norm': 8.154358863830566, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it]                                               {'loss': 0.1629, 'grad_norm': 3.845734119415283, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.22s/it]                                               {'loss': 0.663, 'grad_norm': 4.474183082580566, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.22s/it] 60%|██████    | 24/40 [00:48<00:25,  1.61s/it]                                               {'loss': 0.3235, 'grad_norm': 12.00606918334961, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it]                                               {'loss': 0.4618, 'grad_norm': 4.794139862060547, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.5338, 'grad_norm': 1.7520662546157837, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it]                                               {'loss': 0.0652, 'grad_norm': 1.08942711353302, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.13s/it]                                               {'loss': 0.208, 'grad_norm': 4.935428142547607, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.13s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.769, 'grad_norm': 10.890886306762695, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.20s/it]                                               {'loss': 0.0391, 'grad_norm': 0.9808608889579773, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.20s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.22s/it]                                               {'loss': 0.2656, 'grad_norm': 4.966567039489746, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.22s/it] 80%|████████  | 32/40 [01:04<00:12,  1.61s/it]                                               {'loss': 0.0105, 'grad_norm': 0.7100703120231628, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.2966, 'grad_norm': 3.228584051132202, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.97s/it]                                               {'loss': 0.1178, 'grad_norm': 1.7680678367614746, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.06s/it]                                               {'loss': 0.0381, 'grad_norm': 1.742700457572937, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it]                                               {'loss': 0.3623, 'grad_norm': 17.59258270263672, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it]                                               {'loss': 0.0989, 'grad_norm': 2.184528112411499, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.22s/it]                                               {'loss': 0.1666, 'grad_norm': 6.0065131187438965, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.22s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.991, 'grad_norm': 17.67875862121582, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.003, 'grad_norm': 0.18675172328948975, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 81.0606, 'train_samples_per_second': 6.97, 'train_steps_per_second': 0.493, 'train_loss': 0.9137450363254175, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.62s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
CLIENT:4
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:37,  2.50s/it]                                              {'loss': 2.602, 'grad_norm': 10.589866638183594, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:37,  2.50s/it]  5%|▌         | 2/40 [00:04<01:26,  2.28s/it]                                              {'loss': 2.7273, 'grad_norm': 12.921157836914062, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.28s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 2.073, 'grad_norm': 14.9176025390625, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:20,  2.22s/it]                                              {'loss': 1.8545, 'grad_norm': 14.975700378417969, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.22s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it]                                              {'loss': 2.2651, 'grad_norm': 15.212063789367676, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:13,  2.16s/it]                                              {'loss': 2.7017, 'grad_norm': 12.63178539276123, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:13,  2.16s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it]                                              {'loss': 2.7732, 'grad_norm': 18.705402374267578, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.17s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 3.3273, 'grad_norm': 76.4556655883789, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it]                                              {'loss': 1.7009, 'grad_norm': 15.165672302246094, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.87s/it]                                               {'loss': 2.2935, 'grad_norm': 15.24420166015625, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.87s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.97s/it]                                               {'loss': 0.8647, 'grad_norm': 6.532639980316162, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.97s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 0.6198, 'grad_norm': 4.215921401977539, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it]                                               {'loss': 0.7868, 'grad_norm': 7.029118537902832, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it]                                               {'loss': 0.7434, 'grad_norm': 9.660757064819336, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.13s/it]                                               {'loss': 0.9829, 'grad_norm': 69.23570251464844, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.13s/it] 40%|████      | 16/40 [00:31<00:37,  1.54s/it]                                               {'loss': 0.5058, 'grad_norm': 26.925100326538086, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.54s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.3007, 'grad_norm': 3.28727650642395, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it]                                               {'loss': 0.3273, 'grad_norm': 3.81266713142395, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it]                                               {'loss': 0.5164, 'grad_norm': 7.084036350250244, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.5889, 'grad_norm': 10.318694114685059, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it]                                               {'loss': 0.4838, 'grad_norm': 4.825123310089111, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 0.2019, 'grad_norm': 3.4736251831054688, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it]                                               {'loss': 0.3046, 'grad_norm': 3.3575737476348877, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it] 60%|██████    | 24/40 [00:46<00:24,  1.56s/it]                                               {'loss': 2.7418, 'grad_norm': 9.772700309753418, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:24,  1.56s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.75s/it]                                               {'loss': 0.2209, 'grad_norm': 2.6921486854553223, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.75s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.88s/it]                                               {'loss': 0.0945, 'grad_norm': 1.5583301782608032, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.88s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.99s/it]                                               {'loss': 0.3553, 'grad_norm': 3.876587152481079, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.99s/it] 70%|███████   | 28/40 [00:55<00:24,  2.08s/it]                                               {'loss': 0.3465, 'grad_norm': 2.6606314182281494, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:57<00:23,  2.14s/it]                                               {'loss': 0.0968, 'grad_norm': 2.1913082599639893, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:57<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.5354, 'grad_norm': 2.1219468116760254, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.21s/it]                                               {'loss': 0.1262, 'grad_norm': 2.904386520385742, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.21s/it] 80%|████████  | 32/40 [01:02<00:12,  1.60s/it]                                               {'loss': 0.0145, 'grad_norm': 0.7567156553268433, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.80s/it]                                               {'loss': 0.1635, 'grad_norm': 0.7549001574516296, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it]                                               {'loss': 0.1843, 'grad_norm': 0.42046281695365906, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.1852, 'grad_norm': 1.5547893047332764, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.11s/it]                                               {'loss': 0.1756, 'grad_norm': 1.5221554040908813, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.1706, 'grad_norm': 1.2730385065078735, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 0.2595, 'grad_norm': 1.7313201427459717, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]                                               {'loss': 0.0193, 'grad_norm': 0.4134388566017151, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'loss': 0.0217, 'grad_norm': 1.9160925149917603, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'train_runtime': 79.0209, 'train_samples_per_second': 7.15, 'train_steps_per_second': 0.506, 'train_loss': 0.9314301863312722, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:32
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:34,  2.42s/it]                                              {'loss': 4.1729, 'grad_norm': 11.516593933105469, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:34,  2.42s/it]  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]                                              {'loss': 2.6502, 'grad_norm': 13.271637916564941, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]  8%|▊         | 3/40 [00:06<01:22,  2.23s/it]                                              {'loss': 2.5285, 'grad_norm': 14.770209312438965, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.23s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 1.2651, 'grad_norm': 12.14737606048584, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 1.5976, 'grad_norm': 14.198390007019043, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.24s/it]                                              {'loss': 2.5696, 'grad_norm': 22.492429733276367, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.24s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 1.8251, 'grad_norm': 22.586721420288086, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 3.1238, 'grad_norm': 56.576663970947266, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 1.2845, 'grad_norm': 12.52464771270752, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.4736, 'grad_norm': 4.381870269775391, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.8403, 'grad_norm': 5.985500335693359, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.10s/it]                                               {'loss': 0.7243, 'grad_norm': 7.821991443634033, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.10s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it]                                               {'loss': 1.1037, 'grad_norm': 9.881084442138672, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.19s/it]                                               {'loss': 1.2256, 'grad_norm': 12.275917053222656, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.19s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.22s/it]                                               {'loss': 0.5575, 'grad_norm': 6.293930530548096, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.22s/it] 40%|████      | 16/40 [00:31<00:38,  1.61s/it]                                               {'loss': 1.3894, 'grad_norm': 43.89826583862305, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.61s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it]                                               {'loss': 0.4821, 'grad_norm': 7.8204193115234375, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.6123, 'grad_norm': 6.306242942810059, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it]                                               {'loss': 0.3156, 'grad_norm': 5.612820625305176, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it] 50%|█████     | 20/40 [00:40<00:42,  2.12s/it]                                               {'loss': 0.4919, 'grad_norm': 5.3607988357543945, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it]                                               {'loss': 0.4221, 'grad_norm': 5.359807968139648, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it] 55%|█████▌    | 22/40 [00:45<00:40,  2.24s/it]                                               {'loss': 0.514, 'grad_norm': 11.526376724243164, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:40,  2.24s/it] 57%|█████▊    | 23/40 [00:47<00:38,  2.26s/it]                                               {'loss': 0.3728, 'grad_norm': 5.460030555725098, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:38,  2.26s/it] 60%|██████    | 24/40 [00:48<00:26,  1.64s/it]                                               {'loss': 0.0187, 'grad_norm': 0.8354517221450806, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.64s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.84s/it]                                               {'loss': 0.2134, 'grad_norm': 3.4194414615631104, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.84s/it] 65%|██████▌   | 26/40 [00:52<00:27,  2.00s/it]                                               {'loss': 0.1608, 'grad_norm': 4.521946430206299, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  2.00s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.09s/it]                                               {'loss': 0.0582, 'grad_norm': 1.3793494701385498, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.09s/it] 70%|███████   | 28/40 [00:57<00:26,  2.17s/it]                                               {'loss': 0.2181, 'grad_norm': 1.4762420654296875, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:26,  2.17s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.21s/it]                                               {'loss': 0.4093, 'grad_norm': 5.425528526306152, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.21s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.25s/it]                                               {'loss': 0.0961, 'grad_norm': 2.652665376663208, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.25s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.28s/it]                                               {'loss': 0.1591, 'grad_norm': 3.1794650554656982, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.28s/it] 80%|████████  | 32/40 [01:04<00:13,  1.65s/it]                                               {'loss': 0.0082, 'grad_norm': 0.4761190116405487, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.65s/it] 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it]                                               {'loss': 0.0807, 'grad_norm': 2.430955648422241, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it] 85%|████████▌ | 34/40 [01:09<00:12,  2.01s/it]                                               {'loss': 0.3017, 'grad_norm': 1.6995503902435303, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:12,  2.01s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.12s/it]                                               {'loss': 0.2195, 'grad_norm': 6.357069969177246, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.12s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it]                                               {'loss': 0.3835, 'grad_norm': 8.819055557250977, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.24s/it]                                               {'loss': 0.1004, 'grad_norm': 2.8995513916015625, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.24s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it]                                               {'loss': 0.3278, 'grad_norm': 5.813803195953369, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.30s/it]                                               {'loss': 0.3569, 'grad_norm': 6.461215496063232, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.30s/it]100%|██████████| 40/40 [01:21<00:00,  1.69s/it]                                               {'loss': 0.0282, 'grad_norm': 1.6730746030807495, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.69s/it]                                               {'train_runtime': 81.7052, 'train_samples_per_second': 6.915, 'train_steps_per_second': 0.49, 'train_loss': 0.8420792409684509, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.69s/it]100%|██████████| 40/40 [01:21<00:00,  2.04s/it]
CLIENT:59
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]                                              {'loss': 2.529, 'grad_norm': 9.03085994720459, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]  5%|▌         | 2/40 [00:04<01:30,  2.38s/it]                                              {'loss': 2.2109, 'grad_norm': 10.667839050292969, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.38s/it]  8%|▊         | 3/40 [00:07<01:25,  2.31s/it]                                              {'loss': 2.5465, 'grad_norm': 13.189748764038086, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.31s/it] 10%|█         | 4/40 [00:09<01:22,  2.29s/it]                                              {'loss': 2.6814, 'grad_norm': 13.684717178344727, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.29s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 2.4299, 'grad_norm': 11.469996452331543, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 2.8629, 'grad_norm': 14.968316078186035, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:15<01:14,  2.25s/it]                                              {'loss': 1.9923, 'grad_norm': 12.788322448730469, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:14,  2.25s/it] 20%|██        | 8/40 [00:16<00:50,  1.59s/it]                                              {'loss': 2.2559, 'grad_norm': 49.66404724121094, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 0.6903, 'grad_norm': 8.963692665100098, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 0.4811, 'grad_norm': 5.124186038970947, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.04s/it]                                               {'loss': 0.9022, 'grad_norm': 7.540034770965576, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.04s/it] 30%|███       | 12/40 [00:25<00:58,  2.09s/it]                                               {'loss': 0.3841, 'grad_norm': 6.206070423126221, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 0.5494, 'grad_norm': 5.548278331756592, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 1.0198, 'grad_norm': 7.361072063446045, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.22s/it]                                               {'loss': 0.3926, 'grad_norm': 4.415530681610107, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.22s/it] 40%|████      | 16/40 [00:32<00:38,  1.60s/it]                                               {'loss': 0.0637, 'grad_norm': 4.194441795349121, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it]                                               {'loss': 0.1235, 'grad_norm': 2.68820858001709, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 0.1033, 'grad_norm': 1.0374306440353394, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.05s/it]                                               {'loss': 0.1329, 'grad_norm': 3.029188871383667, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.05s/it] 50%|█████     | 20/40 [00:41<00:42,  2.11s/it]                                               {'loss': 0.8135, 'grad_norm': 9.81643295288086, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it]                                               {'loss': 0.4736, 'grad_norm': 2.7115156650543213, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 0.0634, 'grad_norm': 1.588616967201233, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it]                                               {'loss': 0.1211, 'grad_norm': 2.2565507888793945, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it] 60%|██████    | 24/40 [00:48<00:26,  1.63s/it]                                               {'loss': 0.0717, 'grad_norm': 4.327388286590576, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.63s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.2759, 'grad_norm': 1.9152520895004272, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it]                                               {'loss': 0.0308, 'grad_norm': 0.589255690574646, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.07s/it]                                               {'loss': 0.0264, 'grad_norm': 0.7567837834358215, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.07s/it] 70%|███████   | 28/40 [00:57<00:25,  2.13s/it]                                               {'loss': 0.0187, 'grad_norm': 0.6604829430580139, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.13s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 1.244, 'grad_norm': 11.366519927978516, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.21s/it]                                               {'loss': 0.0887, 'grad_norm': 1.4779374599456787, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.24s/it]                                               {'loss': 0.1506, 'grad_norm': 2.8962693214416504, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.24s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.0118, 'grad_norm': 0.6489868760108948, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.0788, 'grad_norm': 6.615261077880859, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.96s/it]                                               {'loss': 0.0074, 'grad_norm': 0.1961987167596817, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it]                                               {'loss': 0.0117, 'grad_norm': 0.2998317778110504, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it]                                               {'loss': 0.074, 'grad_norm': 4.002277374267578, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.18s/it]                                               {'loss': 0.0393, 'grad_norm': 0.8350933194160461, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.19s/it]                                               {'loss': 2.2069, 'grad_norm': 18.786781311035156, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.0994, 'grad_norm': 2.6796092987060547, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.6963, 'grad_norm': 19.757394790649414, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 81.0761, 'train_samples_per_second': 6.969, 'train_steps_per_second': 0.493, 'train_loss': 0.7738851075060665, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.62s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
CLIENT:91
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:36,  2.46s/it]                                              {'loss': 2.5978, 'grad_norm': 10.422600746154785, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:36,  2.46s/it]  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]                                              {'loss': 1.7306, 'grad_norm': 10.32323932647705, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 1.6409, 'grad_norm': 13.37182903289795, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:18,  2.17s/it]                                              {'loss': 2.108, 'grad_norm': 15.845083236694336, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.17s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.18s/it]                                              {'loss': 2.0504, 'grad_norm': 14.271596908569336, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:13<01:13,  2.17s/it]                                              {'loss': 2.1915, 'grad_norm': 14.72708797454834, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:13,  2.17s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 2.0614, 'grad_norm': 17.254228591918945, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.0096, 'grad_norm': 0.7855786085128784, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.74s/it]                                              {'loss': 1.8148, 'grad_norm': 19.40150260925293, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.74s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 1.2807, 'grad_norm': 15.771831512451172, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.8359, 'grad_norm': 10.970012664794922, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.9253, 'grad_norm': 8.553567886352539, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it]                                               {'loss': 0.7372, 'grad_norm': 7.07869291305542, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it]                                               {'loss': 0.9852, 'grad_norm': 7.761852264404297, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it]                                               {'loss': 0.2586, 'grad_norm': 4.695545196533203, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it] 40%|████      | 16/40 [00:31<00:38,  1.61s/it]                                               {'loss': 1.1928, 'grad_norm': 42.67366027832031, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.61s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.3229, 'grad_norm': 4.192927837371826, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.1511, 'grad_norm': 2.547600030899048, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.08s/it]                                               {'loss': 0.1798, 'grad_norm': 2.6720023155212402, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.08s/it] 50%|█████     | 20/40 [00:40<00:42,  2.13s/it]                                               {'loss': 0.1692, 'grad_norm': 3.0869293212890625, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.13s/it] 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it]                                               {'loss': 0.2684, 'grad_norm': 4.497389793395996, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.6461, 'grad_norm': 7.547172546386719, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 1.5983, 'grad_norm': 14.655065536499023, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.2389, 'grad_norm': 16.89403533935547, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.1676, 'grad_norm': 3.976918935775757, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.0278, 'grad_norm': 0.602159321308136, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.1242, 'grad_norm': 2.514955520629883, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.4381, 'grad_norm': 4.759409427642822, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.1388, 'grad_norm': 4.025534152984619, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.4239, 'grad_norm': 2.918478012084961, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.22s/it]                                               {'loss': 0.0483, 'grad_norm': 1.3028360605239868, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.0479, 'grad_norm': 2.3091185092926025, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it]                                               {'loss': 0.4673, 'grad_norm': 3.7075865268707275, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.98s/it]                                               {'loss': 0.0369, 'grad_norm': 0.9453938603401184, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.98s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.08s/it]                                               {'loss': 0.0375, 'grad_norm': 0.8702638149261475, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.15s/it]                                               {'loss': 0.035, 'grad_norm': 1.1232171058654785, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it]                                               {'loss': 0.0679, 'grad_norm': 1.8758732080459595, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it]                                               {'loss': 0.0147, 'grad_norm': 0.3225446045398712, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]                                               {'loss': 0.2395, 'grad_norm': 2.711319923400879, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 2.6961, 'grad_norm': 52.6258430480957, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 80.2825, 'train_samples_per_second': 7.038, 'train_steps_per_second': 0.498, 'train_loss': 0.7751746193040162, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:10
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:03<01:59,  3.07s/it]                                              {'loss': 4.1118, 'grad_norm': 12.77254867553711, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:03<01:59,  3.07s/it]  5%|▌         | 2/40 [00:05<01:37,  2.57s/it]                                              {'loss': 2.9747, 'grad_norm': 16.2452335357666, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:37,  2.57s/it]  8%|▊         | 3/40 [00:07<01:29,  2.42s/it]                                              {'loss': 2.035, 'grad_norm': 14.167196273803711, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:29,  2.42s/it] 10%|█         | 4/40 [00:09<01:23,  2.33s/it]                                              {'loss': 1.4471, 'grad_norm': 17.88274383544922, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:23,  2.33s/it] 12%|█▎        | 5/40 [00:11<01:20,  2.29s/it]                                              {'loss': 2.8324, 'grad_norm': 16.10140037536621, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:20,  2.29s/it] 15%|█▌        | 6/40 [00:14<01:17,  2.28s/it]                                              {'loss': 1.9521, 'grad_norm': 16.200761795043945, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:14<01:17,  2.28s/it] 18%|█▊        | 7/40 [00:16<01:14,  2.27s/it]                                              {'loss': 2.789, 'grad_norm': 11.374072074890137, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:14,  2.27s/it] 20%|██        | 8/40 [00:16<00:51,  1.60s/it]                                              {'loss': 2.398, 'grad_norm': 63.57863998413086, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.60s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.80s/it]                                              {'loss': 1.1923, 'grad_norm': 9.047075271606445, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.80s/it] 25%|██▌       | 10/40 [00:21<00:58,  1.95s/it]                                               {'loss': 0.6405, 'grad_norm': 9.992654800415039, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:21<00:58,  1.95s/it] 28%|██▊       | 11/40 [00:23<00:59,  2.05s/it]                                               {'loss': 0.8286, 'grad_norm': 8.93260669708252, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:59,  2.05s/it] 30%|███       | 12/40 [00:25<00:58,  2.11s/it]                                               {'loss': 1.006, 'grad_norm': 7.727319717407227, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.11s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 1.3495, 'grad_norm': 9.415632247924805, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:30<00:56,  2.18s/it]                                               {'loss': 1.1123, 'grad_norm': 7.5286126136779785, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:30<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:32<00:55,  2.23s/it]                                               {'loss': 0.8204, 'grad_norm': 8.255701065063477, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:55,  2.23s/it] 40%|████      | 16/40 [00:32<00:39,  1.63s/it]                                               {'loss': 0.0626, 'grad_norm': 4.019246578216553, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:39,  1.63s/it] 42%|████▎     | 17/40 [00:35<00:42,  1.83s/it]                                               {'loss': 0.0624, 'grad_norm': 1.216333031654358, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:35<00:42,  1.83s/it] 45%|████▌     | 18/40 [00:37<00:43,  1.97s/it]                                               {'loss': 0.1229, 'grad_norm': 4.6828932762146, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:37<00:43,  1.97s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it]                                               {'loss': 0.1731, 'grad_norm': 3.7422220706939697, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it] 50%|█████     | 20/40 [00:41<00:42,  2.15s/it]                                               {'loss': 0.1692, 'grad_norm': 2.4698421955108643, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.15s/it] 52%|█████▎    | 21/40 [00:44<00:41,  2.20s/it]                                               {'loss': 0.3886, 'grad_norm': 3.0118966102600098, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:44<00:41,  2.20s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.23s/it]                                               {'loss': 0.3266, 'grad_norm': 4.253592491149902, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.23s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.24s/it]                                               {'loss': 0.9392, 'grad_norm': 7.2305378913879395, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.24s/it] 60%|██████    | 24/40 [00:49<00:26,  1.63s/it]                                               {'loss': 0.1281, 'grad_norm': 5.389594554901123, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:49<00:26,  1.63s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.83s/it]                                               {'loss': 0.2063, 'grad_norm': 2.11275577545166, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.83s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.96s/it]                                               {'loss': 0.2855, 'grad_norm': 4.15141487121582, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.08s/it]                                               {'loss': 0.0883, 'grad_norm': 2.0847105979919434, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.08s/it] 70%|███████   | 28/40 [00:58<00:25,  2.16s/it]                                               {'loss': 0.1299, 'grad_norm': 3.157780170440674, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:58<00:25,  2.16s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.23s/it]                                               {'loss': 0.1224, 'grad_norm': 2.873706340789795, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.23s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.25s/it]                                               {'loss': 0.2511, 'grad_norm': 5.195534706115723, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.25s/it] 78%|███████▊  | 31/40 [01:05<00:20,  2.28s/it]                                               {'loss': 0.1661, 'grad_norm': 1.9654121398925781, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:05<00:20,  2.28s/it] 80%|████████  | 32/40 [01:05<00:13,  1.65s/it]                                               {'loss': 0.0001, 'grad_norm': 0.008102640509605408, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.65s/it] 82%|████████▎ | 33/40 [01:07<00:12,  1.85s/it]                                               {'loss': 0.0242, 'grad_norm': 0.49769625067710876, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:12,  1.85s/it] 85%|████████▌ | 34/40 [01:10<00:12,  2.01s/it]                                               {'loss': 0.0202, 'grad_norm': 0.3930336534976959, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:10<00:12,  2.01s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.10s/it]                                               {'loss': 0.0875, 'grad_norm': 0.7852537035942078, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.10s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it]                                               {'loss': 0.0385, 'grad_norm': 0.8033425211906433, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.18s/it] 92%|█████████▎| 37/40 [01:17<00:06,  2.23s/it]                                               {'loss': 0.045, 'grad_norm': 1.3785724639892578, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:17<00:06,  2.23s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.26s/it]                                               {'loss': 0.0461, 'grad_norm': 1.2638165950775146, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.26s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]                                               {'loss': 0.1884, 'grad_norm': 0.9425334334373474, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]100%|██████████| 40/40 [01:22<00:00,  1.66s/it]                                               {'loss': 0.0001, 'grad_norm': 0.005040921736508608, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.66s/it]                                               {'train_runtime': 82.4915, 'train_samples_per_second': 6.849, 'train_steps_per_second': 0.485, 'train_loss': 0.789060535716817, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.66s/it]100%|██████████| 40/40 [01:22<00:00,  2.06s/it]
CLIENT:50
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:30,  2.32s/it]                                              {'loss': 3.7033, 'grad_norm': 8.229137420654297, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:30,  2.32s/it]  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]                                              {'loss': 2.7201, 'grad_norm': 11.02812385559082, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.24s/it]  8%|▊         | 3/40 [00:06<01:22,  2.24s/it]                                              {'loss': 1.1786, 'grad_norm': 8.697434425354004, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.24s/it] 10%|█         | 4/40 [00:08<01:20,  2.23s/it]                                              {'loss': 2.8337, 'grad_norm': 13.66455078125, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.26s/it]                                              {'loss': 1.3173, 'grad_norm': 9.846677780151367, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.26s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.26s/it]                                              {'loss': 1.4512, 'grad_norm': 19.996232986450195, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.26s/it] 18%|█▊        | 7/40 [00:15<01:14,  2.26s/it]                                              {'loss': 2.2125, 'grad_norm': 14.132429122924805, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:14,  2.26s/it] 20%|██        | 8/40 [00:15<00:51,  1.60s/it]                                              {'loss': 0.658, 'grad_norm': 22.974170684814453, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:51,  1.60s/it] 22%|██▎       | 9/40 [00:18<00:56,  1.81s/it]                                              {'loss': 0.3781, 'grad_norm': 4.43825101852417, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:56,  1.81s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.95s/it]                                               {'loss': 0.7842, 'grad_norm': 8.118943214416504, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.95s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.05s/it]                                               {'loss': 0.4427, 'grad_norm': 4.911026477813721, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.05s/it] 30%|███       | 12/40 [00:25<00:59,  2.12s/it]                                               {'loss': 0.462, 'grad_norm': 4.2941741943359375, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:59,  2.12s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.18s/it]                                               {'loss': 1.0337, 'grad_norm': 7.872675895690918, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.18s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it]                                               {'loss': 1.1351, 'grad_norm': 11.144525527954102, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.24s/it]                                               {'loss': 0.2544, 'grad_norm': 4.582108020782471, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.24s/it] 40%|████      | 16/40 [00:32<00:39,  1.63s/it]                                               {'loss': 0.0623, 'grad_norm': 5.537198543548584, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:39,  1.63s/it] 42%|████▎     | 17/40 [00:34<00:42,  1.85s/it]                                               {'loss': 0.0862, 'grad_norm': 1.5272735357284546, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:42,  1.85s/it] 45%|████▌     | 18/40 [00:37<00:45,  2.08s/it]                                               {'loss': 0.1275, 'grad_norm': 4.776392459869385, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:37<00:45,  2.08s/it] 48%|████▊     | 19/40 [00:39<00:44,  2.14s/it]                                               {'loss': 0.1382, 'grad_norm': 2.6405727863311768, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:44,  2.14s/it] 50%|█████     | 20/40 [00:41<00:43,  2.18s/it]                                               {'loss': 0.2916, 'grad_norm': 5.337897300720215, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:43,  2.18s/it] 52%|█████▎    | 21/40 [00:44<00:42,  2.22s/it]                                               {'loss': 0.1714, 'grad_norm': 2.913515329360962, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:44<00:42,  2.22s/it] 55%|█████▌    | 22/40 [00:46<00:40,  2.26s/it]                                               {'loss': 0.5985, 'grad_norm': 3.346285343170166, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:40,  2.26s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.27s/it]                                               {'loss': 0.7173, 'grad_norm': 24.09040069580078, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.27s/it] 60%|██████    | 24/40 [00:48<00:26,  1.65s/it]                                               {'loss': 0.289, 'grad_norm': 16.21319007873535, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.65s/it] 62%|██████▎   | 25/40 [00:51<00:27,  1.86s/it]                                               {'loss': 0.0717, 'grad_norm': 1.6668485403060913, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:51<00:27,  1.86s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it]                                               {'loss': 0.2097, 'grad_norm': 4.670025825500488, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.99s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.09s/it]                                               {'loss': 0.1661, 'grad_norm': 3.5113584995269775, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.09s/it] 70%|███████   | 28/40 [00:58<00:26,  2.17s/it]                                               {'loss': 0.1435, 'grad_norm': 4.562092304229736, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:58<00:26,  2.17s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.22s/it]                                               {'loss': 0.1349, 'grad_norm': 15.551776885986328, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.22s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.28s/it]                                               {'loss': 0.0465, 'grad_norm': 1.3705352544784546, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.28s/it] 78%|███████▊  | 31/40 [01:05<00:20,  2.31s/it]                                               {'loss': 0.3119, 'grad_norm': 5.030804634094238, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:05<00:20,  2.31s/it] 80%|████████  | 32/40 [01:05<00:13,  1.67s/it]                                               {'loss': 0.0108, 'grad_norm': 0.5137593746185303, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:05<00:13,  1.67s/it] 82%|████████▎ | 33/40 [01:07<00:13,  1.88s/it]                                               {'loss': 0.0413, 'grad_norm': 0.9086670875549316, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:13,  1.88s/it] 85%|████████▌ | 34/40 [01:10<00:12,  2.03s/it]                                               {'loss': 0.0602, 'grad_norm': 1.1211762428283691, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:10<00:12,  2.03s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.13s/it]                                               {'loss': 0.125, 'grad_norm': 8.805420875549316, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.13s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.19s/it]                                               {'loss': 0.0366, 'grad_norm': 0.9142603278160095, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.19s/it] 92%|█████████▎| 37/40 [01:17<00:06,  2.23s/it]                                               {'loss': 0.1534, 'grad_norm': 3.3930320739746094, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:17<00:06,  2.23s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.26s/it]                                               {'loss': 0.4566, 'grad_norm': 4.781534194946289, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.26s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]                                               {'loss': 0.3422, 'grad_norm': 6.375804424285889, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]100%|██████████| 40/40 [01:22<00:00,  1.66s/it]                                               {'loss': 0.0488, 'grad_norm': 3.5407450199127197, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.66s/it]                                               {'train_runtime': 82.4408, 'train_samples_per_second': 6.853, 'train_steps_per_second': 0.485, 'train_loss': 0.6351576891029254, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.66s/it]100%|██████████| 40/40 [01:22<00:00,  2.06s/it]
CLIENT:53
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:36,  2.47s/it]                                              {'loss': 2.5278, 'grad_norm': 8.658233642578125, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:36,  2.47s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 2.507, 'grad_norm': 10.261615753173828, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:24,  2.29s/it]                                              {'loss': 3.2779, 'grad_norm': 15.443264961242676, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:21,  2.27s/it]                                              {'loss': 1.7128, 'grad_norm': 12.936446189880371, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.27s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it]                                              {'loss': 2.8703, 'grad_norm': 22.727190017700195, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it] 15%|█▌        | 6/40 [00:13<01:17,  2.27s/it]                                              {'loss': 2.091, 'grad_norm': 26.50279426574707, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:17,  2.27s/it] 18%|█▊        | 7/40 [00:15<01:14,  2.27s/it]                                              {'loss': 2.2992, 'grad_norm': 20.442256927490234, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:14,  2.27s/it] 20%|██        | 8/40 [00:16<00:51,  1.60s/it]                                              {'loss': 0.0832, 'grad_norm': 4.3331685066223145, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:51,  1.60s/it] 22%|██▎       | 9/40 [00:18<00:56,  1.82s/it]                                              {'loss': 0.6859, 'grad_norm': 11.041464805603027, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:56,  1.82s/it] 25%|██▌       | 10/40 [00:20<00:59,  1.97s/it]                                               {'loss': 0.6405, 'grad_norm': 4.967179298400879, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:59,  1.97s/it] 28%|██▊       | 11/40 [00:23<00:59,  2.06s/it]                                               {'loss': 1.0223, 'grad_norm': 7.4438910484313965, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:59,  2.06s/it] 30%|███       | 12/40 [00:25<00:59,  2.12s/it]                                               {'loss': 0.8704, 'grad_norm': 23.75361442565918, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:59,  2.12s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.18s/it]                                               {'loss': 0.8227, 'grad_norm': 10.624408721923828, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.18s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it]                                               {'loss': 1.8398, 'grad_norm': 13.904359817504883, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it] 38%|███▊      | 15/40 [00:32<00:55,  2.22s/it]                                               {'loss': 0.9359, 'grad_norm': 7.738062381744385, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:55,  2.22s/it] 40%|████      | 16/40 [00:32<00:38,  1.61s/it]                                               {'loss': 0.6146, 'grad_norm': 23.589733123779297, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.61s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it]                                               {'loss': 0.6678, 'grad_norm': 4.661954879760742, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it]                                               {'loss': 0.1286, 'grad_norm': 2.391796350479126, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it] 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it]                                               {'loss': 0.1782, 'grad_norm': 3.073430061340332, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:43,  2.07s/it] 50%|█████     | 20/40 [00:41<00:42,  2.14s/it]                                               {'loss': 0.0654, 'grad_norm': 1.013958215713501, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.14s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it]                                               {'loss': 0.3827, 'grad_norm': 5.106908798217773, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it] 55%|█████▌    | 22/40 [00:46<00:39,  2.22s/it]                                               {'loss': 0.2115, 'grad_norm': 2.7161717414855957, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:46<00:39,  2.22s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.24s/it]                                               {'loss': 0.3684, 'grad_norm': 5.7330708503723145, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.24s/it] 60%|██████    | 24/40 [00:48<00:25,  1.62s/it]                                               {'loss': 2.0738, 'grad_norm': 25.83316421508789, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.0593, 'grad_norm': 1.0334041118621826, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:53<00:27,  1.96s/it]                                               {'loss': 0.0294, 'grad_norm': 0.5770995616912842, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.08s/it]                                               {'loss': 0.4153, 'grad_norm': 70.85942840576172, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.08s/it] 70%|███████   | 28/40 [00:57<00:25,  2.15s/it]                                               {'loss': 0.0398, 'grad_norm': 1.1968305110931396, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.15s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.20s/it]                                               {'loss': 0.0754, 'grad_norm': 2.346931219100952, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.20s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.24s/it]                                               {'loss': 0.175, 'grad_norm': 3.831218719482422, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.24s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.26s/it]                                               {'loss': 0.2391, 'grad_norm': 5.676013946533203, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.26s/it] 80%|████████  | 32/40 [01:04<00:13,  1.64s/it]                                               {'loss': 0.096, 'grad_norm': 6.102823257446289, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.64s/it] 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it]                                               {'loss': 0.037, 'grad_norm': 1.0518031120300293, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:13,  1.86s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.97s/it]                                               {'loss': 0.064, 'grad_norm': 2.0602760314941406, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it]                                               {'loss': 0.1366, 'grad_norm': 5.043831825256348, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.15s/it]                                               {'loss': 0.0159, 'grad_norm': 0.272774875164032, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.21s/it]                                               {'loss': 0.3162, 'grad_norm': 19.277822494506836, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.21s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it]                                               {'loss': 0.0283, 'grad_norm': 0.8289179801940918, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.28s/it]                                               {'loss': 0.0338, 'grad_norm': 0.6067641973495483, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.28s/it]100%|██████████| 40/40 [01:21<00:00,  1.65s/it]                                               {'loss': 0.0603, 'grad_norm': 3.3363475799560547, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.65s/it]                                               {'train_runtime': 81.7523, 'train_samples_per_second': 6.911, 'train_steps_per_second': 0.489, 'train_loss': 0.7674830962903798, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.65s/it]100%|██████████| 40/40 [01:21<00:00,  2.04s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  do_eval=True, seed=self.args.random_seed)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:59,  1.56it/s]  1%|          | 3/471 [00:02<07:04,  1.10it/s]  1%|          | 4/471 [00:03<08:10,  1.05s/it]  1%|          | 5/471 [00:05<08:47,  1.13s/it]  1%|▏         | 6/471 [00:06<09:10,  1.18s/it]  1%|▏         | 7/471 [00:07<09:26,  1.22s/it]  2%|▏         | 8/471 [00:09<09:35,  1.24s/it]  2%|▏         | 9/471 [00:10<09:41,  1.26s/it]  2%|▏         | 10/471 [00:11<09:45,  1.27s/it]  2%|▏         | 11/471 [00:12<09:48,  1.28s/it]  3%|▎         | 12/471 [00:14<09:50,  1.29s/it]  3%|▎         | 13/471 [00:15<09:51,  1.29s/it]  3%|▎         | 14/471 [00:16<09:52,  1.30s/it]  3%|▎         | 15/471 [00:18<09:51,  1.30s/it]  3%|▎         | 16/471 [00:19<09:52,  1.30s/it]  4%|▎         | 17/471 [00:20<09:52,  1.30s/it]  4%|▍         | 18/471 [00:22<09:51,  1.31s/it]  4%|▍         | 19/471 [00:23<09:50,  1.31s/it]  4%|▍         | 20/471 [00:24<09:50,  1.31s/it]  4%|▍         | 21/471 [00:25<09:50,  1.31s/it]  5%|▍         | 22/471 [00:27<09:50,  1.31s/it]  5%|▍         | 23/471 [00:28<09:49,  1.32s/it]  5%|▌         | 24/471 [00:29<09:48,  1.32s/it]  5%|▌         | 25/471 [00:31<09:47,  1.32s/it]  6%|▌         | 26/471 [00:32<09:46,  1.32s/it]  6%|▌         | 27/471 [00:33<09:45,  1.32s/it]  6%|▌         | 28/471 [00:35<09:44,  1.32s/it]  6%|▌         | 29/471 [00:36<09:44,  1.32s/it]  6%|▋         | 30/471 [00:37<09:44,  1.33s/it]  7%|▋         | 31/471 [00:39<09:43,  1.33s/it]  7%|▋         | 32/471 [00:40<09:42,  1.33s/it]  7%|▋         | 33/471 [00:41<09:40,  1.32s/it]  7%|▋         | 34/471 [00:43<09:39,  1.33s/it]  7%|▋         | 35/471 [00:44<09:39,  1.33s/it]  8%|▊         | 36/471 [00:45<09:38,  1.33s/it]  8%|▊         | 37/471 [00:47<09:37,  1.33s/it]  8%|▊         | 38/471 [00:48<09:37,  1.33s/it]  8%|▊         | 39/471 [00:49<09:36,  1.33s/it]  8%|▊         | 40/471 [00:51<09:35,  1.33s/it]  9%|▊         | 41/471 [00:52<09:34,  1.34s/it]  9%|▉         | 42/471 [00:53<09:34,  1.34s/it]  9%|▉         | 43/471 [00:55<09:32,  1.34s/it]  9%|▉         | 44/471 [00:56<09:31,  1.34s/it] 10%|▉         | 45/471 [00:57<09:30,  1.34s/it] 10%|▉         | 46/471 [00:59<09:29,  1.34s/it] 10%|▉         | 47/471 [01:00<09:27,  1.34s/it] 10%|█         | 48/471 [01:01<09:27,  1.34s/it] 10%|█         | 49/471 [01:03<09:26,  1.34s/it] 11%|█         | 50/471 [01:04<09:25,  1.34s/it] 11%|█         | 51/471 [01:05<09:24,  1.34s/it] 11%|█         | 52/471 [01:07<09:23,  1.34s/it] 11%|█▏        | 53/471 [01:08<09:22,  1.35s/it] 11%|█▏        | 54/471 [01:10<09:21,  1.35s/it] 12%|█▏        | 55/471 [01:11<09:20,  1.35s/it] 12%|█▏        | 56/471 [01:12<09:20,  1.35s/it] 12%|█▏        | 57/471 [01:14<09:18,  1.35s/it] 12%|█▏        | 58/471 [01:15<09:17,  1.35s/it] 13%|█▎        | 59/471 [01:16<09:15,  1.35s/it] 13%|█▎        | 60/471 [01:18<09:13,  1.35s/it] 13%|█▎        | 61/471 [01:19<09:12,  1.35s/it] 13%|█▎        | 62/471 [01:20<09:11,  1.35s/it] 13%|█▎        | 63/471 [01:22<09:09,  1.35s/it] 14%|█▎        | 64/471 [01:23<09:08,  1.35s/it] 14%|█▍        | 65/471 [01:24<09:07,  1.35s/it] 14%|█▍        | 66/471 [01:26<09:06,  1.35s/it] 14%|█▍        | 67/471 [01:27<09:04,  1.35s/it] 14%|█▍        | 68/471 [01:28<09:02,  1.35s/it] 15%|█▍        | 69/471 [01:30<09:01,  1.35s/it] 15%|█▍        | 70/471 [01:31<09:00,  1.35s/it] 15%|█▌        | 71/471 [01:32<08:59,  1.35s/it] 15%|█▌        | 72/471 [01:34<08:57,  1.35s/it] 15%|█▌        | 73/471 [01:35<08:56,  1.35s/it] 16%|█▌        | 74/471 [01:36<08:54,  1.35s/it] 16%|█▌        | 75/471 [01:38<08:53,  1.35s/it] 16%|█▌        | 76/471 [01:39<08:52,  1.35s/it] 16%|█▋        | 77/471 [01:41<08:51,  1.35s/it] 17%|█▋        | 78/471 [01:42<08:49,  1.35s/it] 17%|█▋        | 79/471 [01:43<08:48,  1.35s/it] 17%|█▋        | 80/471 [01:45<08:47,  1.35s/it] 17%|█▋        | 81/471 [01:46<08:45,  1.35s/it] 17%|█▋        | 82/471 [01:47<08:44,  1.35s/it] 18%|█▊        | 83/471 [01:49<08:43,  1.35s/it] 18%|█▊        | 84/471 [01:50<08:42,  1.35s/it] 18%|█▊        | 85/471 [01:51<08:41,  1.35s/it] 18%|█▊        | 86/471 [01:53<08:40,  1.35s/it] 18%|█▊        | 87/471 [01:54<08:38,  1.35s/it] 19%|█▊        | 88/471 [01:55<08:37,  1.35s/it] 19%|█▉        | 89/471 [01:57<08:32,  1.34s/it] 19%|█▉        | 90/471 [01:58<08:33,  1.35s/it] 19%|█▉        | 91/471 [01:59<08:31,  1.35s/it] 20%|█▉        | 92/471 [02:01<08:30,  1.35s/it] 20%|█▉        | 93/471 [02:02<08:29,  1.35s/it] 20%|█▉        | 94/471 [02:03<08:28,  1.35s/it] 20%|██        | 95/471 [02:05<08:26,  1.35s/it] 20%|██        | 96/471 [02:06<08:25,  1.35s/it] 21%|██        | 97/471 [02:08<08:25,  1.35s/it] 21%|██        | 98/471 [02:09<08:23,  1.35s/it] 21%|██        | 99/471 [02:10<08:22,  1.35s/it] 21%|██        | 100/471 [02:12<08:20,  1.35s/it] 21%|██▏       | 101/471 [02:13<08:19,  1.35s/it] 22%|██▏       | 102/471 [02:14<08:19,  1.35s/it] 22%|██▏       | 103/471 [02:16<08:18,  1.35s/it] 22%|██▏       | 104/471 [02:17<08:17,  1.36s/it] 22%|██▏       | 105/471 [02:18<08:16,  1.36s/it] 23%|██▎       | 106/471 [02:20<08:14,  1.35s/it] 23%|██▎       | 107/471 [02:21<08:12,  1.35s/it] 23%|██▎       | 108/471 [02:22<08:10,  1.35s/it] 23%|██▎       | 109/471 [02:24<08:08,  1.35s/it] 23%|██▎       | 110/471 [02:25<08:06,  1.35s/it] 24%|██▎       | 111/471 [02:26<08:05,  1.35s/it] 24%|██▍       | 112/471 [02:28<08:04,  1.35s/it] 24%|██▍       | 113/471 [02:29<08:02,  1.35s/it] 24%|██▍       | 114/471 [02:30<08:02,  1.35s/it] 24%|██▍       | 115/471 [02:32<08:01,  1.35s/it] 25%|██▍       | 116/471 [02:33<08:00,  1.35s/it] 25%|██▍       | 117/471 [02:35<07:58,  1.35s/it] 25%|██▌       | 118/471 [02:36<07:57,  1.35s/it] 25%|██▌       | 119/471 [02:37<07:56,  1.35s/it] 25%|██▌       | 120/471 [02:39<07:55,  1.35s/it] 26%|██▌       | 121/471 [02:40<07:54,  1.35s/it] 26%|██▌       | 122/471 [02:41<07:52,  1.35s/it] 26%|██▌       | 123/471 [02:43<07:51,  1.36s/it] 26%|██▋       | 124/471 [02:44<07:50,  1.35s/it] 27%|██▋       | 125/471 [02:45<07:48,  1.36s/it] 27%|██▋       | 126/471 [02:47<07:47,  1.36s/it] 27%|██▋       | 127/471 [02:48<07:46,  1.36s/it] 27%|██▋       | 128/471 [02:49<07:44,  1.35s/it] 27%|██▋       | 129/471 [02:51<07:43,  1.35s/it] 28%|██▊       | 130/471 [02:52<07:42,  1.36s/it] 28%|██▊       | 131/471 [02:54<07:40,  1.36s/it] 28%|██▊       | 132/471 [02:55<07:39,  1.36s/it] 28%|██▊       | 133/471 [02:56<07:37,  1.35s/it] 28%|██▊       | 134/471 [02:58<07:36,  1.36s/it] 29%|██▊       | 135/471 [02:59<07:34,  1.35s/it] 29%|██▉       | 136/471 [03:00<07:33,  1.35s/it] 29%|██▉       | 137/471 [03:02<07:31,  1.35s/it] 29%|██▉       | 138/471 [03:03<07:30,  1.35s/it] 30%|██▉       | 139/471 [03:04<07:28,  1.35s/it] 30%|██▉       | 140/471 [03:06<07:26,  1.35s/it] 30%|██▉       | 141/471 [03:07<07:24,  1.35s/it] 30%|███       | 142/471 [03:08<07:23,  1.35s/it] 30%|███       | 143/471 [03:10<07:21,  1.35s/it] 31%|███       | 144/471 [03:11<07:20,  1.35s/it] 31%|███       | 145/471 [03:12<07:19,  1.35s/it] 31%|███       | 146/471 [03:14<07:18,  1.35s/it] 31%|███       | 147/471 [03:15<07:16,  1.35s/it] 31%|███▏      | 148/471 [03:16<07:15,  1.35s/it] 32%|███▏      | 149/471 [03:18<07:14,  1.35s/it] 32%|███▏      | 150/471 [03:19<07:13,  1.35s/it] 32%|███▏      | 151/471 [03:21<07:11,  1.35s/it] 32%|███▏      | 152/471 [03:22<07:10,  1.35s/it] 32%|███▏      | 153/471 [03:23<07:09,  1.35s/it] 33%|███▎      | 154/471 [03:25<07:06,  1.35s/it] 33%|███▎      | 155/471 [03:26<07:05,  1.35s/it] 33%|███▎      | 156/471 [03:27<07:03,  1.34s/it] 33%|███▎      | 157/471 [03:29<07:01,  1.34s/it] 34%|███▎      | 158/471 [03:30<06:59,  1.34s/it] 34%|███▍      | 159/471 [03:31<06:58,  1.34s/it] 34%|███▍      | 160/471 [03:33<06:57,  1.34s/it] 34%|███▍      | 161/471 [03:34<06:55,  1.34s/it] 34%|███▍      | 162/471 [03:35<06:54,  1.34s/it] 35%|███▍      | 163/471 [03:37<06:53,  1.34s/it] 35%|███▍      | 164/471 [03:38<06:51,  1.34s/it] 35%|███▌      | 165/471 [03:39<06:49,  1.34s/it] 35%|███▌      | 166/471 [03:41<06:48,  1.34s/it] 35%|███▌      | 167/471 [03:42<06:47,  1.34s/it] 36%|███▌      | 168/471 [03:43<06:45,  1.34s/it] 36%|███▌      | 169/471 [03:45<06:44,  1.34s/it] 36%|███▌      | 170/471 [03:46<06:42,  1.34s/it] 36%|███▋      | 171/471 [03:47<06:41,  1.34s/it] 37%|███▋      | 172/471 [03:49<06:39,  1.34s/it] 37%|███▋      | 173/471 [03:50<06:38,  1.34s/it] 37%|███▋      | 174/471 [03:51<06:37,  1.34s/it] 37%|███▋      | 175/471 [03:53<06:36,  1.34s/it] 37%|███▋      | 176/471 [03:54<06:34,  1.34s/it] 38%|███▊      | 177/471 [03:55<06:33,  1.34s/it] 38%|███▊      | 178/471 [03:57<06:31,  1.34s/it] 38%|███▊      | 179/471 [03:58<06:29,  1.33s/it] 38%|███▊      | 180/471 [03:59<06:28,  1.33s/it] 38%|███▊      | 181/471 [04:01<06:26,  1.33s/it] 39%|███▊      | 182/471 [04:02<06:25,  1.33s/it] 39%|███▉      | 183/471 [04:03<06:24,  1.34s/it] 39%|███▉      | 184/471 [04:05<06:22,  1.33s/it] 39%|███▉      | 185/471 [04:06<06:21,  1.33s/it] 39%|███▉      | 186/471 [04:07<06:20,  1.33s/it] 40%|███▉      | 187/471 [04:09<06:19,  1.34s/it] 40%|███▉      | 188/471 [04:10<06:18,  1.34s/it] 40%|████      | 189/471 [04:11<06:16,  1.33s/it] 40%|████      | 190/471 [04:13<06:15,  1.33s/it] 41%|████      | 191/471 [04:14<06:13,  1.34s/it] 41%|████      | 192/471 [04:15<06:12,  1.34s/it] 41%|████      | 193/471 [04:17<06:10,  1.33s/it] 41%|████      | 194/471 [04:18<06:09,  1.33s/it] 41%|████▏     | 195/471 [04:19<06:08,  1.34s/it] 42%|████▏     | 196/471 [04:21<06:07,  1.33s/it] 42%|████▏     | 197/471 [04:22<06:04,  1.33s/it] 42%|████▏     | 198/471 [04:23<06:03,  1.33s/it] 42%|████▏     | 199/471 [04:25<06:02,  1.33s/it] 42%|████▏     | 200/471 [04:26<06:01,  1.33s/it] 43%|████▎     | 201/471 [04:27<05:59,  1.33s/it] 43%|████▎     | 202/471 [04:29<05:58,  1.33s/it] 43%|████▎     | 203/471 [04:30<05:57,  1.33s/it] 43%|████▎     | 204/471 [04:31<05:55,  1.33s/it] 44%|████▎     | 205/471 [04:33<05:54,  1.33s/it] 44%|████▎     | 206/471 [04:34<05:52,  1.33s/it] 44%|████▍     | 207/471 [04:35<05:51,  1.33s/it] 44%|████▍     | 208/471 [04:37<05:49,  1.33s/it] 44%|████▍     | 209/471 [04:38<05:48,  1.33s/it] 45%|████▍     | 210/471 [04:39<05:47,  1.33s/it] 45%|████▍     | 211/471 [04:41<05:46,  1.33s/it] 45%|████▌     | 212/471 [04:42<05:44,  1.33s/it] 45%|████▌     | 213/471 [04:43<05:44,  1.33s/it] 45%|████▌     | 214/471 [04:45<05:42,  1.33s/it] 46%|████▌     | 215/471 [04:46<05:41,  1.33s/it] 46%|████▌     | 216/471 [04:47<05:40,  1.34s/it] 46%|████▌     | 217/471 [04:49<05:39,  1.34s/it] 46%|████▋     | 218/471 [04:50<05:38,  1.34s/it] 46%|████▋     | 219/471 [04:51<05:36,  1.34s/it] 47%|████▋     | 220/471 [04:53<05:35,  1.34s/it] 47%|████▋     | 221/471 [04:54<05:34,  1.34s/it] 47%|████▋     | 222/471 [04:55<05:32,  1.34s/it] 47%|████▋     | 223/471 [04:57<05:30,  1.33s/it] 48%|████▊     | 224/471 [04:58<05:29,  1.34s/it] 48%|████▊     | 225/471 [04:59<05:28,  1.34s/it] 48%|████▊     | 226/471 [05:01<05:27,  1.34s/it] 48%|████▊     | 227/471 [05:02<05:25,  1.34s/it] 48%|████▊     | 228/471 [05:03<05:24,  1.33s/it] 49%|████▊     | 229/471 [05:05<05:23,  1.34s/it] 49%|████▉     | 230/471 [05:06<05:21,  1.33s/it] 49%|████▉     | 231/471 [05:07<05:20,  1.33s/it] 49%|████▉     | 232/471 [05:09<05:18,  1.33s/it] 49%|████▉     | 233/471 [05:10<05:17,  1.33s/it] 50%|████▉     | 234/471 [05:11<05:16,  1.33s/it] 50%|████▉     | 235/471 [05:13<05:14,  1.33s/it] 50%|█████     | 236/471 [05:14<05:12,  1.33s/it] 50%|█████     | 237/471 [05:15<05:11,  1.33s/it] 51%|█████     | 238/471 [05:17<05:10,  1.33s/it] 51%|█████     | 239/471 [05:18<05:08,  1.33s/it] 51%|█████     | 240/471 [05:19<05:07,  1.33s/it] 51%|█████     | 241/471 [05:21<05:06,  1.33s/it] 51%|█████▏    | 242/471 [05:22<05:04,  1.33s/it] 52%|█████▏    | 243/471 [05:23<05:03,  1.33s/it] 52%|█████▏    | 244/471 [05:25<05:02,  1.33s/it] 52%|█████▏    | 245/471 [05:26<05:00,  1.33s/it] 52%|█████▏    | 246/471 [05:27<04:59,  1.33s/it] 52%|█████▏    | 247/471 [05:29<04:57,  1.33s/it] 53%|█████▎    | 248/471 [05:30<04:56,  1.33s/it] 53%|█████▎    | 249/471 [05:31<04:55,  1.33s/it] 53%|█████▎    | 250/471 [05:33<04:53,  1.33s/it] 53%|█████▎    | 251/471 [05:34<04:52,  1.33s/it] 54%|█████▎    | 252/471 [05:35<04:51,  1.33s/it] 54%|█████▎    | 253/471 [05:37<04:49,  1.33s/it] 54%|█████▍    | 254/471 [05:38<04:48,  1.33s/it] 54%|█████▍    | 255/471 [05:39<04:47,  1.33s/it] 54%|█████▍    | 256/471 [05:41<04:45,  1.33s/it] 55%|█████▍    | 257/471 [05:42<04:44,  1.33s/it] 55%|█████▍    | 258/471 [05:43<04:43,  1.33s/it] 55%|█████▍    | 259/471 [05:45<04:42,  1.33s/it] 55%|█████▌    | 260/471 [05:46<04:41,  1.33s/it] 55%|█████▌    | 261/471 [05:47<04:39,  1.33s/it] 56%|█████▌    | 262/471 [05:49<04:37,  1.33s/it] 56%|█████▌    | 263/471 [05:50<04:36,  1.33s/it] 56%|█████▌    | 264/471 [05:51<04:35,  1.33s/it] 56%|█████▋    | 265/471 [05:53<04:34,  1.33s/it] 56%|█████▋    | 266/471 [05:54<04:33,  1.33s/it] 57%|█████▋    | 267/471 [05:55<04:31,  1.33s/it] 57%|█████▋    | 268/471 [05:57<04:30,  1.33s/it] 57%|█████▋    | 269/471 [05:58<04:28,  1.33s/it] 57%|█████▋    | 270/471 [05:59<04:27,  1.33s/it] 58%|█████▊    | 271/471 [06:01<04:25,  1.33s/it] 58%|█████▊    | 272/471 [06:02<04:24,  1.33s/it] 58%|█████▊    | 273/471 [06:03<04:23,  1.33s/it] 58%|█████▊    | 274/471 [06:05<04:21,  1.33s/it] 58%|█████▊    | 275/471 [06:06<04:20,  1.33s/it] 59%|█████▊    | 276/471 [06:07<04:19,  1.33s/it] 59%|█████▉    | 277/471 [06:09<04:17,  1.33s/it] 59%|█████▉    | 278/471 [06:10<04:16,  1.33s/it] 59%|█████▉    | 279/471 [06:11<04:14,  1.33s/it] 59%|█████▉    | 280/471 [06:13<04:13,  1.33s/it] 60%|█████▉    | 281/471 [06:14<04:12,  1.33s/it] 60%|█████▉    | 282/471 [06:15<04:11,  1.33s/it] 60%|██████    | 283/471 [06:17<04:09,  1.33s/it] 60%|██████    | 284/471 [06:18<04:08,  1.33s/it] 61%|██████    | 285/471 [06:19<04:07,  1.33s/it] 61%|██████    | 286/471 [06:21<04:06,  1.33s/it] 61%|██████    | 287/471 [06:22<04:04,  1.33s/it] 61%|██████    | 288/471 [06:23<04:03,  1.33s/it] 61%|██████▏   | 289/471 [06:25<04:02,  1.33s/it] 62%|██████▏   | 290/471 [06:26<04:00,  1.33s/it] 62%|██████▏   | 291/471 [06:27<03:59,  1.33s/it] 62%|██████▏   | 292/471 [06:28<03:58,  1.33s/it] 62%|██████▏   | 293/471 [06:30<03:56,  1.33s/it] 62%|██████▏   | 294/471 [06:31<03:55,  1.33s/it] 63%|██████▎   | 295/471 [06:32<03:54,  1.33s/it] 63%|██████▎   | 296/471 [06:34<03:52,  1.33s/it] 63%|██████▎   | 297/471 [06:35<03:51,  1.33s/it] 63%|██████▎   | 298/471 [06:36<03:50,  1.33s/it] 63%|██████▎   | 299/471 [06:38<03:49,  1.33s/it] 64%|██████▎   | 300/471 [06:39<03:47,  1.33s/it] 64%|██████▍   | 301/471 [06:40<03:46,  1.33s/it] 64%|██████▍   | 302/471 [06:42<03:45,  1.33s/it] 64%|██████▍   | 303/471 [06:43<03:43,  1.33s/it] 65%|██████▍   | 304/471 [06:44<03:42,  1.33s/it] 65%|██████▍   | 305/471 [06:46<03:41,  1.33s/it] 65%|██████▍   | 306/471 [06:47<03:40,  1.33s/it] 65%|██████▌   | 307/471 [06:48<03:39,  1.34s/it] 65%|██████▌   | 308/471 [06:50<03:38,  1.34s/it] 66%|██████▌   | 309/471 [06:51<03:36,  1.34s/it] 66%|██████▌   | 310/471 [06:53<03:35,  1.34s/it] 66%|██████▌   | 311/471 [06:54<03:33,  1.34s/it] 66%|██████▌   | 312/471 [06:55<03:32,  1.33s/it] 66%|██████▋   | 313/471 [06:57<03:31,  1.34s/it] 67%|██████▋   | 314/471 [06:58<03:29,  1.33s/it] 67%|██████▋   | 315/471 [06:59<03:28,  1.34s/it] 67%|██████▋   | 316/471 [07:01<03:27,  1.34s/it] 67%|██████▋   | 317/471 [07:02<03:25,  1.34s/it] 68%|██████▊   | 318/471 [07:03<03:24,  1.34s/it] 68%|██████▊   | 319/471 [07:05<03:23,  1.34s/it] 68%|██████▊   | 320/471 [07:06<03:22,  1.34s/it] 68%|██████▊   | 321/471 [07:07<03:21,  1.34s/it] 68%|██████▊   | 322/471 [07:09<03:19,  1.34s/it] 69%|██████▊   | 323/471 [07:10<03:18,  1.34s/it] 69%|██████▉   | 324/471 [07:11<03:17,  1.34s/it] 69%|██████▉   | 325/471 [07:13<03:15,  1.34s/it] 69%|██████▉   | 326/471 [07:14<03:14,  1.34s/it] 69%|██████▉   | 327/471 [07:15<03:12,  1.34s/it] 70%|██████▉   | 328/471 [07:17<03:11,  1.34s/it] 70%|██████▉   | 329/471 [07:18<03:10,  1.34s/it] 70%|███████   | 330/471 [07:19<03:09,  1.34s/it] 70%|███████   | 331/471 [07:21<03:07,  1.34s/it] 70%|███████   | 332/471 [07:22<03:06,  1.34s/it] 71%|███████   | 333/471 [07:23<03:05,  1.34s/it] 71%|███████   | 334/471 [07:25<03:04,  1.35s/it] 71%|███████   | 335/471 [07:26<03:03,  1.35s/it] 71%|███████▏  | 336/471 [07:27<03:01,  1.35s/it] 72%|███████▏  | 337/471 [07:29<03:00,  1.35s/it] 72%|███████▏  | 338/471 [07:30<02:58,  1.34s/it] 72%|███████▏  | 339/471 [07:31<02:57,  1.35s/it] 72%|███████▏  | 340/471 [07:33<02:56,  1.35s/it] 72%|███████▏  | 341/471 [07:34<02:54,  1.35s/it] 73%|███████▎  | 342/471 [07:35<02:53,  1.35s/it] 73%|███████▎  | 343/471 [07:37<02:52,  1.35s/it] 73%|███████▎  | 344/471 [07:38<02:50,  1.34s/it] 73%|███████▎  | 345/471 [07:39<02:49,  1.35s/it] 73%|███████▎  | 346/471 [07:41<02:48,  1.35s/it] 74%|███████▎  | 347/471 [07:42<02:46,  1.35s/it] 74%|███████▍  | 348/471 [07:44<02:45,  1.35s/it] 74%|███████▍  | 349/471 [07:45<02:44,  1.35s/it] 74%|███████▍  | 350/471 [07:46<02:43,  1.35s/it] 75%|███████▍  | 351/471 [07:48<02:41,  1.35s/it] 75%|███████▍  | 352/471 [07:49<02:40,  1.35s/it] 75%|███████▍  | 353/471 [07:50<02:39,  1.35s/it] 75%|███████▌  | 354/471 [07:52<02:38,  1.35s/it] 75%|███████▌  | 355/471 [07:53<02:36,  1.35s/it] 76%|███████▌  | 356/471 [07:54<02:35,  1.35s/it] 76%|███████▌  | 357/471 [07:56<02:34,  1.35s/it] 76%|███████▌  | 358/471 [07:57<02:32,  1.35s/it] 76%|███████▌  | 359/471 [07:58<02:31,  1.35s/it] 76%|███████▋  | 360/471 [08:00<02:29,  1.35s/it] 77%|███████▋  | 361/471 [08:01<02:28,  1.35s/it] 77%|███████▋  | 362/471 [08:02<02:27,  1.35s/it] 77%|███████▋  | 363/471 [08:04<02:25,  1.35s/it] 77%|███████▋  | 364/471 [08:05<02:24,  1.35s/it] 77%|███████▋  | 365/471 [08:06<02:23,  1.35s/it] 78%|███████▊  | 366/471 [08:08<02:21,  1.35s/it] 78%|███████▊  | 367/471 [08:09<02:20,  1.35s/it] 78%|███████▊  | 368/471 [08:11<02:18,  1.35s/it] 78%|███████▊  | 369/471 [08:12<02:17,  1.34s/it] 79%|███████▊  | 370/471 [08:13<02:15,  1.35s/it] 79%|███████▉  | 371/471 [08:15<02:14,  1.35s/it] 79%|███████▉  | 372/471 [08:16<02:13,  1.35s/it] 79%|███████▉  | 373/471 [08:17<02:12,  1.35s/it] 79%|███████▉  | 374/471 [08:19<02:10,  1.34s/it] 80%|███████▉  | 375/471 [08:20<02:08,  1.34s/it] 80%|███████▉  | 376/471 [08:21<02:07,  1.34s/it] 80%|████████  | 377/471 [08:23<02:06,  1.34s/it] 80%|████████  | 378/471 [08:24<02:04,  1.34s/it] 80%|████████  | 379/471 [08:25<02:03,  1.34s/it] 81%|████████  | 380/471 [08:27<02:02,  1.34s/it] 81%|████████  | 381/471 [08:28<02:00,  1.34s/it] 81%|████████  | 382/471 [08:29<01:59,  1.34s/it] 81%|████████▏ | 383/471 [08:31<01:58,  1.34s/it] 82%|████████▏ | 384/471 [08:32<01:57,  1.35s/it] 82%|████████▏ | 385/471 [08:33<01:55,  1.35s/it] 82%|████████▏ | 386/471 [08:35<01:54,  1.34s/it] 82%|████████▏ | 387/471 [08:36<01:52,  1.34s/it] 82%|████████▏ | 388/471 [08:37<01:51,  1.35s/it] 83%|████████▎ | 389/471 [08:39<01:50,  1.34s/it] 83%|████████▎ | 390/471 [08:40<01:48,  1.34s/it] 83%|████████▎ | 391/471 [08:41<01:47,  1.34s/it] 83%|████████▎ | 392/471 [08:43<01:46,  1.34s/it] 83%|████████▎ | 393/471 [08:44<01:44,  1.34s/it] 84%|████████▎ | 394/471 [08:45<01:43,  1.34s/it] 84%|████████▍ | 395/471 [08:47<01:42,  1.34s/it] 84%|████████▍ | 396/471 [08:48<01:40,  1.34s/it] 84%|████████▍ | 397/471 [08:49<01:39,  1.34s/it] 85%|████████▍ | 398/471 [08:51<01:37,  1.34s/it] 85%|████████▍ | 399/471 [08:52<01:36,  1.34s/it] 85%|████████▍ | 400/471 [08:54<01:35,  1.34s/it] 85%|████████▌ | 401/471 [08:55<01:33,  1.34s/it] 85%|████████▌ | 402/471 [08:56<01:32,  1.34s/it] 86%|████████▌ | 403/471 [08:58<01:30,  1.34s/it] 86%|████████▌ | 404/471 [08:59<01:29,  1.34s/it] 86%|████████▌ | 405/471 [09:00<01:28,  1.34s/it] 86%|████████▌ | 406/471 [09:02<01:26,  1.34s/it] 86%|████████▋ | 407/471 [09:03<01:25,  1.33s/it] 87%|████████▋ | 408/471 [09:04<01:24,  1.34s/it] 87%|████████▋ | 409/471 [09:06<01:22,  1.34s/it] 87%|████████▋ | 410/471 [09:07<01:21,  1.34s/it] 87%|████████▋ | 411/471 [09:08<01:20,  1.33s/it] 87%|████████▋ | 412/471 [09:10<01:18,  1.34s/it] 88%|████████▊ | 413/471 [09:11<01:17,  1.34s/it] 88%|████████▊ | 414/471 [09:12<01:16,  1.34s/it] 88%|████████▊ | 415/471 [09:14<01:14,  1.33s/it] 88%|████████▊ | 416/471 [09:15<01:13,  1.34s/it] 89%|████████▊ | 417/471 [09:16<01:12,  1.34s/it] 89%|████████▊ | 418/471 [09:18<01:10,  1.34s/it] 89%|████████▉ | 419/471 [09:19<01:09,  1.34s/it] 89%|████████▉ | 420/471 [09:20<01:08,  1.34s/it] 89%|████████▉ | 421/471 [09:22<01:06,  1.34s/it] 90%|████████▉ | 422/471 [09:23<01:05,  1.34s/it] 90%|████████▉ | 423/471 [09:24<01:04,  1.33s/it] 90%|█████████ | 424/471 [09:26<01:02,  1.33s/it] 90%|█████████ | 425/471 [09:27<01:01,  1.33s/it] 90%|█████████ | 426/471 [09:28<01:00,  1.34s/it] 91%|█████████ | 427/471 [09:30<00:58,  1.34s/it] 91%|█████████ | 428/471 [09:31<00:57,  1.34s/it] 91%|█████████ | 429/471 [09:32<00:56,  1.34s/it] 91%|█████████▏| 430/471 [09:34<00:54,  1.34s/it] 92%|█████████▏| 431/471 [09:35<00:53,  1.34s/it] 92%|█████████▏| 432/471 [09:36<00:52,  1.34s/it] 92%|█████████▏| 433/471 [09:38<00:50,  1.34s/it] 92%|█████████▏| 434/471 [09:39<00:49,  1.34s/it] 92%|█████████▏| 435/471 [09:40<00:48,  1.34s/it] 93%|█████████▎| 436/471 [09:42<00:46,  1.34s/it] 93%|█████████▎| 437/471 [09:43<00:45,  1.34s/it] 93%|█████████▎| 438/471 [09:44<00:44,  1.34s/it] 93%|█████████▎| 439/471 [09:46<00:42,  1.34s/it] 93%|█████████▎| 440/471 [09:47<00:41,  1.34s/it] 94%|█████████▎| 441/471 [09:48<00:40,  1.34s/it] 94%|█████████▍| 442/471 [09:50<00:38,  1.34s/it] 94%|█████████▍| 443/471 [09:51<00:37,  1.33s/it] 94%|█████████▍| 444/471 [09:52<00:36,  1.34s/it] 94%|█████████▍| 445/471 [09:54<00:34,  1.34s/it] 95%|█████████▍| 446/471 [09:55<00:33,  1.34s/it] 95%|█████████▍| 447/471 [09:56<00:32,  1.34s/it] 95%|█████████▌| 448/471 [09:58<00:30,  1.34s/it] 95%|█████████▌| 449/471 [09:59<00:29,  1.34s/it] 96%|█████████▌| 450/471 [10:00<00:28,  1.34s/it] 96%|█████████▌| 451/471 [10:02<00:26,  1.34s/it] 96%|█████████▌| 452/471 [10:03<00:25,  1.34s/it] 96%|█████████▌| 453/471 [10:04<00:24,  1.34s/it] 96%|█████████▋| 454/471 [10:06<00:22,  1.34s/it] 97%|█████████▋| 455/471 [10:07<00:21,  1.34s/it] 97%|█████████▋| 456/471 [10:08<00:20,  1.34s/it] 97%|█████████▋| 457/471 [10:10<00:18,  1.34s/it] 97%|█████████▋| 458/471 [10:11<00:17,  1.34s/it] 97%|█████████▋| 459/471 [10:12<00:16,  1.33s/it] 98%|█████████▊| 460/471 [10:14<00:14,  1.33s/it] 98%|█████████▊| 461/471 [10:15<00:13,  1.34s/it] 98%|█████████▊| 462/471 [10:16<00:12,  1.34s/it] 98%|█████████▊| 463/471 [10:18<00:10,  1.33s/it] 99%|█████████▊| 464/471 [10:19<00:09,  1.33s/it] 99%|█████████▊| 465/471 [10:20<00:07,  1.33s/it] 99%|█████████▉| 466/471 [10:22<00:06,  1.33s/it] 99%|█████████▉| 467/471 [10:23<00:05,  1.33s/it] 99%|█████████▉| 468/471 [10:24<00:04,  1.34s/it]100%|█████████▉| 469/471 [10:26<00:02,  1.34s/it]100%|█████████▉| 470/471 [10:27<00:01,  1.34s/it]100%|██████████| 471/471 [10:28<00:00,  1.22s/it]100%|██████████| 471/471 [10:28<00:00,  1.33s/it]
{'eval_loss': 2.854783535003662, 'eval_model_preparation_time': 0.0141, 'eval_acc': 0.29753053637812005, 'eval_runtime': 629.7703, 'eval_samples_per_second': 11.96, 'eval_steps_per_second': 0.748}
ROUND:14
CLIENT:72
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:30,  2.32s/it]                                              {'loss': 2.9382, 'grad_norm': 13.446121215820312, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:30,  2.32s/it]  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]                                              {'loss': 2.376, 'grad_norm': 14.417731285095215, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]  8%|▊         | 3/40 [00:06<01:23,  2.25s/it]                                              {'loss': 1.7835, 'grad_norm': 13.270483016967773, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.25s/it] 10%|█         | 4/40 [00:09<01:20,  2.25s/it]                                              {'loss': 1.5038, 'grad_norm': 13.398796081542969, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 1.5412, 'grad_norm': 17.312990188598633, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 0.9711, 'grad_norm': 11.139349937438965, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 2.4675, 'grad_norm': 20.441120147705078, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 0.0494, 'grad_norm': 2.983769655227661, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.77s/it]                                              {'loss': 0.7129, 'grad_norm': 5.5652313232421875, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 0.3542, 'grad_norm': 7.592134952545166, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it]                                               {'loss': 0.8805, 'grad_norm': 12.760099411010742, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 0.3601, 'grad_norm': 5.578726768493652, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.15s/it]                                               {'loss': 1.3847, 'grad_norm': 6.524742603302002, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.15s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.19s/it]                                               {'loss': 0.7848, 'grad_norm': 7.158688545227051, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.19s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it]                                               {'loss': 0.55, 'grad_norm': 4.943143367767334, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it] 40%|████      | 16/40 [00:31<00:38,  1.60s/it]                                               {'loss': 0.1925, 'grad_norm': 7.5529069900512695, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it]                                               {'loss': 0.0431, 'grad_norm': 1.0647354125976562, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it]                                               {'loss': 0.0784, 'grad_norm': 6.284462928771973, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it]                                               {'loss': 0.1759, 'grad_norm': 2.4911611080169678, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it] 50%|█████     | 20/40 [00:41<00:42,  2.12s/it]                                               {'loss': 0.112, 'grad_norm': 2.155113697052002, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it]                                               {'loss': 0.14, 'grad_norm': 1.7534794807434082, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.3374, 'grad_norm': 2.6354119777679443, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.428, 'grad_norm': 6.111691474914551, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0079, 'grad_norm': 0.3881673216819763, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.0961, 'grad_norm': 3.5556247234344482, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.3024, 'grad_norm': 23.032155990600586, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.0243, 'grad_norm': 0.4876905381679535, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.11s/it]                                               {'loss': 0.0304, 'grad_norm': 1.2885514497756958, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it]                                               {'loss': 0.201, 'grad_norm': 13.427334785461426, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.065, 'grad_norm': 2.052077531814575, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.102, 'grad_norm': 1.7822113037109375, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.0073, 'grad_norm': 0.434915155172348, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.0089, 'grad_norm': 0.21891997754573822, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.0459, 'grad_norm': 1.134419560432434, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it]                                               {'loss': 0.0116, 'grad_norm': 0.24385406076908112, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it]                                               {'loss': 0.2304, 'grad_norm': 0.8318597078323364, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it]                                               {'loss': 0.0165, 'grad_norm': 0.3660011887550354, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it]                                               {'loss': 0.0663, 'grad_norm': 0.904118537902832, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.22s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.26s/it]                                               {'loss': 0.0123, 'grad_norm': 0.29224005341529846, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.26s/it]100%|██████████| 40/40 [01:20<00:00,  1.66s/it]                                               {'loss': 0.0173, 'grad_norm': 0.8254947066307068, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.66s/it]                                               {'train_runtime': 81.0388, 'train_samples_per_second': 6.972, 'train_steps_per_second': 0.494, 'train_loss': 0.5352670376538299, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.66s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
CLIENT:33
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:03<02:00,  3.08s/it]                                              {'loss': 2.8304, 'grad_norm': 9.426494598388672, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:03<02:00,  3.08s/it]  5%|▌         | 2/40 [00:05<01:37,  2.55s/it]                                              {'loss': 2.5116, 'grad_norm': 28.25265884399414, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:37,  2.55s/it]  8%|▊         | 3/40 [00:07<01:28,  2.40s/it]                                              {'loss': 2.2503, 'grad_norm': 16.79204559326172, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:28,  2.40s/it] 10%|█         | 4/40 [00:09<01:23,  2.31s/it]                                              {'loss': 2.2155, 'grad_norm': 14.21721076965332, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:23,  2.31s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it]                                              {'loss': 2.6696, 'grad_norm': 14.040184020996094, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.26s/it] 15%|█▌        | 6/40 [00:14<01:16,  2.24s/it]                                              {'loss': 1.8964, 'grad_norm': 13.201986312866211, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:14<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:16<01:13,  2.22s/it]                                              {'loss': 2.1217, 'grad_norm': 14.425749778747559, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 0.5856, 'grad_norm': 32.312522888183594, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 0.4524, 'grad_norm': 5.019747257232666, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 0.7038, 'grad_norm': 9.662203788757324, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:23<00:58,  2.03s/it]                                               {'loss': 1.3675, 'grad_norm': 8.137547492980957, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:23<00:58,  2.03s/it] 30%|███       | 12/40 [00:25<00:58,  2.07s/it]                                               {'loss': 0.8442, 'grad_norm': 6.136812686920166, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.10s/it]                                               {'loss': 0.8248, 'grad_norm': 11.787431716918945, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 0.7119, 'grad_norm': 6.513197898864746, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:32<00:54,  2.18s/it]                                               {'loss': 0.3805, 'grad_norm': 5.426270484924316, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:32<00:54,  2.18s/it] 40%|████      | 16/40 [00:32<00:38,  1.59s/it]                                               {'loss': 0.467, 'grad_norm': 18.165117263793945, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.3392, 'grad_norm': 6.597506046295166, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.2128, 'grad_norm': 4.605457782745361, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it]                                               {'loss': 0.5761, 'grad_norm': 3.96783185005188, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it] 50%|█████     | 20/40 [00:41<00:41,  2.09s/it]                                               {'loss': 0.1954, 'grad_norm': 3.178438901901245, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 0.0867, 'grad_norm': 1.8591703176498413, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.2815, 'grad_norm': 3.851867437362671, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.20s/it]                                               {'loss': 0.407, 'grad_norm': 6.806072235107422, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.20s/it] 60%|██████    | 24/40 [00:48<00:25,  1.62s/it]                                               {'loss': 0.0145, 'grad_norm': 0.7001036405563354, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.0926, 'grad_norm': 2.1975462436676025, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.4099, 'grad_norm': 7.633342266082764, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it]                                               {'loss': 0.1121, 'grad_norm': 3.72652530670166, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.14s/it]                                               {'loss': 0.3502, 'grad_norm': 3.3391194343566895, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.18s/it]                                               {'loss': 0.0687, 'grad_norm': 1.1795448064804077, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.18s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.2092, 'grad_norm': 2.7579402923583984, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.24s/it]                                               {'loss': 0.4329, 'grad_norm': 5.860186576843262, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.24s/it] 80%|████████  | 32/40 [01:04<00:13,  1.63s/it]                                               {'loss': 0.0071, 'grad_norm': 0.4167272448539734, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.1599, 'grad_norm': 3.120189666748047, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.97s/it]                                               {'loss': 0.0581, 'grad_norm': 2.633424997329712, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it]                                               {'loss': 0.0387, 'grad_norm': 1.2079423666000366, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it]                                               {'loss': 0.1972, 'grad_norm': 6.544652938842773, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.1575, 'grad_norm': 3.5710461139678955, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.20s/it]                                               {'loss': 0.0668, 'grad_norm': 1.1052240133285522, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]                                               {'loss': 0.0722, 'grad_norm': 1.9067070484161377, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.0207, 'grad_norm': 1.053947925567627, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 81.0176, 'train_samples_per_second': 6.974, 'train_steps_per_second': 0.494, 'train_loss': 0.6850082299555652, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.62s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
CLIENT:58
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]                                              {'loss': 3.1159, 'grad_norm': 9.612320899963379, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]                                              {'loss': 1.5766, 'grad_norm': 11.17172622680664, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]  8%|▊         | 3/40 [00:06<01:22,  2.24s/it]                                              {'loss': 2.2054, 'grad_norm': 15.066671371459961, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.24s/it] 10%|█         | 4/40 [00:09<01:19,  2.21s/it]                                              {'loss': 2.9463, 'grad_norm': 20.59398651123047, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it]                                              {'loss': 1.505, 'grad_norm': 12.979419708251953, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:13,  2.17s/it]                                              {'loss': 2.1313, 'grad_norm': 15.483548164367676, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:13,  2.17s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 2.8614, 'grad_norm': 16.428855895996094, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 1.59, 'grad_norm': 361.6621398925781, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it]                                              {'loss': 0.6756, 'grad_norm': 9.878067970275879, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.73s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it]                                               {'loss': 0.8046, 'grad_norm': 10.297101974487305, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.88s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 0.6572, 'grad_norm': 7.570070266723633, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 0.995, 'grad_norm': 9.310826301574707, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it]                                               {'loss': 0.9616, 'grad_norm': 9.725341796875, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 0.5523, 'grad_norm': 7.255520820617676, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.14s/it]                                               {'loss': 0.7613, 'grad_norm': 7.510807514190674, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.14s/it] 40%|████      | 16/40 [00:31<00:37,  1.55s/it]                                               {'loss': 0.0769, 'grad_norm': 3.538787841796875, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.55s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.8477, 'grad_norm': 11.301419258117676, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.94s/it]                                               {'loss': 0.1801, 'grad_norm': 3.4112751483917236, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it]                                               {'loss': 0.6069, 'grad_norm': 11.947598457336426, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.0938, 'grad_norm': 2.764976978302002, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:39,  2.09s/it]                                               {'loss': 0.5015, 'grad_norm': 9.795941352844238, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:39,  2.09s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.213, 'grad_norm': 3.363001585006714, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 0.0786, 'grad_norm': 1.9187697172164917, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:47<00:25,  1.57s/it]                                               {'loss': 0.0483, 'grad_norm': 2.0898325443267822, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.0451, 'grad_norm': 1.071623682975769, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it]                                               {'loss': 0.0694, 'grad_norm': 2.2730257511138916, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it]                                               {'loss': 0.3479, 'grad_norm': 7.953362941741943, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it] 70%|███████   | 28/40 [00:55<00:24,  2.06s/it]                                               {'loss': 0.5455, 'grad_norm': 22.324426651000977, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.06s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.11s/it]                                               {'loss': 0.0846, 'grad_norm': 2.5230820178985596, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.11s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.4432, 'grad_norm': 5.8920674324035645, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it]                                               {'loss': 0.0374, 'grad_norm': 0.6791803240776062, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it] 80%|████████  | 32/40 [01:02<00:12,  1.59s/it]                                               {'loss': 0.1789, 'grad_norm': 9.184494972229004, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it]                                               {'loss': 0.0516, 'grad_norm': 2.702399253845215, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.191, 'grad_norm': 9.566790580749512, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.0265, 'grad_norm': 0.6721814870834351, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it]                                               {'loss': 0.4761, 'grad_norm': 2.412276029586792, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.042, 'grad_norm': 0.8898743987083435, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it]                                               {'loss': 0.0645, 'grad_norm': 1.6271799802780151, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]                                               {'loss': 0.0315, 'grad_norm': 0.8180302977561951, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'loss': 0.0143, 'grad_norm': 0.7274190187454224, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'train_runtime': 79.0125, 'train_samples_per_second': 7.151, 'train_steps_per_second': 0.506, 'train_loss': 0.7158978666411713, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:2
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:33,  2.39s/it]                                              {'loss': 2.8175, 'grad_norm': 8.787691116333008, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:33,  2.39s/it]  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]                                              {'loss': 2.9505, 'grad_norm': 12.958046913146973, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]  8%|▊         | 3/40 [00:06<01:22,  2.23s/it]                                              {'loss': 1.4875, 'grad_norm': 13.250204086303711, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.23s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 2.2468, 'grad_norm': 11.882919311523438, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 1.8542, 'grad_norm': 15.0437593460083, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 3.1104, 'grad_norm': 16.898611068725586, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 2.8435, 'grad_norm': 13.99598217010498, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 0.0656, 'grad_norm': 3.1766672134399414, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 0.9673, 'grad_norm': 13.418965339660645, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.9882, 'grad_norm': 10.726184844970703, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.3856, 'grad_norm': 4.7333173751831055, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.5615, 'grad_norm': 4.291046142578125, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 0.6761, 'grad_norm': 6.968195915222168, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 0.3467, 'grad_norm': 3.723205327987671, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.9463, 'grad_norm': 10.235678672790527, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.3004, 'grad_norm': 11.733370780944824, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it]                                               {'loss': 0.0436, 'grad_norm': 1.2819297313690186, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.3508, 'grad_norm': 3.051804304122925, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.1676, 'grad_norm': 3.454545497894287, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.1898, 'grad_norm': 5.079024314880371, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.2893, 'grad_norm': 4.936944007873535, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.1993, 'grad_norm': 5.771904468536377, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.0429, 'grad_norm': 0.9507868885993958, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0145, 'grad_norm': 0.9446631073951721, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it]                                               {'loss': 0.2143, 'grad_norm': 5.022909164428711, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.0718, 'grad_norm': 3.507006883621216, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it]                                               {'loss': 0.1243, 'grad_norm': 3.18819260597229, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it] 70%|███████   | 28/40 [00:56<00:25,  2.12s/it]                                               {'loss': 0.1339, 'grad_norm': 4.3069353103637695, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.055, 'grad_norm': 1.3436607122421265, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it]                                               {'loss': 0.021, 'grad_norm': 0.6378491520881653, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it]                                               {'loss': 0.0637, 'grad_norm': 2.1126513481140137, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.001, 'grad_norm': 0.06543077528476715, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.0446, 'grad_norm': 1.820325493812561, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.0207, 'grad_norm': 0.544868528842926, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.08s/it]                                               {'loss': 0.0292, 'grad_norm': 3.2579407691955566, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.14s/it]                                               {'loss': 0.0227, 'grad_norm': 0.5973110198974609, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it]                                               {'loss': 0.0455, 'grad_norm': 1.2997815608978271, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.0247, 'grad_norm': 0.52751624584198, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.25s/it]                                               {'loss': 0.0319, 'grad_norm': 1.6318275928497314, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.25s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.049, 'grad_norm': 7.908234596252441, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.4107, 'train_samples_per_second': 7.026, 'train_steps_per_second': 0.497, 'train_loss': 0.6199736759648659, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:55
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:03<01:57,  3.01s/it]                                              {'loss': 2.1451, 'grad_norm': 8.32884693145752, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:03<01:57,  3.01s/it]  5%|▌         | 2/40 [00:05<01:34,  2.48s/it]                                              {'loss': 3.7225, 'grad_norm': 14.038261413574219, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:34,  2.48s/it]  8%|▊         | 3/40 [00:07<01:26,  2.34s/it]                                              {'loss': 1.9005, 'grad_norm': 12.940071105957031, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:26,  2.34s/it] 10%|█         | 4/40 [00:09<01:22,  2.29s/it]                                              {'loss': 1.6942, 'grad_norm': 12.018318176269531, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.29s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 2.7642, 'grad_norm': 14.927144050598145, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it]                                              {'loss': 1.368, 'grad_norm': 17.58517074584961, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.24s/it] 18%|█▊        | 7/40 [00:16<01:13,  2.23s/it]                                              {'loss': 3.2158, 'grad_norm': 16.744760513305664, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:13,  2.23s/it] 20%|██        | 8/40 [00:16<00:50,  1.59s/it]                                              {'loss': 0.2028, 'grad_norm': 11.971320152282715, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 1.0053, 'grad_norm': 13.740487098693848, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.7425, 'grad_norm': 14.295619010925293, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.9495, 'grad_norm': 11.205568313598633, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:25<00:57,  2.07s/it]                                               {'loss': 1.6062, 'grad_norm': 8.398768424987793, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 1.0439, 'grad_norm': 6.843780517578125, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 0.9341, 'grad_norm': 5.287021160125732, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.6054, 'grad_norm': 5.639896869659424, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:32<00:38,  1.59s/it]                                               {'loss': 0.989, 'grad_norm': 26.763879776000977, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.78s/it]                                               {'loss': 0.3859, 'grad_norm': 5.855414867401123, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.2434, 'grad_norm': 2.112229347229004, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.4469, 'grad_norm': 6.3611040115356445, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:41<00:41,  2.09s/it]                                               {'loss': 0.4005, 'grad_norm': 6.696163177490234, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 0.3976, 'grad_norm': 4.838892936706543, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.7335, 'grad_norm': 5.9372029304504395, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.1827, 'grad_norm': 3.4495081901550293, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:48<00:25,  1.61s/it]                                               {'loss': 0.0009, 'grad_norm': 0.07817407697439194, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.80s/it]                                               {'loss': 0.1377, 'grad_norm': 3.266347646713257, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.1815, 'grad_norm': 3.942884683609009, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.1123, 'grad_norm': 2.3808627128601074, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.1049, 'grad_norm': 1.6650874614715576, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it]                                               {'loss': 0.0479, 'grad_norm': 0.8144919872283936, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it]                                               {'loss': 0.1493, 'grad_norm': 4.048786163330078, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.23s/it]                                               {'loss': 0.1687, 'grad_norm': 4.160034656524658, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.23s/it] 80%|████████  | 32/40 [01:04<00:13,  1.63s/it]                                               {'loss': 0.0041, 'grad_norm': 0.27681443095207214, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.1163, 'grad_norm': 3.8999838829040527, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.0211, 'grad_norm': 0.44169068336486816, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.04s/it]                                               {'loss': 0.0506, 'grad_norm': 1.3122974634170532, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.11s/it]                                               {'loss': 0.0149, 'grad_norm': 0.29443806409835815, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.0284, 'grad_norm': 0.5553678870201111, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.19s/it]                                               {'loss': 0.0222, 'grad_norm': 0.7338128685951233, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]                                               {'loss': 0.0401, 'grad_norm': 1.0704588890075684, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.0145, 'grad_norm': 1.027023434638977, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.7793, 'train_samples_per_second': 6.994, 'train_steps_per_second': 0.495, 'train_loss': 0.7223616762406891, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:84
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]                                              {'loss': 2.018, 'grad_norm': 9.609573364257812, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 2.9318, 'grad_norm': 10.572867393493652, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:23,  2.27s/it]                                              {'loss': 1.2042, 'grad_norm': 9.285122871398926, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.27s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 1.7003, 'grad_norm': 15.441149711608887, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it]                                              {'loss': 0.5926, 'grad_norm': 9.464253425598145, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:13,  2.18s/it]                                              {'loss': 3.2951, 'grad_norm': 22.024860382080078, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:13,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 2.7484, 'grad_norm': 22.04220199584961, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 0.0117, 'grad_norm': 0.6474841237068176, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it]                                              {'loss': 1.0004, 'grad_norm': 8.720861434936523, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.87s/it]                                               {'loss': 0.4855, 'grad_norm': 7.857572555541992, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.87s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 0.6217, 'grad_norm': 7.763593673706055, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 0.435, 'grad_norm': 3.8075060844421387, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 0.7322, 'grad_norm': 6.874344348907471, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it]                                               {'loss': 0.8615, 'grad_norm': 7.379758358001709, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it]                                               {'loss': 0.6928, 'grad_norm': 6.592749118804932, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 0.2763, 'grad_norm': 13.091487884521484, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.0835, 'grad_norm': 1.7242850065231323, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it]                                               {'loss': 0.121, 'grad_norm': 2.7997794151306152, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it]                                               {'loss': 0.1458, 'grad_norm': 4.589564800262451, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.37, 'grad_norm': 6.8931989669799805, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.2022, 'grad_norm': 3.4614341259002686, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 0.5204, 'grad_norm': 4.909802436828613, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it]                                               {'loss': 0.1983, 'grad_norm': 18.681779861450195, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it] 60%|██████    | 24/40 [00:47<00:25,  1.57s/it]                                               {'loss': 0.0047, 'grad_norm': 0.1972350925207138, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.0787, 'grad_norm': 1.559736967086792, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it]                                               {'loss': 0.4119, 'grad_norm': 2.8902740478515625, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it]                                               {'loss': 0.0497, 'grad_norm': 1.0293715000152588, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.98s/it] 70%|███████   | 28/40 [00:55<00:24,  2.06s/it]                                               {'loss': 0.3237, 'grad_norm': 4.671135425567627, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.06s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it]                                               {'loss': 0.0306, 'grad_norm': 0.5644016265869141, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.15s/it]                                               {'loss': 0.2262, 'grad_norm': 2.0638489723205566, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.15s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it]                                               {'loss': 0.0984, 'grad_norm': 2.3831570148468018, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it] 80%|████████  | 32/40 [01:02<00:12,  1.60s/it]                                               {'loss': 0.2135, 'grad_norm': 11.04565715789795, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0182, 'grad_norm': 0.47159627079963684, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it]                                               {'loss': 0.0294, 'grad_norm': 1.0526821613311768, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it]                                               {'loss': 0.0684, 'grad_norm': 1.9361425638198853, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it]                                               {'loss': 0.4924, 'grad_norm': 7.507382392883301, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.13s/it]                                               {'loss': 0.0607, 'grad_norm': 1.2778756618499756, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.13s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it]                                               {'loss': 0.0839, 'grad_norm': 1.3394787311553955, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.15s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.18s/it]                                               {'loss': 0.0808, 'grad_norm': 2.1862826347351074, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.18s/it]100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'loss': 0.0144, 'grad_norm': 0.8735266923904419, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.58s/it]                                               {'train_runtime': 79.0402, 'train_samples_per_second': 7.148, 'train_steps_per_second': 0.506, 'train_loss': 0.5883584526833147, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.58s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:54
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:39,  2.55s/it]                                              {'loss': 2.6862, 'grad_norm': 11.825630187988281, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:39,  2.55s/it]  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]                                              {'loss': 1.7682, 'grad_norm': 11.634544372558594, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 1.6561, 'grad_norm': 31.650634765625, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 2.122, 'grad_norm': 13.41403579711914, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 1.4017, 'grad_norm': 11.933489799499512, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 1.9357, 'grad_norm': 13.871930122375488, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it]                                              {'loss': 1.9865, 'grad_norm': 13.603203773498535, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 5.3536, 'grad_norm': 70.17012786865234, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 0.3954, 'grad_norm': 8.598755836486816, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.663, 'grad_norm': 7.827334403991699, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.6012, 'grad_norm': 64.72944641113281, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.5762, 'grad_norm': 9.027276039123535, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 0.2692, 'grad_norm': 5.363255977630615, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.5512, 'grad_norm': 5.478621482849121, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it]                                               {'loss': 0.6397, 'grad_norm': 8.492959022521973, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it] 40%|████      | 16/40 [00:31<00:38,  1.62s/it]                                               {'loss': 0.0258, 'grad_norm': 1.307966709136963, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.62s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.82s/it]                                               {'loss': 0.2944, 'grad_norm': 3.9320406913757324, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.82s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.0578, 'grad_norm': 2.838380813598633, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it]                                               {'loss': 0.2713, 'grad_norm': 7.368775367736816, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.2944, 'grad_norm': 2.5990941524505615, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 0.242, 'grad_norm': 5.518096446990967, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.1281, 'grad_norm': 2.7330594062805176, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.1408, 'grad_norm': 2.568471670150757, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0047, 'grad_norm': 0.2838360667228699, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.80s/it]                                               {'loss': 0.0831, 'grad_norm': 1.805627703666687, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.0365, 'grad_norm': 1.2563762664794922, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it]                                               {'loss': 0.0202, 'grad_norm': 0.653985857963562, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it] 70%|███████   | 28/40 [00:57<00:25,  2.13s/it]                                               {'loss': 0.1497, 'grad_norm': 4.8452982902526855, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.13s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.1193, 'grad_norm': 1.9540261030197144, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.22s/it]                                               {'loss': 0.0291, 'grad_norm': 0.7349388599395752, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.22s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it]                                               {'loss': 0.3345, 'grad_norm': 11.218512535095215, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.0043, 'grad_norm': 0.4472220838069916, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it]                                               {'loss': 0.1076, 'grad_norm': 12.276080131530762, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.84s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.99s/it]                                               {'loss': 0.058, 'grad_norm': 1.8183058500289917, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.99s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it]                                               {'loss': 0.0987, 'grad_norm': 2.504631996154785, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.16s/it]                                               {'loss': 0.0628, 'grad_norm': 1.550369381904602, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.16s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.21s/it]                                               {'loss': 0.0243, 'grad_norm': 0.687316358089447, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.21s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.0498, 'grad_norm': 2.1085681915283203, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.0316, 'grad_norm': 1.4456827640533447, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.64s/it]                                               {'loss': 0.0206, 'grad_norm': 1.4292112588882446, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.64s/it]                                               {'train_runtime': 80.8607, 'train_samples_per_second': 6.987, 'train_steps_per_second': 0.495, 'train_loss': 0.6323808238608762, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.64s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:75
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:26,  2.23s/it]                                              {'loss': 3.0546, 'grad_norm': 10.123136520385742, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:26,  2.23s/it]  5%|▌         | 2/40 [00:04<01:22,  2.17s/it]                                              {'loss': 1.848, 'grad_norm': 10.216477394104004, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.17s/it]  8%|▊         | 3/40 [00:06<01:20,  2.17s/it]                                              {'loss': 1.7039, 'grad_norm': 13.570462226867676, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.17s/it] 10%|█         | 4/40 [00:08<01:18,  2.17s/it]                                              {'loss': 1.7138, 'grad_norm': 11.354680061340332, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.17s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it]                                              {'loss': 1.9786, 'grad_norm': 14.302291870117188, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 2.1728, 'grad_norm': 14.189167022705078, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 1.7375, 'grad_norm': 11.749366760253906, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 5.1084, 'grad_norm': 107.94751739501953, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 0.3402, 'grad_norm': 5.173675060272217, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it]                                               {'loss': 0.1719, 'grad_norm': 4.54096794128418, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.4889, 'grad_norm': 6.659609794616699, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 0.8732, 'grad_norm': 6.12154483795166, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it]                                               {'loss': 1.1746, 'grad_norm': 9.476807594299316, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it]                                               {'loss': 0.6823, 'grad_norm': 7.456298828125, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.16s/it]                                               {'loss': 0.608, 'grad_norm': 7.441178321838379, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0384, 'grad_norm': 1.7468758821487427, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it]                                               {'loss': 0.0657, 'grad_norm': 1.2127563953399658, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it]                                               {'loss': 0.1153, 'grad_norm': 3.2333662509918213, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.02s/it]                                               {'loss': 0.1924, 'grad_norm': 5.745606899261475, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.1269, 'grad_norm': 1.2752803564071655, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it]                                               {'loss': 0.6169, 'grad_norm': 4.608890533447266, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.2666, 'grad_norm': 5.433958530426025, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it]                                               {'loss': 0.1112, 'grad_norm': 2.3466176986694336, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.17s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.0808, 'grad_norm': 4.921204566955566, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.3252, 'grad_norm': 1.090296983718872, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.0286, 'grad_norm': 0.6255648732185364, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it]                                               {'loss': 0.0371, 'grad_norm': 0.767491340637207, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it] 70%|███████   | 28/40 [00:55<00:24,  2.08s/it]                                               {'loss': 0.1679, 'grad_norm': 4.349088191986084, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it]                                               {'loss': 0.1654, 'grad_norm': 3.746321678161621, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.08, 'grad_norm': 2.2109873294830322, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it]                                               {'loss': 0.0819, 'grad_norm': 2.6437344551086426, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.19s/it] 80%|████████  | 32/40 [01:02<00:12,  1.59s/it]                                               {'loss': 0.0606, 'grad_norm': 3.4915432929992676, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.1363, 'grad_norm': 3.917497396469116, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.1821, 'grad_norm': 2.366234540939331, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.0219, 'grad_norm': 0.39267340302467346, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it]                                               {'loss': 0.0327, 'grad_norm': 0.909156322479248, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.13s/it]                                               {'loss': 0.4397, 'grad_norm': 4.752320289611816, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.13s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 0.0688, 'grad_norm': 2.5548110008239746, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.0297, 'grad_norm': 0.7783315181732178, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 0.0064, 'grad_norm': 0.5234199166297913, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 79.0137, 'train_samples_per_second': 7.151, 'train_steps_per_second': 0.506, 'train_loss': 0.6783762580947951, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:28
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:51,  2.85s/it]                                              {'loss': 1.9567, 'grad_norm': 9.466057777404785, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:51,  2.85s/it]  5%|▌         | 2/40 [00:05<01:32,  2.44s/it]                                              {'loss': 1.6621, 'grad_norm': 12.616951942443848, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:32,  2.44s/it]  8%|▊         | 3/40 [00:07<01:25,  2.30s/it]                                              {'loss': 2.2377, 'grad_norm': 12.944988250732422, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.30s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 2.8368, 'grad_norm': 26.086214065551758, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 2.8974, 'grad_norm': 23.746829986572266, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 1.9819, 'grad_norm': 16.130504608154297, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.5557, 'grad_norm': 18.208635330200195, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:16<00:49,  1.55s/it]                                              {'loss': 4.5682, 'grad_norm': 53.44008255004883, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 0.649, 'grad_norm': 7.28812313079834, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 0.7265, 'grad_norm': 10.029975891113281, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:56,  1.96s/it]                                               {'loss': 0.9016, 'grad_norm': 12.031271934509277, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:56,  1.96s/it] 30%|███       | 12/40 [00:24<00:56,  2.04s/it]                                               {'loss': 1.4516, 'grad_norm': 13.703125953674316, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:56,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 0.8107, 'grad_norm': 9.642068862915039, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.12s/it]                                               {'loss': 0.9091, 'grad_norm': 20.835086822509766, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.12s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.5435, 'grad_norm': 46.49300765991211, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.9148, 'grad_norm': 551.951171875, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.4686, 'grad_norm': 8.872055053710938, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it]                                               {'loss': 0.2597, 'grad_norm': 14.510449409484863, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.4277, 'grad_norm': 14.405704498291016, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.7528, 'grad_norm': 4.2421488761901855, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.3573, 'grad_norm': 5.717224597930908, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.15s/it]                                               {'loss': 0.4623, 'grad_norm': 29.467594146728516, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.6537, 'grad_norm': 8.235105514526367, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0151, 'grad_norm': 0.826103925704956, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.1999, 'grad_norm': 21.22524642944336, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.0538, 'grad_norm': 1.244702696800232, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it]                                               {'loss': 0.0993, 'grad_norm': 3.21645188331604, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.1469, 'grad_norm': 4.269533157348633, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.2055, 'grad_norm': 7.454431533813477, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.1927, 'grad_norm': 5.315201282501221, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.165, 'grad_norm': 6.363962173461914, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.1893, 'grad_norm': 17.39876937866211, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.2016, 'grad_norm': 4.501250267028809, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.0463, 'grad_norm': 0.9282388091087341, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.0508, 'grad_norm': 1.4299296140670776, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.1283, 'grad_norm': 4.544796466827393, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.1998, 'grad_norm': 5.089406490325928, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.1544, 'grad_norm': 4.260256290435791, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]                                               {'loss': 0.1694, 'grad_norm': 4.588733673095703, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.1071, 'grad_norm': 6.526412010192871, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.7785, 'train_samples_per_second': 7.082, 'train_steps_per_second': 0.501, 'train_loss': 0.8077654760098085, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:40
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:41,  2.59s/it]                                              {'loss': 3.4563, 'grad_norm': 10.058385848999023, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:41,  2.59s/it]  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]                                              {'loss': 2.7258, 'grad_norm': 11.455486297607422, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]  8%|▊         | 3/40 [00:06<01:24,  2.28s/it]                                              {'loss': 2.1298, 'grad_norm': 18.706212997436523, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:21,  2.25s/it]                                              {'loss': 1.7042, 'grad_norm': 13.82110595703125, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 1.4778, 'grad_norm': 11.416152954101562, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.9154, 'grad_norm': 14.501045227050781, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 2.2072, 'grad_norm': 15.558148384094238, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 4.6315, 'grad_norm': 66.1679458618164, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 1.1671, 'grad_norm': 9.231378555297852, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it]                                               {'loss': 0.7614, 'grad_norm': 7.377359867095947, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.8071, 'grad_norm': 7.656153202056885, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 1.1577, 'grad_norm': 8.480618476867676, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 0.8109, 'grad_norm': 5.245244026184082, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 0.4977, 'grad_norm': 4.2362895011901855, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 0.4501, 'grad_norm': 6.214352607727051, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.1149, 'grad_norm': 5.697102069854736, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.3958, 'grad_norm': 3.814520835876465, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.4199, 'grad_norm': 4.834042549133301, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.1347, 'grad_norm': 2.666822910308838, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.3784, 'grad_norm': 4.044328212738037, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.2091, 'grad_norm': 4.232975006103516, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.5272, 'grad_norm': 5.7298455238342285, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.5264, 'grad_norm': 3.7928824424743652, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.1624, 'grad_norm': 10.927648544311523, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.82s/it]                                               {'loss': 0.134, 'grad_norm': 3.213344097137451, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.148, 'grad_norm': 2.425307512283325, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.1478, 'grad_norm': 1.023476004600525, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.0458, 'grad_norm': 1.0471014976501465, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it]                                               {'loss': 0.6121, 'grad_norm': 4.58920955657959, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it]                                               {'loss': 0.0408, 'grad_norm': 1.3890825510025024, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.2826, 'grad_norm': 1.842123031616211, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.1436, 'grad_norm': 11.961645126342773, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it]                                               {'loss': 0.0233, 'grad_norm': 0.5988882780075073, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it]                                               {'loss': 0.0155, 'grad_norm': 0.20702169835567474, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.3582, 'grad_norm': 1.9934309720993042, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.067, 'grad_norm': 1.8390206098556519, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.0344, 'grad_norm': 1.313048243522644, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.1515, 'grad_norm': 1.892024040222168, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.0307, 'grad_norm': 1.1024320125579834, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.0001, 'grad_norm': 0.0031288808677345514, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 80.2388, 'train_samples_per_second': 7.041, 'train_steps_per_second': 0.499, 'train_loss': 0.8001026219102642, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  do_eval=True, seed=self.args.random_seed)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:59,  1.56it/s]  1%|          | 3/471 [00:02<07:03,  1.11it/s]  1%|          | 4/471 [00:03<08:09,  1.05s/it]  1%|          | 5/471 [00:05<08:47,  1.13s/it]  1%|▏         | 6/471 [00:06<09:10,  1.18s/it]  1%|▏         | 7/471 [00:07<09:25,  1.22s/it]  2%|▏         | 8/471 [00:09<09:35,  1.24s/it]  2%|▏         | 9/471 [00:10<09:41,  1.26s/it]  2%|▏         | 10/471 [00:11<09:44,  1.27s/it]  2%|▏         | 11/471 [00:12<09:46,  1.28s/it]  3%|▎         | 12/471 [00:14<09:48,  1.28s/it]  3%|▎         | 13/471 [00:15<09:49,  1.29s/it]  3%|▎         | 14/471 [00:16<09:49,  1.29s/it]  3%|▎         | 15/471 [00:18<09:49,  1.29s/it]  3%|▎         | 16/471 [00:19<09:50,  1.30s/it]  4%|▎         | 17/471 [00:20<09:48,  1.30s/it]  4%|▍         | 18/471 [00:21<09:48,  1.30s/it]  4%|▍         | 19/471 [00:23<09:47,  1.30s/it]  4%|▍         | 20/471 [00:24<09:47,  1.30s/it]  4%|▍         | 21/471 [00:25<09:46,  1.30s/it]  5%|▍         | 22/471 [00:27<09:45,  1.30s/it]  5%|▍         | 23/471 [00:28<09:44,  1.31s/it]  5%|▌         | 24/471 [00:29<09:44,  1.31s/it]  5%|▌         | 25/471 [00:31<09:43,  1.31s/it]  6%|▌         | 26/471 [00:32<09:43,  1.31s/it]  6%|▌         | 27/471 [00:33<09:42,  1.31s/it]  6%|▌         | 28/471 [00:35<09:41,  1.31s/it]  6%|▌         | 29/471 [00:36<09:40,  1.31s/it]  6%|▋         | 30/471 [00:37<09:40,  1.32s/it]  7%|▋         | 31/471 [00:39<09:38,  1.31s/it]  7%|▋         | 32/471 [00:40<09:36,  1.31s/it]  7%|▋         | 33/471 [00:41<09:34,  1.31s/it]  7%|▋         | 34/471 [00:42<09:33,  1.31s/it]  7%|▋         | 35/471 [00:44<09:33,  1.32s/it]  8%|▊         | 36/471 [00:45<09:32,  1.32s/it]  8%|▊         | 37/471 [00:46<09:32,  1.32s/it]  8%|▊         | 38/471 [00:48<09:31,  1.32s/it]  8%|▊         | 39/471 [00:49<09:30,  1.32s/it]  8%|▊         | 40/471 [00:50<09:28,  1.32s/it]  9%|▊         | 41/471 [00:52<09:27,  1.32s/it]  9%|▉         | 42/471 [00:53<09:26,  1.32s/it]  9%|▉         | 43/471 [00:54<09:25,  1.32s/it]  9%|▉         | 44/471 [00:56<09:23,  1.32s/it] 10%|▉         | 45/471 [00:57<09:23,  1.32s/it] 10%|▉         | 46/471 [00:58<09:21,  1.32s/it] 10%|▉         | 47/471 [01:00<09:20,  1.32s/it] 10%|█         | 48/471 [01:01<09:19,  1.32s/it] 10%|█         | 49/471 [01:02<09:18,  1.32s/it] 11%|█         | 50/471 [01:04<09:17,  1.33s/it] 11%|█         | 51/471 [01:05<09:16,  1.33s/it] 11%|█         | 52/471 [01:06<09:15,  1.33s/it] 11%|█▏        | 53/471 [01:08<09:15,  1.33s/it] 11%|█▏        | 54/471 [01:09<09:14,  1.33s/it] 12%|█▏        | 55/471 [01:10<09:13,  1.33s/it] 12%|█▏        | 56/471 [01:12<09:12,  1.33s/it] 12%|█▏        | 57/471 [01:13<09:11,  1.33s/it] 12%|█▏        | 58/471 [01:14<09:10,  1.33s/it] 13%|█▎        | 59/471 [01:16<09:08,  1.33s/it] 13%|█▎        | 60/471 [01:17<09:07,  1.33s/it] 13%|█▎        | 61/471 [01:18<09:06,  1.33s/it] 13%|█▎        | 62/471 [01:20<09:04,  1.33s/it] 13%|█▎        | 63/471 [01:21<09:03,  1.33s/it] 14%|█▎        | 64/471 [01:22<09:02,  1.33s/it] 14%|█▍        | 65/471 [01:24<09:00,  1.33s/it] 14%|█▍        | 66/471 [01:25<08:59,  1.33s/it] 14%|█▍        | 67/471 [01:26<08:58,  1.33s/it] 14%|█▍        | 68/471 [01:28<08:56,  1.33s/it] 15%|█▍        | 69/471 [01:29<08:54,  1.33s/it] 15%|█▍        | 70/471 [01:30<08:54,  1.33s/it] 15%|█▌        | 71/471 [01:32<08:53,  1.33s/it] 15%|█▌        | 72/471 [01:33<08:51,  1.33s/it] 15%|█▌        | 73/471 [01:34<08:50,  1.33s/it] 16%|█▌        | 74/471 [01:36<08:48,  1.33s/it] 16%|█▌        | 75/471 [01:37<08:48,  1.33s/it] 16%|█▌        | 76/471 [01:38<08:46,  1.33s/it] 16%|█▋        | 77/471 [01:40<08:46,  1.34s/it] 17%|█▋        | 78/471 [01:41<08:44,  1.33s/it] 17%|█▋        | 79/471 [01:42<08:43,  1.34s/it] 17%|█▋        | 80/471 [01:44<08:42,  1.34s/it] 17%|█▋        | 81/471 [01:45<08:41,  1.34s/it] 17%|█▋        | 82/471 [01:46<08:39,  1.34s/it] 18%|█▊        | 83/471 [01:48<08:38,  1.34s/it] 18%|█▊        | 84/471 [01:49<08:36,  1.34s/it] 18%|█▊        | 85/471 [01:50<08:35,  1.34s/it] 18%|█▊        | 86/471 [01:52<08:34,  1.34s/it] 18%|█▊        | 87/471 [01:53<08:32,  1.34s/it] 19%|█▊        | 88/471 [01:54<08:30,  1.33s/it] 19%|█▉        | 89/471 [01:56<08:28,  1.33s/it] 19%|█▉        | 90/471 [01:57<08:28,  1.33s/it] 19%|█▉        | 91/471 [01:58<08:26,  1.33s/it] 20%|█▉        | 92/471 [02:00<08:24,  1.33s/it] 20%|█▉        | 93/471 [02:01<08:23,  1.33s/it] 20%|█▉        | 94/471 [02:02<08:22,  1.33s/it] 20%|██        | 95/471 [02:04<08:20,  1.33s/it] 20%|██        | 96/471 [02:05<08:19,  1.33s/it] 21%|██        | 97/471 [02:06<08:18,  1.33s/it] 21%|██        | 98/471 [02:08<08:16,  1.33s/it] 21%|██        | 99/471 [02:09<08:15,  1.33s/it] 21%|██        | 100/471 [02:10<08:13,  1.33s/it] 21%|██▏       | 101/471 [02:12<08:12,  1.33s/it] 22%|██▏       | 102/471 [02:13<08:11,  1.33s/it] 22%|██▏       | 103/471 [02:14<08:10,  1.33s/it] 22%|██▏       | 104/471 [02:16<08:10,  1.34s/it] 22%|██▏       | 105/471 [02:17<08:08,  1.34s/it] 23%|██▎       | 106/471 [02:18<08:06,  1.33s/it] 23%|██▎       | 107/471 [02:20<08:04,  1.33s/it] 23%|██▎       | 108/471 [02:21<08:03,  1.33s/it] 23%|██▎       | 109/471 [02:22<08:01,  1.33s/it] 23%|██▎       | 110/471 [02:24<07:59,  1.33s/it] 24%|██▎       | 111/471 [02:25<07:59,  1.33s/it] 24%|██▍       | 112/471 [02:26<07:58,  1.33s/it] 24%|██▍       | 113/471 [02:28<07:56,  1.33s/it] 24%|██▍       | 114/471 [02:29<07:56,  1.33s/it] 24%|██▍       | 115/471 [02:30<07:54,  1.33s/it] 25%|██▍       | 116/471 [02:32<07:53,  1.33s/it] 25%|██▍       | 117/471 [02:33<07:51,  1.33s/it] 25%|██▌       | 118/471 [02:34<07:50,  1.33s/it] 25%|██▌       | 119/471 [02:36<07:48,  1.33s/it] 25%|██▌       | 120/471 [02:37<07:47,  1.33s/it] 26%|██▌       | 121/471 [02:38<07:46,  1.33s/it] 26%|██▌       | 122/471 [02:40<07:44,  1.33s/it] 26%|██▌       | 123/471 [02:41<07:43,  1.33s/it] 26%|██▋       | 124/471 [02:42<07:42,  1.33s/it] 27%|██▋       | 125/471 [02:44<07:41,  1.33s/it] 27%|██▋       | 126/471 [02:45<07:40,  1.33s/it] 27%|██▋       | 127/471 [02:46<07:38,  1.33s/it] 27%|██▋       | 128/471 [02:48<07:36,  1.33s/it] 27%|██▋       | 129/471 [02:49<07:35,  1.33s/it] 28%|██▊       | 130/471 [02:50<07:33,  1.33s/it] 28%|██▊       | 131/471 [02:52<07:32,  1.33s/it] 28%|██▊       | 132/471 [02:53<07:31,  1.33s/it] 28%|██▊       | 133/471 [02:54<07:30,  1.33s/it] 28%|██▊       | 134/471 [02:56<07:29,  1.33s/it] 29%|██▊       | 135/471 [02:57<07:27,  1.33s/it] 29%|██▉       | 136/471 [02:58<07:25,  1.33s/it] 29%|██▉       | 137/471 [03:00<07:24,  1.33s/it] 29%|██▉       | 138/471 [03:01<07:23,  1.33s/it] 30%|██▉       | 139/471 [03:02<07:21,  1.33s/it] 30%|██▉       | 140/471 [03:04<07:20,  1.33s/it] 30%|██▉       | 141/471 [03:05<07:18,  1.33s/it] 30%|███       | 142/471 [03:06<07:17,  1.33s/it] 30%|███       | 143/471 [03:08<07:15,  1.33s/it] 31%|███       | 144/471 [03:09<07:15,  1.33s/it] 31%|███       | 145/471 [03:10<07:13,  1.33s/it] 31%|███       | 146/471 [03:12<07:12,  1.33s/it] 31%|███       | 147/471 [03:13<07:11,  1.33s/it] 31%|███▏      | 148/471 [03:14<07:10,  1.33s/it] 32%|███▏      | 149/471 [03:16<07:09,  1.33s/it] 32%|███▏      | 150/471 [03:17<07:08,  1.33s/it] 32%|███▏      | 151/471 [03:18<07:06,  1.33s/it] 32%|███▏      | 152/471 [03:20<07:05,  1.33s/it] 32%|███▏      | 153/471 [03:21<07:04,  1.33s/it] 33%|███▎      | 154/471 [03:22<07:02,  1.33s/it] 33%|███▎      | 155/471 [03:24<07:00,  1.33s/it] 33%|███▎      | 156/471 [03:25<06:59,  1.33s/it] 33%|███▎      | 157/471 [03:26<06:57,  1.33s/it] 34%|███▎      | 158/471 [03:27<06:55,  1.33s/it] 34%|███▍      | 159/471 [03:29<06:54,  1.33s/it] 34%|███▍      | 160/471 [03:30<06:53,  1.33s/it] 34%|███▍      | 161/471 [03:31<06:51,  1.33s/it] 34%|███▍      | 162/471 [03:33<06:51,  1.33s/it] 35%|███▍      | 163/471 [03:34<06:49,  1.33s/it] 35%|███▍      | 164/471 [03:35<06:47,  1.33s/it] 35%|███▌      | 165/471 [03:37<06:46,  1.33s/it] 35%|███▌      | 166/471 [03:38<06:45,  1.33s/it] 35%|███▌      | 167/471 [03:39<06:44,  1.33s/it] 36%|███▌      | 168/471 [03:41<06:42,  1.33s/it] 36%|███▌      | 169/471 [03:42<06:41,  1.33s/it] 36%|███▌      | 170/471 [03:43<06:40,  1.33s/it] 36%|███▋      | 171/471 [03:45<06:38,  1.33s/it] 37%|███▋      | 172/471 [03:46<06:37,  1.33s/it] 37%|███▋      | 173/471 [03:47<06:36,  1.33s/it] 37%|███▋      | 174/471 [03:49<06:35,  1.33s/it] 37%|███▋      | 175/471 [03:50<06:34,  1.33s/it] 37%|███▋      | 176/471 [03:51<06:32,  1.33s/it] 38%|███▊      | 177/471 [03:53<06:31,  1.33s/it] 38%|███▊      | 178/471 [03:54<06:29,  1.33s/it] 38%|███▊      | 179/471 [03:55<06:27,  1.33s/it] 38%|███▊      | 180/471 [03:57<06:26,  1.33s/it] 38%|███▊      | 181/471 [03:58<06:25,  1.33s/it] 39%|███▊      | 182/471 [03:59<06:24,  1.33s/it] 39%|███▉      | 183/471 [04:01<06:23,  1.33s/it] 39%|███▉      | 184/471 [04:02<06:21,  1.33s/it] 39%|███▉      | 185/471 [04:03<06:20,  1.33s/it] 39%|███▉      | 186/471 [04:05<06:19,  1.33s/it] 40%|███▉      | 187/471 [04:06<06:19,  1.33s/it] 40%|███▉      | 188/471 [04:07<06:17,  1.34s/it] 40%|████      | 189/471 [04:09<06:16,  1.33s/it] 40%|████      | 190/471 [04:10<06:14,  1.33s/it] 41%|████      | 191/471 [04:11<06:14,  1.34s/it] 41%|████      | 192/471 [04:13<06:12,  1.34s/it] 41%|████      | 193/471 [04:14<06:10,  1.33s/it] 41%|████      | 194/471 [04:15<06:09,  1.33s/it] 41%|████▏     | 195/471 [04:17<06:08,  1.34s/it] 42%|████▏     | 196/471 [04:18<06:07,  1.34s/it] 42%|████▏     | 197/471 [04:19<06:05,  1.34s/it] 42%|████▏     | 198/471 [04:21<06:04,  1.34s/it] 42%|████▏     | 199/471 [04:22<06:03,  1.34s/it] 42%|████▏     | 200/471 [04:23<06:03,  1.34s/it] 43%|████▎     | 201/471 [04:25<06:00,  1.34s/it] 43%|████▎     | 202/471 [04:26<06:00,  1.34s/it] 43%|████▎     | 203/471 [04:27<05:59,  1.34s/it] 43%|████▎     | 204/471 [04:29<05:58,  1.34s/it] 44%|████▎     | 205/471 [04:30<05:56,  1.34s/it] 44%|████▎     | 206/471 [04:31<05:55,  1.34s/it] 44%|████▍     | 207/471 [04:33<05:53,  1.34s/it] 44%|████▍     | 208/471 [04:34<05:52,  1.34s/it] 44%|████▍     | 209/471 [04:36<05:50,  1.34s/it] 45%|████▍     | 210/471 [04:37<05:50,  1.34s/it] 45%|████▍     | 211/471 [04:38<05:48,  1.34s/it] 45%|████▌     | 212/471 [04:40<05:47,  1.34s/it] 45%|████▌     | 213/471 [04:41<05:46,  1.34s/it] 45%|████▌     | 214/471 [04:42<05:45,  1.34s/it] 46%|████▌     | 215/471 [04:44<05:43,  1.34s/it] 46%|████▌     | 216/471 [04:45<05:43,  1.35s/it] 46%|████▌     | 217/471 [04:46<05:42,  1.35s/it] 46%|████▋     | 218/471 [04:48<05:41,  1.35s/it] 46%|████▋     | 219/471 [04:49<05:39,  1.35s/it] 47%|████▋     | 220/471 [04:50<05:38,  1.35s/it] 47%|████▋     | 221/471 [04:52<05:37,  1.35s/it] 47%|████▋     | 222/471 [04:53<05:36,  1.35s/it] 47%|████▋     | 223/471 [04:54<05:34,  1.35s/it] 48%|████▊     | 224/471 [04:56<05:33,  1.35s/it] 48%|████▊     | 225/471 [04:57<05:32,  1.35s/it] 48%|████▊     | 226/471 [04:58<05:31,  1.35s/it] 48%|████▊     | 227/471 [05:00<05:29,  1.35s/it] 48%|████▊     | 228/471 [05:01<05:28,  1.35s/it] 49%|████▊     | 229/471 [05:03<05:27,  1.35s/it] 49%|████▉     | 230/471 [05:04<05:26,  1.35s/it] 49%|████▉     | 231/471 [05:05<05:24,  1.35s/it] 49%|████▉     | 232/471 [05:07<05:22,  1.35s/it] 49%|████▉     | 233/471 [05:08<05:21,  1.35s/it] 50%|████▉     | 234/471 [05:09<05:20,  1.35s/it] 50%|████▉     | 235/471 [05:11<05:19,  1.35s/it] 50%|█████     | 236/471 [05:12<05:17,  1.35s/it] 50%|█████     | 237/471 [05:13<05:16,  1.35s/it] 51%|█████     | 238/471 [05:15<05:15,  1.35s/it] 51%|█████     | 239/471 [05:16<05:14,  1.35s/it] 51%|█████     | 240/471 [05:17<05:13,  1.36s/it] 51%|█████     | 241/471 [05:19<05:11,  1.36s/it] 51%|█████▏    | 242/471 [05:20<05:10,  1.36s/it] 52%|█████▏    | 243/471 [05:21<05:08,  1.35s/it] 52%|█████▏    | 244/471 [05:23<05:07,  1.35s/it] 52%|█████▏    | 245/471 [05:24<05:06,  1.35s/it] 52%|█████▏    | 246/471 [05:26<05:04,  1.35s/it] 52%|█████▏    | 247/471 [05:27<05:02,  1.35s/it] 53%|█████▎    | 248/471 [05:28<05:01,  1.35s/it] 53%|█████▎    | 249/471 [05:30<04:59,  1.35s/it] 53%|█████▎    | 250/471 [05:31<04:58,  1.35s/it] 53%|█████▎    | 251/471 [05:32<04:56,  1.35s/it] 54%|█████▎    | 252/471 [05:34<04:55,  1.35s/it] 54%|█████▎    | 253/471 [05:35<04:54,  1.35s/it] 54%|█████▍    | 254/471 [05:36<04:53,  1.35s/it] 54%|█████▍    | 255/471 [05:38<04:51,  1.35s/it] 54%|█████▍    | 256/471 [05:39<04:50,  1.35s/it] 55%|█████▍    | 257/471 [05:40<04:49,  1.35s/it] 55%|█████▍    | 258/471 [05:42<04:47,  1.35s/it] 55%|█████▍    | 259/471 [05:43<04:46,  1.35s/it] 55%|█████▌    | 260/471 [05:44<04:45,  1.35s/it] 55%|█████▌    | 261/471 [05:46<04:43,  1.35s/it] 56%|█████▌    | 262/471 [05:47<04:41,  1.35s/it] 56%|█████▌    | 263/471 [05:48<04:40,  1.35s/it] 56%|█████▌    | 264/471 [05:50<04:38,  1.35s/it] 56%|█████▋    | 265/471 [05:51<04:37,  1.35s/it] 56%|█████▋    | 266/471 [05:53<04:36,  1.35s/it] 57%|█████▋    | 267/471 [05:54<04:34,  1.35s/it] 57%|█████▋    | 268/471 [05:55<04:33,  1.35s/it] 57%|█████▋    | 269/471 [05:57<04:32,  1.35s/it] 57%|█████▋    | 270/471 [05:58<04:30,  1.35s/it] 58%|█████▊    | 271/471 [05:59<04:29,  1.35s/it] 58%|█████▊    | 272/471 [06:01<04:27,  1.34s/it] 58%|█████▊    | 273/471 [06:02<04:26,  1.35s/it] 58%|█████▊    | 274/471 [06:03<04:24,  1.34s/it] 58%|█████▊    | 275/471 [06:05<04:23,  1.34s/it] 59%|█████▊    | 276/471 [06:06<04:21,  1.34s/it] 59%|█████▉    | 277/471 [06:07<04:20,  1.34s/it] 59%|█████▉    | 278/471 [06:09<04:19,  1.35s/it] 59%|█████▉    | 279/471 [06:10<04:17,  1.34s/it] 59%|█████▉    | 280/471 [06:11<04:16,  1.34s/it] 60%|█████▉    | 281/471 [06:13<04:15,  1.34s/it] 60%|█████▉    | 282/471 [06:14<04:13,  1.34s/it] 60%|██████    | 283/471 [06:15<04:12,  1.34s/it] 60%|██████    | 284/471 [06:17<04:11,  1.34s/it] 61%|██████    | 285/471 [06:18<04:09,  1.34s/it] 61%|██████    | 286/471 [06:19<04:08,  1.34s/it] 61%|██████    | 287/471 [06:21<04:07,  1.34s/it] 61%|██████    | 288/471 [06:22<04:06,  1.35s/it] 61%|██████▏   | 289/471 [06:23<04:04,  1.34s/it] 62%|██████▏   | 290/471 [06:25<04:03,  1.34s/it] 62%|██████▏   | 291/471 [06:26<04:01,  1.34s/it] 62%|██████▏   | 292/471 [06:27<04:00,  1.34s/it] 62%|██████▏   | 293/471 [06:29<03:58,  1.34s/it] 62%|██████▏   | 294/471 [06:30<03:57,  1.34s/it] 63%|██████▎   | 295/471 [06:31<03:55,  1.34s/it] 63%|██████▎   | 296/471 [06:33<03:54,  1.34s/it] 63%|██████▎   | 297/471 [06:34<03:53,  1.34s/it] 63%|██████▎   | 298/471 [06:35<03:52,  1.34s/it] 63%|██████▎   | 299/471 [06:37<03:50,  1.34s/it] 64%|██████▎   | 300/471 [06:38<03:49,  1.34s/it] 64%|██████▍   | 301/471 [06:40<03:48,  1.34s/it] 64%|██████▍   | 302/471 [06:41<03:46,  1.34s/it] 64%|██████▍   | 303/471 [06:42<03:44,  1.34s/it] 65%|██████▍   | 304/471 [06:44<03:43,  1.34s/it] 65%|██████▍   | 305/471 [06:45<03:41,  1.34s/it] 65%|██████▍   | 306/471 [06:46<03:40,  1.34s/it] 65%|██████▌   | 307/471 [06:48<03:39,  1.34s/it] 65%|██████▌   | 308/471 [06:49<03:38,  1.34s/it] 66%|██████▌   | 309/471 [06:50<03:36,  1.34s/it] 66%|██████▌   | 310/471 [06:52<03:35,  1.34s/it] 66%|██████▌   | 311/471 [06:53<03:33,  1.34s/it] 66%|██████▌   | 312/471 [06:54<03:32,  1.34s/it] 66%|██████▋   | 313/471 [06:56<03:31,  1.34s/it] 67%|██████▋   | 314/471 [06:57<03:29,  1.33s/it] 67%|██████▋   | 315/471 [06:58<03:28,  1.33s/it] 67%|██████▋   | 316/471 [07:00<03:26,  1.33s/it] 67%|██████▋   | 317/471 [07:01<03:25,  1.33s/it] 68%|██████▊   | 318/471 [07:02<03:24,  1.33s/it] 68%|██████▊   | 319/471 [07:04<03:22,  1.33s/it] 68%|██████▊   | 320/471 [07:05<03:21,  1.33s/it] 68%|██████▊   | 321/471 [07:06<03:20,  1.33s/it] 68%|██████▊   | 322/471 [07:08<03:18,  1.33s/it] 69%|██████▊   | 323/471 [07:09<03:17,  1.34s/it] 69%|██████▉   | 324/471 [07:10<03:16,  1.34s/it] 69%|██████▉   | 325/471 [07:12<03:14,  1.34s/it] 69%|██████▉   | 326/471 [07:13<03:13,  1.33s/it] 69%|██████▉   | 327/471 [07:14<03:11,  1.33s/it] 70%|██████▉   | 328/471 [07:16<03:10,  1.33s/it] 70%|██████▉   | 329/471 [07:17<03:09,  1.33s/it] 70%|███████   | 330/471 [07:18<03:07,  1.33s/it] 70%|███████   | 331/471 [07:20<03:06,  1.33s/it] 70%|███████   | 332/471 [07:21<03:05,  1.33s/it] 71%|███████   | 333/471 [07:22<03:03,  1.33s/it] 71%|███████   | 334/471 [07:24<03:02,  1.33s/it] 71%|███████   | 335/471 [07:25<03:01,  1.33s/it] 71%|███████▏  | 336/471 [07:26<02:59,  1.33s/it] 72%|███████▏  | 337/471 [07:28<02:58,  1.33s/it] 72%|███████▏  | 338/471 [07:29<02:56,  1.33s/it] 72%|███████▏  | 339/471 [07:30<02:55,  1.33s/it] 72%|███████▏  | 340/471 [07:32<02:54,  1.33s/it] 72%|███████▏  | 341/471 [07:33<02:52,  1.33s/it] 73%|███████▎  | 342/471 [07:34<02:51,  1.33s/it] 73%|███████▎  | 343/471 [07:36<02:50,  1.33s/it] 73%|███████▎  | 344/471 [07:37<02:48,  1.33s/it] 73%|███████▎  | 345/471 [07:38<02:47,  1.33s/it] 73%|███████▎  | 346/471 [07:39<02:46,  1.33s/it] 74%|███████▎  | 347/471 [07:41<02:44,  1.33s/it] 74%|███████▍  | 348/471 [07:42<02:43,  1.33s/it] 74%|███████▍  | 349/471 [07:43<02:41,  1.33s/it] 74%|███████▍  | 350/471 [07:45<02:40,  1.33s/it] 75%|███████▍  | 351/471 [07:46<02:38,  1.32s/it] 75%|███████▍  | 352/471 [07:47<02:37,  1.33s/it] 75%|███████▍  | 353/471 [07:49<02:36,  1.33s/it] 75%|███████▌  | 354/471 [07:50<02:35,  1.33s/it] 75%|███████▌  | 355/471 [07:51<02:34,  1.33s/it] 76%|███████▌  | 356/471 [07:53<02:32,  1.33s/it] 76%|███████▌  | 357/471 [07:54<02:31,  1.33s/it] 76%|███████▌  | 358/471 [07:55<02:29,  1.33s/it] 76%|███████▌  | 359/471 [07:57<02:28,  1.33s/it] 76%|███████▋  | 360/471 [07:58<02:27,  1.32s/it] 77%|███████▋  | 361/471 [07:59<02:25,  1.32s/it] 77%|███████▋  | 362/471 [08:01<02:24,  1.33s/it] 77%|███████▋  | 363/471 [08:02<02:22,  1.32s/it] 77%|███████▋  | 364/471 [08:03<02:21,  1.32s/it] 77%|███████▋  | 365/471 [08:05<02:20,  1.33s/it] 78%|███████▊  | 366/471 [08:06<02:19,  1.33s/it] 78%|███████▊  | 367/471 [08:07<02:17,  1.33s/it] 78%|███████▊  | 368/471 [08:09<02:16,  1.32s/it] 78%|███████▊  | 369/471 [08:10<02:14,  1.32s/it] 79%|███████▊  | 370/471 [08:11<02:13,  1.32s/it] 79%|███████▉  | 371/471 [08:13<02:12,  1.33s/it] 79%|███████▉  | 372/471 [08:14<02:11,  1.33s/it] 79%|███████▉  | 373/471 [08:15<02:09,  1.33s/it] 79%|███████▉  | 374/471 [08:17<02:08,  1.32s/it] 80%|███████▉  | 375/471 [08:18<02:07,  1.32s/it] 80%|███████▉  | 376/471 [08:19<02:05,  1.32s/it] 80%|████████  | 377/471 [08:21<02:04,  1.32s/it] 80%|████████  | 378/471 [08:22<02:02,  1.32s/it] 80%|████████  | 379/471 [08:23<02:01,  1.32s/it] 81%|████████  | 380/471 [08:25<02:00,  1.33s/it] 81%|████████  | 381/471 [08:26<01:59,  1.32s/it] 81%|████████  | 382/471 [08:27<01:57,  1.33s/it] 81%|████████▏ | 383/471 [08:29<01:56,  1.33s/it] 82%|████████▏ | 384/471 [08:30<01:55,  1.33s/it] 82%|████████▏ | 385/471 [08:31<01:54,  1.33s/it] 82%|████████▏ | 386/471 [08:32<01:52,  1.33s/it] 82%|████████▏ | 387/471 [08:34<01:51,  1.33s/it] 82%|████████▏ | 388/471 [08:35<01:50,  1.33s/it] 83%|████████▎ | 389/471 [08:36<01:48,  1.32s/it] 83%|████████▎ | 390/471 [08:38<01:47,  1.33s/it] 83%|████████▎ | 391/471 [08:39<01:46,  1.33s/it] 83%|████████▎ | 392/471 [08:40<01:44,  1.33s/it] 83%|████████▎ | 393/471 [08:42<01:43,  1.33s/it] 84%|████████▎ | 394/471 [08:43<01:42,  1.33s/it] 84%|████████▍ | 395/471 [08:44<01:40,  1.33s/it] 84%|████████▍ | 396/471 [08:46<01:39,  1.33s/it] 84%|████████▍ | 397/471 [08:47<01:38,  1.33s/it] 85%|████████▍ | 398/471 [08:48<01:36,  1.33s/it] 85%|████████▍ | 399/471 [08:50<01:35,  1.33s/it] 85%|████████▍ | 400/471 [08:51<01:34,  1.33s/it] 85%|████████▌ | 401/471 [08:52<01:32,  1.33s/it] 85%|████████▌ | 402/471 [08:54<01:31,  1.33s/it] 86%|████████▌ | 403/471 [08:55<01:30,  1.32s/it] 86%|████████▌ | 404/471 [08:56<01:28,  1.32s/it] 86%|████████▌ | 405/471 [08:58<01:27,  1.33s/it] 86%|████████▌ | 406/471 [08:59<01:26,  1.33s/it] 86%|████████▋ | 407/471 [09:00<01:24,  1.33s/it] 87%|████████▋ | 408/471 [09:02<01:23,  1.33s/it] 87%|████████▋ | 409/471 [09:03<01:22,  1.33s/it] 87%|████████▋ | 410/471 [09:04<01:20,  1.33s/it] 87%|████████▋ | 411/471 [09:06<01:19,  1.32s/it] 87%|████████▋ | 412/471 [09:07<01:18,  1.33s/it] 88%|████████▊ | 413/471 [09:08<01:17,  1.33s/it] 88%|████████▊ | 414/471 [09:10<01:15,  1.33s/it] 88%|████████▊ | 415/471 [09:11<01:14,  1.33s/it] 88%|████████▊ | 416/471 [09:12<01:13,  1.33s/it] 89%|████████▊ | 417/471 [09:14<01:11,  1.33s/it] 89%|████████▊ | 418/471 [09:15<01:10,  1.33s/it] 89%|████████▉ | 419/471 [09:16<01:09,  1.33s/it] 89%|████████▉ | 420/471 [09:18<01:07,  1.33s/it] 89%|████████▉ | 421/471 [09:19<01:06,  1.33s/it] 90%|████████▉ | 422/471 [09:20<01:05,  1.33s/it] 90%|████████▉ | 423/471 [09:22<01:03,  1.33s/it] 90%|█████████ | 424/471 [09:23<01:02,  1.33s/it] 90%|█████████ | 425/471 [09:24<01:01,  1.33s/it] 90%|█████████ | 426/471 [09:26<01:00,  1.33s/it] 91%|█████████ | 427/471 [09:27<00:58,  1.34s/it] 91%|█████████ | 428/471 [09:28<00:57,  1.34s/it] 91%|█████████ | 429/471 [09:30<00:56,  1.33s/it] 91%|█████████▏| 430/471 [09:31<00:54,  1.34s/it] 92%|█████████▏| 431/471 [09:32<00:53,  1.34s/it] 92%|█████████▏| 432/471 [09:34<00:52,  1.34s/it] 92%|█████████▏| 433/471 [09:35<00:50,  1.34s/it] 92%|█████████▏| 434/471 [09:36<00:49,  1.34s/it] 92%|█████████▏| 435/471 [09:38<00:48,  1.34s/it] 93%|█████████▎| 436/471 [09:39<00:46,  1.34s/it] 93%|█████████▎| 437/471 [09:40<00:45,  1.34s/it] 93%|█████████▎| 438/471 [09:42<00:44,  1.34s/it] 93%|█████████▎| 439/471 [09:43<00:42,  1.34s/it] 93%|█████████▎| 440/471 [09:44<00:41,  1.34s/it] 94%|█████████▎| 441/471 [09:46<00:40,  1.34s/it] 94%|█████████▍| 442/471 [09:47<00:38,  1.34s/it] 94%|█████████▍| 443/471 [09:48<00:37,  1.34s/it] 94%|█████████▍| 444/471 [09:50<00:36,  1.34s/it] 94%|█████████▍| 445/471 [09:51<00:34,  1.34s/it] 95%|█████████▍| 446/471 [09:52<00:33,  1.34s/it] 95%|█████████▍| 447/471 [09:54<00:32,  1.34s/it] 95%|█████████▌| 448/471 [09:55<00:30,  1.34s/it] 95%|█████████▌| 449/471 [09:56<00:29,  1.34s/it] 96%|█████████▌| 450/471 [09:58<00:28,  1.34s/it] 96%|█████████▌| 451/471 [09:59<00:26,  1.34s/it] 96%|█████████▌| 452/471 [10:01<00:25,  1.34s/it] 96%|█████████▌| 453/471 [10:02<00:24,  1.35s/it] 96%|█████████▋| 454/471 [10:03<00:22,  1.35s/it] 97%|█████████▋| 455/471 [10:05<00:21,  1.35s/it] 97%|█████████▋| 456/471 [10:06<00:20,  1.35s/it] 97%|█████████▋| 457/471 [10:07<00:18,  1.35s/it] 97%|█████████▋| 458/471 [10:09<00:17,  1.35s/it] 97%|█████████▋| 459/471 [10:10<00:16,  1.35s/it] 98%|█████████▊| 460/471 [10:11<00:14,  1.35s/it] 98%|█████████▊| 461/471 [10:13<00:13,  1.35s/it] 98%|█████████▊| 462/471 [10:14<00:12,  1.35s/it] 98%|█████████▊| 463/471 [10:15<00:10,  1.35s/it] 99%|█████████▊| 464/471 [10:17<00:09,  1.35s/it] 99%|█████████▊| 465/471 [10:18<00:08,  1.34s/it] 99%|█████████▉| 466/471 [10:19<00:06,  1.35s/it] 99%|█████████▉| 467/471 [10:21<00:05,  1.35s/it] 99%|█████████▉| 468/471 [10:22<00:04,  1.35s/it]100%|█████████▉| 469/471 [10:23<00:02,  1.35s/it]100%|█████████▉| 470/471 [10:25<00:01,  1.35s/it]100%|██████████| 471/471 [10:26<00:00,  1.24s/it]100%|██████████| 471/471 [10:26<00:00,  1.33s/it]
{'eval_loss': 2.6616921424865723, 'eval_model_preparation_time': 0.0116, 'eval_acc': 0.31970260223048325, 'eval_runtime': 627.5129, 'eval_samples_per_second': 12.003, 'eval_steps_per_second': 0.751}
ROUND:15
CLIENT:2
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:34,  2.43s/it]                                              {'loss': 2.53, 'grad_norm': 8.780464172363281, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:34,  2.43s/it]  5%|▌         | 2/40 [00:04<01:27,  2.31s/it]                                              {'loss': 2.5921, 'grad_norm': 13.371391296386719, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:27,  2.31s/it]  8%|▊         | 3/40 [00:06<01:24,  2.27s/it]                                              {'loss': 1.3353, 'grad_norm': 14.707076072692871, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.27s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 1.9106, 'grad_norm': 12.45729923248291, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it]                                              {'loss': 1.8405, 'grad_norm': 15.835203170776367, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.25s/it] 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it]                                              {'loss': 2.7827, 'grad_norm': 16.36591339111328, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:16,  2.25s/it] 18%|█▊        | 7/40 [00:15<01:14,  2.25s/it]                                              {'loss': 2.5079, 'grad_norm': 14.06930923461914, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:14,  2.25s/it] 20%|██        | 8/40 [00:16<00:50,  1.59s/it]                                              {'loss': 0.0833, 'grad_norm': 4.220334529876709, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.80s/it]                                              {'loss': 0.6968, 'grad_norm': 18.000301361083984, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.80s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 0.7919, 'grad_norm': 11.13668441772461, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it]                                               {'loss': 0.2985, 'grad_norm': 5.201864242553711, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it] 30%|███       | 12/40 [00:25<00:58,  2.09s/it]                                               {'loss': 0.4176, 'grad_norm': 4.976827621459961, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 0.5442, 'grad_norm': 5.769197463989258, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 0.3319, 'grad_norm': 3.6430459022521973, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it]                                               {'loss': 1.0795, 'grad_norm': 12.256572723388672, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it] 40%|████      | 16/40 [00:31<00:38,  1.60s/it]                                               {'loss': 0.139, 'grad_norm': 6.8657426834106445, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.80s/it]                                               {'loss': 0.11, 'grad_norm': 3.5789694786071777, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 0.297, 'grad_norm': 4.063497543334961, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.0786, 'grad_norm': 1.8518556356430054, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:41<00:42,  2.11s/it]                                               {'loss': 0.2068, 'grad_norm': 3.9922773838043213, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 0.2876, 'grad_norm': 5.453625679016113, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.1207, 'grad_norm': 2.4330713748931885, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.0381, 'grad_norm': 0.7781183123588562, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:48<00:25,  1.61s/it]                                               {'loss': 0.2671, 'grad_norm': 18.740446090698242, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.0429, 'grad_norm': 0.9780970215797424, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.0252, 'grad_norm': 0.5966872572898865, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.0509, 'grad_norm': 1.6762974262237549, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.0562, 'grad_norm': 1.745474100112915, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it]                                               {'loss': 0.0195, 'grad_norm': 0.5820639133453369, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.0381, 'grad_norm': 1.080551266670227, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it]                                               {'loss': 0.0701, 'grad_norm': 2.0208535194396973, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it] 80%|████████  | 32/40 [01:04<00:12,  1.61s/it]                                               {'loss': 0.0072, 'grad_norm': 0.48397767543792725, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.0668, 'grad_norm': 1.7695610523223877, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.0093, 'grad_norm': 0.2527324855327606, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.015, 'grad_norm': 0.5468231439590454, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it]                                               {'loss': 0.0211, 'grad_norm': 0.49862027168273926, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.15s/it]                                               {'loss': 0.069, 'grad_norm': 2.2243800163269043, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0295, 'grad_norm': 0.7384196519851685, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]                                               {'loss': 0.021, 'grad_norm': 0.5614805221557617, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.23s/it]100%|██████████| 40/40 [01:20<00:00,  1.61s/it]                                               {'loss': 0.0114, 'grad_norm': 1.264450192451477, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]                                               {'train_runtime': 80.5332, 'train_samples_per_second': 7.016, 'train_steps_per_second': 0.497, 'train_loss': 0.5460225186892785, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:49
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:41,  2.59s/it]                                              {'loss': 3.7532, 'grad_norm': 11.914413452148438, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:41,  2.59s/it]  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]                                              {'loss': 1.7446, 'grad_norm': 12.180938720703125, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 1.7273, 'grad_norm': 13.356195449829102, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 1.7664, 'grad_norm': 14.499250411987305, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 1.1953, 'grad_norm': 11.433276176452637, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 2.5426, 'grad_norm': 15.152969360351562, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 2.087, 'grad_norm': 12.733551025390625, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.0305, 'grad_norm': 1.7447056770324707, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 0.5444, 'grad_norm': 6.8556599617004395, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.3231, 'grad_norm': 4.005420684814453, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.6498, 'grad_norm': 6.72361946105957, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.8116, 'grad_norm': 7.431639671325684, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it]                                               {'loss': 0.9703, 'grad_norm': 5.953732013702393, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.09s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it]                                               {'loss': 0.9017, 'grad_norm': 9.447080612182617, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 0.2529, 'grad_norm': 4.322397232055664, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.4084, 'grad_norm': 22.065065383911133, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.1007, 'grad_norm': 3.0806736946105957, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it]                                               {'loss': 0.506, 'grad_norm': 2.6712424755096436, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:41,  1.98s/it]                                               {'loss': 0.2756, 'grad_norm': 2.425778865814209, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  1.98s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.1297, 'grad_norm': 3.3373031616210938, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.1626, 'grad_norm': 2.3309614658355713, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.4478, 'grad_norm': 9.192670822143555, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.4044, 'grad_norm': 9.85883903503418, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0045, 'grad_norm': 0.26146164536476135, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.3106, 'grad_norm': 1.530060887336731, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it]                                               {'loss': 0.0726, 'grad_norm': 2.968362331390381, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.00s/it]                                               {'loss': 0.3278, 'grad_norm': 3.51188588142395, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.00s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.0675, 'grad_norm': 1.3806304931640625, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it]                                               {'loss': 0.2443, 'grad_norm': 9.959022521972656, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.0318, 'grad_norm': 1.0063109397888184, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.1351, 'grad_norm': 8.348984718322754, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0158, 'grad_norm': 0.9733342528343201, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.1401, 'grad_norm': 5.230015754699707, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.1032, 'grad_norm': 1.7912994623184204, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.02, 'grad_norm': 0.4675179421901703, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.0332, 'grad_norm': 0.8385481238365173, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.8001, 'grad_norm': 6.372788429260254, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.07, 'grad_norm': 2.8847622871398926, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.4817, 'grad_norm': 2.918978214263916, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0726, 'grad_norm': 3.353778600692749, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.5092, 'train_samples_per_second': 7.106, 'train_steps_per_second': 0.503, 'train_loss': 0.6166732072713785, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:82
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:23,  2.14s/it]                                              {'loss': 3.7597, 'grad_norm': 13.291534423828125, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:23,  2.14s/it]  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]                                              {'loss': 2.1471, 'grad_norm': 11.625948905944824, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]  8%|▊         | 3/40 [00:06<01:19,  2.16s/it]                                              {'loss': 1.2415, 'grad_norm': 8.411855697631836, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.16s/it] 10%|█         | 4/40 [00:08<01:18,  2.17s/it]                                              {'loss': 2.9337, 'grad_norm': 16.816131591796875, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.17s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it]                                              {'loss': 1.6519, 'grad_norm': 13.048408508300781, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 2.2952, 'grad_norm': 20.896690368652344, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 1.9901, 'grad_norm': 15.219735145568848, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.009, 'grad_norm': 0.4324486255645752, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 1.1814, 'grad_norm': 12.846869468688965, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it]                                               {'loss': 0.439, 'grad_norm': 6.217589378356934, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.8036, 'grad_norm': 8.84713077545166, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.7075, 'grad_norm': 7.438859939575195, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 1.4875, 'grad_norm': 10.01118278503418, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it]                                               {'loss': 1.7978, 'grad_norm': 11.91451358795166, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:30<00:54,  2.18s/it]                                               {'loss': 0.6929, 'grad_norm': 6.54278039932251, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 4.5578, 'grad_norm': 27.17359161376953, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.4391, 'grad_norm': 7.966991901397705, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.6719, 'grad_norm': 7.0366387367248535, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it]                                               {'loss': 0.5432, 'grad_norm': 6.200564861297607, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.4347, 'grad_norm': 4.984057426452637, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.6357, 'grad_norm': 4.083086013793945, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it]                                               {'loss': 0.2339, 'grad_norm': 2.5146398544311523, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it]                                               {'loss': 0.3728, 'grad_norm': 3.131434202194214, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0128, 'grad_norm': 0.9956045746803284, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.76s/it]                                               {'loss': 0.5357, 'grad_norm': 3.6597447395324707, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.76s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.041, 'grad_norm': 1.11155104637146, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.1121, 'grad_norm': 2.761850595474243, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.138, 'grad_norm': 3.6823737621307373, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.2915, 'grad_norm': 0.8680980205535889, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.4395, 'grad_norm': 1.8263665437698364, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.0465, 'grad_norm': 0.9281182885169983, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:02<00:12,  1.59s/it]                                               {'loss': 0.2474, 'grad_norm': 15.37570858001709, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0207, 'grad_norm': 0.42900151014328003, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.0824, 'grad_norm': 3.575984477996826, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it]                                               {'loss': 0.3887, 'grad_norm': 6.884841442108154, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.0287, 'grad_norm': 0.9010549187660217, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.1621, 'grad_norm': 2.8068511486053467, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.1443, 'grad_norm': 1.0911308526992798, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.4057, 'grad_norm': 1.2915942668914795, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 0.0135, 'grad_norm': 0.9008169770240784, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 79.2772, 'train_samples_per_second': 7.127, 'train_steps_per_second': 0.505, 'train_loss': 0.8534395948285237, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:34,  2.43s/it]                                              {'loss': 1.9545, 'grad_norm': 10.380472183227539, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:34,  2.43s/it]  5%|▌         | 2/40 [00:04<01:27,  2.30s/it]                                              {'loss': 1.8527, 'grad_norm': 12.48111629486084, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:27,  2.30s/it]  8%|▊         | 3/40 [00:06<01:23,  2.25s/it]                                              {'loss': 1.8366, 'grad_norm': 13.448817253112793, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.25s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 3.2897, 'grad_norm': 22.40452003479004, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 3.4494, 'grad_norm': 28.783266067504883, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 3.3524, 'grad_norm': 20.289587020874023, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 1.9183, 'grad_norm': 17.962646484375, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 0.9715, 'grad_norm': 32.46940231323242, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 1.0006, 'grad_norm': 13.853984832763672, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.16, 'grad_norm': 11.943872451782227, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.5021, 'grad_norm': 6.648810386657715, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 0.587, 'grad_norm': 8.188033103942871, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 2.3221, 'grad_norm': 14.148417472839355, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 2.1606, 'grad_norm': 12.804727554321289, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 1.1762, 'grad_norm': 7.92938232421875, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 1.07, 'grad_norm': 33.595977783203125, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it]                                               {'loss': 0.1117, 'grad_norm': 2.021878480911255, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.1345, 'grad_norm': 1.9942481517791748, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.6821, 'grad_norm': 5.928882122039795, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:42,  2.10s/it]                                               {'loss': 0.0799, 'grad_norm': 1.4514278173446655, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.1371, 'grad_norm': 3.9699227809906006, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.2281, 'grad_norm': 4.600396156311035, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.2463, 'grad_norm': 2.9980881214141846, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.1355, 'grad_norm': 7.389575004577637, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.0832, 'grad_norm': 2.4413514137268066, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.0241, 'grad_norm': 0.557928740978241, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.083, 'grad_norm': 0.9344589114189148, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.2375, 'grad_norm': 14.132034301757812, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it]                                               {'loss': 0.0635, 'grad_norm': 2.057370185852051, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it]                                               {'loss': 0.0313, 'grad_norm': 1.076822280883789, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.0152, 'grad_norm': 0.3870588541030884, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.0057, 'grad_norm': 0.3834294080734253, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.0188, 'grad_norm': 0.34691277146339417, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.0342, 'grad_norm': 0.5411705374717712, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.0261, 'grad_norm': 0.738076388835907, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.027, 'grad_norm': 1.2147324085235596, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it]                                               {'loss': 0.0177, 'grad_norm': 0.6139806509017944, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0113, 'grad_norm': 0.22872716188430786, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.0122, 'grad_norm': 0.268118292093277, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.0005, 'grad_norm': 0.03231608495116234, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.3214, 'train_samples_per_second': 7.034, 'train_steps_per_second': 0.498, 'train_loss': 0.7762575778680911, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:37
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:38,  2.53s/it]                                              {'loss': 2.0406, 'grad_norm': 8.442710876464844, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:38,  2.53s/it]  5%|▌         | 2/40 [00:04<01:28,  2.33s/it]                                              {'loss': 2.1386, 'grad_norm': 11.276984214782715, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.33s/it]  8%|▊         | 3/40 [00:06<01:23,  2.27s/it]                                              {'loss': 1.5027, 'grad_norm': 9.731093406677246, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.27s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 2.6735, 'grad_norm': 19.11216926574707, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 1.9358, 'grad_norm': 13.99972915649414, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 1.7813, 'grad_norm': 14.34697437286377, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 2.3982, 'grad_norm': 11.045568466186523, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 0.8296, 'grad_norm': 41.393795013427734, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 0.7071, 'grad_norm': 7.898562431335449, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 0.2287, 'grad_norm': 4.006306171417236, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.712, 'grad_norm': 9.44165325164795, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:58,  2.07s/it]                                               {'loss': 0.5035, 'grad_norm': 7.264989376068115, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it]                                               {'loss': 1.1197, 'grad_norm': 7.310830116271973, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it]                                               {'loss': 0.515, 'grad_norm': 7.327427387237549, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it]                                               {'loss': 0.896, 'grad_norm': 9.249423027038574, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 0.7048, 'grad_norm': 53.01880645751953, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.1591, 'grad_norm': 1.447718858718872, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it]                                               {'loss': 0.0999, 'grad_norm': 3.6098392009735107, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it] 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it]                                               {'loss': 0.6469, 'grad_norm': 9.851096153259277, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 1.3101, 'grad_norm': 38.50291442871094, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.4107, 'grad_norm': 7.1830596923828125, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 1.2649, 'grad_norm': 37.37310028076172, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it]                                               {'loss': 0.5368, 'grad_norm': 31.14336585998535, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0621, 'grad_norm': 4.6684041023254395, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.5823, 'grad_norm': 12.847214698791504, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.0568, 'grad_norm': 2.16178297996521, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.99s/it]                                               {'loss': 0.6637, 'grad_norm': 4.917463779449463, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.99s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.0762, 'grad_norm': 1.6761306524276733, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.4406, 'grad_norm': 2.506635904312134, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.0889, 'grad_norm': 1.4236066341400146, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.1416, 'grad_norm': 9.832027435302734, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0239, 'grad_norm': 1.4125871658325195, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0559, 'grad_norm': 2.441455125808716, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.0262, 'grad_norm': 0.9096748232841492, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.1802, 'grad_norm': 2.548214912414551, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0458, 'grad_norm': 1.1244913339614868, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.1038, 'grad_norm': 2.55509614944458, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.5682, 'grad_norm': 5.282307147979736, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 1.1799, 'grad_norm': 24.65874481201172, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0024, 'grad_norm': 0.163969948887825, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.3922, 'train_samples_per_second': 7.117, 'train_steps_per_second': 0.504, 'train_loss': 0.7353473876777571, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:12
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:29,  2.30s/it]                                              {'loss': 1.9683, 'grad_norm': 10.819573402404785, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:29,  2.30s/it]  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]                                              {'loss': 2.2422, 'grad_norm': 11.603001594543457, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]  8%|▊         | 3/40 [00:06<01:21,  2.19s/it]                                              {'loss': 1.9927, 'grad_norm': 16.07621192932129, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.19s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 1.2799, 'grad_norm': 13.13550090789795, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it]                                              {'loss': 1.8767, 'grad_norm': 58.24665832519531, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 1.6158, 'grad_norm': 12.967254638671875, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 1.7335, 'grad_norm': 14.360222816467285, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 0.6311, 'grad_norm': 37.630680084228516, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 0.4936, 'grad_norm': 10.932098388671875, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it]                                               {'loss': 1.0861, 'grad_norm': 11.667829513549805, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.4822, 'grad_norm': 7.452272891998291, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.3774, 'grad_norm': 5.595250129699707, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 0.6145, 'grad_norm': 6.4938812255859375, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it]                                               {'loss': 1.2488, 'grad_norm': 7.348586082458496, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.3761, 'grad_norm': 6.113463878631592, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.1742, 'grad_norm': 9.426114082336426, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.098, 'grad_norm': 3.0681371688842773, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.1747, 'grad_norm': 3.550612688064575, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.2666, 'grad_norm': 9.094685554504395, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.1868, 'grad_norm': 4.67484712600708, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.1293, 'grad_norm': 3.638077735900879, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.2161, 'grad_norm': 3.6856648921966553, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it]                                               {'loss': 0.2039, 'grad_norm': 4.283720970153809, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0802, 'grad_norm': 4.39150857925415, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.1087, 'grad_norm': 3.5609874725341797, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it]                                               {'loss': 0.0376, 'grad_norm': 0.7002819180488586, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.0983, 'grad_norm': 2.1163206100463867, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.08s/it]                                               {'loss': 0.1049, 'grad_norm': 2.302938461303711, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.2506, 'grad_norm': 2.7579891681671143, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.6346, 'grad_norm': 12.22683334350586, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.0557, 'grad_norm': 2.489243268966675, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0085, 'grad_norm': 0.6240660548210144, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.505, 'grad_norm': 6.252969741821289, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.0185, 'grad_norm': 0.4847654402256012, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.07, 'grad_norm': 2.3896842002868652, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.0227, 'grad_norm': 0.699476420879364, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.0883, 'grad_norm': 2.2172346115112305, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 0.0874, 'grad_norm': 5.766905784606934, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.0528, 'grad_norm': 1.5376964807510376, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'loss': 0.247, 'grad_norm': 33.241512298583984, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'train_runtime': 79.2908, 'train_samples_per_second': 7.126, 'train_steps_per_second': 0.504, 'train_loss': 0.5484899772563949, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:87
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:45,  2.70s/it]                                              {'loss': 2.9015, 'grad_norm': 13.42806625366211, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:45,  2.70s/it]  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]                                              {'loss': 1.8123, 'grad_norm': 12.09808349609375, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]  8%|▊         | 3/40 [00:07<01:25,  2.31s/it]                                              {'loss': 1.9389, 'grad_norm': 13.7816743850708, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.31s/it] 10%|█         | 4/40 [00:09<01:21,  2.27s/it]                                              {'loss': 1.386, 'grad_norm': 24.209190368652344, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.27s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 3.5977, 'grad_norm': 36.69316864013672, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 2.1282, 'grad_norm': 15.278599739074707, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.2473, 'grad_norm': 16.027965545654297, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 0.1346, 'grad_norm': 8.800986289978027, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 0.85, 'grad_norm': 10.074424743652344, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 0.4162, 'grad_norm': 6.538588047027588, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.7431, 'grad_norm': 6.608575344085693, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 1.2107, 'grad_norm': 9.411766052246094, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it]                                               {'loss': 0.7399, 'grad_norm': 5.666127681732178, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it]                                               {'loss': 1.8903, 'grad_norm': 10.236220359802246, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 1.0259, 'grad_norm': 11.207733154296875, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0079, 'grad_norm': 0.46940457820892334, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it]                                               {'loss': 0.2826, 'grad_norm': 7.8739166259765625, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 0.6942, 'grad_norm': 8.401423454284668, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.3801, 'grad_norm': 4.2878737449646, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.10s/it]                                               {'loss': 0.0657, 'grad_norm': 1.247761607170105, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.10s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 0.3317, 'grad_norm': 4.387996673583984, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it]                                               {'loss': 0.3049, 'grad_norm': 2.352799415588379, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.1952, 'grad_norm': 4.91533899307251, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.2126, 'grad_norm': 9.596969604492188, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.78s/it]                                               {'loss': 0.1333, 'grad_norm': 2.2623543739318848, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it]                                               {'loss': 0.0305, 'grad_norm': 0.7002236843109131, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it]                                               {'loss': 0.0816, 'grad_norm': 2.3964946269989014, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.0932, 'grad_norm': 2.9646477699279785, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.1443, 'grad_norm': 2.332540512084961, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.0842, 'grad_norm': 2.187591552734375, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.2716, 'grad_norm': 3.7592344284057617, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0512, 'grad_norm': 2.6339609622955322, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.1206, 'grad_norm': 2.1969094276428223, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.0713, 'grad_norm': 1.9542628526687622, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.0073, 'grad_norm': 0.2546207308769226, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0548, 'grad_norm': 2.7563118934631348, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.15s/it]                                               {'loss': 0.0327, 'grad_norm': 0.7682275772094727, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it]                                               {'loss': 0.0519, 'grad_norm': 1.259273648262024, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.0167, 'grad_norm': 0.9118819236755371, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.5411, 'grad_norm': 26.917421340942383, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.0207, 'train_samples_per_second': 7.061, 'train_steps_per_second': 0.5, 'train_loss': 0.6820937359705568, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]                                              {'loss': 1.8833, 'grad_norm': 9.557698249816895, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]                                              {'loss': 1.9325, 'grad_norm': 10.614420890808105, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.26s/it]  8%|▊         | 3/40 [00:06<01:22,  2.23s/it]                                              {'loss': 1.6849, 'grad_norm': 11.57517147064209, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.23s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 1.9457, 'grad_norm': 16.939294815063477, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 1.6487, 'grad_norm': 19.677173614501953, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 2.0061, 'grad_norm': 18.122684478759766, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it]                                              {'loss': 1.4728, 'grad_norm': 17.66796112060547, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 1.3333, 'grad_norm': 36.806026458740234, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 2.5738, 'grad_norm': 21.70741081237793, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.111, 'grad_norm': 11.33456039428711, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.4566, 'grad_norm': 8.965739250183105, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:58,  2.07s/it]                                               {'loss': 1.5286, 'grad_norm': 5.470994472503662, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 2.0223, 'grad_norm': 11.655218124389648, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 1.05, 'grad_norm': 8.009747505187988, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 1.0484, 'grad_norm': 8.061710357666016, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 2.1279, 'grad_norm': 49.93391418457031, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.4428, 'grad_norm': 6.912262916564941, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it]                                               {'loss': 0.4879, 'grad_norm': 9.066361427307129, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.1936, 'grad_norm': 4.525618076324463, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.3667, 'grad_norm': 3.734578847885132, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.194, 'grad_norm': 2.3945276737213135, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.435, 'grad_norm': 5.541391372680664, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.5005, 'grad_norm': 6.714143753051758, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.0126, 'grad_norm': 0.5230743885040283, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it]                                               {'loss': 0.284, 'grad_norm': 5.662032604217529, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it]                                               {'loss': 0.1584, 'grad_norm': 1.0526223182678223, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.0848, 'grad_norm': 2.0117998123168945, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.2795, 'grad_norm': 4.179448127746582, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.17s/it]                                               {'loss': 0.0654, 'grad_norm': 1.3565770387649536, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it]                                               {'loss': 0.29, 'grad_norm': 5.770673751831055, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.3282, 'grad_norm': 2.9476630687713623, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.4242, 'grad_norm': 20.296297073364258, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it]                                               {'loss': 0.0198, 'grad_norm': 0.4262348413467407, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.1784, 'grad_norm': 2.659196376800537, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.1444, 'grad_norm': 3.771817684173584, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.5656, 'grad_norm': 9.28929328918457, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.1791, 'grad_norm': 6.326923847198486, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0688, 'grad_norm': 2.8694398403167725, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]                                               {'loss': 0.2288, 'grad_norm': 15.610966682434082, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.1819, 'grad_norm': 11.104761123657227, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 80.0474, 'train_samples_per_second': 7.058, 'train_steps_per_second': 0.5, 'train_loss': 0.823518328438513, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:99
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]                                              {'loss': 3.3057, 'grad_norm': 12.778196334838867, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:32,  2.38s/it]  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]                                              {'loss': 1.8685, 'grad_norm': 11.436479568481445, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:25,  2.25s/it]  8%|▊         | 3/40 [00:06<01:22,  2.22s/it]                                              {'loss': 1.1617, 'grad_norm': 12.766666412353516, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.22s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 1.959, 'grad_norm': 13.86146354675293, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 2.6286, 'grad_norm': 16.046972274780273, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 2.1196, 'grad_norm': 15.810351371765137, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 2.443, 'grad_norm': 18.173965454101562, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:17<01:08,  2.15s/it]                                              {'loss': 2.661, 'grad_norm': 13.814613342285156, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:17<01:08,  2.15s/it] 22%|██▎       | 9/40 [00:19<01:07,  2.16s/it]                                              {'loss': 0.9601, 'grad_norm': 6.173791408538818, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:19<01:07,  2.16s/it] 25%|██▌       | 10/40 [00:21<01:05,  2.17s/it]                                               {'loss': 1.3521, 'grad_norm': 11.508694648742676, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:21<01:05,  2.17s/it] 28%|██▊       | 11/40 [00:24<01:03,  2.20s/it]                                               {'loss': 0.393, 'grad_norm': 5.5997843742370605, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:24<01:03,  2.20s/it] 30%|███       | 12/40 [00:26<01:01,  2.20s/it]                                               {'loss': 0.3484, 'grad_norm': 5.100524425506592, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:26<01:01,  2.20s/it] 32%|███▎      | 13/40 [00:28<00:59,  2.21s/it]                                               {'loss': 0.6249, 'grad_norm': 6.46338415145874, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:28<00:59,  2.21s/it] 35%|███▌      | 14/40 [00:30<00:57,  2.22s/it]                                               {'loss': 0.6778, 'grad_norm': 7.496148586273193, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:30<00:57,  2.22s/it] 38%|███▊      | 15/40 [00:33<00:55,  2.23s/it]                                               {'loss': 0.9, 'grad_norm': 10.781350135803223, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:33<00:55,  2.23s/it] 40%|████      | 16/40 [00:35<00:52,  2.19s/it]                                               {'loss': 0.9439, 'grad_norm': 11.991649627685547, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:35<00:52,  2.19s/it] 42%|████▎     | 17/40 [00:37<00:50,  2.19s/it]                                               {'loss': 0.1536, 'grad_norm': 2.9396884441375732, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:37<00:50,  2.19s/it] 45%|████▌     | 18/40 [00:39<00:48,  2.21s/it]                                               {'loss': 0.1912, 'grad_norm': 3.330178737640381, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:39<00:48,  2.21s/it] 48%|████▊     | 19/40 [00:41<00:46,  2.22s/it]                                               {'loss': 0.2095, 'grad_norm': 3.5515871047973633, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:41<00:46,  2.22s/it] 50%|█████     | 20/40 [00:44<00:44,  2.22s/it]                                               {'loss': 0.3351, 'grad_norm': 3.289707660675049, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:44<00:44,  2.22s/it] 52%|█████▎    | 21/40 [00:46<00:42,  2.24s/it]                                               {'loss': 0.3563, 'grad_norm': 4.692418575286865, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:46<00:42,  2.24s/it] 55%|█████▌    | 22/40 [00:48<00:40,  2.23s/it]                                               {'loss': 0.5829, 'grad_norm': 5.988954067230225, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:48<00:40,  2.23s/it] 57%|█████▊    | 23/40 [00:50<00:38,  2.24s/it]                                               {'loss': 0.1963, 'grad_norm': 3.18393611907959, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:50<00:38,  2.24s/it] 60%|██████    | 24/40 [00:53<00:35,  2.20s/it]                                               {'loss': 0.2354, 'grad_norm': 2.8889451026916504, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:53<00:35,  2.20s/it] 62%|██████▎   | 25/40 [00:55<00:33,  2.20s/it]                                               {'loss': 0.0593, 'grad_norm': 1.2153578996658325, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:55<00:33,  2.20s/it] 65%|██████▌   | 26/40 [00:57<00:31,  2.23s/it]                                               {'loss': 0.1129, 'grad_norm': 1.3163435459136963, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:57<00:31,  2.23s/it] 68%|██████▊   | 27/40 [00:59<00:28,  2.22s/it]                                               {'loss': 0.3372, 'grad_norm': 2.9927988052368164, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:59<00:28,  2.22s/it] 70%|███████   | 28/40 [01:01<00:26,  2.23s/it]                                               {'loss': 0.0409, 'grad_norm': 1.0824034214019775, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [01:01<00:26,  2.23s/it] 72%|███████▎  | 29/40 [01:04<00:24,  2.25s/it]                                               {'loss': 0.0444, 'grad_norm': 1.1612684726715088, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:04<00:24,  2.25s/it] 75%|███████▌  | 30/40 [01:06<00:22,  2.25s/it]                                               {'loss': 0.0662, 'grad_norm': 2.213099718093872, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:06<00:22,  2.25s/it] 78%|███████▊  | 31/40 [01:08<00:20,  2.23s/it]                                               {'loss': 0.0465, 'grad_norm': 1.529964804649353, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:08<00:20,  2.23s/it] 80%|████████  | 32/40 [01:10<00:17,  2.20s/it]                                               {'loss': 0.1121, 'grad_norm': 2.1768524646759033, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:10<00:17,  2.20s/it] 82%|████████▎ | 33/40 [01:13<00:15,  2.23s/it]                                               {'loss': 0.0619, 'grad_norm': 1.4336644411087036, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:13<00:15,  2.23s/it] 85%|████████▌ | 34/40 [01:15<00:13,  2.24s/it]                                               {'loss': 0.0317, 'grad_norm': 0.9652500748634338, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:15<00:13,  2.24s/it] 88%|████████▊ | 35/40 [01:17<00:11,  2.26s/it]                                               {'loss': 0.015, 'grad_norm': 0.43086591362953186, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:17<00:11,  2.26s/it] 90%|█████████ | 36/40 [01:19<00:09,  2.26s/it]                                               {'loss': 0.0374, 'grad_norm': 1.286220669746399, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:19<00:09,  2.26s/it] 92%|█████████▎| 37/40 [01:22<00:06,  2.24s/it]                                               {'loss': 0.0323, 'grad_norm': 1.1592836380004883, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:22<00:06,  2.24s/it] 95%|█████████▌| 38/40 [01:24<00:04,  2.25s/it]                                               {'loss': 0.0513, 'grad_norm': 1.8813835382461548, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:24<00:04,  2.25s/it] 98%|█████████▊| 39/40 [01:26<00:02,  2.25s/it]                                               {'loss': 0.2987, 'grad_norm': 2.893808126449585, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:26<00:02,  2.25s/it]100%|██████████| 40/40 [01:28<00:00,  2.20s/it]                                               {'loss': 0.0608, 'grad_norm': 3.410853147506714, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:28<00:00,  2.20s/it]                                               {'train_runtime': 89.0745, 'train_samples_per_second': 7.129, 'train_steps_per_second': 0.449, 'train_loss': 0.7003992542624473, 'epoch': 5.0}
100%|██████████| 40/40 [01:29<00:00,  2.20s/it]100%|██████████| 40/40 [01:29<00:00,  2.23s/it]
CLIENT:85
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:38,  2.51s/it]                                              {'loss': 0.2156, 'grad_norm': 2.755817413330078, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:38,  2.51s/it]  5%|▌         | 2/40 [00:04<01:27,  2.31s/it]                                              {'loss': 0.1196, 'grad_norm': 2.847086191177368, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:27,  2.31s/it]  8%|▊         | 3/40 [00:06<01:22,  2.24s/it]                                              {'loss': 0.0624, 'grad_norm': 1.476773738861084, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.24s/it] 10%|█         | 4/40 [00:09<01:19,  2.21s/it]                                              {'loss': 0.6341, 'grad_norm': 1.5132583379745483, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 0.4698, 'grad_norm': 17.628955841064453, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.21s/it]                                              {'loss': 0.0069, 'grad_norm': 0.0859362855553627, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 0.7188, 'grad_norm': 0.8169113993644714, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 0.0166, 'grad_norm': 0.7083476781845093, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 0.0275, 'grad_norm': 0.9490510821342468, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 0.0052, 'grad_norm': 0.21901461482048035, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.0053, 'grad_norm': 0.07429525256156921, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 0.5607, 'grad_norm': 13.172253608703613, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 0.1802, 'grad_norm': 3.7312891483306885, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 0.5753, 'grad_norm': 4.220818996429443, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 0.1621, 'grad_norm': 1.1012842655181885, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 0.0, 'grad_norm': 0.00016911122656892985, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.0103, 'grad_norm': 0.450065553188324, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it]                                               {'loss': 0.0042, 'grad_norm': 0.06057262793183327, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.0055, 'grad_norm': 0.28753095865249634, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.0372, 'grad_norm': 0.5609200596809387, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.2382, 'grad_norm': 0.790683388710022, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.13s/it]                                               {'loss': 0.7766, 'grad_norm': 9.53974437713623, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.13s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it]                                               {'loss': 0.555, 'grad_norm': 2.3869550228118896, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it] 60%|██████    | 24/40 [00:47<00:25,  1.57s/it]                                               {'loss': 0.0079, 'grad_norm': 0.3630572557449341, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0058, 'grad_norm': 0.08056997507810593, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.0038, 'grad_norm': 0.03721461072564125, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it]                                               {'loss': 0.1211, 'grad_norm': 1.7208768129348755, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:24,  2.07s/it]                                               {'loss': 0.3402, 'grad_norm': 1.8513442277908325, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.2504, 'grad_norm': 1.0751118659973145, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.0064, 'grad_norm': 0.06809333711862564, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it]                                               {'loss': 0.3857, 'grad_norm': 2.0215325355529785, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it] 80%|████████  | 32/40 [01:02<00:12,  1.58s/it]                                               {'loss': 0.0044, 'grad_norm': 0.11061536520719528, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.2124, 'grad_norm': 3.138395309448242, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it]                                               {'loss': 0.1454, 'grad_norm': 1.3266751766204834, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it] 88%|████████▊ | 35/40 [01:09<00:09,  2.00s/it]                                               {'loss': 0.3904, 'grad_norm': 0.9849749803543091, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:09,  2.00s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.07s/it]                                               {'loss': 0.0071, 'grad_norm': 0.056524746119976044, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.07s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.13s/it]                                               {'loss': 0.1759, 'grad_norm': 1.11995530128479, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.13s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.0013, 'grad_norm': 0.01222154963761568, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]                                               {'loss': 0.159, 'grad_norm': 1.4392573833465576, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 0.0003, 'grad_norm': 0.005521077662706375, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 79.1833, 'train_samples_per_second': 7.135, 'train_steps_per_second': 0.505, 'train_loss': 0.19011421914301535, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  do_eval=True, seed=self.args.random_seed)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:57,  1.58it/s]  1%|          | 3/471 [00:02<07:01,  1.11it/s]  1%|          | 4/471 [00:03<08:05,  1.04s/it]  1%|          | 5/471 [00:05<08:43,  1.12s/it]  1%|▏         | 6/471 [00:06<09:06,  1.17s/it]  1%|▏         | 7/471 [00:07<09:21,  1.21s/it]  2%|▏         | 8/471 [00:08<09:31,  1.23s/it]  2%|▏         | 9/471 [00:10<09:37,  1.25s/it]  2%|▏         | 10/471 [00:11<09:41,  1.26s/it]  2%|▏         | 11/471 [00:12<09:44,  1.27s/it]  3%|▎         | 12/471 [00:14<09:46,  1.28s/it]  3%|▎         | 13/471 [00:15<09:47,  1.28s/it]  3%|▎         | 14/471 [00:16<09:47,  1.29s/it]  3%|▎         | 15/471 [00:17<09:47,  1.29s/it]  3%|▎         | 16/471 [00:19<09:47,  1.29s/it]  4%|▎         | 17/471 [00:20<09:47,  1.29s/it]  4%|▍         | 18/471 [00:21<09:46,  1.30s/it]  4%|▍         | 19/471 [00:23<09:45,  1.30s/it]  4%|▍         | 20/471 [00:24<09:45,  1.30s/it]  4%|▍         | 21/471 [00:25<09:44,  1.30s/it]  5%|▍         | 22/471 [00:27<09:43,  1.30s/it]  5%|▍         | 23/471 [00:28<09:42,  1.30s/it]  5%|▌         | 24/471 [00:29<09:42,  1.30s/it]  5%|▌         | 25/471 [00:30<09:41,  1.30s/it]  6%|▌         | 26/471 [00:32<09:40,  1.30s/it]  6%|▌         | 27/471 [00:33<09:39,  1.31s/it]  6%|▌         | 28/471 [00:34<09:38,  1.31s/it]  6%|▌         | 29/471 [00:36<09:37,  1.31s/it]  6%|▋         | 30/471 [00:37<09:37,  1.31s/it]  7%|▋         | 31/471 [00:38<09:35,  1.31s/it]  7%|▋         | 32/471 [00:40<09:34,  1.31s/it]  7%|▋         | 33/471 [00:41<09:31,  1.31s/it]  7%|▋         | 34/471 [00:42<09:31,  1.31s/it]  7%|▋         | 35/471 [00:44<09:31,  1.31s/it]  8%|▊         | 36/471 [00:45<09:30,  1.31s/it]  8%|▊         | 37/471 [00:46<09:30,  1.31s/it]  8%|▊         | 38/471 [00:48<09:29,  1.32s/it]  8%|▊         | 39/471 [00:49<09:27,  1.31s/it]  8%|▊         | 40/471 [00:50<09:25,  1.31s/it]  9%|▊         | 41/471 [00:51<09:24,  1.31s/it]  9%|▉         | 42/471 [00:53<09:23,  1.31s/it]  9%|▉         | 43/471 [00:54<09:21,  1.31s/it]  9%|▉         | 44/471 [00:55<09:20,  1.31s/it] 10%|▉         | 45/471 [00:57<09:20,  1.32s/it] 10%|▉         | 46/471 [00:58<09:19,  1.32s/it] 10%|▉         | 47/471 [00:59<09:17,  1.31s/it] 10%|█         | 48/471 [01:01<09:16,  1.32s/it] 10%|█         | 49/471 [01:02<09:15,  1.32s/it] 11%|█         | 50/471 [01:03<09:14,  1.32s/it] 11%|█         | 51/471 [01:05<09:14,  1.32s/it] 11%|█         | 52/471 [01:06<09:13,  1.32s/it] 11%|█▏        | 53/471 [01:07<09:12,  1.32s/it] 11%|█▏        | 54/471 [01:09<09:11,  1.32s/it] 12%|█▏        | 55/471 [01:10<09:10,  1.32s/it] 12%|█▏        | 56/471 [01:11<09:09,  1.32s/it] 12%|█▏        | 57/471 [01:13<09:08,  1.32s/it] 12%|█▏        | 58/471 [01:14<09:06,  1.32s/it] 13%|█▎        | 59/471 [01:15<09:05,  1.32s/it] 13%|█▎        | 60/471 [01:17<09:04,  1.32s/it] 13%|█▎        | 61/471 [01:18<09:02,  1.32s/it] 13%|█▎        | 62/471 [01:19<09:01,  1.32s/it] 13%|█▎        | 63/471 [01:21<08:59,  1.32s/it] 14%|█▎        | 64/471 [01:22<08:58,  1.32s/it] 14%|█▍        | 65/471 [01:23<08:56,  1.32s/it] 14%|█▍        | 66/471 [01:25<08:55,  1.32s/it] 14%|█▍        | 67/471 [01:26<08:54,  1.32s/it] 14%|█▍        | 68/471 [01:27<08:53,  1.32s/it] 15%|█▍        | 69/471 [01:28<08:51,  1.32s/it] 15%|█▍        | 70/471 [01:30<08:51,  1.32s/it] 15%|█▌        | 71/471 [01:31<08:50,  1.33s/it] 15%|█▌        | 72/471 [01:32<08:48,  1.32s/it] 15%|█▌        | 73/471 [01:34<08:47,  1.32s/it] 16%|█▌        | 74/471 [01:35<08:45,  1.32s/it] 16%|█▌        | 75/471 [01:36<08:44,  1.33s/it] 16%|█▌        | 76/471 [01:38<08:42,  1.32s/it] 16%|█▋        | 77/471 [01:39<08:42,  1.32s/it] 17%|█▋        | 78/471 [01:40<08:40,  1.33s/it] 17%|█▋        | 79/471 [01:42<08:40,  1.33s/it] 17%|█▋        | 80/471 [01:43<08:39,  1.33s/it] 17%|█▋        | 81/471 [01:44<08:37,  1.33s/it] 17%|█▋        | 82/471 [01:46<08:35,  1.33s/it] 18%|█▊        | 83/471 [01:47<08:34,  1.33s/it] 18%|█▊        | 84/471 [01:48<08:33,  1.33s/it] 18%|█▊        | 85/471 [01:50<08:32,  1.33s/it] 18%|█▊        | 86/471 [01:51<08:31,  1.33s/it] 18%|█▊        | 87/471 [01:52<08:29,  1.33s/it] 19%|█▊        | 88/471 [01:54<08:28,  1.33s/it] 19%|█▉        | 89/471 [01:55<08:26,  1.33s/it] 19%|█▉        | 90/471 [01:56<08:26,  1.33s/it] 19%|█▉        | 91/471 [01:58<08:24,  1.33s/it] 20%|█▉        | 92/471 [01:59<08:23,  1.33s/it] 20%|█▉        | 93/471 [02:00<08:22,  1.33s/it] 20%|█▉        | 94/471 [02:02<08:21,  1.33s/it] 20%|██        | 95/471 [02:03<08:19,  1.33s/it] 20%|██        | 96/471 [02:04<08:18,  1.33s/it] 21%|██        | 97/471 [02:06<08:17,  1.33s/it] 21%|██        | 98/471 [02:07<08:15,  1.33s/it] 21%|██        | 99/471 [02:08<08:14,  1.33s/it] 21%|██        | 100/471 [02:10<08:12,  1.33s/it] 21%|██▏       | 101/471 [02:11<08:12,  1.33s/it] 22%|██▏       | 102/471 [02:12<08:11,  1.33s/it] 22%|██▏       | 103/471 [02:14<08:08,  1.33s/it] 22%|██▏       | 104/471 [02:15<08:08,  1.33s/it] 22%|██▏       | 105/471 [02:16<08:07,  1.33s/it] 23%|██▎       | 106/471 [02:18<08:05,  1.33s/it] 23%|██▎       | 107/471 [02:19<08:04,  1.33s/it] 23%|██▎       | 108/471 [02:20<08:02,  1.33s/it] 23%|██▎       | 109/471 [02:22<08:01,  1.33s/it] 23%|██▎       | 110/471 [02:23<07:59,  1.33s/it] 24%|██▎       | 111/471 [02:24<07:58,  1.33s/it] 24%|██▍       | 112/471 [02:26<07:57,  1.33s/it] 24%|██▍       | 113/471 [02:27<07:55,  1.33s/it] 24%|██▍       | 114/471 [02:28<07:55,  1.33s/it] 24%|██▍       | 115/471 [02:30<07:54,  1.33s/it] 25%|██▍       | 116/471 [02:31<07:52,  1.33s/it] 25%|██▍       | 117/471 [02:32<07:51,  1.33s/it] 25%|██▌       | 118/471 [02:34<07:50,  1.33s/it] 25%|██▌       | 119/471 [02:35<07:49,  1.33s/it] 25%|██▌       | 120/471 [02:36<07:48,  1.34s/it] 26%|██▌       | 121/471 [02:38<07:47,  1.34s/it] 26%|██▌       | 122/471 [02:39<07:45,  1.33s/it] 26%|██▌       | 123/471 [02:40<07:44,  1.33s/it] 26%|██▋       | 124/471 [02:42<07:43,  1.33s/it] 27%|██▋       | 125/471 [02:43<07:42,  1.34s/it] 27%|██▋       | 126/471 [02:44<07:40,  1.34s/it] 27%|██▋       | 127/471 [02:46<07:39,  1.34s/it] 27%|██▋       | 128/471 [02:47<07:37,  1.33s/it] 27%|██▋       | 129/471 [02:48<07:36,  1.33s/it] 28%|██▊       | 130/471 [02:50<07:35,  1.34s/it] 28%|██▊       | 131/471 [02:51<07:34,  1.34s/it] 28%|██▊       | 132/471 [02:52<07:33,  1.34s/it] 28%|██▊       | 133/471 [02:54<07:31,  1.34s/it] 28%|██▊       | 134/471 [02:55<07:31,  1.34s/it] 29%|██▊       | 135/471 [02:56<07:29,  1.34s/it] 29%|██▉       | 136/471 [02:58<07:27,  1.34s/it] 29%|██▉       | 137/471 [02:59<07:26,  1.34s/it] 29%|██▉       | 138/471 [03:00<07:25,  1.34s/it] 30%|██▉       | 139/471 [03:02<07:23,  1.34s/it] 30%|██▉       | 140/471 [03:03<07:22,  1.34s/it] 30%|██▉       | 141/471 [03:04<07:21,  1.34s/it] 30%|███       | 142/471 [03:06<07:19,  1.34s/it] 30%|███       | 143/471 [03:07<07:17,  1.33s/it] 31%|███       | 144/471 [03:08<07:16,  1.34s/it] 31%|███       | 145/471 [03:10<07:14,  1.33s/it] 31%|███       | 146/471 [03:11<07:14,  1.34s/it] 31%|███       | 147/471 [03:12<07:12,  1.34s/it] 31%|███▏      | 148/471 [03:14<07:11,  1.34s/it] 32%|███▏      | 149/471 [03:15<07:10,  1.34s/it] 32%|███▏      | 150/471 [03:16<07:09,  1.34s/it] 32%|███▏      | 151/471 [03:18<07:07,  1.34s/it] 32%|███▏      | 152/471 [03:19<07:05,  1.34s/it] 32%|███▏      | 153/471 [03:20<07:04,  1.34s/it] 33%|███▎      | 154/471 [03:22<07:02,  1.33s/it] 33%|███▎      | 155/471 [03:23<07:01,  1.34s/it] 33%|███▎      | 156/471 [03:24<07:00,  1.33s/it] 33%|███▎      | 157/471 [03:26<06:58,  1.33s/it] 34%|███▎      | 158/471 [03:27<06:57,  1.33s/it] 34%|███▍      | 159/471 [03:28<06:55,  1.33s/it] 34%|███▍      | 160/471 [03:30<06:55,  1.33s/it] 34%|███▍      | 161/471 [03:31<06:53,  1.34s/it] 34%|███▍      | 162/471 [03:32<06:52,  1.33s/it] 35%|███▍      | 163/471 [03:34<06:51,  1.34s/it] 35%|███▍      | 164/471 [03:35<06:49,  1.33s/it] 35%|███▌      | 165/471 [03:36<06:48,  1.33s/it] 35%|███▌      | 166/471 [03:38<06:47,  1.34s/it] 35%|███▌      | 167/471 [03:39<06:46,  1.34s/it] 36%|███▌      | 168/471 [03:40<06:44,  1.34s/it] 36%|███▌      | 169/471 [03:42<06:43,  1.34s/it] 36%|███▌      | 170/471 [03:43<06:42,  1.34s/it] 36%|███▋      | 171/471 [03:44<06:40,  1.34s/it] 37%|███▋      | 172/471 [03:46<06:39,  1.33s/it] 37%|███▋      | 173/471 [03:47<06:37,  1.34s/it] 37%|███▋      | 174/471 [03:48<06:36,  1.33s/it] 37%|███▋      | 175/471 [03:50<06:35,  1.34s/it] 37%|███▋      | 176/471 [03:51<06:33,  1.33s/it] 38%|███▊      | 177/471 [03:52<06:32,  1.33s/it] 38%|███▊      | 178/471 [03:54<06:31,  1.34s/it] 38%|███▊      | 179/471 [03:55<06:29,  1.33s/it] 38%|███▊      | 180/471 [03:56<06:28,  1.33s/it] 38%|███▊      | 181/471 [03:58<06:27,  1.33s/it] 39%|███▊      | 182/471 [03:59<06:25,  1.34s/it] 39%|███▉      | 183/471 [04:00<06:24,  1.34s/it] 39%|███▉      | 184/471 [04:02<06:22,  1.33s/it] 39%|███▉      | 185/471 [04:03<06:21,  1.33s/it] 39%|███▉      | 186/471 [04:04<06:20,  1.34s/it] 40%|███▉      | 187/471 [04:06<06:19,  1.34s/it] 40%|███▉      | 188/471 [04:07<06:18,  1.34s/it] 40%|████      | 189/471 [04:08<06:16,  1.33s/it] 40%|████      | 190/471 [04:10<06:15,  1.33s/it] 41%|████      | 191/471 [04:11<06:14,  1.34s/it] 41%|████      | 192/471 [04:12<06:12,  1.34s/it] 41%|████      | 193/471 [04:14<06:10,  1.33s/it] 41%|████      | 194/471 [04:15<06:10,  1.34s/it] 41%|████▏     | 195/471 [04:16<06:08,  1.34s/it] 42%|████▏     | 196/471 [04:18<06:07,  1.34s/it] 42%|████▏     | 197/471 [04:19<06:05,  1.33s/it] 42%|████▏     | 198/471 [04:20<06:03,  1.33s/it] 42%|████▏     | 199/471 [04:22<06:02,  1.33s/it] 42%|████▏     | 200/471 [04:23<06:01,  1.34s/it] 43%|████▎     | 201/471 [04:24<05:59,  1.33s/it] 43%|████▎     | 202/471 [04:26<05:58,  1.33s/it] 43%|████▎     | 203/471 [04:27<05:57,  1.33s/it] 43%|████▎     | 204/471 [04:28<05:56,  1.33s/it] 44%|████▎     | 205/471 [04:30<05:54,  1.33s/it] 44%|████▎     | 206/471 [04:31<05:53,  1.33s/it] 44%|████▍     | 207/471 [04:32<05:52,  1.33s/it] 44%|████▍     | 208/471 [04:34<05:50,  1.33s/it] 44%|████▍     | 209/471 [04:35<05:49,  1.33s/it] 45%|████▍     | 210/471 [04:36<05:47,  1.33s/it] 45%|████▍     | 211/471 [04:38<05:46,  1.33s/it] 45%|████▌     | 212/471 [04:39<05:45,  1.33s/it] 45%|████▌     | 213/471 [04:40<05:44,  1.34s/it] 45%|████▌     | 214/471 [04:42<05:43,  1.34s/it] 46%|████▌     | 215/471 [04:43<05:41,  1.34s/it] 46%|████▌     | 216/471 [04:44<05:41,  1.34s/it] 46%|████▌     | 217/471 [04:46<05:39,  1.34s/it] 46%|████▋     | 218/471 [04:47<05:38,  1.34s/it] 46%|████▋     | 219/471 [04:48<05:37,  1.34s/it] 47%|████▋     | 220/471 [04:50<05:36,  1.34s/it] 47%|████▋     | 221/471 [04:51<05:34,  1.34s/it] 47%|████▋     | 222/471 [04:52<05:33,  1.34s/it] 47%|████▋     | 223/471 [04:54<05:32,  1.34s/it] 48%|████▊     | 224/471 [04:55<05:30,  1.34s/it] 48%|████▊     | 225/471 [04:56<05:29,  1.34s/it] 48%|████▊     | 226/471 [04:58<05:28,  1.34s/it] 48%|████▊     | 227/471 [04:59<05:26,  1.34s/it] 48%|████▊     | 228/471 [05:01<05:25,  1.34s/it] 49%|████▊     | 229/471 [05:02<05:24,  1.34s/it] 49%|████▉     | 230/471 [05:03<05:22,  1.34s/it] 49%|████▉     | 231/471 [05:05<05:21,  1.34s/it] 49%|████▉     | 232/471 [05:06<05:18,  1.33s/it] 49%|████▉     | 233/471 [05:07<05:17,  1.33s/it] 50%|████▉     | 234/471 [05:09<05:16,  1.34s/it] 50%|████▉     | 235/471 [05:10<05:15,  1.34s/it] 50%|█████     | 236/471 [05:11<05:13,  1.33s/it] 50%|█████     | 237/471 [05:13<05:11,  1.33s/it] 51%|█████     | 238/471 [05:14<05:10,  1.33s/it] 51%|█████     | 239/471 [05:15<05:09,  1.33s/it] 51%|█████     | 240/471 [05:17<05:08,  1.33s/it] 51%|█████     | 241/471 [05:18<05:06,  1.33s/it] 51%|█████▏    | 242/471 [05:19<05:05,  1.33s/it] 52%|█████▏    | 243/471 [05:21<05:04,  1.33s/it] 52%|█████▏    | 244/471 [05:22<05:03,  1.34s/it] 52%|█████▏    | 245/471 [05:23<05:01,  1.34s/it] 52%|█████▏    | 246/471 [05:25<05:00,  1.33s/it] 52%|█████▏    | 247/471 [05:26<04:58,  1.33s/it] 53%|█████▎    | 248/471 [05:27<04:57,  1.33s/it] 53%|█████▎    | 249/471 [05:29<04:56,  1.33s/it] 53%|█████▎    | 250/471 [05:30<04:54,  1.33s/it] 53%|█████▎    | 251/471 [05:31<04:53,  1.33s/it] 54%|█████▎    | 252/471 [05:33<04:51,  1.33s/it] 54%|█████▎    | 253/471 [05:34<04:50,  1.33s/it] 54%|█████▍    | 254/471 [05:35<04:49,  1.33s/it] 54%|█████▍    | 255/471 [05:37<04:47,  1.33s/it] 54%|█████▍    | 256/471 [05:38<04:46,  1.33s/it] 55%|█████▍    | 257/471 [05:39<04:45,  1.33s/it] 55%|█████▍    | 258/471 [05:41<04:44,  1.33s/it] 55%|█████▍    | 259/471 [05:42<04:43,  1.34s/it] 55%|█████▌    | 260/471 [05:43<04:41,  1.34s/it] 55%|█████▌    | 261/471 [05:45<04:40,  1.33s/it] 56%|█████▌    | 262/471 [05:46<04:38,  1.33s/it] 56%|█████▌    | 263/471 [05:47<04:37,  1.33s/it] 56%|█████▌    | 264/471 [05:49<04:35,  1.33s/it] 56%|█████▋    | 265/471 [05:50<04:34,  1.33s/it] 56%|█████▋    | 266/471 [05:51<04:33,  1.33s/it] 57%|█████▋    | 267/471 [05:53<04:32,  1.33s/it] 57%|█████▋    | 268/471 [05:54<04:31,  1.34s/it] 57%|█████▋    | 269/471 [05:55<04:29,  1.33s/it] 57%|█████▋    | 270/471 [05:57<04:28,  1.33s/it] 58%|█████▊    | 271/471 [05:58<04:26,  1.33s/it] 58%|█████▊    | 272/471 [05:59<04:25,  1.33s/it] 58%|█████▊    | 273/471 [06:01<04:24,  1.33s/it] 58%|█████▊    | 274/471 [06:02<04:22,  1.33s/it] 58%|█████▊    | 275/471 [06:03<04:21,  1.33s/it] 59%|█████▊    | 276/471 [06:05<04:20,  1.33s/it] 59%|█████▉    | 277/471 [06:06<04:18,  1.33s/it] 59%|█████▉    | 278/471 [06:07<04:18,  1.34s/it] 59%|█████▉    | 279/471 [06:09<04:16,  1.33s/it] 59%|█████▉    | 280/471 [06:10<04:14,  1.33s/it] 60%|█████▉    | 281/471 [06:11<04:13,  1.33s/it] 60%|█████▉    | 282/471 [06:13<04:11,  1.33s/it] 60%|██████    | 283/471 [06:14<04:10,  1.33s/it] 60%|██████    | 284/471 [06:15<04:09,  1.33s/it] 61%|██████    | 285/471 [06:17<04:08,  1.33s/it] 61%|██████    | 286/471 [06:18<04:06,  1.33s/it] 61%|██████    | 287/471 [06:19<04:05,  1.33s/it] 61%|██████    | 288/471 [06:21<04:04,  1.34s/it] 61%|██████▏   | 289/471 [06:22<04:02,  1.33s/it] 62%|██████▏   | 290/471 [06:23<04:01,  1.33s/it] 62%|██████▏   | 291/471 [06:25<04:00,  1.33s/it] 62%|██████▏   | 292/471 [06:26<03:58,  1.33s/it] 62%|██████▏   | 293/471 [06:27<03:57,  1.33s/it] 62%|██████▏   | 294/471 [06:29<03:56,  1.33s/it] 63%|██████▎   | 295/471 [06:30<03:54,  1.33s/it] 63%|██████▎   | 296/471 [06:31<03:53,  1.33s/it] 63%|██████▎   | 297/471 [06:33<03:51,  1.33s/it] 63%|██████▎   | 298/471 [06:34<03:50,  1.34s/it] 63%|██████▎   | 299/471 [06:35<03:49,  1.33s/it] 64%|██████▎   | 300/471 [06:37<03:48,  1.33s/it] 64%|██████▍   | 301/471 [06:38<03:46,  1.33s/it] 64%|██████▍   | 302/471 [06:39<03:45,  1.33s/it] 64%|██████▍   | 303/471 [06:41<03:43,  1.33s/it] 65%|██████▍   | 304/471 [06:42<03:42,  1.33s/it] 65%|██████▍   | 305/471 [06:43<03:40,  1.33s/it] 65%|██████▍   | 306/471 [06:45<03:40,  1.33s/it] 65%|██████▌   | 307/471 [06:46<03:38,  1.33s/it] 65%|██████▌   | 308/471 [06:47<03:37,  1.34s/it] 66%|██████▌   | 309/471 [06:49<03:36,  1.34s/it] 66%|██████▌   | 310/471 [06:50<03:34,  1.33s/it] 66%|██████▌   | 311/471 [06:51<03:33,  1.33s/it] 66%|██████▌   | 312/471 [06:53<03:32,  1.33s/it] 66%|██████▋   | 313/471 [06:54<03:30,  1.33s/it] 67%|██████▋   | 314/471 [06:55<03:29,  1.33s/it] 67%|██████▋   | 315/471 [06:57<03:28,  1.33s/it] 67%|██████▋   | 316/471 [06:58<03:26,  1.33s/it] 67%|██████▋   | 317/471 [06:59<03:25,  1.33s/it] 68%|██████▊   | 318/471 [07:01<03:24,  1.33s/it] 68%|██████▊   | 319/471 [07:02<03:22,  1.33s/it] 68%|██████▊   | 320/471 [07:03<03:21,  1.33s/it] 68%|██████▊   | 321/471 [07:05<03:20,  1.33s/it] 68%|██████▊   | 322/471 [07:06<03:18,  1.33s/it] 69%|██████▊   | 323/471 [07:07<03:17,  1.34s/it] 69%|██████▉   | 324/471 [07:09<03:16,  1.34s/it] 69%|██████▉   | 325/471 [07:10<03:15,  1.34s/it] 69%|██████▉   | 326/471 [07:11<03:13,  1.33s/it] 69%|██████▉   | 327/471 [07:13<03:11,  1.33s/it] 70%|██████▉   | 328/471 [07:14<03:10,  1.33s/it] 70%|██████▉   | 329/471 [07:15<03:09,  1.33s/it] 70%|███████   | 330/471 [07:17<03:07,  1.33s/it] 70%|███████   | 331/471 [07:18<03:06,  1.33s/it] 70%|███████   | 332/471 [07:19<03:05,  1.33s/it] 71%|███████   | 333/471 [07:21<03:03,  1.33s/it] 71%|███████   | 334/471 [07:22<03:02,  1.33s/it] 71%|███████   | 335/471 [07:23<03:01,  1.33s/it] 71%|███████▏  | 336/471 [07:25<02:59,  1.33s/it] 72%|███████▏  | 337/471 [07:26<02:58,  1.33s/it] 72%|███████▏  | 338/471 [07:27<02:57,  1.33s/it] 72%|███████▏  | 339/471 [07:29<02:56,  1.33s/it] 72%|███████▏  | 340/471 [07:30<02:54,  1.33s/it] 72%|███████▏  | 341/471 [07:31<02:53,  1.33s/it] 73%|███████▎  | 342/471 [07:33<02:51,  1.33s/it] 73%|███████▎  | 343/471 [07:34<02:50,  1.33s/it] 73%|███████▎  | 344/471 [07:35<02:49,  1.33s/it] 73%|███████▎  | 345/471 [07:37<02:48,  1.33s/it] 73%|███████▎  | 346/471 [07:38<02:46,  1.34s/it] 74%|███████▎  | 347/471 [07:39<02:45,  1.33s/it] 74%|███████▍  | 348/471 [07:41<02:44,  1.33s/it] 74%|███████▍  | 349/471 [07:42<02:43,  1.34s/it] 74%|███████▍  | 350/471 [07:43<02:41,  1.34s/it] 75%|███████▍  | 351/471 [07:45<02:39,  1.33s/it] 75%|███████▍  | 352/471 [07:46<02:38,  1.34s/it] 75%|███████▍  | 353/471 [07:47<02:37,  1.34s/it] 75%|███████▌  | 354/471 [07:49<02:36,  1.34s/it] 75%|███████▌  | 355/471 [07:50<02:35,  1.34s/it] 76%|███████▌  | 356/471 [07:51<02:33,  1.34s/it] 76%|███████▌  | 357/471 [07:53<02:32,  1.34s/it] 76%|███████▌  | 358/471 [07:54<02:30,  1.34s/it] 76%|███████▌  | 359/471 [07:55<02:29,  1.34s/it] 76%|███████▋  | 360/471 [07:57<02:27,  1.33s/it] 77%|███████▋  | 361/471 [07:58<02:26,  1.33s/it] 77%|███████▋  | 362/471 [07:59<02:25,  1.33s/it] 77%|███████▋  | 363/471 [08:01<02:23,  1.33s/it] 77%|███████▋  | 364/471 [08:02<02:22,  1.33s/it] 77%|███████▋  | 365/471 [08:03<02:21,  1.33s/it] 78%|███████▊  | 366/471 [08:05<02:20,  1.34s/it] 78%|███████▊  | 367/471 [08:06<02:18,  1.33s/it] 78%|███████▊  | 368/471 [08:07<02:17,  1.33s/it] 78%|███████▊  | 369/471 [08:09<02:15,  1.33s/it] 79%|███████▊  | 370/471 [08:10<02:14,  1.33s/it] 79%|███████▉  | 371/471 [08:11<02:13,  1.33s/it] 79%|███████▉  | 372/471 [08:13<02:11,  1.33s/it] 79%|███████▉  | 373/471 [08:14<02:10,  1.33s/it] 79%|███████▉  | 374/471 [08:15<02:09,  1.33s/it] 80%|███████▉  | 375/471 [08:17<02:07,  1.33s/it] 80%|███████▉  | 376/471 [08:18<02:06,  1.33s/it] 80%|████████  | 377/471 [08:19<02:05,  1.33s/it] 80%|████████  | 378/471 [08:21<02:03,  1.33s/it] 80%|████████  | 379/471 [08:22<02:02,  1.33s/it] 81%|████████  | 380/471 [08:23<02:01,  1.33s/it] 81%|████████  | 381/471 [08:25<01:59,  1.33s/it] 81%|████████  | 382/471 [08:26<01:58,  1.33s/it] 81%|████████▏ | 383/471 [08:27<01:57,  1.33s/it] 82%|████████▏ | 384/471 [08:29<01:56,  1.33s/it] 82%|████████▏ | 385/471 [08:30<01:54,  1.33s/it] 82%|████████▏ | 386/471 [08:31<01:53,  1.33s/it] 82%|████████▏ | 387/471 [08:33<01:51,  1.33s/it] 82%|████████▏ | 388/471 [08:34<01:50,  1.33s/it] 83%|████████▎ | 389/471 [08:35<01:49,  1.33s/it] 83%|████████▎ | 390/471 [08:37<01:47,  1.33s/it] 83%|████████▎ | 391/471 [08:38<01:46,  1.33s/it] 83%|████████▎ | 392/471 [08:39<01:45,  1.33s/it] 83%|████████▎ | 393/471 [08:41<01:43,  1.33s/it] 84%|████████▎ | 394/471 [08:42<01:42,  1.33s/it] 84%|████████▍ | 395/471 [08:43<01:41,  1.33s/it] 84%|████████▍ | 396/471 [08:45<01:39,  1.33s/it] 84%|████████▍ | 397/471 [08:46<01:38,  1.33s/it] 85%|████████▍ | 398/471 [08:47<01:37,  1.33s/it] 85%|████████▍ | 399/471 [08:49<01:35,  1.33s/it] 85%|████████▍ | 400/471 [08:50<01:34,  1.33s/it] 85%|████████▌ | 401/471 [08:51<01:33,  1.33s/it] 85%|████████▌ | 402/471 [08:53<01:31,  1.33s/it] 86%|████████▌ | 403/471 [08:54<01:30,  1.33s/it] 86%|████████▌ | 404/471 [08:55<01:28,  1.33s/it] 86%|████████▌ | 405/471 [08:57<01:27,  1.33s/it] 86%|████████▌ | 406/471 [08:58<01:26,  1.33s/it] 86%|████████▋ | 407/471 [08:59<01:24,  1.33s/it] 87%|████████▋ | 408/471 [09:00<01:23,  1.33s/it] 87%|████████▋ | 409/471 [09:02<01:22,  1.33s/it] 87%|████████▋ | 410/471 [09:03<01:20,  1.33s/it] 87%|████████▋ | 411/471 [09:04<01:19,  1.33s/it] 87%|████████▋ | 412/471 [09:06<01:18,  1.33s/it] 88%|████████▊ | 413/471 [09:07<01:17,  1.33s/it] 88%|████████▊ | 414/471 [09:08<01:15,  1.33s/it] 88%|████████▊ | 415/471 [09:10<01:14,  1.33s/it] 88%|████████▊ | 416/471 [09:11<01:13,  1.33s/it] 89%|████████▊ | 417/471 [09:12<01:11,  1.33s/it] 89%|████████▊ | 418/471 [09:14<01:10,  1.33s/it] 89%|████████▉ | 419/471 [09:15<01:09,  1.33s/it] 89%|████████▉ | 420/471 [09:16<01:07,  1.33s/it] 89%|████████▉ | 421/471 [09:18<01:06,  1.33s/it] 90%|████████▉ | 422/471 [09:19<01:04,  1.33s/it] 90%|████████▉ | 423/471 [09:20<01:03,  1.33s/it] 90%|█████████ | 424/471 [09:22<01:02,  1.33s/it] 90%|█████████ | 425/471 [09:23<01:01,  1.33s/it] 90%|█████████ | 426/471 [09:24<00:59,  1.33s/it] 91%|█████████ | 427/471 [09:26<00:58,  1.33s/it] 91%|█████████ | 428/471 [09:27<00:57,  1.33s/it] 91%|█████████ | 429/471 [09:28<00:55,  1.33s/it] 91%|█████████▏| 430/471 [09:30<00:54,  1.33s/it] 92%|█████████▏| 431/471 [09:31<00:53,  1.33s/it] 92%|█████████▏| 432/471 [09:32<00:52,  1.33s/it] 92%|█████████▏| 433/471 [09:34<00:50,  1.33s/it] 92%|█████████▏| 434/471 [09:35<00:49,  1.34s/it] 92%|█████████▏| 435/471 [09:36<00:48,  1.34s/it] 93%|█████████▎| 436/471 [09:38<00:46,  1.33s/it] 93%|█████████▎| 437/471 [09:39<00:45,  1.34s/it] 93%|█████████▎| 438/471 [09:40<00:44,  1.34s/it] 93%|█████████▎| 439/471 [09:42<00:42,  1.34s/it] 93%|█████████▎| 440/471 [09:43<00:41,  1.34s/it] 94%|█████████▎| 441/471 [09:44<00:40,  1.34s/it] 94%|█████████▍| 442/471 [09:46<00:38,  1.34s/it] 94%|█████████▍| 443/471 [09:47<00:37,  1.34s/it] 94%|█████████▍| 444/471 [09:48<00:36,  1.34s/it] 94%|█████████▍| 445/471 [09:50<00:34,  1.34s/it] 95%|█████████▍| 446/471 [09:51<00:33,  1.34s/it] 95%|█████████▍| 447/471 [09:52<00:32,  1.34s/it] 95%|█████████▌| 448/471 [09:54<00:30,  1.34s/it] 95%|█████████▌| 449/471 [09:55<00:29,  1.34s/it] 96%|█████████▌| 450/471 [09:57<00:28,  1.34s/it] 96%|█████████▌| 451/471 [09:58<00:26,  1.34s/it] 96%|█████████▌| 452/471 [09:59<00:25,  1.34s/it] 96%|█████████▌| 453/471 [10:01<00:24,  1.34s/it] 96%|█████████▋| 454/471 [10:02<00:22,  1.34s/it] 97%|█████████▋| 455/471 [10:03<00:21,  1.34s/it] 97%|█████████▋| 456/471 [10:05<00:20,  1.34s/it] 97%|█████████▋| 457/471 [10:06<00:18,  1.34s/it] 97%|█████████▋| 458/471 [10:07<00:17,  1.34s/it] 97%|█████████▋| 459/471 [10:09<00:16,  1.34s/it] 98%|█████████▊| 460/471 [10:10<00:14,  1.34s/it] 98%|█████████▊| 461/471 [10:11<00:13,  1.34s/it] 98%|█████████▊| 462/471 [10:13<00:12,  1.34s/it] 98%|█████████▊| 463/471 [10:14<00:10,  1.34s/it] 99%|█████████▊| 464/471 [10:15<00:09,  1.34s/it] 99%|█████████▊| 465/471 [10:17<00:08,  1.34s/it] 99%|█████████▉| 466/471 [10:18<00:06,  1.34s/it] 99%|█████████▉| 467/471 [10:19<00:05,  1.34s/it] 99%|█████████▉| 468/471 [10:21<00:04,  1.34s/it]100%|█████████▉| 469/471 [10:22<00:02,  1.34s/it]100%|█████████▉| 470/471 [10:23<00:01,  1.34s/it]100%|██████████| 471/471 [10:24<00:00,  1.23s/it]100%|██████████| 471/471 [10:24<00:00,  1.33s/it]
{'eval_loss': 2.5740537643432617, 'eval_model_preparation_time': 0.0116, 'eval_acc': 0.3357673924588423, 'eval_runtime': 626.0708, 'eval_samples_per_second': 12.031, 'eval_steps_per_second': 0.752}
ROUND:16
CLIENT:7
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.63s/it]                                              {'loss': 3.0021, 'grad_norm': 11.262046813964844, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.63s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 1.3714, 'grad_norm': 12.198298454284668, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:24,  2.28s/it]                                              {'loss': 1.9647, 'grad_norm': 15.33249282836914, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 3.8522, 'grad_norm': 33.082763671875, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 2.6836, 'grad_norm': 22.560367584228516, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 0.6698, 'grad_norm': 7.239158630371094, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it]                                              {'loss': 2.7018, 'grad_norm': 44.04751205444336, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.19s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 0.1493, 'grad_norm': 8.907648086547852, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 1.7153, 'grad_norm': 13.115954399108887, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 0.7393, 'grad_norm': 7.814633369445801, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.1135, 'grad_norm': 8.35081958770752, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.6471, 'grad_norm': 8.257609367370605, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 1.3871, 'grad_norm': 10.702800750732422, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 1.2976, 'grad_norm': 14.862685203552246, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 2.1081, 'grad_norm': 19.0615234375, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 2.4154, 'grad_norm': 56.854068756103516, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.9546, 'grad_norm': 11.23813533782959, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.2872, 'grad_norm': 4.680184841156006, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.8959, 'grad_norm': 6.543556213378906, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.4647, 'grad_norm': 8.752449989318848, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.4398, 'grad_norm': 5.353169918060303, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it]                                               {'loss': 0.3877, 'grad_norm': 7.120201587677002, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.3302, 'grad_norm': 4.255829334259033, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0177, 'grad_norm': 1.046844482421875, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0822, 'grad_norm': 1.8390668630599976, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.4966, 'grad_norm': 6.3086323738098145, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it]                                               {'loss': 0.6244, 'grad_norm': 14.112585067749023, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:25,  2.08s/it]                                               {'loss': 0.7669, 'grad_norm': 4.077820777893066, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.2187, 'grad_norm': 12.562333106994629, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.1437, 'grad_norm': 1.9133105278015137, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.3063, 'grad_norm': 8.082839012145996, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0661, 'grad_norm': 3.8494372367858887, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0581, 'grad_norm': 1.7784687280654907, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.0889, 'grad_norm': 1.1972163915634155, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it]                                               {'loss': 0.3585, 'grad_norm': 2.284032106399536, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.15, 'grad_norm': 0.8454241752624512, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.2106, 'grad_norm': 1.985662817955017, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.0993, 'grad_norm': 2.2600345611572266, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]                                               {'loss': 0.0364, 'grad_norm': 1.2577165365219116, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.1796, 'grad_norm': 10.069777488708496, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.6366, 'train_samples_per_second': 7.095, 'train_steps_per_second': 0.502, 'train_loss': 0.8870541244279593, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:25
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:43,  2.65s/it]                                              {'loss': 2.1092, 'grad_norm': 10.323774337768555, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:43,  2.65s/it]  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]                                              {'loss': 1.3386, 'grad_norm': 9.485785484313965, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]  8%|▊         | 3/40 [00:06<01:23,  2.25s/it]                                              {'loss': 1.5111, 'grad_norm': 9.540580749511719, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.25s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 2.6206, 'grad_norm': 17.003963470458984, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 3.1109, 'grad_norm': 12.621609687805176, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 3.758, 'grad_norm': 19.333467483520508, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.18s/it]                                              {'loss': 2.5315, 'grad_norm': 13.998185157775879, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 0.4277, 'grad_norm': 16.883047103881836, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it]                                              {'loss': 0.8471, 'grad_norm': 7.1850128173828125, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:53,  1.74s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.87s/it]                                               {'loss': 1.3426, 'grad_norm': 10.258281707763672, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.87s/it] 28%|██▊       | 11/40 [00:22<00:56,  1.96s/it]                                               {'loss': 1.6846, 'grad_norm': 11.24859619140625, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:56,  1.96s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 0.3653, 'grad_norm': 5.724798202514648, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it]                                               {'loss': 0.9849, 'grad_norm': 12.337224960327148, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it]                                               {'loss': 0.6917, 'grad_norm': 8.08702564239502, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it]                                               {'loss': 1.3494, 'grad_norm': 9.37833023071289, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 1.0645, 'grad_norm': 49.341827392578125, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.6428, 'grad_norm': 15.052634239196777, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.3157, 'grad_norm': 5.26249885559082, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it]                                               {'loss': 0.4126, 'grad_norm': 5.755688190460205, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it] 50%|█████     | 20/40 [00:40<00:41,  2.05s/it]                                               {'loss': 0.4862, 'grad_norm': 6.703029155731201, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.05s/it] 52%|█████▎    | 21/40 [00:42<00:39,  2.09s/it]                                               {'loss': 0.8561, 'grad_norm': 17.679668426513672, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:39,  2.09s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.13s/it]                                               {'loss': 0.4665, 'grad_norm': 6.611131191253662, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.13s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it]                                               {'loss': 0.2001, 'grad_norm': 5.577059268951416, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0136, 'grad_norm': 0.7130862474441528, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.2312, 'grad_norm': 4.244512557983398, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it]                                               {'loss': 0.0717, 'grad_norm': 1.5469509363174438, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it]                                               {'loss': 0.1342, 'grad_norm': 2.1190996170043945, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.00s/it] 70%|███████   | 28/40 [00:55<00:24,  2.07s/it]                                               {'loss': 0.477, 'grad_norm': 5.1545915603637695, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.1167, 'grad_norm': 2.850985288619995, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 0.2703, 'grad_norm': 4.456891059875488, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it]                                               {'loss': 0.3556, 'grad_norm': 3.6120715141296387, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it] 80%|████████  | 32/40 [01:02<00:12,  1.59s/it]                                               {'loss': 0.0013, 'grad_norm': 0.07552852481603622, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it]                                               {'loss': 0.3676, 'grad_norm': 6.808084964752197, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.6277, 'grad_norm': 7.096702575683594, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.0934, 'grad_norm': 1.768865704536438, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it]                                               {'loss': 0.1156, 'grad_norm': 3.8258049488067627, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.1001, 'grad_norm': 1.9882088899612427, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.0468, 'grad_norm': 1.214806318283081, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]                                               {'loss': 0.1607, 'grad_norm': 4.138467311859131, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'loss': 0.0109, 'grad_norm': 0.7099981307983398, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'train_runtime': 79.1442, 'train_samples_per_second': 7.139, 'train_steps_per_second': 0.505, 'train_loss': 0.8077989557496039, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:71
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]                                              {'loss': 2.3142, 'grad_norm': 9.285298347473145, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]  5%|▌         | 2/40 [00:04<01:30,  2.38s/it]                                              {'loss': 1.4061, 'grad_norm': 9.47742748260498, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.38s/it]  8%|▊         | 3/40 [00:07<01:24,  2.29s/it]                                              {'loss': 1.9837, 'grad_norm': 12.615942001342773, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 1.3624, 'grad_norm': 15.232136726379395, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it]                                              {'loss': 1.2335, 'grad_norm': 18.453453063964844, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.1276, 'grad_norm': 14.404644966125488, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it]                                              {'loss': 1.225, 'grad_norm': 12.463695526123047, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 0.986, 'grad_norm': 41.25775909423828, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 1.003, 'grad_norm': 9.31396484375, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 0.5384, 'grad_norm': 5.346309661865234, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.6743, 'grad_norm': 8.86038875579834, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.9245, 'grad_norm': 7.177049160003662, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 0.8886, 'grad_norm': 11.847139358520508, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 0.4039, 'grad_norm': 5.782756805419922, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it]                                               {'loss': 0.2573, 'grad_norm': 3.461487293243408, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.20s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.4373, 'grad_norm': 20.430761337280273, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.80s/it]                                               {'loss': 0.2525, 'grad_norm': 6.887282848358154, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.1761, 'grad_norm': 5.059324264526367, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:39<00:44,  2.14s/it]                                               {'loss': 0.2731, 'grad_norm': 15.1843843460083, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:39<00:44,  2.14s/it] 50%|█████     | 20/40 [00:41<00:43,  2.16s/it]                                               {'loss': 0.1746, 'grad_norm': 2.928955078125, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:43,  2.16s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it]                                               {'loss': 0.26, 'grad_norm': 11.301092147827148, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.19s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.6375, 'grad_norm': 10.398499488830566, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.22s/it]                                               {'loss': 0.1925, 'grad_norm': 3.6735243797302246, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.22s/it] 60%|██████    | 24/40 [00:48<00:25,  1.61s/it]                                               {'loss': 0.1007, 'grad_norm': 4.4153571128845215, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.062, 'grad_norm': 1.2246724367141724, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.0379, 'grad_norm': 0.6888431310653687, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it]                                               {'loss': 0.0618, 'grad_norm': 1.5818705558776855, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.05s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.5056, 'grad_norm': 4.372646808624268, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it]                                               {'loss': 0.305, 'grad_norm': 5.831672668457031, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.2415, 'grad_norm': 0.8392529487609863, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it]                                               {'loss': 0.0301, 'grad_norm': 0.4994252920150757, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:19,  2.21s/it] 80%|████████  | 32/40 [01:04<00:12,  1.60s/it]                                               {'loss': 0.3665, 'grad_norm': 11.3973388671875, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.0274, 'grad_norm': 0.8499776721000671, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.075, 'grad_norm': 1.63822603225708, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it]                                               {'loss': 0.2984, 'grad_norm': 19.067747116088867, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.11s/it]                                               {'loss': 0.2751, 'grad_norm': 3.9463493824005127, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.0285, 'grad_norm': 0.6065854430198669, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.20s/it]                                               {'loss': 0.0488, 'grad_norm': 1.2405047416687012, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.1474, 'grad_norm': 22.651493072509766, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.0264, 'grad_norm': 1.2933038473129272, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.768, 'train_samples_per_second': 6.995, 'train_steps_per_second': 0.495, 'train_loss': 0.5592549979221075, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:42
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:29,  2.28s/it]                                              {'loss': 1.6844, 'grad_norm': 9.69314193725586, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:29,  2.28s/it]  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]                                              {'loss': 1.7036, 'grad_norm': 10.487908363342285, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 1.4875, 'grad_norm': 12.14826774597168, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 1.6566, 'grad_norm': 17.184368133544922, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 1.8708, 'grad_norm': 24.588958740234375, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 2.0379, 'grad_norm': 11.789048194885254, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 1.3964, 'grad_norm': 14.31955623626709, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.6533, 'grad_norm': 23.04846954345703, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.79s/it]                                              {'loss': 2.4593, 'grad_norm': 19.554786682128906, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.9574, 'grad_norm': 8.572983741760254, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 1.3443, 'grad_norm': 6.8349199295043945, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 1.3973, 'grad_norm': 4.881557941436768, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it]                                               {'loss': 1.8548, 'grad_norm': 12.234365463256836, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.19s/it]                                               {'loss': 1.0086, 'grad_norm': 6.794747352600098, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.19s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.7415, 'grad_norm': 4.856071472167969, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 1.0017, 'grad_norm': 36.28028869628906, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:42,  1.86s/it]                                               {'loss': 0.2554, 'grad_norm': 5.857054233551025, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:42,  1.86s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it]                                               {'loss': 0.247, 'grad_norm': 5.896627902984619, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it]                                               {'loss': 0.3025, 'grad_norm': 7.802775859832764, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.05s/it] 50%|█████     | 20/40 [00:40<00:42,  2.11s/it]                                               {'loss': 0.4527, 'grad_norm': 4.584534645080566, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.16s/it]                                               {'loss': 0.2301, 'grad_norm': 3.7413697242736816, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.16s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.2628, 'grad_norm': 4.0655012130737305, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.432, 'grad_norm': 5.007187843322754, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.0116, 'grad_norm': 0.5334214568138123, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it]                                               {'loss': 0.1837, 'grad_norm': 3.8222906589508057, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it]                                               {'loss': 0.1512, 'grad_norm': 1.1462550163269043, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.0528, 'grad_norm': 1.9053736925125122, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.2348, 'grad_norm': 3.2839272022247314, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it]                                               {'loss': 0.1149, 'grad_norm': 5.009396076202393, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.0841, 'grad_norm': 2.332167863845825, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it]                                               {'loss': 0.2784, 'grad_norm': 3.7224583625793457, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.4378, 'grad_norm': 20.580554962158203, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it]                                               {'loss': 0.0316, 'grad_norm': 1.8726766109466553, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it]                                               {'loss': 0.2416, 'grad_norm': 3.270563840866089, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.0536, 'grad_norm': 0.958561897277832, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0364, 'grad_norm': 0.7861185669898987, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.15s/it]                                               {'loss': 0.057, 'grad_norm': 1.583802580833435, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.4277, 'grad_norm': 2.729778289794922, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.1033, 'grad_norm': 1.7225838899612427, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0083, 'grad_norm': 0.46412548422813416, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.1037, 'train_samples_per_second': 7.053, 'train_steps_per_second': 0.499, 'train_loss': 0.6986703521106392, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:47
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:43,  2.64s/it]                                              {'loss': 2.5939, 'grad_norm': 12.572566032409668, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:43,  2.64s/it]  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]                                              {'loss': 1.7803, 'grad_norm': 9.279949188232422, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.36s/it]  8%|▊         | 3/40 [00:07<01:24,  2.30s/it]                                              {'loss': 1.551, 'grad_norm': 17.737504959106445, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.30s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 2.4928, 'grad_norm': 18.666677474975586, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 1.0602, 'grad_norm': 11.854989051818848, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.8174, 'grad_norm': 23.174711227416992, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.8709, 'grad_norm': 20.2039737701416, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 0.0085, 'grad_norm': 0.6017375588417053, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 1.1549, 'grad_norm': 11.168834686279297, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it]                                               {'loss': 0.8117, 'grad_norm': 7.957635402679443, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 1.4984, 'grad_norm': 8.022688865661621, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.3064, 'grad_norm': 3.4616949558258057, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it]                                               {'loss': 0.7457, 'grad_norm': 7.8086090087890625, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it]                                               {'loss': 0.9332, 'grad_norm': 7.366408348083496, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 1.1845, 'grad_norm': 12.974841117858887, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 0.0152, 'grad_norm': 0.8906823992729187, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.9146, 'grad_norm': 15.719918251037598, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it]                                               {'loss': 0.5702, 'grad_norm': 10.833150863647461, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it] 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it]                                               {'loss': 0.1714, 'grad_norm': 3.781435489654541, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  1.99s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.3373, 'grad_norm': 5.3691606521606445, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.7978, 'grad_norm': 6.125762462615967, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.2147, 'grad_norm': 3.3552632331848145, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.1771, 'grad_norm': 2.4134182929992676, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0079, 'grad_norm': 0.4704066216945648, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.76s/it]                                               {'loss': 0.3467, 'grad_norm': 19.35590362548828, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.76s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.2965, 'grad_norm': 4.852041244506836, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it]                                               {'loss': 0.0708, 'grad_norm': 1.5039619207382202, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.0558, 'grad_norm': 1.85666823387146, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.1014, 'grad_norm': 2.8186933994293213, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it]                                               {'loss': 0.1319, 'grad_norm': 6.916778087615967, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.7857, 'grad_norm': 36.12211990356445, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 1.4478, 'grad_norm': 43.023311614990234, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.1023, 'grad_norm': 2.5037271976470947, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.0399, 'grad_norm': 1.0241190195083618, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.1664, 'grad_norm': 7.883434295654297, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.0564, 'grad_norm': 1.409029245376587, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.149, 'grad_norm': 4.175565242767334, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.0365, 'grad_norm': 0.6876519918441772, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.1732, 'grad_norm': 2.8781521320343018, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0, 'grad_norm': 0.001863167155534029, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.544, 'train_samples_per_second': 7.103, 'train_steps_per_second': 0.503, 'train_loss': 0.6994097531446186, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:29
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]                                              {'loss': 2.4774, 'grad_norm': 10.961559295654297, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]                                              {'loss': 1.424, 'grad_norm': 10.526344299316406, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.37s/it]  8%|▊         | 3/40 [00:07<01:24,  2.29s/it]                                              {'loss': 3.0457, 'grad_norm': 16.660104751586914, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:20,  2.25s/it]                                              {'loss': 2.0671, 'grad_norm': 14.772588729858398, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 2.7922, 'grad_norm': 18.513687133789062, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 1.8031, 'grad_norm': 14.72372055053711, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 2.1106, 'grad_norm': 13.828984260559082, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:16<00:50,  1.58s/it]                                              {'loss': 4.1744, 'grad_norm': 65.87797546386719, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 0.3196, 'grad_norm': 5.377609729766846, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it]                                               {'loss': 0.7922, 'grad_norm': 7.322246551513672, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.845, 'grad_norm': 9.517141342163086, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.9762, 'grad_norm': 40.66070556640625, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 1.3096, 'grad_norm': 10.191739082336426, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 1.5037, 'grad_norm': 12.1967134475708, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.9684, 'grad_norm': 9.001538276672363, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 5.1808, 'grad_norm': 253.59005737304688, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it]                                               {'loss': 0.1961, 'grad_norm': 4.148166656494141, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it]                                               {'loss': 0.7078, 'grad_norm': 28.439210891723633, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it]                                               {'loss': 0.4491, 'grad_norm': 27.51275634765625, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.4019, 'grad_norm': 9.276062965393066, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 0.2604, 'grad_norm': 3.881121873855591, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it]                                               {'loss': 0.1491, 'grad_norm': 2.6522457599639893, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.3911, 'grad_norm': 6.132419109344482, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.1344, 'grad_norm': 6.331327438354492, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.4081, 'grad_norm': 16.850252151489258, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it]                                               {'loss': 0.2869, 'grad_norm': 3.9256105422973633, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.1339, 'grad_norm': 3.9303712844848633, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.2063, 'grad_norm': 4.909506797790527, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it]                                               {'loss': 0.4651, 'grad_norm': 6.439029693603516, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.212, 'grad_norm': 4.443492412567139, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.0593, 'grad_norm': 3.419583559036255, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0885, 'grad_norm': 4.941916465759277, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0363, 'grad_norm': 1.859474539756775, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.0473, 'grad_norm': 1.5905057191848755, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.7244, 'grad_norm': 4.173947334289551, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.0769, 'grad_norm': 1.4740859270095825, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.0839, 'grad_norm': 1.5719897747039795, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.059, 'grad_norm': 1.3865704536437988, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.0371, 'grad_norm': 1.020281434059143, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0246, 'grad_norm': 1.5643271207809448, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 80.0539, 'train_samples_per_second': 7.058, 'train_steps_per_second': 0.5, 'train_loss': 0.935740947118029, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.60s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]                                              {'loss': 2.8087, 'grad_norm': 10.614384651184082, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.67s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 2.1857, 'grad_norm': 10.49743938446045, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 1.962, 'grad_norm': 11.81297492980957, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:19,  2.21s/it]                                              {'loss': 3.2665, 'grad_norm': 12.583456993103027, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it]                                              {'loss': 2.0651, 'grad_norm': 12.186141967773438, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 2.7909, 'grad_norm': 13.741070747375488, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.5102, 'grad_norm': 14.96394157409668, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 8.1388, 'grad_norm': 67.22493743896484, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 1.0317, 'grad_norm': 18.713865280151367, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.0818, 'grad_norm': 16.3772029876709, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.7809, 'grad_norm': 12.923381805419922, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 0.6472, 'grad_norm': 11.195937156677246, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it]                                               {'loss': 0.8723, 'grad_norm': 11.709145545959473, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it] 35%|███▌      | 14/40 [00:29<00:54,  2.11s/it]                                               {'loss': 0.4626, 'grad_norm': 3.365902900695801, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:54,  2.11s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it]                                               {'loss': 0.5631, 'grad_norm': 5.05929708480835, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 3.9774, 'grad_norm': 53.477020263671875, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.74s/it]                                               {'loss': 0.7483, 'grad_norm': 16.173179626464844, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.74s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it]                                               {'loss': 0.3063, 'grad_norm': 4.8976240158081055, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it] 48%|████▊     | 19/40 [00:38<00:41,  1.98s/it]                                               {'loss': 0.3444, 'grad_norm': 5.373472690582275, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  1.98s/it] 50%|█████     | 20/40 [00:40<00:41,  2.05s/it]                                               {'loss': 0.2381, 'grad_norm': 4.826292037963867, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.05s/it] 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it]                                               {'loss': 0.3238, 'grad_norm': 4.404501914978027, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 0.3549, 'grad_norm': 4.30671501159668, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.18s/it]                                               {'loss': 0.4473, 'grad_norm': 7.483786106109619, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0496, 'grad_norm': 2.7857840061187744, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.2635, 'grad_norm': 4.4602370262146, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it]                                               {'loss': 0.8516, 'grad_norm': 26.875885009765625, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:53<00:25,  2.00s/it]                                               {'loss': 0.3226, 'grad_norm': 10.529715538024902, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  2.00s/it] 70%|███████   | 28/40 [00:56<00:24,  2.07s/it]                                               {'loss': 0.3024, 'grad_norm': 5.736697673797607, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.07s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it]                                               {'loss': 0.0449, 'grad_norm': 1.1087371110916138, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.12s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.15s/it]                                               {'loss': 0.0431, 'grad_norm': 1.0393329858779907, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.15s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it]                                               {'loss': 0.0907, 'grad_norm': 2.091536521911621, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it] 80%|████████  | 32/40 [01:02<00:12,  1.59s/it]                                               {'loss': 0.1001, 'grad_norm': 6.343080520629883, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.77s/it]                                               {'loss': 0.0782, 'grad_norm': 1.7826250791549683, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.77s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.90s/it]                                               {'loss': 0.1049, 'grad_norm': 2.3388171195983887, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.90s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.065, 'grad_norm': 3.4791667461395264, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it]                                               {'loss': 0.0672, 'grad_norm': 1.7859766483306885, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.08s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.13s/it]                                               {'loss': 0.024, 'grad_norm': 0.5317652821540833, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.13s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 0.0388, 'grad_norm': 1.260499358177185, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]                                               {'loss': 0.0889, 'grad_norm': 3.125718832015991, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'loss': 0.0135, 'grad_norm': 0.6804006695747375, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'train_runtime': 79.0533, 'train_samples_per_second': 7.147, 'train_steps_per_second': 0.506, 'train_loss': 0.9864297627471388, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:88
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:43,  2.66s/it]                                              {'loss': 3.3321, 'grad_norm': 13.349908828735352, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:43,  2.66s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 1.7384, 'grad_norm': 12.638486862182617, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:24,  2.28s/it]                                              {'loss': 1.9497, 'grad_norm': 14.426558494567871, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:20,  2.25s/it]                                              {'loss': 1.9529, 'grad_norm': 13.2562255859375, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.25s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it]                                              {'loss': 1.7006, 'grad_norm': 11.421157836914062, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.3277, 'grad_norm': 30.662500381469727, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 2.1979, 'grad_norm': 22.34390640258789, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 0.5454, 'grad_norm': 26.511566162109375, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 0.9993, 'grad_norm': 11.152884483337402, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 0.7251, 'grad_norm': 13.861220359802246, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.3797, 'grad_norm': 6.265093803405762, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 1.2453, 'grad_norm': 10.530806541442871, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it]                                               {'loss': 0.9698, 'grad_norm': 10.709929466247559, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it]                                               {'loss': 0.7591, 'grad_norm': 6.404857158660889, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it]                                               {'loss': 0.8467, 'grad_norm': 8.098917007446289, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.1958, 'grad_norm': 12.003663063049316, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.9144, 'grad_norm': 10.082091331481934, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it]                                               {'loss': 0.4861, 'grad_norm': 7.198815822601318, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it]                                               {'loss': 0.2711, 'grad_norm': 4.303496837615967, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.242, 'grad_norm': 3.9777040481567383, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.0785, 'grad_norm': 1.4870003461837769, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.2888, 'grad_norm': 4.626898765563965, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:36,  2.18s/it]                                               {'loss': 0.7248, 'grad_norm': 6.936392307281494, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:36,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0012, 'grad_norm': 0.0795375183224678, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.1668, 'grad_norm': 2.172234058380127, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it]                                               {'loss': 0.1204, 'grad_norm': 1.9647979736328125, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.1638, 'grad_norm': 1.669034481048584, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.0292, 'grad_norm': 0.8209657669067383, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.0423, 'grad_norm': 1.779036521911621, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.3836, 'grad_norm': 11.883102416992188, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.0584, 'grad_norm': 1.4562318325042725, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0058, 'grad_norm': 0.4325343072414398, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.77s/it]                                               {'loss': 0.0199, 'grad_norm': 0.5591974258422852, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.77s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.0185, 'grad_norm': 0.6227457523345947, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.0081, 'grad_norm': 0.29988962411880493, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.4128, 'grad_norm': 3.835761308670044, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.2794, 'grad_norm': 3.1980655193328857, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.0455, 'grad_norm': 2.3133366107940674, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.0573, 'grad_norm': 2.5973384380340576, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.1908, 'grad_norm': 9.51487922668457, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.7308, 'train_samples_per_second': 7.086, 'train_steps_per_second': 0.502, 'train_loss': 0.6718763527926057, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:50
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:30,  2.31s/it]                                              {'loss': 3.209, 'grad_norm': 10.662646293640137, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:30,  2.31s/it]  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]                                              {'loss': 2.0765, 'grad_norm': 18.790441513061523, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 0.9909, 'grad_norm': 10.982622146606445, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 2.5677, 'grad_norm': 16.30903434753418, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 1.6253, 'grad_norm': 13.946288108825684, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 1.2014, 'grad_norm': 12.133891105651855, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 1.933, 'grad_norm': 14.10152816772461, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.2466, 'grad_norm': 13.14081859588623, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.79s/it]                                              {'loss': 0.2829, 'grad_norm': 5.762018203735352, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.8757, 'grad_norm': 10.783702850341797, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.5628, 'grad_norm': 17.2532901763916, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.5104, 'grad_norm': 8.832352638244629, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it]                                               {'loss': 0.7713, 'grad_norm': 19.823204040527344, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 1.2242, 'grad_norm': 53.95922088623047, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.4035, 'grad_norm': 13.454303741455078, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.0142, 'grad_norm': 1.092538595199585, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it]                                               {'loss': 0.2827, 'grad_norm': 2.4703469276428223, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.1185, 'grad_norm': 2.5240042209625244, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it]                                               {'loss': 0.246, 'grad_norm': 4.437505722045898, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.396, 'grad_norm': 6.785067081451416, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.1365, 'grad_norm': 2.5863285064697266, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.6624, 'grad_norm': 9.552145004272461, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.754, 'grad_norm': 6.311468601226807, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0238, 'grad_norm': 1.2933577299118042, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.0337, 'grad_norm': 1.0036801099777222, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it]                                               {'loss': 0.2396, 'grad_norm': 4.530003070831299, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.1141, 'grad_norm': 15.161636352539062, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.1076, 'grad_norm': 9.03295612335205, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.2282, 'grad_norm': 9.664435386657715, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.0405, 'grad_norm': 1.4710917472839355, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it]                                               {'loss': 0.3174, 'grad_norm': 8.305419921875, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.0075, 'grad_norm': 0.46086567640304565, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it]                                               {'loss': 0.2042, 'grad_norm': 6.662281513214111, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it]                                               {'loss': 0.0754, 'grad_norm': 2.485872507095337, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.96s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it]                                               {'loss': 0.2316, 'grad_norm': 11.327543258666992, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.06s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.0298, 'grad_norm': 0.6829668879508972, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.3866, 'grad_norm': 8.73353385925293, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it]                                               {'loss': 1.2447, 'grad_norm': 7.907563209533691, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.1117, 'grad_norm': 3.4637370109558105, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.1216, 'grad_norm': 10.097792625427246, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 80.0829, 'train_samples_per_second': 7.055, 'train_steps_per_second': 0.499, 'train_loss': 0.6152362866559997, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:9
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]                                              {'loss': 2.1209, 'grad_norm': 11.264344215393066, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 2.3661, 'grad_norm': 13.822885513305664, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:24,  2.29s/it]                                              {'loss': 1.6302, 'grad_norm': 11.516435623168945, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 1.8314, 'grad_norm': 13.189172744750977, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 2.6011, 'grad_norm': 21.429025650024414, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 2.5631, 'grad_norm': 15.508624076843262, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 2.4772, 'grad_norm': 16.824892044067383, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 1.6547, 'grad_norm': 56.53997039794922, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 0.7221, 'grad_norm': 7.054505348205566, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.5819, 'grad_norm': 7.914205074310303, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.2582, 'grad_norm': 5.560481548309326, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.639, 'grad_norm': 4.324902057647705, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it]                                               {'loss': 0.1644, 'grad_norm': 3.782844305038452, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.6555, 'grad_norm': 8.524455070495605, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.6411, 'grad_norm': 9.146565437316895, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 1.5534, 'grad_norm': 52.68291091918945, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.78s/it]                                               {'loss': 0.3635, 'grad_norm': 6.44045877456665, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.0848, 'grad_norm': 1.79258131980896, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.0288, 'grad_norm': 0.4693078398704529, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.1969, 'grad_norm': 2.279052495956421, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 0.3636, 'grad_norm': 8.978669166564941, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.1686, 'grad_norm': 3.923311710357666, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.2056, 'grad_norm': 3.68607234954834, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0518, 'grad_norm': 2.9445815086364746, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.1169, 'grad_norm': 3.3582375049591064, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.0559, 'grad_norm': 3.9426980018615723, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.0916, 'grad_norm': 1.0968629121780396, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.1285, 'grad_norm': 2.0144925117492676, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.0282, 'grad_norm': 0.6279821991920471, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.0244, 'grad_norm': 0.6125536561012268, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.02, 'grad_norm': 0.6401720643043518, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.0023, 'grad_norm': 0.131217822432518, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it]                                               {'loss': 0.0089, 'grad_norm': 0.200365349650383, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.0207, 'grad_norm': 0.6258536577224731, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.0144, 'grad_norm': 0.5268021821975708, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it]                                               {'loss': 0.109, 'grad_norm': 5.180149555206299, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it]                                               {'loss': 0.0189, 'grad_norm': 0.6350529193878174, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it]                                               {'loss': 0.0592, 'grad_norm': 1.8725862503051758, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.25s/it]                                               {'loss': 0.0166, 'grad_norm': 0.3610246777534485, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.25s/it]100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'loss': 0.0005, 'grad_norm': 0.030842022970318794, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]                                               {'train_runtime': 80.444, 'train_samples_per_second': 7.024, 'train_steps_per_second': 0.497, 'train_loss': 0.6159939729441248, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  do_eval=True, seed=self.args.random_seed)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<05:01,  1.56it/s]  1%|          | 3/471 [00:02<07:06,  1.10it/s]  1%|          | 4/471 [00:03<08:13,  1.06s/it]  1%|          | 5/471 [00:05<08:51,  1.14s/it]  1%|▏         | 6/471 [00:06<09:13,  1.19s/it]  1%|▏         | 7/471 [00:07<09:29,  1.23s/it]  2%|▏         | 8/471 [00:09<09:39,  1.25s/it]  2%|▏         | 9/471 [00:10<09:45,  1.27s/it]  2%|▏         | 10/471 [00:11<09:50,  1.28s/it]  2%|▏         | 11/471 [00:12<09:52,  1.29s/it]  3%|▎         | 12/471 [00:14<09:54,  1.30s/it]  3%|▎         | 13/471 [00:15<09:56,  1.30s/it]  3%|▎         | 14/471 [00:16<09:56,  1.31s/it]  3%|▎         | 15/471 [00:18<09:57,  1.31s/it]  3%|▎         | 16/471 [00:19<09:56,  1.31s/it]  4%|▎         | 17/471 [00:20<09:56,  1.31s/it]  4%|▍         | 18/471 [00:22<09:57,  1.32s/it]  4%|▍         | 19/471 [00:23<09:56,  1.32s/it]  4%|▍         | 20/471 [00:24<09:55,  1.32s/it]  4%|▍         | 21/471 [00:26<09:54,  1.32s/it]  5%|▍         | 22/471 [00:27<09:49,  1.31s/it]  5%|▍         | 23/471 [00:28<09:50,  1.32s/it]  5%|▌         | 24/471 [00:30<09:51,  1.32s/it]  5%|▌         | 25/471 [00:31<09:50,  1.32s/it]  6%|▌         | 26/471 [00:32<09:49,  1.32s/it]  6%|▌         | 27/471 [00:34<09:48,  1.33s/it]  6%|▌         | 28/471 [00:35<09:47,  1.33s/it]  6%|▌         | 29/471 [00:36<09:47,  1.33s/it]  6%|▋         | 30/471 [00:38<09:47,  1.33s/it]  7%|▋         | 31/471 [00:39<09:45,  1.33s/it]  7%|▋         | 32/471 [00:40<09:43,  1.33s/it]  7%|▋         | 33/471 [00:42<09:41,  1.33s/it]  7%|▋         | 34/471 [00:43<09:40,  1.33s/it]  7%|▋         | 35/471 [00:44<09:40,  1.33s/it]  8%|▊         | 36/471 [00:46<09:38,  1.33s/it]  8%|▊         | 37/471 [00:47<09:37,  1.33s/it]  8%|▊         | 38/471 [00:48<09:37,  1.33s/it]  8%|▊         | 39/471 [00:50<09:35,  1.33s/it]  8%|▊         | 40/471 [00:51<09:33,  1.33s/it]  9%|▊         | 41/471 [00:52<09:32,  1.33s/it]  9%|▉         | 42/471 [00:54<09:32,  1.33s/it]  9%|▉         | 43/471 [00:55<09:30,  1.33s/it]  9%|▉         | 44/471 [00:56<09:28,  1.33s/it] 10%|▉         | 45/471 [00:58<09:28,  1.33s/it] 10%|▉         | 46/471 [00:59<09:26,  1.33s/it] 10%|▉         | 47/471 [01:00<09:25,  1.33s/it] 10%|█         | 48/471 [01:02<09:24,  1.34s/it] 10%|█         | 49/471 [01:03<09:23,  1.34s/it] 11%|█         | 50/471 [01:04<09:22,  1.34s/it] 11%|█         | 51/471 [01:06<09:21,  1.34s/it] 11%|█         | 52/471 [01:07<09:20,  1.34s/it] 11%|█▏        | 53/471 [01:08<09:20,  1.34s/it] 11%|█▏        | 54/471 [01:10<09:18,  1.34s/it] 12%|█▏        | 55/471 [01:11<09:17,  1.34s/it] 12%|█▏        | 56/471 [01:12<09:16,  1.34s/it] 12%|█▏        | 57/471 [01:14<09:14,  1.34s/it] 12%|█▏        | 58/471 [01:15<09:13,  1.34s/it] 13%|█▎        | 59/471 [01:16<09:11,  1.34s/it] 13%|█▎        | 60/471 [01:18<09:09,  1.34s/it] 13%|█▎        | 61/471 [01:19<09:08,  1.34s/it] 13%|█▎        | 62/471 [01:20<09:07,  1.34s/it] 13%|█▎        | 63/471 [01:22<09:05,  1.34s/it] 14%|█▎        | 64/471 [01:23<09:04,  1.34s/it] 14%|█▍        | 65/471 [01:24<09:03,  1.34s/it] 14%|█▍        | 66/471 [01:26<09:02,  1.34s/it] 14%|█▍        | 67/471 [01:27<09:00,  1.34s/it] 14%|█▍        | 68/471 [01:28<08:59,  1.34s/it] 15%|█▍        | 69/471 [01:30<08:57,  1.34s/it] 15%|█▍        | 70/471 [01:31<08:56,  1.34s/it] 15%|█▌        | 71/471 [01:32<08:55,  1.34s/it] 15%|█▌        | 72/471 [01:34<08:54,  1.34s/it] 15%|█▌        | 73/471 [01:35<08:52,  1.34s/it] 16%|█▌        | 74/471 [01:36<08:49,  1.33s/it] 16%|█▌        | 75/471 [01:38<08:48,  1.34s/it] 16%|█▌        | 76/471 [01:39<08:47,  1.33s/it] 16%|█▋        | 77/471 [01:40<08:45,  1.33s/it] 17%|█▋        | 78/471 [01:42<08:44,  1.33s/it] 17%|█▋        | 79/471 [01:43<08:43,  1.34s/it] 17%|█▋        | 80/471 [01:44<08:42,  1.34s/it] 17%|█▋        | 81/471 [01:46<08:40,  1.33s/it] 17%|█▋        | 82/471 [01:47<08:39,  1.33s/it] 18%|█▊        | 83/471 [01:48<08:37,  1.33s/it] 18%|█▊        | 84/471 [01:50<08:36,  1.33s/it] 18%|█▊        | 85/471 [01:51<08:35,  1.33s/it] 18%|█▊        | 86/471 [01:52<08:34,  1.34s/it] 18%|█▊        | 87/471 [01:54<08:32,  1.33s/it] 19%|█▊        | 88/471 [01:55<08:30,  1.33s/it] 19%|█▉        | 89/471 [01:56<08:29,  1.33s/it] 19%|█▉        | 90/471 [01:58<08:28,  1.34s/it] 19%|█▉        | 91/471 [01:59<08:26,  1.33s/it] 20%|█▉        | 92/471 [02:00<08:25,  1.33s/it] 20%|█▉        | 93/471 [02:02<08:24,  1.33s/it] 20%|█▉        | 94/471 [02:03<08:22,  1.33s/it] 20%|██        | 95/471 [02:04<08:20,  1.33s/it] 20%|██        | 96/471 [02:06<08:19,  1.33s/it] 21%|██        | 97/471 [02:07<08:19,  1.33s/it] 21%|██        | 98/471 [02:08<08:16,  1.33s/it] 21%|██        | 99/471 [02:10<08:15,  1.33s/it] 21%|██        | 100/471 [02:11<08:14,  1.33s/it] 21%|██▏       | 101/471 [02:12<08:13,  1.33s/it] 22%|██▏       | 102/471 [02:14<08:11,  1.33s/it] 22%|██▏       | 103/471 [02:15<08:10,  1.33s/it] 22%|██▏       | 104/471 [02:16<08:09,  1.33s/it] 22%|██▏       | 105/471 [02:18<08:08,  1.34s/it] 23%|██▎       | 106/471 [02:19<08:06,  1.33s/it] 23%|██▎       | 107/471 [02:20<08:04,  1.33s/it] 23%|██▎       | 108/471 [02:22<08:03,  1.33s/it] 23%|██▎       | 109/471 [02:23<08:01,  1.33s/it] 23%|██▎       | 110/471 [02:24<07:59,  1.33s/it] 24%|██▎       | 111/471 [02:26<07:58,  1.33s/it] 24%|██▍       | 112/471 [02:27<07:58,  1.33s/it] 24%|██▍       | 113/471 [02:28<07:56,  1.33s/it] 24%|██▍       | 114/471 [02:30<07:55,  1.33s/it] 24%|██▍       | 115/471 [02:31<07:55,  1.33s/it] 25%|██▍       | 116/471 [02:32<07:54,  1.34s/it] 25%|██▍       | 117/471 [02:34<07:52,  1.34s/it] 25%|██▌       | 118/471 [02:35<07:51,  1.34s/it] 25%|██▌       | 119/471 [02:36<07:50,  1.34s/it] 25%|██▌       | 120/471 [02:38<07:49,  1.34s/it] 26%|██▌       | 121/471 [02:39<07:47,  1.34s/it] 26%|██▌       | 122/471 [02:40<07:46,  1.34s/it] 26%|██▌       | 123/471 [02:42<07:45,  1.34s/it] 26%|██▋       | 124/471 [02:43<07:44,  1.34s/it] 27%|██▋       | 125/471 [02:44<07:42,  1.34s/it] 27%|██▋       | 126/471 [02:46<07:41,  1.34s/it] 27%|██▋       | 127/471 [02:47<07:40,  1.34s/it] 27%|██▋       | 128/471 [02:48<07:38,  1.34s/it] 27%|██▋       | 129/471 [02:50<07:36,  1.34s/it] 28%|██▊       | 130/471 [02:51<07:35,  1.34s/it] 28%|██▊       | 131/471 [02:52<07:34,  1.34s/it] 28%|██▊       | 132/471 [02:54<07:33,  1.34s/it] 28%|██▊       | 133/471 [02:55<07:32,  1.34s/it] 28%|██▊       | 134/471 [02:56<07:31,  1.34s/it] 29%|██▊       | 135/471 [02:58<07:30,  1.34s/it] 29%|██▉       | 136/471 [02:59<07:28,  1.34s/it] 29%|██▉       | 137/471 [03:01<07:27,  1.34s/it] 29%|██▉       | 138/471 [03:02<07:26,  1.34s/it] 30%|██▉       | 139/471 [03:03<07:24,  1.34s/it] 30%|██▉       | 140/471 [03:05<07:23,  1.34s/it] 30%|██▉       | 141/471 [03:06<07:22,  1.34s/it] 30%|███       | 142/471 [03:07<07:20,  1.34s/it] 30%|███       | 143/471 [03:09<07:19,  1.34s/it] 31%|███       | 144/471 [03:10<07:18,  1.34s/it] 31%|███       | 145/471 [03:11<07:16,  1.34s/it] 31%|███       | 146/471 [03:13<07:15,  1.34s/it] 31%|███       | 147/471 [03:14<07:14,  1.34s/it] 31%|███▏      | 148/471 [03:15<07:12,  1.34s/it] 32%|███▏      | 149/471 [03:17<07:12,  1.34s/it] 32%|███▏      | 150/471 [03:18<07:11,  1.34s/it] 32%|███▏      | 151/471 [03:19<07:09,  1.34s/it] 32%|███▏      | 152/471 [03:21<07:08,  1.34s/it] 32%|███▏      | 153/471 [03:22<07:07,  1.34s/it] 33%|███▎      | 154/471 [03:23<07:05,  1.34s/it] 33%|███▎      | 155/471 [03:25<07:03,  1.34s/it] 33%|███▎      | 156/471 [03:26<07:02,  1.34s/it] 33%|███▎      | 157/471 [03:27<07:00,  1.34s/it] 34%|███▎      | 158/471 [03:29<06:58,  1.34s/it] 34%|███▍      | 159/471 [03:30<06:57,  1.34s/it] 34%|███▍      | 160/471 [03:31<06:56,  1.34s/it] 34%|███▍      | 161/471 [03:33<06:55,  1.34s/it] 34%|███▍      | 162/471 [03:34<06:54,  1.34s/it] 35%|███▍      | 163/471 [03:35<06:53,  1.34s/it] 35%|███▍      | 164/471 [03:37<06:51,  1.34s/it] 35%|███▌      | 165/471 [03:38<06:50,  1.34s/it] 35%|███▌      | 166/471 [03:39<06:49,  1.34s/it] 35%|███▌      | 167/471 [03:41<06:48,  1.34s/it] 36%|███▌      | 168/471 [03:42<06:46,  1.34s/it] 36%|███▌      | 169/471 [03:43<06:46,  1.34s/it] 36%|███▌      | 170/471 [03:45<06:44,  1.34s/it] 36%|███▋      | 171/471 [03:46<06:42,  1.34s/it] 37%|███▋      | 172/471 [03:47<06:41,  1.34s/it] 37%|███▋      | 173/471 [03:49<06:39,  1.34s/it] 37%|███▋      | 174/471 [03:50<06:38,  1.34s/it] 37%|███▋      | 175/471 [03:51<06:37,  1.34s/it] 37%|███▋      | 176/471 [03:53<06:35,  1.34s/it] 38%|███▊      | 177/471 [03:54<06:34,  1.34s/it] 38%|███▊      | 178/471 [03:56<06:33,  1.34s/it] 38%|███▊      | 179/471 [03:57<06:31,  1.34s/it] 38%|███▊      | 180/471 [03:58<06:30,  1.34s/it] 38%|███▊      | 181/471 [04:00<06:29,  1.34s/it] 39%|███▊      | 182/471 [04:01<06:27,  1.34s/it] 39%|███▉      | 183/471 [04:02<06:26,  1.34s/it] 39%|███▉      | 184/471 [04:04<06:24,  1.34s/it] 39%|███▉      | 185/471 [04:05<06:23,  1.34s/it] 39%|███▉      | 186/471 [04:06<06:22,  1.34s/it] 40%|███▉      | 187/471 [04:08<06:21,  1.34s/it] 40%|███▉      | 188/471 [04:09<06:20,  1.34s/it] 40%|████      | 189/471 [04:10<06:18,  1.34s/it] 40%|████      | 190/471 [04:12<06:16,  1.34s/it] 41%|████      | 191/471 [04:13<06:16,  1.34s/it] 41%|████      | 192/471 [04:14<06:14,  1.34s/it] 41%|████      | 193/471 [04:16<06:12,  1.34s/it] 41%|████      | 194/471 [04:17<06:11,  1.34s/it] 41%|████▏     | 195/471 [04:18<06:10,  1.34s/it] 42%|████▏     | 196/471 [04:20<06:09,  1.34s/it] 42%|████▏     | 197/471 [04:21<06:06,  1.34s/it] 42%|████▏     | 198/471 [04:22<06:05,  1.34s/it] 42%|████▏     | 199/471 [04:24<06:04,  1.34s/it] 42%|████▏     | 200/471 [04:25<06:03,  1.34s/it] 43%|████▎     | 201/471 [04:26<06:01,  1.34s/it] 43%|████▎     | 202/471 [04:28<06:00,  1.34s/it] 43%|████▎     | 203/471 [04:29<05:59,  1.34s/it] 43%|████▎     | 204/471 [04:30<05:57,  1.34s/it] 44%|████▎     | 205/471 [04:32<05:56,  1.34s/it] 44%|████▎     | 206/471 [04:33<05:54,  1.34s/it] 44%|████▍     | 207/471 [04:34<05:53,  1.34s/it] 44%|████▍     | 208/471 [04:36<05:51,  1.34s/it] 44%|████▍     | 209/471 [04:37<05:50,  1.34s/it] 45%|████▍     | 210/471 [04:38<05:49,  1.34s/it] 45%|████▍     | 211/471 [04:40<05:48,  1.34s/it] 45%|████▌     | 212/471 [04:41<05:46,  1.34s/it] 45%|████▌     | 213/471 [04:42<05:45,  1.34s/it] 45%|████▌     | 214/471 [04:44<05:44,  1.34s/it] 46%|████▌     | 215/471 [04:45<05:42,  1.34s/it] 46%|████▌     | 216/471 [04:46<05:42,  1.34s/it] 46%|████▌     | 217/471 [04:48<05:41,  1.34s/it] 46%|████▋     | 218/471 [04:49<05:39,  1.34s/it] 46%|████▋     | 219/471 [04:50<05:38,  1.34s/it] 47%|████▋     | 220/471 [04:52<05:37,  1.34s/it] 47%|████▋     | 221/471 [04:53<05:36,  1.34s/it] 47%|████▋     | 222/471 [04:55<05:34,  1.34s/it] 47%|████▋     | 223/471 [04:56<05:32,  1.34s/it] 48%|████▊     | 224/471 [04:57<05:31,  1.34s/it] 48%|████▊     | 225/471 [04:59<05:30,  1.34s/it] 48%|████▊     | 226/471 [05:00<05:29,  1.34s/it] 48%|████▊     | 227/471 [05:01<05:27,  1.34s/it] 48%|████▊     | 228/471 [05:03<05:26,  1.34s/it] 49%|████▊     | 229/471 [05:04<05:25,  1.35s/it] 49%|████▉     | 230/471 [05:05<05:24,  1.35s/it] 49%|████▉     | 231/471 [05:07<05:22,  1.35s/it] 49%|████▉     | 232/471 [05:08<05:21,  1.34s/it] 49%|████▉     | 233/471 [05:09<05:19,  1.34s/it] 50%|████▉     | 234/471 [05:11<05:18,  1.34s/it] 50%|████▉     | 235/471 [05:12<05:17,  1.35s/it] 50%|█████     | 236/471 [05:13<05:15,  1.34s/it] 50%|█████     | 237/471 [05:15<05:14,  1.34s/it] 51%|█████     | 238/471 [05:16<05:13,  1.34s/it] 51%|█████     | 239/471 [05:17<05:11,  1.34s/it] 51%|█████     | 240/471 [05:19<05:10,  1.34s/it] 51%|█████     | 241/471 [05:20<05:09,  1.34s/it] 51%|█████▏    | 242/471 [05:21<05:07,  1.34s/it] 52%|█████▏    | 243/471 [05:23<05:06,  1.34s/it] 52%|█████▏    | 244/471 [05:24<05:05,  1.34s/it] 52%|█████▏    | 245/471 [05:25<05:04,  1.35s/it] 52%|█████▏    | 246/471 [05:27<05:02,  1.34s/it] 52%|█████▏    | 247/471 [05:28<05:01,  1.34s/it] 53%|█████▎    | 248/471 [05:29<05:00,  1.35s/it] 53%|█████▎    | 249/471 [05:31<04:59,  1.35s/it] 53%|█████▎    | 250/471 [05:32<04:57,  1.35s/it] 53%|█████▎    | 251/471 [05:33<04:55,  1.34s/it] 54%|█████▎    | 252/471 [05:35<04:54,  1.35s/it] 54%|█████▎    | 253/471 [05:36<04:53,  1.35s/it] 54%|█████▍    | 254/471 [05:38<04:52,  1.35s/it] 54%|█████▍    | 255/471 [05:39<04:50,  1.35s/it] 54%|█████▍    | 256/471 [05:40<04:49,  1.35s/it] 55%|█████▍    | 257/471 [05:42<04:48,  1.35s/it] 55%|█████▍    | 258/471 [05:43<04:46,  1.35s/it] 55%|█████▍    | 259/471 [05:44<04:45,  1.35s/it] 55%|█████▌    | 260/471 [05:46<04:44,  1.35s/it] 55%|█████▌    | 261/471 [05:47<04:42,  1.34s/it] 56%|█████▌    | 262/471 [05:48<04:40,  1.34s/it] 56%|█████▌    | 263/471 [05:50<04:39,  1.35s/it] 56%|█████▌    | 264/471 [05:51<04:38,  1.34s/it] 56%|█████▋    | 265/471 [05:52<04:37,  1.35s/it] 56%|█████▋    | 266/471 [05:54<04:36,  1.35s/it] 57%|█████▋    | 267/471 [05:55<04:34,  1.35s/it] 57%|█████▋    | 268/471 [05:56<04:33,  1.35s/it] 57%|█████▋    | 269/471 [05:58<04:32,  1.35s/it] 57%|█████▋    | 270/471 [05:59<04:30,  1.35s/it] 58%|█████▊    | 271/471 [06:00<04:29,  1.35s/it] 58%|█████▊    | 272/471 [06:02<04:27,  1.34s/it] 58%|█████▊    | 273/471 [06:03<04:26,  1.34s/it] 58%|█████▊    | 274/471 [06:04<04:24,  1.34s/it] 58%|█████▊    | 275/471 [06:06<04:23,  1.34s/it] 59%|█████▊    | 276/471 [06:07<04:21,  1.34s/it] 59%|█████▉    | 277/471 [06:08<04:20,  1.34s/it] 59%|█████▉    | 278/471 [06:10<04:19,  1.34s/it] 59%|█████▉    | 279/471 [06:11<04:17,  1.34s/it] 59%|█████▉    | 280/471 [06:12<04:16,  1.34s/it] 60%|█████▉    | 281/471 [06:14<04:15,  1.34s/it] 60%|█████▉    | 282/471 [06:15<04:13,  1.34s/it] 60%|██████    | 283/471 [06:17<04:12,  1.34s/it] 60%|██████    | 284/471 [06:18<04:10,  1.34s/it] 61%|██████    | 285/471 [06:19<04:09,  1.34s/it] 61%|██████    | 286/471 [06:21<04:08,  1.34s/it] 61%|██████    | 287/471 [06:22<04:07,  1.34s/it] 61%|██████    | 288/471 [06:23<04:05,  1.34s/it] 61%|██████▏   | 289/471 [06:25<04:04,  1.34s/it] 62%|██████▏   | 290/471 [06:26<04:02,  1.34s/it] 62%|██████▏   | 291/471 [06:27<04:01,  1.34s/it] 62%|██████▏   | 292/471 [06:29<03:59,  1.34s/it] 62%|██████▏   | 293/471 [06:30<03:58,  1.34s/it] 62%|██████▏   | 294/471 [06:31<03:56,  1.34s/it] 63%|██████▎   | 295/471 [06:33<03:55,  1.34s/it] 63%|██████▎   | 296/471 [06:34<03:54,  1.34s/it] 63%|██████▎   | 297/471 [06:35<03:52,  1.34s/it] 63%|██████▎   | 298/471 [06:37<03:52,  1.34s/it] 63%|██████▎   | 299/471 [06:38<03:50,  1.34s/it] 64%|██████▎   | 300/471 [06:39<03:49,  1.34s/it] 64%|██████▍   | 301/471 [06:41<03:47,  1.34s/it] 64%|██████▍   | 302/471 [06:42<03:45,  1.34s/it] 64%|██████▍   | 303/471 [06:43<03:44,  1.33s/it] 65%|██████▍   | 304/471 [06:45<03:42,  1.33s/it] 65%|██████▍   | 305/471 [06:46<03:41,  1.33s/it] 65%|██████▍   | 306/471 [06:47<03:40,  1.33s/it] 65%|██████▌   | 307/471 [06:49<03:38,  1.34s/it] 65%|██████▌   | 308/471 [06:50<03:38,  1.34s/it] 66%|██████▌   | 309/471 [06:51<03:36,  1.34s/it] 66%|██████▌   | 310/471 [06:53<03:35,  1.34s/it] 66%|██████▌   | 311/471 [06:54<03:33,  1.34s/it] 66%|██████▌   | 312/471 [06:55<03:32,  1.33s/it] 66%|██████▋   | 313/471 [06:57<03:30,  1.33s/it] 67%|██████▋   | 314/471 [06:58<03:29,  1.33s/it] 67%|██████▋   | 315/471 [06:59<03:28,  1.33s/it] 67%|██████▋   | 316/471 [07:01<03:26,  1.33s/it] 67%|██████▋   | 317/471 [07:02<03:25,  1.33s/it] 68%|██████▊   | 318/471 [07:03<03:24,  1.34s/it] 68%|██████▊   | 319/471 [07:05<03:23,  1.34s/it] 68%|██████▊   | 320/471 [07:06<03:21,  1.34s/it] 68%|██████▊   | 321/471 [07:07<03:20,  1.34s/it] 68%|██████▊   | 322/471 [07:09<03:19,  1.34s/it] 69%|██████▊   | 323/471 [07:10<03:18,  1.34s/it] 69%|██████▉   | 324/471 [07:11<03:17,  1.34s/it] 69%|██████▉   | 325/471 [07:13<03:15,  1.34s/it] 69%|██████▉   | 326/471 [07:14<03:14,  1.34s/it] 69%|██████▉   | 327/471 [07:15<03:12,  1.34s/it] 70%|██████▉   | 328/471 [07:17<03:11,  1.34s/it] 70%|██████▉   | 329/471 [07:18<03:10,  1.34s/it] 70%|███████   | 330/471 [07:19<03:08,  1.34s/it] 70%|███████   | 331/471 [07:21<03:07,  1.34s/it] 70%|███████   | 332/471 [07:22<03:06,  1.34s/it] 71%|███████   | 333/471 [07:23<03:04,  1.34s/it] 71%|███████   | 334/471 [07:25<03:03,  1.34s/it] 71%|███████   | 335/471 [07:26<03:02,  1.34s/it] 71%|███████▏  | 336/471 [07:27<03:00,  1.34s/it] 72%|███████▏  | 337/471 [07:29<02:59,  1.34s/it] 72%|███████▏  | 338/471 [07:30<02:57,  1.34s/it] 72%|███████▏  | 339/471 [07:31<02:56,  1.34s/it] 72%|███████▏  | 340/471 [07:33<02:55,  1.34s/it] 72%|███████▏  | 341/471 [07:34<02:53,  1.34s/it] 73%|███████▎  | 342/471 [07:35<02:52,  1.34s/it] 73%|███████▎  | 343/471 [07:37<02:51,  1.34s/it] 73%|███████▎  | 344/471 [07:38<02:49,  1.34s/it] 73%|███████▎  | 345/471 [07:39<02:48,  1.34s/it] 73%|███████▎  | 346/471 [07:41<02:47,  1.34s/it] 74%|███████▎  | 347/471 [07:42<02:45,  1.34s/it] 74%|███████▍  | 348/471 [07:43<02:44,  1.34s/it] 74%|███████▍  | 349/471 [07:45<02:43,  1.34s/it] 74%|███████▍  | 350/471 [07:46<02:41,  1.34s/it] 75%|███████▍  | 351/471 [07:47<02:40,  1.34s/it] 75%|███████▍  | 352/471 [07:49<02:39,  1.34s/it] 75%|███████▍  | 353/471 [07:50<02:38,  1.34s/it] 75%|███████▌  | 354/471 [07:52<02:36,  1.34s/it] 75%|███████▌  | 355/471 [07:53<02:35,  1.34s/it] 76%|███████▌  | 356/471 [07:54<02:34,  1.34s/it] 76%|███████▌  | 357/471 [07:56<02:32,  1.34s/it] 76%|███████▌  | 358/471 [07:57<02:31,  1.34s/it] 76%|███████▌  | 359/471 [07:58<02:30,  1.34s/it] 76%|███████▋  | 360/471 [08:00<02:28,  1.34s/it] 77%|███████▋  | 361/471 [08:01<02:27,  1.34s/it] 77%|███████▋  | 362/471 [08:02<02:25,  1.34s/it] 77%|███████▋  | 363/471 [08:04<02:24,  1.34s/it] 77%|███████▋  | 364/471 [08:05<02:23,  1.34s/it] 77%|███████▋  | 365/471 [08:06<02:22,  1.34s/it] 78%|███████▊  | 366/471 [08:08<02:20,  1.34s/it] 78%|███████▊  | 367/471 [08:09<02:19,  1.34s/it] 78%|███████▊  | 368/471 [08:10<02:18,  1.34s/it] 78%|███████▊  | 369/471 [08:12<02:16,  1.34s/it] 79%|███████▊  | 370/471 [08:13<02:15,  1.34s/it] 79%|███████▉  | 371/471 [08:14<02:14,  1.34s/it] 79%|███████▉  | 372/471 [08:16<02:12,  1.34s/it] 79%|███████▉  | 373/471 [08:17<02:11,  1.34s/it] 79%|███████▉  | 374/471 [08:18<02:09,  1.34s/it] 80%|███████▉  | 375/471 [08:20<02:08,  1.34s/it] 80%|███████▉  | 376/471 [08:21<02:07,  1.34s/it] 80%|████████  | 377/471 [08:22<02:05,  1.34s/it] 80%|████████  | 378/471 [08:24<02:04,  1.34s/it] 80%|████████  | 379/471 [08:25<02:03,  1.34s/it] 81%|████████  | 380/471 [08:26<02:01,  1.34s/it] 81%|████████  | 381/471 [08:28<02:00,  1.34s/it] 81%|████████  | 382/471 [08:29<01:59,  1.34s/it] 81%|████████▏ | 383/471 [08:30<01:57,  1.34s/it] 82%|████████▏ | 384/471 [08:32<01:56,  1.34s/it] 82%|████████▏ | 385/471 [08:33<01:55,  1.34s/it] 82%|████████▏ | 386/471 [08:34<01:53,  1.34s/it] 82%|████████▏ | 387/471 [08:36<01:52,  1.34s/it] 82%|████████▏ | 388/471 [08:37<01:51,  1.34s/it] 83%|████████▎ | 389/471 [08:38<01:49,  1.34s/it] 83%|████████▎ | 390/471 [08:40<01:48,  1.34s/it] 83%|████████▎ | 391/471 [08:41<01:46,  1.34s/it] 83%|████████▎ | 392/471 [08:42<01:45,  1.34s/it] 83%|████████▎ | 393/471 [08:44<01:44,  1.34s/it] 84%|████████▎ | 394/471 [08:45<01:43,  1.34s/it] 84%|████████▍ | 395/471 [08:46<01:41,  1.34s/it] 84%|████████▍ | 396/471 [08:48<01:40,  1.34s/it] 84%|████████▍ | 397/471 [08:49<01:39,  1.34s/it] 85%|████████▍ | 398/471 [08:50<01:37,  1.34s/it] 85%|████████▍ | 399/471 [08:52<01:36,  1.34s/it] 85%|████████▍ | 400/471 [08:53<01:35,  1.34s/it] 85%|████████▌ | 401/471 [08:54<01:33,  1.34s/it] 85%|████████▌ | 402/471 [08:56<01:32,  1.34s/it] 86%|████████▌ | 403/471 [08:57<01:30,  1.34s/it] 86%|████████▌ | 404/471 [08:58<01:29,  1.33s/it] 86%|████████▌ | 405/471 [09:00<01:28,  1.34s/it] 86%|████████▌ | 406/471 [09:01<01:26,  1.33s/it] 86%|████████▋ | 407/471 [09:02<01:25,  1.33s/it] 87%|████████▋ | 408/471 [09:04<01:24,  1.33s/it] 87%|████████▋ | 409/471 [09:05<01:22,  1.34s/it] 87%|████████▋ | 410/471 [09:06<01:21,  1.34s/it] 87%|████████▋ | 411/471 [09:08<01:20,  1.33s/it] 87%|████████▋ | 412/471 [09:09<01:18,  1.34s/it] 88%|████████▊ | 413/471 [09:10<01:17,  1.34s/it] 88%|████████▊ | 414/471 [09:12<01:16,  1.34s/it] 88%|████████▊ | 415/471 [09:13<01:14,  1.34s/it] 88%|████████▊ | 416/471 [09:14<01:13,  1.34s/it] 89%|████████▊ | 417/471 [09:16<01:12,  1.34s/it] 89%|████████▊ | 418/471 [09:17<01:11,  1.34s/it] 89%|████████▉ | 419/471 [09:18<01:09,  1.34s/it] 89%|████████▉ | 420/471 [09:20<01:08,  1.34s/it] 89%|████████▉ | 421/471 [09:21<01:06,  1.34s/it] 90%|████████▉ | 422/471 [09:23<01:05,  1.34s/it] 90%|████████▉ | 423/471 [09:24<01:04,  1.34s/it] 90%|█████████ | 424/471 [09:25<01:02,  1.34s/it] 90%|█████████ | 425/471 [09:27<01:01,  1.34s/it] 90%|█████████ | 426/471 [09:28<01:00,  1.34s/it] 91%|█████████ | 427/471 [09:29<00:59,  1.34s/it] 91%|█████████ | 428/471 [09:31<00:57,  1.34s/it] 91%|█████████ | 429/471 [09:32<00:56,  1.34s/it] 91%|█████████▏| 430/471 [09:33<00:55,  1.34s/it] 92%|█████████▏| 431/471 [09:35<00:53,  1.34s/it] 92%|█████████▏| 432/471 [09:36<00:52,  1.34s/it] 92%|█████████▏| 433/471 [09:37<00:51,  1.34s/it] 92%|█████████▏| 434/471 [09:39<00:49,  1.35s/it] 92%|█████████▏| 435/471 [09:40<00:48,  1.35s/it] 93%|█████████▎| 436/471 [09:41<00:47,  1.35s/it] 93%|█████████▎| 437/471 [09:43<00:45,  1.35s/it] 93%|█████████▎| 438/471 [09:44<00:44,  1.35s/it] 93%|█████████▎| 439/471 [09:45<00:43,  1.35s/it] 93%|█████████▎| 440/471 [09:47<00:41,  1.35s/it] 94%|█████████▎| 441/471 [09:48<00:40,  1.35s/it] 94%|█████████▍| 442/471 [09:49<00:39,  1.35s/it] 94%|█████████▍| 443/471 [09:51<00:37,  1.35s/it] 94%|█████████▍| 444/471 [09:52<00:36,  1.35s/it] 94%|█████████▍| 445/471 [09:53<00:35,  1.35s/it] 95%|█████████▍| 446/471 [09:55<00:33,  1.35s/it] 95%|█████████▍| 447/471 [09:56<00:32,  1.35s/it] 95%|█████████▌| 448/471 [09:57<00:30,  1.35s/it] 95%|█████████▌| 449/471 [09:59<00:29,  1.35s/it] 96%|█████████▌| 450/471 [10:00<00:28,  1.35s/it] 96%|█████████▌| 451/471 [10:02<00:26,  1.35s/it] 96%|█████████▌| 452/471 [10:03<00:25,  1.35s/it] 96%|█████████▌| 453/471 [10:04<00:24,  1.35s/it] 96%|█████████▋| 454/471 [10:06<00:22,  1.35s/it] 97%|█████████▋| 455/471 [10:07<00:21,  1.35s/it] 97%|█████████▋| 456/471 [10:08<00:20,  1.35s/it] 97%|█████████▋| 457/471 [10:10<00:18,  1.35s/it] 97%|█████████▋| 458/471 [10:11<00:17,  1.35s/it] 97%|█████████▋| 459/471 [10:12<00:16,  1.35s/it] 98%|█████████▊| 460/471 [10:14<00:14,  1.35s/it] 98%|█████████▊| 461/471 [10:15<00:13,  1.35s/it] 98%|█████████▊| 462/471 [10:16<00:12,  1.35s/it] 98%|█████████▊| 463/471 [10:18<00:10,  1.35s/it] 99%|█████████▊| 464/471 [10:19<00:09,  1.35s/it] 99%|█████████▊| 465/471 [10:20<00:08,  1.35s/it] 99%|█████████▉| 466/471 [10:22<00:06,  1.35s/it] 99%|█████████▉| 467/471 [10:23<00:05,  1.35s/it] 99%|█████████▉| 468/471 [10:24<00:04,  1.35s/it]100%|█████████▉| 469/471 [10:26<00:02,  1.35s/it]100%|█████████▉| 470/471 [10:27<00:01,  1.35s/it]100%|██████████| 471/471 [10:28<00:00,  1.24s/it]100%|██████████| 471/471 [10:28<00:00,  1.33s/it]
{'eval_loss': 2.442047357559204, 'eval_model_preparation_time': 0.0133, 'eval_acc': 0.3590015932023367, 'eval_runtime': 629.9007, 'eval_samples_per_second': 11.957, 'eval_steps_per_second': 0.748}
ROUND:17
CLIENT:20
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:36,  2.47s/it]                                              {'loss': 2.6287, 'grad_norm': 12.153070449829102, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:36,  2.47s/it]  5%|▌         | 2/40 [00:04<01:26,  2.26s/it]                                              {'loss': 2.773, 'grad_norm': 12.603421211242676, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.26s/it]  8%|▊         | 3/40 [00:06<01:22,  2.23s/it]                                              {'loss': 1.9513, 'grad_norm': 12.04345417022705, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.23s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 2.5723, 'grad_norm': 22.802074432373047, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 1.3936, 'grad_norm': 14.159420013427734, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 1.4168, 'grad_norm': 11.760583877563477, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it]                                              {'loss': 2.4078, 'grad_norm': 22.286453247070312, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 0.028, 'grad_norm': 1.694847583770752, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 0.4404, 'grad_norm': 7.114680767059326, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 1.155, 'grad_norm': 11.033087730407715, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it]                                               {'loss': 0.5817, 'grad_norm': 5.522160053253174, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.03s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 1.1923, 'grad_norm': 9.833115577697754, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 0.9561, 'grad_norm': 9.103638648986816, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.982, 'grad_norm': 5.7564802169799805, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it]                                               {'loss': 0.9193, 'grad_norm': 9.401363372802734, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.2623, 'grad_norm': 16.37433624267578, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.7935, 'grad_norm': 9.879571914672852, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.1088, 'grad_norm': 1.9855480194091797, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.7576, 'grad_norm': 7.882964611053467, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.2384, 'grad_norm': 5.56503438949585, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.0517, 'grad_norm': 1.0927859544754028, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it]                                               {'loss': 0.3061, 'grad_norm': 4.920219421386719, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.2891, 'grad_norm': 3.976377248764038, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.2649, 'grad_norm': 11.62696361541748, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.1854, 'grad_norm': 3.070631742477417, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.2771, 'grad_norm': 4.813714504241943, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.2336, 'grad_norm': 4.566950798034668, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.531, 'grad_norm': 4.812391757965088, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.14s/it]                                               {'loss': 0.2034, 'grad_norm': 1.965113639831543, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.324, 'grad_norm': 6.350693225860596, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it]                                               {'loss': 0.0845, 'grad_norm': 2.3443832397460938, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.1725, 'grad_norm': 14.706515312194824, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it]                                               {'loss': 0.5175, 'grad_norm': 101.42317962646484, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.7319, 'grad_norm': 27.76392936706543, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.3947, 'grad_norm': 9.516877174377441, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.503, 'grad_norm': 8.110107421875, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it]                                               {'loss': 0.2531, 'grad_norm': 3.0446126461029053, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it]                                               {'loss': 0.2905, 'grad_norm': 2.468693494796753, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.1525, 'grad_norm': 4.492201805114746, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0444, 'grad_norm': 2.666872501373291, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.188, 'train_samples_per_second': 7.046, 'train_steps_per_second': 0.499, 'train_loss': 0.7342532011680305, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:10
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:41,  2.61s/it]                                              {'loss': 3.0907, 'grad_norm': 13.604745864868164, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:41,  2.61s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 2.4899, 'grad_norm': 13.974128723144531, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:24,  2.29s/it]                                              {'loss': 1.2439, 'grad_norm': 11.174553871154785, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 0.6716, 'grad_norm': 13.773488998413086, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it]                                              {'loss': 2.6027, 'grad_norm': 17.931182861328125, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 1.3386, 'grad_norm': 10.581620216369629, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it]                                              {'loss': 2.4198, 'grad_norm': 10.759876251220703, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 1.5316, 'grad_norm': 51.471046447753906, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 0.5787, 'grad_norm': 5.421504020690918, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.5186, 'grad_norm': 8.779329299926758, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.7273, 'grad_norm': 8.529032707214355, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.6328, 'grad_norm': 8.084269523620605, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:56,  2.10s/it]                                               {'loss': 0.7253, 'grad_norm': 9.488155364990234, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it]                                               {'loss': 0.6112, 'grad_norm': 7.1068854331970215, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.4056, 'grad_norm': 6.237595081329346, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0171, 'grad_norm': 1.1629846096038818, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.0472, 'grad_norm': 1.352131724357605, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.0543, 'grad_norm': 1.5420653820037842, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.1535, 'grad_norm': 5.052590847015381, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.2895, 'grad_norm': 4.517120361328125, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.4236, 'grad_norm': 4.128444194793701, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it]                                               {'loss': 0.14, 'grad_norm': 1.26571786403656, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.1829, 'grad_norm': 3.4715447425842285, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0237, 'grad_norm': 1.2397531270980835, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.1995, 'grad_norm': 1.2913944721221924, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.91s/it]                                               {'loss': 0.0534, 'grad_norm': 1.495172142982483, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.0257, 'grad_norm': 0.5284684300422668, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.1002, 'grad_norm': 2.554152250289917, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.0233, 'grad_norm': 0.5826408863067627, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.1239, 'grad_norm': 1.6436644792556763, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.0483, 'grad_norm': 1.3140902519226074, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0039, 'grad_norm': 0.24586784839630127, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0208, 'grad_norm': 0.8848490118980408, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.01, 'grad_norm': 0.2617514431476593, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.0354, 'grad_norm': 0.5731196999549866, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.0231, 'grad_norm': 0.5355398654937744, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.0607, 'grad_norm': 2.9298770427703857, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.019, 'grad_norm': 0.5167815685272217, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.2508, 'grad_norm': 1.0176259279251099, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0097, 'grad_norm': 0.629397451877594, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.0523, 'train_samples_per_second': 7.058, 'train_steps_per_second': 0.5, 'train_loss': 0.5481897947727703, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:96
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:29,  2.30s/it]                                              {'loss': 3.2215, 'grad_norm': 12.99849796295166, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:29,  2.30s/it]  5%|▌         | 2/40 [00:04<01:23,  2.21s/it]                                              {'loss': 2.8208, 'grad_norm': 16.581466674804688, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.21s/it]  8%|▊         | 3/40 [00:06<01:22,  2.22s/it]                                              {'loss': 3.0484, 'grad_norm': 15.496604919433594, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.22s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 2.6141, 'grad_norm': 21.341941833496094, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 2.0203, 'grad_norm': 19.695280075073242, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 1.6864, 'grad_norm': 16.033363342285156, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 0.9958, 'grad_norm': 11.194697380065918, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 4.2537, 'grad_norm': 329.3469543457031, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 0.4116, 'grad_norm': 11.666202545166016, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 2.2408, 'grad_norm': 26.779603958129883, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 2.4019, 'grad_norm': 48.77766799926758, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 1.77, 'grad_norm': 53.1484489440918, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 0.7826, 'grad_norm': 26.495342254638672, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 0.9188, 'grad_norm': 52.944889068603516, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.7332, 'grad_norm': 13.66515827178955, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 2.0794, 'grad_norm': 241.67530822753906, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it]                                               {'loss': 1.4388, 'grad_norm': 18.07663917541504, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it]                                               {'loss': 1.3314, 'grad_norm': 29.09576416015625, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 2.1533, 'grad_norm': 27.383777618408203, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 1.7555, 'grad_norm': 56.574947357177734, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 1.9299, 'grad_norm': 140.4081268310547, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 2.3624, 'grad_norm': 222.50149536132812, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 2.1499, 'grad_norm': 234.63497924804688, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.9089, 'grad_norm': 71.49462890625, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 2.9472, 'grad_norm': 66.71994018554688, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it]                                               {'loss': 1.5663, 'grad_norm': 236.32394409179688, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.00s/it]                                               {'loss': 2.3581, 'grad_norm': 46.2430534362793, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.00s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 1.584, 'grad_norm': 109.51826477050781, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 1.9845, 'grad_norm': 210.3445587158203, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it]                                               {'loss': 1.995, 'grad_norm': 96.33609771728516, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 1.2947, 'grad_norm': 23.518875122070312, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 1.8695, 'grad_norm': 162.63209533691406, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 1.8139, 'grad_norm': 112.8553466796875, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.7569, 'grad_norm': 37.06336212158203, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 1.3355, 'grad_norm': 19.543455123901367, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 1.0235, 'grad_norm': 32.062625885009766, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.9141, 'grad_norm': 13.496503829956055, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 1.2636, 'grad_norm': 59.97108840942383, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.19s/it]                                               {'loss': 2.1724, 'grad_norm': 50.15939712524414, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.19s/it]100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'loss': 0.1613, 'grad_norm': 19.583742141723633, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'train_runtime': 79.519, 'train_samples_per_second': 7.105, 'train_steps_per_second': 0.503, 'train_loss': 1.776738829538226, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:16
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:35,  2.45s/it]                                              {'loss': 3.4157, 'grad_norm': 17.101299285888672, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:35,  2.45s/it]  5%|▌         | 2/40 [00:05<01:36,  2.53s/it]                                              {'loss': 1.131, 'grad_norm': 10.401660919189453, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:05<01:36,  2.53s/it]  8%|▊         | 3/40 [00:07<01:27,  2.36s/it]                                              {'loss': 1.6055, 'grad_norm': 17.586729049682617, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:27,  2.36s/it] 10%|█         | 4/40 [00:09<01:22,  2.30s/it]                                              {'loss': 1.4037, 'grad_norm': 12.646370887756348, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:22,  2.30s/it] 12%|█▎        | 5/40 [00:11<01:19,  2.28s/it]                                              {'loss': 0.8321, 'grad_norm': 10.800378799438477, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:19,  2.28s/it] 15%|█▌        | 6/40 [00:13<01:17,  2.27s/it]                                              {'loss': 2.5, 'grad_norm': 13.634757995605469, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:17,  2.27s/it] 18%|█▊        | 7/40 [00:16<01:14,  2.25s/it]                                              {'loss': 1.4612, 'grad_norm': 10.227420806884766, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:16<01:14,  2.25s/it] 20%|██        | 8/40 [00:16<00:50,  1.59s/it]                                              {'loss': 1.7507, 'grad_norm': 39.5859489440918, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 0.7201, 'grad_norm': 9.320037841796875, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.4432, 'grad_norm': 6.053262710571289, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 1.025, 'grad_norm': 7.849392414093018, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:25<00:58,  2.09s/it]                                               {'loss': 0.5984, 'grad_norm': 6.312047958374023, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:25<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 0.877, 'grad_norm': 7.4429097175598145, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 0.6476, 'grad_norm': 6.769492149353027, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.2022, 'grad_norm': 2.870471239089966, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:32<00:38,  1.59s/it]                                               {'loss': 0.0426, 'grad_norm': 2.5422818660736084, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:32<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.2503, 'grad_norm': 4.990611553192139, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.1794, 'grad_norm': 4.000247478485107, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.2419, 'grad_norm': 7.30896520614624, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:41<00:41,  2.09s/it]                                               {'loss': 0.0483, 'grad_norm': 1.0192269086837769, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it]                                               {'loss': 0.11, 'grad_norm': 2.949188470840454, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it]                                               {'loss': 0.0932, 'grad_norm': 2.163402795791626, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.20s/it] 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it]                                               {'loss': 0.2376, 'grad_norm': 2.1773974895477295, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:37,  2.23s/it] 60%|██████    | 24/40 [00:48<00:25,  1.62s/it]                                               {'loss': 0.0274, 'grad_norm': 1.1758708953857422, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it]                                               {'loss': 0.0954, 'grad_norm': 3.402043342590332, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.81s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.0115, 'grad_norm': 0.5071378946304321, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:55<00:26,  2.04s/it]                                               {'loss': 0.0436, 'grad_norm': 0.9112268090248108, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:26,  2.04s/it] 70%|███████   | 28/40 [00:57<00:25,  2.12s/it]                                               {'loss': 0.0589, 'grad_norm': 1.8912869691848755, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it]                                               {'loss': 0.0144, 'grad_norm': 0.3797573149204254, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.17s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it]                                               {'loss': 0.0361, 'grad_norm': 1.3386625051498413, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.23s/it]                                               {'loss': 0.3261, 'grad_norm': 3.250209093093872, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.23s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.1081, 'grad_norm': 11.306985855102539, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.0115, 'grad_norm': 0.28715330362319946, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.0616, 'grad_norm': 1.7968721389770508, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.04s/it]                                               {'loss': 0.0072, 'grad_norm': 0.3223640024662018, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it]                                               {'loss': 0.0094, 'grad_norm': 0.23928302526474, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it]                                               {'loss': 0.2703, 'grad_norm': 1.8537139892578125, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.21s/it]                                               {'loss': 0.0741, 'grad_norm': 3.461796760559082, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.0154, 'grad_norm': 0.5901554822921753, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.0007, 'grad_norm': 0.05421361327171326, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.8729, 'train_samples_per_second': 6.986, 'train_steps_per_second': 0.495, 'train_loss': 0.5247132195640006, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:43,  2.64s/it]                                              {'loss': 2.5113, 'grad_norm': 11.190995216369629, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:43,  2.64s/it]  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]                                              {'loss': 1.964, 'grad_norm': 12.236966133117676, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.34s/it]  8%|▊         | 3/40 [00:06<01:23,  2.26s/it]                                              {'loss': 1.8213, 'grad_norm': 12.248165130615234, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.26s/it] 10%|█         | 4/40 [00:09<01:19,  2.21s/it]                                              {'loss': 3.0159, 'grad_norm': 12.610084533691406, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it]                                              {'loss': 1.7209, 'grad_norm': 11.734537124633789, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 2.2639, 'grad_norm': 20.96497344970703, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.3225, 'grad_norm': 12.892834663391113, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 6.3956, 'grad_norm': 78.6546859741211, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 0.9051, 'grad_norm': 16.706472396850586, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.7087, 'grad_norm': 49.794071197509766, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.4432, 'grad_norm': 8.601234436035156, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 0.385, 'grad_norm': 11.446331977844238, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it]                                               {'loss': 0.9656, 'grad_norm': 13.632332801818848, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.08s/it] 35%|███▌      | 14/40 [00:28<00:54,  2.11s/it]                                               {'loss': 0.8578, 'grad_norm': 11.512472152709961, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:54,  2.11s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it]                                               {'loss': 0.5598, 'grad_norm': 8.407782554626465, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.15s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 2.9996, 'grad_norm': 60.102012634277344, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:39,  1.74s/it]                                               {'loss': 0.3617, 'grad_norm': 4.5913591384887695, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:39,  1.74s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it]                                               {'loss': 0.2954, 'grad_norm': 7.488354682922363, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.88s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it]                                               {'loss': 0.3697, 'grad_norm': 7.053638458251953, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it] 50%|█████     | 20/40 [00:40<00:41,  2.06s/it]                                               {'loss': 0.8044, 'grad_norm': 11.196512222290039, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.5074, 'grad_norm': 7.840151786804199, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.6241, 'grad_norm': 8.557550430297852, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.18s/it]                                               {'loss': 0.2065, 'grad_norm': 3.8938915729522705, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0162, 'grad_norm': 0.9659373164176941, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0907, 'grad_norm': 3.120462417602539, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.5265, 'grad_norm': 14.041535377502441, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it]                                               {'loss': 0.2144, 'grad_norm': 3.9557673931121826, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.1838, 'grad_norm': 3.3608765602111816, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.0813, 'grad_norm': 2.0465087890625, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.0394, 'grad_norm': 1.171778917312622, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:20,  2.24s/it]                                               {'loss': 0.2693, 'grad_norm': 6.859745025634766, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:20,  2.24s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.1538, 'grad_norm': 9.184520721435547, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0594, 'grad_norm': 1.3808722496032715, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.2467, 'grad_norm': 2.1567282676696777, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it]                                               {'loss': 0.1081, 'grad_norm': 7.8436455726623535, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0592, 'grad_norm': 1.6697572469711304, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.0303, 'grad_norm': 0.8494765758514404, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.0484, 'grad_norm': 1.4002206325531006, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]                                               {'loss': 0.0496, 'grad_norm': 1.429453730583191, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.2088, 'grad_norm': 25.282310485839844, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.3992, 'train_samples_per_second': 7.116, 'train_steps_per_second': 0.504, 'train_loss': 0.8598772458732128, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.98s/it]
CLIENT:24
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:45,  2.70s/it]                                              {'loss': 2.1964, 'grad_norm': 12.351840019226074, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:45,  2.70s/it]  5%|▌         | 2/40 [00:04<01:30,  2.38s/it]                                              {'loss': 2.2663, 'grad_norm': 12.391409873962402, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:30,  2.38s/it]  8%|▊         | 3/40 [00:07<01:24,  2.29s/it]                                              {'loss': 1.663, 'grad_norm': 17.111003875732422, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:21,  2.27s/it]                                              {'loss': 2.0702, 'grad_norm': 21.261856079101562, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.27s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 2.0981, 'grad_norm': 24.299152374267578, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 2.4973, 'grad_norm': 16.16993522644043, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 2.2975, 'grad_norm': 18.299659729003906, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:16<00:49,  1.56s/it]                                              {'loss': 0.4284, 'grad_norm': 20.13526725769043, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 1.224, 'grad_norm': 9.920034408569336, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 0.4615, 'grad_norm': 6.315894603729248, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 1.0019, 'grad_norm': 17.75603485107422, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.4878, 'grad_norm': 4.804997444152832, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 1.1222, 'grad_norm': 5.663241863250732, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.15s/it]                                               {'loss': 0.3926, 'grad_norm': 4.277248382568359, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it]                                               {'loss': 1.3688, 'grad_norm': 8.850144386291504, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.0366, 'grad_norm': 2.5125060081481934, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.0647, 'grad_norm': 1.6877409219741821, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it]                                               {'loss': 0.3229, 'grad_norm': 8.953428268432617, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.1795, 'grad_norm': 3.5457825660705566, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.065, 'grad_norm': 1.4357479810714722, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.2697, 'grad_norm': 3.3932504653930664, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.15s/it]                                               {'loss': 0.7162, 'grad_norm': 4.917785167694092, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.1391, 'grad_norm': 2.5493125915527344, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0427, 'grad_norm': 2.5286409854888916, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.2926, 'grad_norm': 3.03707218170166, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.2069, 'grad_norm': 2.4982919692993164, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.1574, 'grad_norm': 2.2434701919555664, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.0598, 'grad_norm': 1.8608142137527466, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.0711, 'grad_norm': 2.988865613937378, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.0199, 'grad_norm': 0.9954174757003784, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.8466, 'grad_norm': 5.164086818695068, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0062, 'grad_norm': 0.9054258465766907, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it]                                               {'loss': 0.0795, 'grad_norm': 1.841774582862854, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it]                                               {'loss': 0.5019, 'grad_norm': 2.7292728424072266, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.0177, 'grad_norm': 0.4286985397338867, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.0942, 'grad_norm': 3.1564950942993164, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.0463, 'grad_norm': 1.0625669956207275, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.0323, 'grad_norm': 1.0982422828674316, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]                                               {'loss': 0.5017, 'grad_norm': 2.9389395713806152, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0286, 'grad_norm': 1.6352466344833374, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.7024, 'train_samples_per_second': 7.089, 'train_steps_per_second': 0.502, 'train_loss': 0.6593745233956725, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:53
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:47,  2.75s/it]                                              {'loss': 2.3094, 'grad_norm': 10.201757431030273, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:47,  2.75s/it]  5%|▌         | 2/40 [00:04<01:32,  2.43s/it]                                              {'loss': 2.3198, 'grad_norm': 9.529041290283203, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:32,  2.43s/it]  8%|▊         | 3/40 [00:07<01:25,  2.31s/it]                                              {'loss': 2.7459, 'grad_norm': 11.925644874572754, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.31s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 1.738, 'grad_norm': 11.444465637207031, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 2.1397, 'grad_norm': 11.975377082824707, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 1.1081, 'grad_norm': 12.550087928771973, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.0297, 'grad_norm': 18.978012084960938, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 3.091, 'grad_norm': 88.4229736328125, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it]                                              {'loss': 0.4002, 'grad_norm': 6.196210861206055, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.5954, 'grad_norm': 6.19573450088501, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.3714, 'grad_norm': 4.146694183349609, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.5561, 'grad_norm': 5.673317909240723, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 0.7428, 'grad_norm': 8.170119285583496, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it]                                               {'loss': 1.5212, 'grad_norm': 7.9346466064453125, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.4785, 'grad_norm': 6.426929950714111, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.5736, 'grad_norm': 24.33270835876465, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:34<00:40,  1.76s/it]                                               {'loss': 0.8523, 'grad_norm': 4.195752143859863, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.91s/it]                                               {'loss': 0.2302, 'grad_norm': 4.933506965637207, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.301, 'grad_norm': 5.177681922912598, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.0178, 'grad_norm': 0.28881990909576416, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 0.1916, 'grad_norm': 3.1060309410095215, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.17s/it]                                               {'loss': 0.1312, 'grad_norm': 2.5215415954589844, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.17s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.2407, 'grad_norm': 4.765357494354248, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.8797, 'grad_norm': 21.390460968017578, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.0447, 'grad_norm': 1.00252103805542, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:52<00:26,  1.91s/it]                                               {'loss': 0.0605, 'grad_norm': 1.324095606803894, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.3848, 'grad_norm': 2.080148458480835, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.0161, 'grad_norm': 0.4095813035964966, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.0577, 'grad_norm': 2.0844297409057617, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.0365, 'grad_norm': 1.4012004137039185, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.0986, 'grad_norm': 2.180769205093384, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.075, 'grad_norm': 5.344487190246582, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it]                                               {'loss': 0.0333, 'grad_norm': 0.704912543296814, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.92s/it]                                               {'loss': 0.0952, 'grad_norm': 2.299703359603882, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.0542, 'grad_norm': 1.9900130033493042, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0347, 'grad_norm': 0.8971534967422485, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.0168, 'grad_norm': 0.5218198895454407, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0108, 'grad_norm': 0.25611743330955505, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.5481, 'grad_norm': 7.100969314575195, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'loss': 0.0004, 'grad_norm': 0.018401727080345154, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.62s/it]                                               {'train_runtime': 80.0536, 'train_samples_per_second': 7.058, 'train_steps_per_second': 0.5, 'train_loss': 0.6783181554201292, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:97
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:35,  2.45s/it]                                              {'loss': 2.047, 'grad_norm': 10.840047836303711, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:35,  2.45s/it]  5%|▌         | 2/40 [00:04<01:26,  2.28s/it]                                              {'loss': 2.1796, 'grad_norm': 13.723332405090332, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.28s/it]  8%|▊         | 3/40 [00:06<01:22,  2.23s/it]                                              {'loss': 2.0675, 'grad_norm': 14.018986701965332, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.23s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 2.8627, 'grad_norm': 15.30830192565918, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it]                                              {'loss': 2.4308, 'grad_norm': 19.331268310546875, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 2.6223, 'grad_norm': 24.678184509277344, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.0605, 'grad_norm': 21.483642578125, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 3.6786, 'grad_norm': 53.091041564941406, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 0.4174, 'grad_norm': 9.392241477966309, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 1.1723, 'grad_norm': 11.836856842041016, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.3155, 'grad_norm': 12.702425003051758, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:58,  2.07s/it]                                               {'loss': 0.3978, 'grad_norm': 5.3431549072265625, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 0.301, 'grad_norm': 4.57474422454834, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 1.5377, 'grad_norm': 13.491964340209961, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.4011, 'grad_norm': 5.4771952629089355, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 4.3159, 'grad_norm': 207.74270629882812, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.2682, 'grad_norm': 3.917503595352173, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.2867, 'grad_norm': 2.0551745891571045, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it]                                               {'loss': 0.3617, 'grad_norm': 5.947051048278809, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.652, 'grad_norm': 5.477669715881348, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.1882, 'grad_norm': 4.284244537353516, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.3245, 'grad_norm': 4.270410060882568, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.4106, 'grad_norm': 5.989151477813721, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0014, 'grad_norm': 0.08602927625179291, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.1672, 'grad_norm': 12.68799877166748, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.0783, 'grad_norm': 1.8293312788009644, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it]                                               {'loss': 0.1466, 'grad_norm': 3.174940824508667, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.03s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.2991, 'grad_norm': 7.945084571838379, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.037, 'grad_norm': 0.6741166710853577, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it]                                               {'loss': 0.2513, 'grad_norm': 2.5939888954162598, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.3375, 'grad_norm': 4.57564115524292, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.005, 'grad_norm': 0.2821285128593445, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0204, 'grad_norm': 0.5682862997055054, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.0288, 'grad_norm': 0.7369868755340576, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it]                                               {'loss': 0.1557, 'grad_norm': 1.625369668006897, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0329, 'grad_norm': 1.047126054763794, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.0748, 'grad_norm': 3.2678945064544678, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it]                                               {'loss': 0.0945, 'grad_norm': 2.099555730819702, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.19s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]                                               {'loss': 0.7923, 'grad_norm': 13.503925323486328, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]100%|██████████| 40/40 [01:19<00:00,  1.64s/it]                                               {'loss': 0.3294, 'grad_norm': 17.456771850585938, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.64s/it]                                               {'train_runtime': 79.9155, 'train_samples_per_second': 7.07, 'train_steps_per_second': 0.501, 'train_loss': 0.8787919378635707, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.64s/it]100%|██████████| 40/40 [01:19<00:00,  2.00s/it]
CLIENT:41
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:36,  2.46s/it]                                              {'loss': 2.1174, 'grad_norm': 9.300812721252441, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:36,  2.46s/it]  5%|▌         | 2/40 [00:04<01:26,  2.28s/it]                                              {'loss': 1.8348, 'grad_norm': 12.104766845703125, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.28s/it]  8%|▊         | 3/40 [00:06<01:22,  2.24s/it]                                              {'loss': 2.3478, 'grad_norm': 12.793048858642578, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.24s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 1.7366, 'grad_norm': 27.76894760131836, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it]                                              {'loss': 2.4186, 'grad_norm': 13.881342887878418, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 3.3776, 'grad_norm': 14.950165748596191, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.6989, 'grad_norm': 12.4657621383667, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 5.1241, 'grad_norm': 95.77680206298828, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 0.985, 'grad_norm': 11.278558731079102, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.6756, 'grad_norm': 7.829962730407715, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.0786, 'grad_norm': 26.58051872253418, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.6301, 'grad_norm': 8.587257385253906, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 1.1513, 'grad_norm': 9.408614158630371, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 1.311, 'grad_norm': 9.591553688049316, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 1.3167, 'grad_norm': 46.01115417480469, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 1.8595, 'grad_norm': 61.369895935058594, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.4991, 'grad_norm': 6.0247039794921875, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it]                                               {'loss': 0.5092, 'grad_norm': 8.185218811035156, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it]                                               {'loss': 0.5494, 'grad_norm': 9.519832611083984, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.00s/it] 50%|█████     | 20/40 [00:40<00:40,  2.05s/it]                                               {'loss': 1.2964, 'grad_norm': 6.183595180511475, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:40,  2.05s/it] 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it]                                               {'loss': 0.3889, 'grad_norm': 7.01579475402832, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:39,  2.10s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.0721, 'grad_norm': 2.1881861686706543, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it]                                               {'loss': 0.2544, 'grad_norm': 4.2906880378723145, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 0.0878, 'grad_norm': 4.817913055419922, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.6486, 'grad_norm': 6.35731315612793, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it]                                               {'loss': 0.4248, 'grad_norm': 4.272539138793945, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.90s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it]                                               {'loss': 0.3317, 'grad_norm': 5.600525379180908, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.61, 'grad_norm': 9.446917533874512, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.0751, 'grad_norm': 1.3916784524917603, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it]                                               {'loss': 0.2246, 'grad_norm': 5.269179821014404, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.4117, 'grad_norm': 13.087865829467773, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 11.0481, 'grad_norm': 76.55580139160156, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0941, 'grad_norm': 3.2690205574035645, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it]                                               {'loss': 0.3833, 'grad_norm': 6.868181228637695, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.91s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.0241, 'grad_norm': 0.6302081346511841, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.1938, 'grad_norm': 5.529018878936768, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.0532, 'grad_norm': 1.2894282341003418, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 1.0966, 'grad_norm': 7.293625354766846, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.633, 'grad_norm': 7.551496505737305, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.1696, 'grad_norm': 7.594411373138428, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.4235, 'train_samples_per_second': 7.114, 'train_steps_per_second': 0.504, 'train_loss': 1.243574862414971, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:47
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:43,  2.64s/it]                                              {'loss': 2.1831, 'grad_norm': 11.82882022857666, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:43,  2.64s/it]  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]                                              {'loss': 1.5234, 'grad_norm': 9.028653144836426, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.35s/it]  8%|▊         | 3/40 [00:06<01:24,  2.29s/it]                                              {'loss': 1.3074, 'grad_norm': 13.974874496459961, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.29s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 2.066, 'grad_norm': 16.877696990966797, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 0.9459, 'grad_norm': 16.687875747680664, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.132, 'grad_norm': 18.702791213989258, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 1.7361, 'grad_norm': 33.84843826293945, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 0.0649, 'grad_norm': 5.980826377868652, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it]                                              {'loss': 1.1235, 'grad_norm': 57.771915435791016, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it]                                               {'loss': 1.0422, 'grad_norm': 10.303211212158203, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 1.841, 'grad_norm': 23.434907913208008, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.418, 'grad_norm': 7.594307899475098, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it]                                               {'loss': 0.8143, 'grad_norm': 27.479211807250977, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it]                                               {'loss': 0.9671, 'grad_norm': 10.545977592468262, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it]                                               {'loss': 0.5805, 'grad_norm': 15.948694229125977, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.0146, 'grad_norm': 0.9422386288642883, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 1.0405, 'grad_norm': 26.02497100830078, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:36<00:41,  1.89s/it]                                               {'loss': 0.8312, 'grad_norm': 32.64019012451172, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.3346, 'grad_norm': 12.136899948120117, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.8303, 'grad_norm': 13.175871849060059, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.6703, 'grad_norm': 51.24394989013672, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it]                                               {'loss': 0.2366, 'grad_norm': 3.8531177043914795, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.3194, 'grad_norm': 4.630674362182617, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.1015, 'grad_norm': 5.729428768157959, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.2548, 'grad_norm': 4.103867530822754, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.3667, 'grad_norm': 4.390754699707031, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.2458, 'grad_norm': 4.208138942718506, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.1768, 'grad_norm': 4.053585052490234, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.3958, 'grad_norm': 7.209746360778809, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.409, 'grad_norm': 5.060759544372559, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.2464, 'grad_norm': 5.4567999839782715, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.1896, 'grad_norm': 8.227392196655273, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it]                                               {'loss': 0.0788, 'grad_norm': 27.471384048461914, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.0634, 'grad_norm': 1.9223906993865967, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.3035, 'grad_norm': 9.559412002563477, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it]                                               {'loss': 0.2282, 'grad_norm': 4.399370193481445, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.11s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.3205, 'grad_norm': 5.374188423156738, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.1587, 'grad_norm': 3.3151564598083496, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.2426, 'grad_norm': 3.585484266281128, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0328, 'grad_norm': 2.4395973682403564, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.854, 'train_samples_per_second': 7.075, 'train_steps_per_second': 0.501, 'train_loss': 0.6709432295989245, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  2.00s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  do_eval=True, seed=self.args.random_seed)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:58,  1.57it/s]  1%|          | 3/471 [00:02<07:01,  1.11it/s]  1%|          | 4/471 [00:03<08:06,  1.04s/it]  1%|          | 5/471 [00:05<08:44,  1.13s/it]  1%|▏         | 6/471 [00:06<09:06,  1.18s/it]  1%|▏         | 7/471 [00:07<09:22,  1.21s/it]  2%|▏         | 8/471 [00:08<09:31,  1.23s/it]  2%|▏         | 9/471 [00:10<09:37,  1.25s/it]  2%|▏         | 10/471 [00:11<09:40,  1.26s/it]  2%|▏         | 11/471 [00:12<09:43,  1.27s/it]  3%|▎         | 12/471 [00:14<09:45,  1.28s/it]  3%|▎         | 13/471 [00:15<09:46,  1.28s/it]  3%|▎         | 14/471 [00:16<09:46,  1.28s/it]  3%|▎         | 15/471 [00:17<09:45,  1.28s/it]  3%|▎         | 16/471 [00:19<09:46,  1.29s/it]  4%|▎         | 17/471 [00:20<09:46,  1.29s/it]  4%|▍         | 18/471 [00:21<09:45,  1.29s/it]  4%|▍         | 19/471 [00:23<09:44,  1.29s/it]  4%|▍         | 20/471 [00:24<09:44,  1.30s/it]  4%|▍         | 21/471 [00:25<09:43,  1.30s/it]  5%|▍         | 22/471 [00:27<09:42,  1.30s/it]  5%|▍         | 23/471 [00:28<09:41,  1.30s/it]  5%|▌         | 24/471 [00:29<09:41,  1.30s/it]  5%|▌         | 25/471 [00:30<09:40,  1.30s/it]  6%|▌         | 26/471 [00:32<09:40,  1.30s/it]  6%|▌         | 27/471 [00:33<09:39,  1.30s/it]  6%|▌         | 28/471 [00:34<09:37,  1.30s/it]  6%|▌         | 29/471 [00:36<09:37,  1.31s/it]  6%|▋         | 30/471 [00:37<09:37,  1.31s/it]  7%|▋         | 31/471 [00:38<09:35,  1.31s/it]  7%|▋         | 32/471 [00:40<09:34,  1.31s/it]  7%|▋         | 33/471 [00:41<09:31,  1.31s/it]  7%|▋         | 34/471 [00:42<09:31,  1.31s/it]  7%|▋         | 35/471 [00:44<09:30,  1.31s/it]  8%|▊         | 36/471 [00:45<09:29,  1.31s/it]  8%|▊         | 37/471 [00:46<09:29,  1.31s/it]  8%|▊         | 38/471 [00:47<09:28,  1.31s/it]  8%|▊         | 39/471 [00:49<09:26,  1.31s/it]  8%|▊         | 40/471 [00:50<09:25,  1.31s/it]  9%|▊         | 41/471 [00:51<09:24,  1.31s/it]  9%|▉         | 42/471 [00:53<09:24,  1.31s/it]  9%|▉         | 43/471 [00:54<09:22,  1.31s/it]  9%|▉         | 44/471 [00:55<09:21,  1.31s/it] 10%|▉         | 45/471 [00:57<09:19,  1.31s/it] 10%|▉         | 46/471 [00:58<09:18,  1.31s/it] 10%|▉         | 47/471 [00:59<09:17,  1.31s/it] 10%|█         | 48/471 [01:01<09:16,  1.32s/it] 10%|█         | 49/471 [01:02<09:15,  1.32s/it] 11%|█         | 50/471 [01:03<09:14,  1.32s/it] 11%|█         | 51/471 [01:05<09:14,  1.32s/it] 11%|█         | 52/471 [01:06<09:13,  1.32s/it] 11%|█▏        | 53/471 [01:07<09:12,  1.32s/it] 11%|█▏        | 54/471 [01:09<09:11,  1.32s/it] 12%|█▏        | 55/471 [01:10<09:10,  1.32s/it] 12%|█▏        | 56/471 [01:11<09:09,  1.32s/it] 12%|█▏        | 57/471 [01:13<09:08,  1.32s/it] 12%|█▏        | 58/471 [01:14<09:06,  1.32s/it] 13%|█▎        | 59/471 [01:15<09:05,  1.33s/it] 13%|█▎        | 60/471 [01:17<09:03,  1.32s/it] 13%|█▎        | 61/471 [01:18<09:03,  1.32s/it] 13%|█▎        | 62/471 [01:19<09:01,  1.33s/it] 13%|█▎        | 63/471 [01:21<09:00,  1.32s/it] 14%|█▎        | 64/471 [01:22<08:58,  1.32s/it] 14%|█▍        | 65/471 [01:23<08:57,  1.32s/it] 14%|█▍        | 66/471 [01:24<08:56,  1.32s/it] 14%|█▍        | 67/471 [01:26<08:54,  1.32s/it] 14%|█▍        | 68/471 [01:27<08:53,  1.32s/it] 15%|█▍        | 69/471 [01:28<08:52,  1.32s/it] 15%|█▍        | 70/471 [01:30<08:51,  1.33s/it] 15%|█▌        | 71/471 [01:31<08:50,  1.33s/it] 15%|█▌        | 72/471 [01:32<08:48,  1.33s/it] 15%|█▌        | 73/471 [01:34<08:47,  1.32s/it] 16%|█▌        | 74/471 [01:35<08:44,  1.32s/it] 16%|█▌        | 75/471 [01:36<08:44,  1.32s/it] 16%|█▌        | 76/471 [01:38<08:42,  1.32s/it] 16%|█▋        | 77/471 [01:39<08:41,  1.32s/it] 17%|█▋        | 78/471 [01:40<08:40,  1.32s/it] 17%|█▋        | 79/471 [01:42<08:40,  1.33s/it] 17%|█▋        | 80/471 [01:43<08:38,  1.33s/it] 17%|█▋        | 81/471 [01:44<08:37,  1.33s/it] 17%|█▋        | 82/471 [01:46<08:36,  1.33s/it] 18%|█▊        | 83/471 [01:47<08:35,  1.33s/it] 18%|█▊        | 84/471 [01:48<08:34,  1.33s/it] 18%|█▊        | 85/471 [01:50<08:33,  1.33s/it] 18%|█▊        | 86/471 [01:51<08:32,  1.33s/it] 18%|█▊        | 87/471 [01:52<08:30,  1.33s/it] 19%|█▊        | 88/471 [01:54<08:28,  1.33s/it] 19%|█▉        | 89/471 [01:55<08:27,  1.33s/it] 19%|█▉        | 90/471 [01:56<08:26,  1.33s/it] 19%|█▉        | 91/471 [01:58<08:25,  1.33s/it] 20%|█▉        | 92/471 [01:59<08:23,  1.33s/it] 20%|█▉        | 93/471 [02:00<08:22,  1.33s/it] 20%|█▉        | 94/471 [02:02<08:21,  1.33s/it] 20%|██        | 95/471 [02:03<08:19,  1.33s/it] 20%|██        | 96/471 [02:04<08:18,  1.33s/it] 21%|██        | 97/471 [02:06<08:17,  1.33s/it] 21%|██        | 98/471 [02:07<08:16,  1.33s/it] 21%|██        | 99/471 [02:08<08:14,  1.33s/it] 21%|██        | 100/471 [02:10<08:13,  1.33s/it] 21%|██▏       | 101/471 [02:11<08:12,  1.33s/it] 22%|██▏       | 102/471 [02:12<08:11,  1.33s/it] 22%|██▏       | 103/471 [02:14<08:10,  1.33s/it] 22%|██▏       | 104/471 [02:15<08:09,  1.33s/it] 22%|██▏       | 105/471 [02:16<08:08,  1.33s/it] 23%|██▎       | 106/471 [02:18<08:05,  1.33s/it] 23%|██▎       | 107/471 [02:19<08:04,  1.33s/it] 23%|██▎       | 108/471 [02:20<08:02,  1.33s/it] 23%|██▎       | 109/471 [02:22<08:00,  1.33s/it] 23%|██▎       | 110/471 [02:23<07:58,  1.33s/it] 24%|██▎       | 111/471 [02:24<07:57,  1.33s/it] 24%|██▍       | 112/471 [02:26<07:56,  1.33s/it] 24%|██▍       | 113/471 [02:27<07:55,  1.33s/it] 24%|██▍       | 114/471 [02:28<07:54,  1.33s/it] 24%|██▍       | 115/471 [02:30<07:53,  1.33s/it] 25%|██▍       | 116/471 [02:31<07:52,  1.33s/it] 25%|██▍       | 117/471 [02:32<07:51,  1.33s/it] 25%|██▌       | 118/471 [02:34<07:50,  1.33s/it] 25%|██▌       | 119/471 [02:35<07:49,  1.33s/it] 25%|██▌       | 120/471 [02:36<07:48,  1.34s/it] 26%|██▌       | 121/471 [02:38<07:47,  1.33s/it] 26%|██▌       | 122/471 [02:39<07:45,  1.33s/it] 26%|██▌       | 123/471 [02:40<07:44,  1.33s/it] 26%|██▋       | 124/471 [02:42<07:43,  1.33s/it] 27%|██▋       | 125/471 [02:43<07:41,  1.33s/it] 27%|██▋       | 126/471 [02:44<07:41,  1.34s/it] 27%|██▋       | 127/471 [02:46<07:39,  1.34s/it] 27%|██▋       | 128/471 [02:47<07:37,  1.33s/it] 27%|██▋       | 129/471 [02:48<07:35,  1.33s/it] 28%|██▊       | 130/471 [02:50<07:34,  1.33s/it] 28%|██▊       | 131/471 [02:51<07:33,  1.33s/it] 28%|██▊       | 132/471 [02:52<07:32,  1.34s/it] 28%|██▊       | 133/471 [02:54<07:31,  1.33s/it] 28%|██▊       | 134/471 [02:55<07:30,  1.34s/it] 29%|██▊       | 135/471 [02:56<07:29,  1.34s/it] 29%|██▉       | 136/471 [02:58<07:27,  1.33s/it] 29%|██▉       | 137/471 [02:59<07:25,  1.33s/it] 29%|██▉       | 138/471 [03:00<07:24,  1.33s/it] 30%|██▉       | 139/471 [03:02<07:23,  1.34s/it] 30%|██▉       | 140/471 [03:03<07:22,  1.34s/it] 30%|██▉       | 141/471 [03:04<07:20,  1.33s/it] 30%|███       | 142/471 [03:06<07:18,  1.33s/it] 30%|███       | 143/471 [03:07<07:16,  1.33s/it] 31%|███       | 144/471 [03:08<07:16,  1.34s/it] 31%|███       | 145/471 [03:10<07:14,  1.33s/it] 31%|███       | 146/471 [03:11<07:12,  1.33s/it] 31%|███       | 147/471 [03:12<07:11,  1.33s/it] 31%|███▏      | 148/471 [03:14<07:10,  1.33s/it] 32%|███▏      | 149/471 [03:15<07:09,  1.33s/it] 32%|███▏      | 150/471 [03:16<07:08,  1.34s/it] 32%|███▏      | 151/471 [03:18<07:07,  1.34s/it] 32%|███▏      | 152/471 [03:19<07:05,  1.33s/it] 32%|███▏      | 153/471 [03:20<07:04,  1.34s/it] 33%|███▎      | 154/471 [03:22<07:03,  1.34s/it] 33%|███▎      | 155/471 [03:23<07:01,  1.34s/it] 33%|███▎      | 156/471 [03:24<06:59,  1.33s/it] 33%|███▎      | 157/471 [03:26<06:58,  1.33s/it] 34%|███▎      | 158/471 [03:27<06:56,  1.33s/it] 34%|███▍      | 159/471 [03:28<06:54,  1.33s/it] 34%|███▍      | 160/471 [03:30<06:53,  1.33s/it] 34%|███▍      | 161/471 [03:31<06:52,  1.33s/it] 34%|███▍      | 162/471 [03:32<06:51,  1.33s/it] 35%|███▍      | 163/471 [03:34<06:50,  1.33s/it] 35%|███▍      | 164/471 [03:35<06:49,  1.33s/it] 35%|███▌      | 165/471 [03:36<06:48,  1.33s/it] 35%|███▌      | 166/471 [03:38<06:47,  1.34s/it] 35%|███▌      | 167/471 [03:39<06:45,  1.34s/it] 36%|███▌      | 168/471 [03:40<06:44,  1.34s/it] 36%|███▌      | 169/471 [03:42<06:43,  1.34s/it] 36%|███▌      | 170/471 [03:43<06:42,  1.34s/it] 36%|███▋      | 171/471 [03:44<06:40,  1.34s/it] 37%|███▋      | 172/471 [03:46<06:39,  1.33s/it] 37%|███▋      | 173/471 [03:47<06:37,  1.34s/it] 37%|███▋      | 174/471 [03:48<06:36,  1.34s/it] 37%|███▋      | 175/471 [03:50<06:35,  1.34s/it] 37%|███▋      | 176/471 [03:51<06:34,  1.34s/it] 38%|███▊      | 177/471 [03:52<06:33,  1.34s/it] 38%|███▊      | 178/471 [03:54<06:31,  1.34s/it] 38%|███▊      | 179/471 [03:55<06:30,  1.34s/it] 38%|███▊      | 180/471 [03:56<06:29,  1.34s/it] 38%|███▊      | 181/471 [03:58<06:28,  1.34s/it] 39%|███▊      | 182/471 [03:59<06:27,  1.34s/it] 39%|███▉      | 183/471 [04:00<06:25,  1.34s/it] 39%|███▉      | 184/471 [04:02<06:24,  1.34s/it] 39%|███▉      | 185/471 [04:03<06:23,  1.34s/it] 39%|███▉      | 186/471 [04:04<06:22,  1.34s/it] 40%|███▉      | 187/471 [04:06<06:21,  1.34s/it] 40%|███▉      | 188/471 [04:07<06:20,  1.34s/it] 40%|████      | 189/471 [04:08<06:18,  1.34s/it] 40%|████      | 190/471 [04:10<06:17,  1.34s/it] 41%|████      | 191/471 [04:11<06:16,  1.35s/it] 41%|████      | 192/471 [04:12<06:15,  1.35s/it] 41%|████      | 193/471 [04:14<06:13,  1.34s/it] 41%|████      | 194/471 [04:15<06:13,  1.35s/it] 41%|████▏     | 195/471 [04:16<06:11,  1.35s/it] 42%|████▏     | 196/471 [04:18<06:10,  1.35s/it] 42%|████▏     | 197/471 [04:19<06:08,  1.34s/it] 42%|████▏     | 198/471 [04:21<06:06,  1.34s/it] 42%|████▏     | 199/471 [04:22<06:05,  1.34s/it] 42%|████▏     | 200/471 [04:23<06:04,  1.35s/it] 43%|████▎     | 201/471 [04:25<06:02,  1.34s/it] 43%|████▎     | 202/471 [04:26<06:01,  1.34s/it] 43%|████▎     | 203/471 [04:27<06:00,  1.35s/it] 43%|████▎     | 204/471 [04:29<05:59,  1.34s/it] 44%|████▎     | 205/471 [04:30<05:57,  1.34s/it] 44%|████▎     | 206/471 [04:31<05:56,  1.34s/it] 44%|████▍     | 207/471 [04:33<05:55,  1.35s/it] 44%|████▍     | 208/471 [04:34<05:53,  1.35s/it] 44%|████▍     | 209/471 [04:35<05:52,  1.35s/it] 45%|████▍     | 210/471 [04:37<05:51,  1.35s/it] 45%|████▍     | 211/471 [04:38<05:49,  1.35s/it] 45%|████▌     | 212/471 [04:39<05:48,  1.35s/it] 45%|████▌     | 213/471 [04:41<05:48,  1.35s/it] 45%|████▌     | 214/471 [04:42<05:46,  1.35s/it] 46%|████▌     | 215/471 [04:43<05:45,  1.35s/it] 46%|████▌     | 216/471 [04:45<05:44,  1.35s/it] 46%|████▌     | 217/471 [04:46<05:43,  1.35s/it] 46%|████▋     | 218/471 [04:47<05:42,  1.35s/it] 46%|████▋     | 219/471 [04:49<05:40,  1.35s/it] 47%|████▋     | 220/471 [04:50<05:39,  1.35s/it] 47%|████▋     | 221/471 [04:52<05:37,  1.35s/it] 47%|████▋     | 222/471 [04:53<05:35,  1.35s/it] 47%|████▋     | 223/471 [04:54<05:34,  1.35s/it] 48%|████▊     | 224/471 [04:56<05:33,  1.35s/it] 48%|████▊     | 225/471 [04:57<05:31,  1.35s/it] 48%|████▊     | 226/471 [04:58<05:30,  1.35s/it] 48%|████▊     | 227/471 [05:00<05:29,  1.35s/it] 48%|████▊     | 228/471 [05:01<05:27,  1.35s/it] 49%|████▊     | 229/471 [05:02<05:26,  1.35s/it] 49%|████▉     | 230/471 [05:04<05:25,  1.35s/it] 49%|████▉     | 231/471 [05:05<05:24,  1.35s/it] 49%|████▉     | 232/471 [05:06<05:21,  1.35s/it] 49%|████▉     | 233/471 [05:08<05:20,  1.35s/it] 50%|████▉     | 234/471 [05:09<05:19,  1.35s/it] 50%|████▉     | 235/471 [05:10<05:18,  1.35s/it] 50%|█████     | 236/471 [05:12<05:16,  1.35s/it] 50%|█████     | 237/471 [05:13<05:15,  1.35s/it] 51%|█████     | 238/471 [05:14<05:14,  1.35s/it] 51%|█████     | 239/471 [05:16<05:12,  1.35s/it] 51%|█████     | 240/471 [05:17<05:11,  1.35s/it] 51%|█████     | 241/471 [05:18<05:10,  1.35s/it] 51%|█████▏    | 242/471 [05:20<05:08,  1.35s/it] 52%|█████▏    | 243/471 [05:21<05:07,  1.35s/it] 52%|█████▏    | 244/471 [05:23<05:05,  1.35s/it] 52%|█████▏    | 245/471 [05:24<05:04,  1.35s/it] 52%|█████▏    | 246/471 [05:25<05:02,  1.35s/it] 52%|█████▏    | 247/471 [05:27<05:01,  1.34s/it] 53%|█████▎    | 248/471 [05:28<05:00,  1.35s/it] 53%|█████▎    | 249/471 [05:29<04:59,  1.35s/it] 53%|█████▎    | 250/471 [05:31<04:57,  1.35s/it] 53%|█████▎    | 251/471 [05:32<04:55,  1.34s/it] 54%|█████▎    | 252/471 [05:33<04:54,  1.34s/it] 54%|█████▎    | 253/471 [05:35<04:53,  1.35s/it] 54%|█████▍    | 254/471 [05:36<04:51,  1.35s/it] 54%|█████▍    | 255/471 [05:37<04:50,  1.34s/it] 54%|█████▍    | 256/471 [05:39<04:49,  1.34s/it] 55%|█████▍    | 257/471 [05:40<04:47,  1.34s/it] 55%|█████▍    | 258/471 [05:41<04:46,  1.34s/it] 55%|█████▍    | 259/471 [05:43<04:44,  1.34s/it] 55%|█████▌    | 260/471 [05:44<04:43,  1.34s/it] 55%|█████▌    | 261/471 [05:45<04:41,  1.34s/it] 56%|█████▌    | 262/471 [05:47<04:40,  1.34s/it] 56%|█████▌    | 263/471 [05:48<04:38,  1.34s/it] 56%|█████▌    | 264/471 [05:49<04:37,  1.34s/it] 56%|█████▋    | 265/471 [05:51<04:36,  1.34s/it] 56%|█████▋    | 266/471 [05:52<04:35,  1.34s/it] 57%|█████▋    | 267/471 [05:53<04:33,  1.34s/it] 57%|█████▋    | 268/471 [05:55<04:32,  1.34s/it] 57%|█████▋    | 269/471 [05:56<04:31,  1.34s/it] 57%|█████▋    | 270/471 [05:57<04:29,  1.34s/it] 58%|█████▊    | 271/471 [05:59<04:28,  1.34s/it] 58%|█████▊    | 272/471 [06:00<04:26,  1.34s/it] 58%|█████▊    | 273/471 [06:01<04:25,  1.34s/it] 58%|█████▊    | 274/471 [06:03<04:23,  1.34s/it] 58%|█████▊    | 275/471 [06:04<04:21,  1.34s/it] 59%|█████▊    | 276/471 [06:05<04:20,  1.34s/it] 59%|█████▉    | 277/471 [06:07<04:19,  1.34s/it] 59%|█████▉    | 278/471 [06:08<04:18,  1.34s/it] 59%|█████▉    | 279/471 [06:09<04:17,  1.34s/it] 59%|█████▉    | 280/471 [06:11<04:15,  1.34s/it] 60%|█████▉    | 281/471 [06:12<04:14,  1.34s/it] 60%|█████▉    | 282/471 [06:13<04:13,  1.34s/it] 60%|██████    | 283/471 [06:15<04:12,  1.34s/it] 60%|██████    | 284/471 [06:16<04:10,  1.34s/it] 61%|██████    | 285/471 [06:18<04:09,  1.34s/it] 61%|██████    | 286/471 [06:19<04:08,  1.34s/it] 61%|██████    | 287/471 [06:20<04:06,  1.34s/it] 61%|██████    | 288/471 [06:22<04:05,  1.34s/it] 61%|██████▏   | 289/471 [06:23<04:03,  1.34s/it] 62%|██████▏   | 290/471 [06:24<04:02,  1.34s/it] 62%|██████▏   | 291/471 [06:26<04:01,  1.34s/it] 62%|██████▏   | 292/471 [06:27<03:59,  1.34s/it] 62%|██████▏   | 293/471 [06:28<03:57,  1.34s/it] 62%|██████▏   | 294/471 [06:30<03:56,  1.34s/it] 63%|██████▎   | 295/471 [06:31<03:55,  1.34s/it] 63%|██████▎   | 296/471 [06:32<03:53,  1.34s/it] 63%|██████▎   | 297/471 [06:34<03:52,  1.34s/it] 63%|██████▎   | 298/471 [06:35<03:51,  1.34s/it] 63%|██████▎   | 299/471 [06:36<03:50,  1.34s/it] 64%|██████▎   | 300/471 [06:38<03:48,  1.34s/it] 64%|██████▍   | 301/471 [06:39<03:47,  1.34s/it] 64%|██████▍   | 302/471 [06:40<03:45,  1.34s/it] 64%|██████▍   | 303/471 [06:42<03:44,  1.34s/it] 65%|██████▍   | 304/471 [06:43<03:42,  1.34s/it] 65%|██████▍   | 305/471 [06:44<03:41,  1.34s/it] 65%|██████▍   | 306/471 [06:46<03:40,  1.34s/it] 65%|██████▌   | 307/471 [06:47<03:39,  1.34s/it] 65%|██████▌   | 308/471 [06:48<03:38,  1.34s/it] 66%|██████▌   | 309/471 [06:50<03:36,  1.34s/it] 66%|██████▌   | 310/471 [06:51<03:35,  1.34s/it] 66%|██████▌   | 311/471 [06:52<03:33,  1.34s/it] 66%|██████▌   | 312/471 [06:54<03:32,  1.34s/it] 66%|██████▋   | 313/471 [06:55<03:31,  1.34s/it] 67%|██████▋   | 314/471 [06:56<03:29,  1.33s/it] 67%|██████▋   | 315/471 [06:58<03:28,  1.34s/it] 67%|██████▋   | 316/471 [06:59<03:26,  1.33s/it] 67%|██████▋   | 317/471 [07:00<03:25,  1.33s/it] 68%|██████▊   | 318/471 [07:02<03:24,  1.34s/it] 68%|██████▊   | 319/471 [07:03<03:23,  1.34s/it] 68%|██████▊   | 320/471 [07:04<03:21,  1.34s/it] 68%|██████▊   | 321/471 [07:06<03:20,  1.34s/it] 68%|██████▊   | 322/471 [07:07<03:19,  1.34s/it] 69%|██████▊   | 323/471 [07:08<03:18,  1.34s/it] 69%|██████▉   | 324/471 [07:10<03:16,  1.34s/it] 69%|██████▉   | 325/471 [07:11<03:15,  1.34s/it] 69%|██████▉   | 326/471 [07:12<03:13,  1.34s/it] 69%|██████▉   | 327/471 [07:14<03:12,  1.34s/it] 70%|██████▉   | 328/471 [07:15<03:11,  1.34s/it] 70%|██████▉   | 329/471 [07:16<03:10,  1.34s/it] 70%|███████   | 330/471 [07:18<03:08,  1.34s/it] 70%|███████   | 331/471 [07:19<03:07,  1.34s/it] 70%|███████   | 332/471 [07:20<03:05,  1.34s/it] 71%|███████   | 333/471 [07:22<03:04,  1.34s/it] 71%|███████   | 334/471 [07:23<03:03,  1.34s/it] 71%|███████   | 335/471 [07:24<03:01,  1.34s/it] 71%|███████▏  | 336/471 [07:26<03:00,  1.34s/it] 72%|███████▏  | 337/471 [07:27<02:58,  1.33s/it] 72%|███████▏  | 338/471 [07:28<02:57,  1.33s/it] 72%|███████▏  | 339/471 [07:30<02:56,  1.33s/it] 72%|███████▏  | 340/471 [07:31<02:54,  1.33s/it] 72%|███████▏  | 341/471 [07:32<02:53,  1.33s/it] 73%|███████▎  | 342/471 [07:34<02:52,  1.33s/it] 73%|███████▎  | 343/471 [07:35<02:50,  1.34s/it] 73%|███████▎  | 344/471 [07:36<02:49,  1.33s/it] 73%|███████▎  | 345/471 [07:38<02:47,  1.33s/it] 73%|███████▎  | 346/471 [07:39<02:46,  1.33s/it] 74%|███████▎  | 347/471 [07:40<02:45,  1.33s/it] 74%|███████▍  | 348/471 [07:42<02:43,  1.33s/it] 74%|███████▍  | 349/471 [07:43<02:42,  1.33s/it] 74%|███████▍  | 350/471 [07:44<02:41,  1.33s/it] 75%|███████▍  | 351/471 [07:46<02:39,  1.33s/it] 75%|███████▍  | 352/471 [07:47<02:38,  1.33s/it] 75%|███████▍  | 353/471 [07:48<02:37,  1.34s/it] 75%|███████▌  | 354/471 [07:50<02:36,  1.33s/it] 75%|███████▌  | 355/471 [07:51<02:34,  1.34s/it] 76%|███████▌  | 356/471 [07:52<02:33,  1.34s/it] 76%|███████▌  | 357/471 [07:54<02:32,  1.34s/it] 76%|███████▌  | 358/471 [07:55<02:30,  1.34s/it] 76%|███████▌  | 359/471 [07:56<02:29,  1.34s/it] 76%|███████▋  | 360/471 [07:58<02:28,  1.34s/it] 77%|███████▋  | 361/471 [07:59<02:26,  1.34s/it] 77%|███████▋  | 362/471 [08:00<02:25,  1.34s/it] 77%|███████▋  | 363/471 [08:02<02:24,  1.33s/it] 77%|███████▋  | 364/471 [08:03<02:22,  1.34s/it] 77%|███████▋  | 365/471 [08:04<02:21,  1.34s/it] 78%|███████▊  | 366/471 [08:06<02:20,  1.34s/it] 78%|███████▊  | 367/471 [08:07<02:19,  1.34s/it] 78%|███████▊  | 368/471 [08:08<02:17,  1.34s/it] 78%|███████▊  | 369/471 [08:10<02:16,  1.33s/it] 79%|███████▊  | 370/471 [08:11<02:15,  1.34s/it] 79%|███████▉  | 371/471 [08:12<02:13,  1.34s/it] 79%|███████▉  | 372/471 [08:14<02:12,  1.34s/it] 79%|███████▉  | 373/471 [08:15<02:11,  1.34s/it] 79%|███████▉  | 374/471 [08:16<02:09,  1.34s/it] 80%|███████▉  | 375/471 [08:18<02:08,  1.34s/it] 80%|███████▉  | 376/471 [08:19<02:06,  1.34s/it] 80%|████████  | 377/471 [08:20<02:05,  1.34s/it] 80%|████████  | 378/471 [08:22<02:04,  1.34s/it] 80%|████████  | 379/471 [08:23<02:02,  1.34s/it] 81%|████████  | 380/471 [08:24<02:01,  1.34s/it] 81%|████████  | 381/471 [08:26<02:00,  1.34s/it] 81%|████████  | 382/471 [08:27<01:59,  1.34s/it] 81%|████████▏ | 383/471 [08:28<01:57,  1.34s/it] 82%|████████▏ | 384/471 [08:30<01:56,  1.34s/it] 82%|████████▏ | 385/471 [08:31<01:55,  1.34s/it] 82%|████████▏ | 386/471 [08:33<01:53,  1.34s/it] 82%|████████▏ | 387/471 [08:34<01:52,  1.34s/it] 82%|████████▏ | 388/471 [08:35<01:51,  1.34s/it] 83%|████████▎ | 389/471 [08:37<01:49,  1.34s/it] 83%|████████▎ | 390/471 [08:38<01:48,  1.34s/it] 83%|████████▎ | 391/471 [08:39<01:47,  1.34s/it] 83%|████████▎ | 392/471 [08:41<01:45,  1.34s/it] 83%|████████▎ | 393/471 [08:42<01:44,  1.34s/it] 84%|████████▎ | 394/471 [08:43<01:43,  1.34s/it] 84%|████████▍ | 395/471 [08:45<01:42,  1.34s/it] 84%|████████▍ | 396/471 [08:46<01:40,  1.34s/it] 84%|████████▍ | 397/471 [08:47<01:39,  1.34s/it] 85%|████████▍ | 398/471 [08:49<01:37,  1.34s/it] 85%|████████▍ | 399/471 [08:50<01:36,  1.34s/it] 85%|████████▍ | 400/471 [08:51<01:35,  1.34s/it] 85%|████████▌ | 401/471 [08:53<01:33,  1.34s/it] 85%|████████▌ | 402/471 [08:54<01:32,  1.34s/it] 86%|████████▌ | 403/471 [08:55<01:30,  1.34s/it] 86%|████████▌ | 404/471 [08:57<01:29,  1.34s/it] 86%|████████▌ | 405/471 [08:58<01:28,  1.34s/it] 86%|████████▌ | 406/471 [08:59<01:27,  1.34s/it] 86%|████████▋ | 407/471 [09:01<01:25,  1.34s/it] 87%|████████▋ | 408/471 [09:02<01:24,  1.34s/it] 87%|████████▋ | 409/471 [09:03<01:23,  1.34s/it] 87%|████████▋ | 410/471 [09:05<01:21,  1.34s/it] 87%|████████▋ | 411/471 [09:06<01:20,  1.34s/it] 87%|████████▋ | 412/471 [09:07<01:19,  1.34s/it] 88%|████████▊ | 413/471 [09:09<01:17,  1.34s/it] 88%|████████▊ | 414/471 [09:10<01:16,  1.34s/it] 88%|████████▊ | 415/471 [09:11<01:14,  1.34s/it] 88%|████████▊ | 416/471 [09:13<01:13,  1.34s/it] 89%|████████▊ | 417/471 [09:14<01:12,  1.34s/it] 89%|████████▊ | 418/471 [09:15<01:11,  1.34s/it] 89%|████████▉ | 419/471 [09:17<01:09,  1.34s/it] 89%|████████▉ | 420/471 [09:18<01:08,  1.34s/it] 89%|████████▉ | 421/471 [09:19<01:07,  1.34s/it] 90%|████████▉ | 422/471 [09:21<01:05,  1.34s/it] 90%|████████▉ | 423/471 [09:22<01:04,  1.34s/it] 90%|█████████ | 424/471 [09:23<01:03,  1.34s/it] 90%|█████████ | 425/471 [09:25<01:01,  1.34s/it] 90%|█████████ | 426/471 [09:26<01:00,  1.34s/it] 91%|█████████ | 427/471 [09:27<00:59,  1.34s/it] 91%|█████████ | 428/471 [09:29<00:57,  1.34s/it] 91%|█████████ | 429/471 [09:30<00:56,  1.34s/it] 91%|█████████▏| 430/471 [09:31<00:54,  1.34s/it] 92%|█████████▏| 431/471 [09:33<00:53,  1.34s/it] 92%|█████████▏| 432/471 [09:34<00:52,  1.34s/it] 92%|█████████▏| 433/471 [09:36<00:50,  1.34s/it] 92%|█████████▏| 434/471 [09:37<00:49,  1.34s/it] 92%|█████████▏| 435/471 [09:38<00:48,  1.34s/it] 93%|█████████▎| 436/471 [09:40<00:46,  1.34s/it] 93%|█████████▎| 437/471 [09:41<00:45,  1.34s/it] 93%|█████████▎| 438/471 [09:42<00:44,  1.34s/it] 93%|█████████▎| 439/471 [09:44<00:42,  1.34s/it] 93%|█████████▎| 440/471 [09:45<00:41,  1.34s/it] 94%|█████████▎| 441/471 [09:46<00:40,  1.34s/it] 94%|█████████▍| 442/471 [09:48<00:38,  1.34s/it] 94%|█████████▍| 443/471 [09:49<00:37,  1.34s/it] 94%|█████████▍| 444/471 [09:50<00:36,  1.34s/it] 94%|█████████▍| 445/471 [09:52<00:34,  1.34s/it] 95%|█████████▍| 446/471 [09:53<00:33,  1.34s/it] 95%|█████████▍| 447/471 [09:54<00:32,  1.34s/it] 95%|█████████▌| 448/471 [09:56<00:30,  1.34s/it] 95%|█████████▌| 449/471 [09:57<00:29,  1.34s/it] 96%|█████████▌| 450/471 [09:58<00:28,  1.34s/it] 96%|█████████▌| 451/471 [10:00<00:26,  1.34s/it] 96%|█████████▌| 452/471 [10:01<00:25,  1.34s/it] 96%|█████████▌| 453/471 [10:02<00:24,  1.35s/it] 96%|█████████▋| 454/471 [10:04<00:22,  1.35s/it] 97%|█████████▋| 455/471 [10:05<00:21,  1.35s/it] 97%|█████████▋| 456/471 [10:06<00:20,  1.34s/it] 97%|█████████▋| 457/471 [10:08<00:18,  1.35s/it] 97%|█████████▋| 458/471 [10:09<00:17,  1.34s/it] 97%|█████████▋| 459/471 [10:10<00:16,  1.34s/it] 98%|█████████▊| 460/471 [10:12<00:14,  1.34s/it] 98%|█████████▊| 461/471 [10:13<00:13,  1.34s/it] 98%|█████████▊| 462/471 [10:14<00:12,  1.34s/it] 98%|█████████▊| 463/471 [10:16<00:10,  1.34s/it] 99%|█████████▊| 464/471 [10:17<00:09,  1.34s/it] 99%|█████████▊| 465/471 [10:18<00:08,  1.34s/it] 99%|█████████▉| 466/471 [10:20<00:06,  1.34s/it] 99%|█████████▉| 467/471 [10:21<00:05,  1.34s/it] 99%|█████████▉| 468/471 [10:22<00:04,  1.34s/it]100%|█████████▉| 469/471 [10:24<00:02,  1.34s/it]100%|█████████▉| 470/471 [10:25<00:01,  1.34s/it]100%|██████████| 471/471 [10:26<00:00,  1.23s/it]100%|██████████| 471/471 [10:26<00:00,  1.33s/it]
{'eval_loss': 2.35646390914917, 'eval_model_preparation_time': 0.016, 'eval_acc': 0.37612851832182687, 'eval_runtime': 627.9006, 'eval_samples_per_second': 11.996, 'eval_steps_per_second': 0.75}
ROUND:18
CLIENT:83
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:31,  2.35s/it]                                              {'loss': 2.0338, 'grad_norm': 10.43689250946045, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:31,  2.35s/it]  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]                                              {'loss': 2.2094, 'grad_norm': 12.505924224853516, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]  8%|▊         | 3/40 [00:06<01:22,  2.23s/it]                                              {'loss': 1.6177, 'grad_norm': 12.307507514953613, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.23s/it] 10%|█         | 4/40 [00:08<01:20,  2.22s/it]                                              {'loss': 2.3818, 'grad_norm': 19.566787719726562, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:20,  2.22s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 2.3834, 'grad_norm': 17.591527938842773, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 1.7917, 'grad_norm': 12.332414627075195, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 2.302, 'grad_norm': 24.911588668823242, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.0138, 'grad_norm': 0.9712167978286743, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 1.0586, 'grad_norm': 14.80253791809082, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.6953, 'grad_norm': 7.6893815994262695, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 0.9363, 'grad_norm': 8.247818946838379, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 1.4093, 'grad_norm': 8.368681907653809, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 0.8283, 'grad_norm': 19.299457550048828, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it]                                               {'loss': 0.7443, 'grad_norm': 7.890218257904053, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.3913, 'grad_norm': 6.779590129852295, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.0153, 'grad_norm': 0.8781875967979431, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it]                                               {'loss': 0.1445, 'grad_norm': 3.749021053314209, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.3005, 'grad_norm': 5.3665008544921875, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it]                                               {'loss': 0.4382, 'grad_norm': 4.9470295906066895, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it] 50%|█████     | 20/40 [00:40<00:41,  2.10s/it]                                               {'loss': 0.2712, 'grad_norm': 5.24606466293335, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.10s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it]                                               {'loss': 0.426, 'grad_norm': 5.995309829711914, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.6326, 'grad_norm': 4.724743843078613, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.5965, 'grad_norm': 10.713509559631348, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.3917, 'grad_norm': 18.137109756469727, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it]                                               {'loss': 0.0857, 'grad_norm': 2.18735408782959, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.80s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it]                                               {'loss': 0.101, 'grad_norm': 3.3830299377441406, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.1453, 'grad_norm': 3.8735930919647217, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.1819, 'grad_norm': 4.439356803894043, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.2159, 'grad_norm': 2.8306188583374023, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it]                                               {'loss': 0.201, 'grad_norm': 2.8148531913757324, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.18s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.0753, 'grad_norm': 1.2236050367355347, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0046, 'grad_norm': 0.2775169909000397, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0281, 'grad_norm': 0.6537076234817505, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it]                                               {'loss': 0.0555, 'grad_norm': 3.8613619804382324, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it]                                               {'loss': 0.1391, 'grad_norm': 3.4748635292053223, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.04s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0573, 'grad_norm': 1.6754333972930908, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.017, 'grad_norm': 0.48773789405822754, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.039, 'grad_norm': 1.0555214881896973, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]                                               {'loss': 0.1032, 'grad_norm': 3.7890355587005615, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.24s/it]100%|██████████| 40/40 [01:19<00:00,  1.63s/it]                                               {'loss': 0.262, 'grad_norm': 31.443374633789062, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.63s/it]                                               {'train_runtime': 80.1243, 'train_samples_per_second': 7.052, 'train_steps_per_second': 0.499, 'train_loss': 0.6431396463187411, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.63s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:1
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:35,  2.46s/it]                                              {'loss': 2.1003, 'grad_norm': 10.135825157165527, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:35,  2.46s/it]  5%|▌         | 2/40 [00:04<01:26,  2.28s/it]                                              {'loss': 1.9428, 'grad_norm': 14.661042213439941, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.28s/it]  8%|▊         | 3/40 [00:06<01:22,  2.23s/it]                                              {'loss': 2.6017, 'grad_norm': 13.259495735168457, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.23s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 2.9742, 'grad_norm': 18.807586669921875, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 2.0011, 'grad_norm': 14.266251564025879, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 3.1711, 'grad_norm': 18.00364875793457, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 2.1149, 'grad_norm': 16.087453842163086, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 1.1536, 'grad_norm': 62.629150390625, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it]                                              {'loss': 1.8362, 'grad_norm': 18.49388885498047, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 1.8683, 'grad_norm': 16.46482276916504, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 1.1481, 'grad_norm': 11.333834648132324, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.7628, 'grad_norm': 10.123574256896973, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 0.8304, 'grad_norm': 8.849644660949707, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 1.0463, 'grad_norm': 8.491823196411133, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it]                                               {'loss': 0.6092, 'grad_norm': 5.495452404022217, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:53,  2.16s/it] 40%|████      | 16/40 [00:31<00:37,  1.56s/it]                                               {'loss': 0.1548, 'grad_norm': 5.860968112945557, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.56s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.3049, 'grad_norm': 4.867598533630371, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.4739, 'grad_norm': 5.172276973724365, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it]                                               {'loss': 0.3612, 'grad_norm': 4.44968843460083, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it] 50%|█████     | 20/40 [00:40<00:41,  2.09s/it]                                               {'loss': 0.5716, 'grad_norm': 5.507215976715088, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.09s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.1861, 'grad_norm': 5.097925662994385, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.2519, 'grad_norm': 4.474127292633057, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it]                                               {'loss': 0.2719, 'grad_norm': 5.096777439117432, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0393, 'grad_norm': 2.3808584213256836, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.349, 'grad_norm': 6.840668678283691, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.2668, 'grad_norm': 4.834334850311279, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it]                                               {'loss': 0.0953, 'grad_norm': 3.269634246826172, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.01s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.3005, 'grad_norm': 4.048323154449463, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.3511, 'grad_norm': 2.20462965965271, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.0731, 'grad_norm': 1.8425225019454956, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.0748, 'grad_norm': 2.0414462089538574, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0109, 'grad_norm': 0.7343270182609558, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0294, 'grad_norm': 0.7707435488700867, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.0404, 'grad_norm': 1.6916611194610596, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.0614, 'grad_norm': 1.5894237756729126, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.2159, 'grad_norm': 5.699224948883057, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.072, 'grad_norm': 1.8581324815750122, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it]                                               {'loss': 0.4341, 'grad_norm': 4.830478668212891, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.17s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]                                               {'loss': 0.0513, 'grad_norm': 1.8527579307556152, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.1269, 'grad_norm': 8.218101501464844, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.6201, 'train_samples_per_second': 7.096, 'train_steps_per_second': 0.502, 'train_loss': 0.7832351680612192, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:55
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:30,  2.33s/it]                                              {'loss': 1.7026, 'grad_norm': 9.119308471679688, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:30,  2.33s/it]  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]                                              {'loss': 3.228, 'grad_norm': 15.073089599609375, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]  8%|▊         | 3/40 [00:06<01:21,  2.20s/it]                                              {'loss': 2.0063, 'grad_norm': 13.789545059204102, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.20s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 1.4074, 'grad_norm': 11.574748992919922, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it]                                              {'loss': 2.4231, 'grad_norm': 13.456851959228516, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.21s/it]                                              {'loss': 1.0712, 'grad_norm': 11.687952041625977, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it]                                              {'loss': 2.8143, 'grad_norm': 19.148731231689453, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.21s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 0.8844, 'grad_norm': 35.53176498413086, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 0.7935, 'grad_norm': 11.694381713867188, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it]                                               {'loss': 0.6536, 'grad_norm': 11.835232734680176, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.5386, 'grad_norm': 8.167458534240723, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 1.0555, 'grad_norm': 8.066353797912598, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 0.8429, 'grad_norm': 29.756908416748047, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it]                                               {'loss': 0.759, 'grad_norm': 14.498204231262207, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.6541, 'grad_norm': 6.1068010330200195, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 1.2742, 'grad_norm': 36.70698928833008, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.2376, 'grad_norm': 7.706533432006836, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.235, 'grad_norm': 3.395068407058716, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it]                                               {'loss': 0.78, 'grad_norm': 7.326142311096191, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.1754, 'grad_norm': 5.335920333862305, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.1777, 'grad_norm': 2.665755033493042, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.426, 'grad_norm': 6.6944122314453125, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it]                                               {'loss': 0.1859, 'grad_norm': 4.467652320861816, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0024, 'grad_norm': 0.16543564200401306, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0915, 'grad_norm': 2.84489107131958, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.1125, 'grad_norm': 2.1068179607391357, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.2494, 'grad_norm': 4.728631973266602, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.269, 'grad_norm': 6.352916240692139, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.3703, 'grad_norm': 4.815624237060547, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it]                                               {'loss': 0.057, 'grad_norm': 2.1611711978912354, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.0757, 'grad_norm': 2.6916732788085938, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0096, 'grad_norm': 0.7115591764450073, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.2044, 'grad_norm': 6.826171398162842, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.0582, 'grad_norm': 1.6520917415618896, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.0905, 'grad_norm': 2.3602006435394287, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0937, 'grad_norm': 2.7765953540802, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.0264, 'grad_norm': 0.5532320737838745, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.0662, 'grad_norm': 3.663520097732544, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.22s/it]                                               {'loss': 0.0345, 'grad_norm': 0.9119462370872498, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0207, 'grad_norm': 1.9897661209106445, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.4483, 'train_samples_per_second': 7.112, 'train_steps_per_second': 0.503, 'train_loss': 0.6539617726637517, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:9
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]                                              {'loss': 1.7313, 'grad_norm': 11.110304832458496, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:42,  2.62s/it]  5%|▌         | 2/40 [00:04<01:29,  2.34s/it]                                              {'loss': 1.7944, 'grad_norm': 13.031791687011719, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:29,  2.34s/it]  8%|▊         | 3/40 [00:06<01:24,  2.28s/it]                                              {'loss': 1.5816, 'grad_norm': 12.746541023254395, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:24,  2.28s/it] 10%|█         | 4/40 [00:09<01:20,  2.24s/it]                                              {'loss': 1.6656, 'grad_norm': 14.898576736450195, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.24s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 2.1675, 'grad_norm': 17.466840744018555, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 1.9163, 'grad_norm': 13.372477531433105, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.4467, 'grad_norm': 16.37503433227539, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 0.9285, 'grad_norm': 37.883216857910156, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 0.5463, 'grad_norm': 9.005499839782715, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it]                                               {'loss': 0.866, 'grad_norm': 11.318406105041504, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it]                                               {'loss': 0.5707, 'grad_norm': 7.731551170349121, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.7689, 'grad_norm': 8.68165111541748, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it]                                               {'loss': 0.2538, 'grad_norm': 4.241880893707275, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it]                                               {'loss': 0.4644, 'grad_norm': 6.40285062789917, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:55,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.4108, 'grad_norm': 10.514315605163574, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.614, 'grad_norm': 31.85990333557129, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it]                                               {'loss': 0.3039, 'grad_norm': 8.04289722442627, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.77s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it]                                               {'loss': 0.1036, 'grad_norm': 3.226294755935669, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.08s/it]                                               {'loss': 0.1395, 'grad_norm': 3.9426469802856445, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.08s/it] 50%|█████     | 20/40 [00:40<00:42,  2.12s/it]                                               {'loss': 0.1376, 'grad_norm': 4.07171106338501, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it]                                               {'loss': 0.3918, 'grad_norm': 9.856528282165527, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.1257, 'grad_norm': 2.5472335815429688, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.2214, 'grad_norm': 4.381567001342773, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.011, 'grad_norm': 0.5952135324478149, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.0229, 'grad_norm': 0.5421695709228516, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it]                                               {'loss': 0.0401, 'grad_norm': 0.7517092823982239, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.94s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.0672, 'grad_norm': 0.7558702826499939, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:24,  2.08s/it]                                               {'loss': 0.0274, 'grad_norm': 0.800858199596405, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.03, 'grad_norm': 0.5498255491256714, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.16s/it]                                               {'loss': 0.1265, 'grad_norm': 6.037971019744873, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.16s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it]                                               {'loss': 0.0322, 'grad_norm': 0.8413941860198975, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.19s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0001, 'grad_norm': 0.007350616157054901, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it]                                               {'loss': 0.0107, 'grad_norm': 0.2192685306072235, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.79s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.91s/it]                                               {'loss': 0.0057, 'grad_norm': 0.11492911726236343, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.91s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.01s/it]                                               {'loss': 0.0147, 'grad_norm': 0.45781636238098145, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.01s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it]                                               {'loss': 0.0214, 'grad_norm': 0.629464864730835, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.09s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.13s/it]                                               {'loss': 0.0131, 'grad_norm': 0.3404909670352936, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.13s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it]                                               {'loss': 0.0148, 'grad_norm': 0.4601615071296692, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]                                               {'loss': 0.0159, 'grad_norm': 0.37020987272262573, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0006, 'grad_norm': 0.04289834573864937, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.8293, 'train_samples_per_second': 7.078, 'train_steps_per_second': 0.501, 'train_loss': 0.5151120977101528, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  2.00s/it]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:44,  2.69s/it]                                              {'loss': 1.548, 'grad_norm': 10.692391395568848, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:44,  2.69s/it]  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]                                              {'loss': 1.616, 'grad_norm': 12.182904243469238, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:31,  2.40s/it]  8%|▊         | 3/40 [00:07<01:25,  2.31s/it]                                              {'loss': 1.2554, 'grad_norm': 11.66514778137207, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:07<01:25,  2.31s/it] 10%|█         | 4/40 [00:09<01:21,  2.26s/it]                                              {'loss': 2.6722, 'grad_norm': 18.731016159057617, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:21,  2.26s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it]                                              {'loss': 3.1239, 'grad_norm': 20.020572662353516, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.8501, 'grad_norm': 18.289981842041016, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 1.6075, 'grad_norm': 14.182995796203613, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:16<00:50,  1.57s/it]                                              {'loss': 0.6253, 'grad_norm': 23.128549575805664, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:16<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it]                                              {'loss': 0.4934, 'grad_norm': 8.00316333770752, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.9058, 'grad_norm': 11.196200370788574, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it]                                               {'loss': 0.4149, 'grad_norm': 6.075137615203857, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.01s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.6115, 'grad_norm': 5.2923712730407715, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it]                                               {'loss': 1.5275, 'grad_norm': 12.966712951660156, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 1.6198, 'grad_norm': 12.492619514465332, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.8391, 'grad_norm': 8.189618110656738, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 1.8545, 'grad_norm': 61.45014953613281, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it]                                               {'loss': 0.1238, 'grad_norm': 4.069749355316162, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.1872, 'grad_norm': 3.4377810955047607, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.3273, 'grad_norm': 4.773770809173584, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:42,  2.10s/it]                                               {'loss': 0.1295, 'grad_norm': 2.889296531677246, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it]                                               {'loss': 0.0742, 'grad_norm': 2.0024192333221436, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.4322, 'grad_norm': 6.6810383796691895, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.2365, 'grad_norm': 3.654733180999756, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0187, 'grad_norm': 0.9530608654022217, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it]                                               {'loss': 0.0602, 'grad_norm': 1.808351993560791, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.0603, 'grad_norm': 1.8552106618881226, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.0999, 'grad_norm': 1.852813720703125, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:57<00:25,  2.10s/it]                                               {'loss': 0.1949, 'grad_norm': 3.3084397315979004, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it]                                               {'loss': 0.0639, 'grad_norm': 1.4369542598724365, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.0194, 'grad_norm': 0.39749300479888916, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.0545, 'grad_norm': 1.1363003253936768, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:04<00:12,  1.62s/it]                                               {'loss': 0.0005, 'grad_norm': 0.02904585748910904, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.055, 'grad_norm': 2.8561551570892334, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.3236, 'grad_norm': 6.987924575805664, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.0497, 'grad_norm': 2.9508488178253174, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it]                                               {'loss': 0.0366, 'grad_norm': 1.0653282403945923, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it]                                               {'loss': 0.0452, 'grad_norm': 1.6922686100006104, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.18s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it]                                               {'loss': 0.031, 'grad_norm': 0.8853077292442322, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]                                               {'loss': 0.0252, 'grad_norm': 0.7306565642356873, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.24s/it]100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'loss': 0.0334, 'grad_norm': 2.1564748287200928, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]                                               {'train_runtime': 80.5915, 'train_samples_per_second': 7.011, 'train_steps_per_second': 0.496, 'train_loss': 0.6561890727098216, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.62s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:28
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:31,  2.34s/it]                                              {'loss': 1.4114, 'grad_norm': 9.01004695892334, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:31,  2.34s/it]  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]                                              {'loss': 1.2006, 'grad_norm': 9.82901382446289, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:26,  2.27s/it]  8%|▊         | 3/40 [00:06<01:21,  2.22s/it]                                              {'loss': 2.0214, 'grad_norm': 16.282365798950195, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.22s/it] 10%|█         | 4/40 [00:08<01:19,  2.21s/it]                                              {'loss': 1.8877, 'grad_norm': 12.680415153503418, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.21s/it] 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it]                                              {'loss': 2.3654, 'grad_norm': 20.20708656311035, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:16,  2.19s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 1.9048, 'grad_norm': 15.712611198425293, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.3078, 'grad_norm': 15.56396198272705, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 3.9857, 'grad_norm': 43.338436126708984, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 0.9945, 'grad_norm': 10.376737594604492, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it]                                               {'loss': 0.675, 'grad_norm': 7.083389759063721, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.90s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 0.6706, 'grad_norm': 8.697970390319824, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 0.5801, 'grad_norm': 7.715720176696777, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it]                                               {'loss': 0.5339, 'grad_norm': 6.383113384246826, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.12s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it]                                               {'loss': 1.0612, 'grad_norm': 11.229649543762207, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.4454, 'grad_norm': 4.786159992218018, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.1533, 'grad_norm': 5.919704437255859, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.6233, 'grad_norm': 4.327720642089844, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.3929, 'grad_norm': 4.168677806854248, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.2125, 'grad_norm': 8.166131973266602, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.203, 'grad_norm': 3.8606343269348145, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.0512, 'grad_norm': 1.2553048133850098, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it]                                               {'loss': 0.199, 'grad_norm': 3.198370933532715, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.15s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it]                                               {'loss': 0.2442, 'grad_norm': 5.289741516113281, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.18s/it] 60%|██████    | 24/40 [00:47<00:25,  1.58s/it]                                               {'loss': 1.1081, 'grad_norm': 45.503292083740234, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.58s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0695, 'grad_norm': 0.8753159046173096, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.1328, 'grad_norm': 3.070455312728882, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.1874, 'grad_norm': 7.394510746002197, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.0856, 'grad_norm': 2.0250649452209473, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.0532, 'grad_norm': 1.5607622861862183, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.558, 'grad_norm': 659.6495361328125, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.4123, 'grad_norm': 6.298951148986816, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.59s/it]                                               {'loss': 0.0393, 'grad_norm': 2.447601318359375, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.59s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0733, 'grad_norm': 1.9589505195617676, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it]                                               {'loss': 0.0181, 'grad_norm': 0.5419285893440247, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.05s/it]                                               {'loss': 0.0266, 'grad_norm': 0.7109692096710205, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.2083, 'grad_norm': 10.243856430053711, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it]                                               {'loss': 0.0414, 'grad_norm': 3.4186668395996094, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.14s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.0474, 'grad_norm': 2.252370834350586, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]                                               {'loss': 0.023, 'grad_norm': 0.5124155879020691, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.20s/it]100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'loss': 0.0009, 'grad_norm': 0.05336200073361397, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]                                               {'train_runtime': 79.4179, 'train_samples_per_second': 7.114, 'train_steps_per_second': 0.504, 'train_loss': 0.6552556046633982, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.59s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:96
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:28,  2.26s/it]                                              {'loss': 2.9312, 'grad_norm': 12.781270027160645, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:28,  2.26s/it]  5%|▌         | 2/40 [00:04<01:23,  2.19s/it]                                              {'loss': 2.566, 'grad_norm': 16.12627410888672, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.19s/it]  8%|▊         | 3/40 [00:06<01:21,  2.20s/it]                                              {'loss': 2.688, 'grad_norm': 15.836370468139648, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.20s/it] 10%|█         | 4/40 [00:08<01:18,  2.18s/it]                                              {'loss': 2.2058, 'grad_norm': 29.334854125976562, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.18s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it]                                              {'loss': 1.9847, 'grad_norm': 22.243240356445312, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 1.5831, 'grad_norm': 15.72024917602539, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.18s/it]                                              {'loss': 0.9287, 'grad_norm': 10.638936042785645, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 2.9126, 'grad_norm': 121.30854797363281, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.74s/it]                                              {'loss': 0.4114, 'grad_norm': 7.02516508102417, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.74s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it]                                               {'loss': 1.0219, 'grad_norm': 9.125953674316406, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it]                                               {'loss': 0.9992, 'grad_norm': 9.458080291748047, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.98s/it] 30%|███       | 12/40 [00:24<00:57,  2.04s/it]                                               {'loss': 0.7007, 'grad_norm': 10.653284072875977, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.04s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 0.6406, 'grad_norm': 11.660019874572754, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it]                                               {'loss': 0.2402, 'grad_norm': 4.603369235992432, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.14s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it]                                               {'loss': 0.2391, 'grad_norm': 4.887451171875, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it] 40%|████      | 16/40 [00:31<00:37,  1.55s/it]                                               {'loss': 0.0224, 'grad_norm': 2.7788264751434326, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.55s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it]                                               {'loss': 0.0984, 'grad_norm': 2.6377997398376465, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.75s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it]                                               {'loss': 0.0612, 'grad_norm': 2.8245632648468018, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.89s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it]                                               {'loss': 0.4606, 'grad_norm': 7.806159019470215, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.98s/it] 50%|█████     | 20/40 [00:39<00:41,  2.07s/it]                                               {'loss': 0.4042, 'grad_norm': 9.790275573730469, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.1744, 'grad_norm': 4.867080211639404, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it]                                               {'loss': 0.167, 'grad_norm': 7.662105560302734, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.14s/it] 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it]                                               {'loss': 0.763, 'grad_norm': 8.813769340515137, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:36,  2.16s/it] 60%|██████    | 24/40 [00:46<00:25,  1.57s/it]                                               {'loss': 0.0332, 'grad_norm': 1.8534424304962158, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.57s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.1387, 'grad_norm': 8.352676391601562, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it]                                               {'loss': 0.1027, 'grad_norm': 3.8315694332122803, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.92s/it] 68%|██████▊   | 27/40 [00:53<00:25,  1.99s/it]                                               {'loss': 0.1182, 'grad_norm': 3.019650936126709, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:25,  1.99s/it] 70%|███████   | 28/40 [00:55<00:24,  2.08s/it]                                               {'loss': 0.0553, 'grad_norm': 2.3318071365356445, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:24,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.2957, 'grad_norm': 4.435487747192383, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.15s/it]                                               {'loss': 0.0971, 'grad_norm': 5.536174297332764, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.15s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it]                                               {'loss': 0.0789, 'grad_norm': 1.989071249961853, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.18s/it] 80%|████████  | 32/40 [01:02<00:12,  1.58s/it]                                               {'loss': 0.0008, 'grad_norm': 0.05737832561135292, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.58s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.77s/it]                                               {'loss': 0.0718, 'grad_norm': 3.116460084915161, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.77s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.0438, 'grad_norm': 2.310864210128784, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it]                                               {'loss': 0.0382, 'grad_norm': 0.8698762655258179, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.02s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it]                                               {'loss': 0.0454, 'grad_norm': 1.2695155143737793, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.15s/it]                                               {'loss': 0.2901, 'grad_norm': 5.133261203765869, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.0958, 'grad_norm': 2.1213884353637695, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]                                               {'loss': 0.051, 'grad_norm': 1.901471495628357, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.19s/it]100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'loss': 0.0072, 'grad_norm': 0.5670489072799683, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]                                               {'train_runtime': 78.8478, 'train_samples_per_second': 7.166, 'train_steps_per_second': 0.507, 'train_loss': 0.6442056433632388, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.59s/it]100%|██████████| 40/40 [01:18<00:00,  1.97s/it]
CLIENT:29
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:26,  2.22s/it]                                              {'loss': 2.0953, 'grad_norm': 11.641961097717285, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:26,  2.22s/it]  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]                                              {'loss': 1.2974, 'grad_norm': 10.172403335571289, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]  8%|▊         | 3/40 [00:06<01:21,  2.19s/it]                                              {'loss': 2.594, 'grad_norm': 16.0958251953125, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.19s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 1.7753, 'grad_norm': 16.117738723754883, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 2.4499, 'grad_norm': 17.59052085876465, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 1.7824, 'grad_norm': 14.65812873840332, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 1.9714, 'grad_norm': 13.761341094970703, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 2.8634, 'grad_norm': 58.16096496582031, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it]                                              {'loss': 0.3029, 'grad_norm': 6.143573760986328, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.6679, 'grad_norm': 13.448091506958008, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 0.5728, 'grad_norm': 8.815732955932617, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 0.6907, 'grad_norm': 12.353157043457031, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it]                                               {'loss': 1.0254, 'grad_norm': 11.14068603515625, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 0.8337, 'grad_norm': 8.400979995727539, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.5636, 'grad_norm': 6.42922830581665, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 5.683, 'grad_norm': 324.13385009765625, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it]                                               {'loss': 0.6719, 'grad_norm': 16.63867950439453, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.232, 'grad_norm': 6.639547348022461, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it]                                               {'loss': 0.8245, 'grad_norm': 7.088808536529541, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.02s/it] 50%|█████     | 20/40 [00:40<00:42,  2.11s/it]                                               {'loss': 0.1264, 'grad_norm': 4.2121968269348145, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it]                                               {'loss': 0.2179, 'grad_norm': 5.292552471160889, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.1386, 'grad_norm': 3.505279064178467, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.2308, 'grad_norm': 6.238775730133057, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0959, 'grad_norm': 5.799673557281494, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.3782, 'grad_norm': 8.4652738571167, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it]                                               {'loss': 0.4694, 'grad_norm': 7.435478687286377, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.1203, 'grad_norm': 2.297302007675171, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.11s/it]                                               {'loss': 0.0918, 'grad_norm': 1.8825572729110718, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.11s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.1724, 'grad_norm': 5.120984077453613, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it]                                               {'loss': 0.1001, 'grad_norm': 2.5102481842041016, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.1693, 'grad_norm': 5.734789848327637, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.0311, 'grad_norm': 2.3461904525756836, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it]                                               {'loss': 0.0772, 'grad_norm': 1.141996145248413, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.81s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.0177, 'grad_norm': 0.5352112650871277, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.3947, 'grad_norm': 2.421823501586914, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.0346, 'grad_norm': 0.9206472039222717, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.0547, 'grad_norm': 1.713505744934082, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0201, 'grad_norm': 0.9082087278366089, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.0295, 'grad_norm': 0.788568913936615, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.1772, 'grad_norm': 17.31056785583496, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.9352, 'train_samples_per_second': 7.068, 'train_steps_per_second': 0.5, 'train_loss': 0.8011324708815664, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  2.00s/it]
CLIENT:86
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:40,  2.57s/it]                                              {'loss': 2.3921, 'grad_norm': 10.212366104125977, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:40,  2.57s/it]  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]                                              {'loss': 1.7339, 'grad_norm': 11.09988784790039, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:28,  2.32s/it]  8%|▊         | 3/40 [00:06<01:23,  2.25s/it]                                              {'loss': 1.5405, 'grad_norm': 9.950026512145996, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:23,  2.25s/it] 10%|█         | 4/40 [00:09<01:20,  2.23s/it]                                              {'loss': 1.1308, 'grad_norm': 10.105463027954102, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:09<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it]                                              {'loss': 2.0945, 'grad_norm': 21.932363510131836, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:18,  2.24s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 2.6222, 'grad_norm': 25.586700439453125, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.7624, 'grad_norm': 31.019895553588867, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 6.0545, 'grad_norm': 67.32067108154297, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it]                                              {'loss': 0.4223, 'grad_norm': 6.211343288421631, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:54,  1.75s/it] 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it]                                               {'loss': 0.7133, 'grad_norm': 3.551091432571411, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.93, 'grad_norm': 11.25586223602295, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.3179, 'grad_norm': 4.1392717361450195, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it]                                               {'loss': 0.7534, 'grad_norm': 8.22725772857666, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.11s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.15s/it]                                               {'loss': 0.6069, 'grad_norm': 7.941699981689453, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.15s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.4324, 'grad_norm': 5.027010440826416, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 0.0229, 'grad_norm': 1.790251612663269, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.3198, 'grad_norm': 4.970062255859375, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.1058, 'grad_norm': 3.238617181777954, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it]                                               {'loss': 0.5038, 'grad_norm': 3.9450581073760986, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:41,  2.00s/it] 50%|█████     | 20/40 [00:40<00:41,  2.05s/it]                                               {'loss': 0.2521, 'grad_norm': 6.383092880249023, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.05s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it]                                               {'loss': 0.1275, 'grad_norm': 3.7560524940490723, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.12s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.0381, 'grad_norm': 0.8150158524513245, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.3582, 'grad_norm': 5.213687896728516, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.59s/it]                                               {'loss': 0.0139, 'grad_norm': 0.7761717438697815, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it]                                               {'loss': 0.0768, 'grad_norm': 2.039310932159424, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.77s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.9822, 'grad_norm': 50.505489349365234, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it]                                               {'loss': 0.0418, 'grad_norm': 1.1713004112243652, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.09s/it]                                               {'loss': 0.1245, 'grad_norm': 2.1346240043640137, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.09s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it]                                               {'loss': 0.2696, 'grad_norm': 2.331859588623047, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.14s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.0348, 'grad_norm': 3.909119129180908, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it]                                               {'loss': 0.1238, 'grad_norm': 3.513404607772827, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.20s/it] 80%|████████  | 32/40 [01:03<00:12,  1.60s/it]                                               {'loss': 0.0235, 'grad_norm': 1.4310617446899414, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0616, 'grad_norm': 1.5144604444503784, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it]                                               {'loss': 0.4282, 'grad_norm': 4.832287311553955, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.93s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it]                                               {'loss': 0.1422, 'grad_norm': 1.3115874528884888, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it]                                               {'loss': 0.0235, 'grad_norm': 0.8863967657089233, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it]                                               {'loss': 0.3785, 'grad_norm': 1.4774210453033447, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.3714, 'grad_norm': 30.278045654296875, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]                                               {'loss': 0.0535, 'grad_norm': 2.0028629302978516, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.21s/it]100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'loss': 0.0665, 'grad_norm': 4.573915481567383, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]                                               {'train_runtime': 79.6242, 'train_samples_per_second': 7.096, 'train_steps_per_second': 0.502, 'train_loss': 0.7112880479544401, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.60s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:31,  2.33s/it]                                              {'loss': 2.2383, 'grad_norm': 10.809986114501953, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:31,  2.33s/it]  5%|▌         | 2/40 [00:04<01:23,  2.21s/it]                                              {'loss': 1.8959, 'grad_norm': 93.78695678710938, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.21s/it]  8%|▊         | 3/40 [00:06<01:20,  2.19s/it]                                              {'loss': 2.0591, 'grad_norm': 10.933401107788086, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.19s/it] 10%|█         | 4/40 [00:08<01:17,  2.16s/it]                                              {'loss': 2.5616, 'grad_norm': 10.797377586364746, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.16s/it] 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it]                                              {'loss': 1.8469, 'grad_norm': 19.3090877532959, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:15,  2.17s/it] 15%|█▌        | 6/40 [00:13<01:13,  2.17s/it]                                              {'loss': 2.7759, 'grad_norm': 15.404558181762695, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:13,  2.17s/it] 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it]                                              {'loss': 1.403, 'grad_norm': 12.36268138885498, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:11,  2.18s/it] 20%|██        | 8/40 [00:15<00:49,  1.54s/it]                                              {'loss': 4.8245, 'grad_norm': 71.11767578125, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.54s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 0.618, 'grad_norm': 14.079804420471191, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:19<00:57,  1.91s/it]                                               {'loss': 1.0102, 'grad_norm': 7.808986663818359, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it]                                               {'loss': 0.6036, 'grad_norm': 5.819367408752441, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  1.99s/it] 30%|███       | 12/40 [00:24<00:57,  2.05s/it]                                               {'loss': 0.6637, 'grad_norm': 8.858287811279297, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.05s/it] 32%|███▎      | 13/40 [00:26<00:55,  2.07s/it]                                               {'loss': 0.742, 'grad_norm': 12.783692359924316, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:55,  2.07s/it] 35%|███▌      | 14/40 [00:28<00:54,  2.11s/it]                                               {'loss': 0.8477, 'grad_norm': 9.909544944763184, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:54,  2.11s/it] 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it]                                               {'loss': 0.6991, 'grad_norm': 8.325288772583008, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:30<00:53,  2.15s/it] 40%|████      | 16/40 [00:31<00:37,  1.55s/it]                                               {'loss': 1.7295, 'grad_norm': 43.84380340576172, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.55s/it] 42%|████▎     | 17/40 [00:33<00:39,  1.74s/it]                                               {'loss': 0.2318, 'grad_norm': 5.250588893890381, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:39,  1.74s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.87s/it]                                               {'loss': 0.2192, 'grad_norm': 5.181352615356445, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.87s/it] 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it]                                               {'loss': 0.2701, 'grad_norm': 4.839051723480225, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:41,  1.99s/it] 50%|█████     | 20/40 [00:39<00:41,  2.06s/it]                                               {'loss': 0.4167, 'grad_norm': 3.125319004058838, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:39<00:41,  2.06s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it]                                               {'loss': 0.4326, 'grad_norm': 4.978846549987793, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.11s/it] 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it]                                               {'loss': 0.3262, 'grad_norm': 6.701059818267822, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:38,  2.16s/it] 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it]                                               {'loss': 0.2489, 'grad_norm': 4.0535664558410645, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:46<00:37,  2.19s/it] 60%|██████    | 24/40 [00:46<00:25,  1.59s/it]                                               {'loss': 0.0286, 'grad_norm': 1.5799667835235596, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:46<00:25,  1.59s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it]                                               {'loss': 0.0657, 'grad_norm': 1.888214349746704, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.79s/it] 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it]                                               {'loss': 0.3658, 'grad_norm': 2.5887672901153564, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:26,  1.91s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it]                                               {'loss': 0.0415, 'grad_norm': 0.8912113904953003, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.01s/it] 70%|███████   | 28/40 [00:55<00:25,  2.08s/it]                                               {'loss': 0.0451, 'grad_norm': 1.0205720663070679, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:55<00:25,  2.08s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it]                                               {'loss': 0.0482, 'grad_norm': 1.8768815994262695, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.13s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it]                                               {'loss': 0.0529, 'grad_norm': 1.2550387382507324, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.17s/it] 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it]                                               {'loss': 0.0254, 'grad_norm': 0.8072317242622375, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:02<00:19,  2.20s/it] 80%|████████  | 32/40 [01:02<00:12,  1.60s/it]                                               {'loss': 0.076, 'grad_norm': 5.002073287963867, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:02<00:12,  1.60s/it] 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it]                                               {'loss': 0.0169, 'grad_norm': 0.6719868779182434, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:04<00:12,  1.78s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it]                                               {'loss': 0.3894, 'grad_norm': 1.7739747762680054, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.92s/it] 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it]                                               {'loss': 0.0153, 'grad_norm': 0.489591121673584, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:09<00:10,  2.03s/it] 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it]                                               {'loss': 0.2091, 'grad_norm': 2.593593120574951, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:11<00:08,  2.10s/it] 92%|█████████▎| 37/40 [01:13<00:06,  2.15s/it]                                               {'loss': 0.0163, 'grad_norm': 0.402811735868454, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:13<00:06,  2.15s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it]                                               {'loss': 0.0174, 'grad_norm': 0.5622901320457458, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.18s/it] 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]                                               {'loss': 0.0869, 'grad_norm': 5.666699409484863, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:18<00:02,  2.21s/it]100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'loss': 0.0041, 'grad_norm': 0.28034543991088867, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]                                               {'train_runtime': 78.9975, 'train_samples_per_second': 7.152, 'train_steps_per_second': 0.506, 'train_loss': 0.7542301532696001, 'epoch': 5.0}
100%|██████████| 40/40 [01:18<00:00,  1.60s/it]100%|██████████| 40/40 [01:18<00:00,  1.97s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  do_eval=True, seed=self.args.random_seed)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<04:58,  1.57it/s]  1%|          | 3/471 [00:02<07:01,  1.11it/s]  1%|          | 4/471 [00:03<08:06,  1.04s/it]  1%|          | 5/471 [00:05<08:44,  1.13s/it]  1%|▏         | 6/471 [00:06<09:06,  1.18s/it]  1%|▏         | 7/471 [00:07<09:22,  1.21s/it]  2%|▏         | 8/471 [00:08<09:31,  1.24s/it]  2%|▏         | 9/471 [00:10<09:38,  1.25s/it]  2%|▏         | 10/471 [00:11<09:41,  1.26s/it]  2%|▏         | 11/471 [00:12<09:43,  1.27s/it]  3%|▎         | 12/471 [00:14<09:45,  1.28s/it]  3%|▎         | 13/471 [00:15<09:47,  1.28s/it]  3%|▎         | 14/471 [00:16<09:47,  1.28s/it]  3%|▎         | 15/471 [00:17<09:46,  1.29s/it]  3%|▎         | 16/471 [00:19<09:47,  1.29s/it]  4%|▎         | 17/471 [00:20<09:46,  1.29s/it]  4%|▍         | 18/471 [00:21<09:46,  1.29s/it]  4%|▍         | 19/471 [00:23<09:45,  1.30s/it]  4%|▍         | 20/471 [00:24<09:45,  1.30s/it]  4%|▍         | 21/471 [00:25<09:44,  1.30s/it]  5%|▍         | 22/471 [00:27<09:44,  1.30s/it]  5%|▍         | 23/471 [00:28<09:43,  1.30s/it]  5%|▌         | 24/471 [00:29<09:42,  1.30s/it]  5%|▌         | 25/471 [00:31<09:41,  1.30s/it]  6%|▌         | 26/471 [00:32<09:40,  1.30s/it]  6%|▌         | 27/471 [00:33<09:39,  1.31s/it]  6%|▌         | 28/471 [00:34<09:38,  1.31s/it]  6%|▌         | 29/471 [00:36<09:37,  1.31s/it]  6%|▋         | 30/471 [00:37<09:37,  1.31s/it]  7%|▋         | 31/471 [00:38<09:36,  1.31s/it]  7%|▋         | 32/471 [00:40<09:34,  1.31s/it]  7%|▋         | 33/471 [00:41<09:32,  1.31s/it]  7%|▋         | 34/471 [00:42<09:30,  1.31s/it]  7%|▋         | 35/471 [00:44<09:30,  1.31s/it]  8%|▊         | 36/471 [00:45<09:29,  1.31s/it]  8%|▊         | 37/471 [00:46<09:29,  1.31s/it]  8%|▊         | 38/471 [00:48<09:28,  1.31s/it]  8%|▊         | 39/471 [00:49<09:27,  1.31s/it]  8%|▊         | 40/471 [00:50<09:25,  1.31s/it]  9%|▊         | 41/471 [00:51<09:24,  1.31s/it]  9%|▉         | 42/471 [00:53<09:24,  1.32s/it]  9%|▉         | 43/471 [00:54<09:22,  1.31s/it]  9%|▉         | 44/471 [00:55<09:20,  1.31s/it] 10%|▉         | 45/471 [00:57<09:19,  1.31s/it] 10%|▉         | 46/471 [00:58<09:18,  1.31s/it] 10%|▉         | 47/471 [00:59<09:17,  1.31s/it] 10%|█         | 48/471 [01:01<09:16,  1.31s/it] 10%|█         | 49/471 [01:02<09:15,  1.32s/it] 11%|█         | 50/471 [01:03<09:14,  1.32s/it] 11%|█         | 51/471 [01:05<09:13,  1.32s/it] 11%|█         | 52/471 [01:06<09:11,  1.32s/it] 11%|█▏        | 53/471 [01:07<09:11,  1.32s/it] 11%|█▏        | 54/471 [01:09<09:10,  1.32s/it] 12%|█▏        | 55/471 [01:10<09:09,  1.32s/it] 12%|█▏        | 56/471 [01:11<09:08,  1.32s/it] 12%|█▏        | 57/471 [01:13<09:07,  1.32s/it] 12%|█▏        | 58/471 [01:14<09:05,  1.32s/it] 13%|█▎        | 59/471 [01:15<09:04,  1.32s/it] 13%|█▎        | 60/471 [01:17<09:03,  1.32s/it] 13%|█▎        | 61/471 [01:18<09:01,  1.32s/it] 13%|█▎        | 62/471 [01:19<09:00,  1.32s/it] 13%|█▎        | 63/471 [01:20<08:58,  1.32s/it] 14%|█▎        | 64/471 [01:22<08:57,  1.32s/it] 14%|█▍        | 65/471 [01:23<08:56,  1.32s/it] 14%|█▍        | 66/471 [01:24<08:55,  1.32s/it] 14%|█▍        | 67/471 [01:26<08:54,  1.32s/it] 14%|█▍        | 68/471 [01:27<08:52,  1.32s/it] 15%|█▍        | 69/471 [01:28<08:51,  1.32s/it] 15%|█▍        | 70/471 [01:30<08:51,  1.33s/it] 15%|█▌        | 71/471 [01:31<08:50,  1.33s/it] 15%|█▌        | 72/471 [01:32<08:48,  1.33s/it] 15%|█▌        | 73/471 [01:34<08:47,  1.32s/it] 16%|█▌        | 74/471 [01:35<08:44,  1.32s/it] 16%|█▌        | 75/471 [01:36<08:44,  1.32s/it] 16%|█▌        | 76/471 [01:38<08:42,  1.32s/it] 16%|█▋        | 77/471 [01:39<08:41,  1.32s/it] 17%|█▋        | 78/471 [01:40<08:40,  1.32s/it] 17%|█▋        | 79/471 [01:42<08:39,  1.33s/it] 17%|█▋        | 80/471 [01:43<08:38,  1.33s/it] 17%|█▋        | 81/471 [01:44<08:37,  1.33s/it] 17%|█▋        | 82/471 [01:46<08:35,  1.33s/it] 18%|█▊        | 83/471 [01:47<08:34,  1.33s/it] 18%|█▊        | 84/471 [01:48<08:33,  1.33s/it] 18%|█▊        | 85/471 [01:50<08:32,  1.33s/it] 18%|█▊        | 86/471 [01:51<08:31,  1.33s/it] 18%|█▊        | 87/471 [01:52<08:29,  1.33s/it] 19%|█▊        | 88/471 [01:54<08:27,  1.32s/it] 19%|█▉        | 89/471 [01:55<08:26,  1.33s/it] 19%|█▉        | 90/471 [01:56<08:26,  1.33s/it] 19%|█▉        | 91/471 [01:58<08:23,  1.32s/it] 20%|█▉        | 92/471 [01:59<08:21,  1.32s/it] 20%|█▉        | 93/471 [02:00<08:21,  1.33s/it] 20%|█▉        | 94/471 [02:02<08:20,  1.33s/it] 20%|██        | 95/471 [02:03<08:19,  1.33s/it] 20%|██        | 96/471 [02:04<08:17,  1.33s/it] 21%|██        | 97/471 [02:06<08:17,  1.33s/it] 21%|██        | 98/471 [02:07<08:15,  1.33s/it] 21%|██        | 99/471 [02:08<08:14,  1.33s/it] 21%|██        | 100/471 [02:10<08:12,  1.33s/it] 21%|██▏       | 101/471 [02:11<08:11,  1.33s/it] 22%|██▏       | 102/471 [02:12<08:11,  1.33s/it] 22%|██▏       | 103/471 [02:14<08:09,  1.33s/it] 22%|██▏       | 104/471 [02:15<08:09,  1.33s/it] 22%|██▏       | 105/471 [02:16<08:08,  1.34s/it] 23%|██▎       | 106/471 [02:18<08:06,  1.33s/it] 23%|██▎       | 107/471 [02:19<08:04,  1.33s/it] 23%|██▎       | 108/471 [02:20<08:03,  1.33s/it] 23%|██▎       | 109/471 [02:22<08:01,  1.33s/it] 23%|██▎       | 110/471 [02:23<07:59,  1.33s/it] 24%|██▎       | 111/471 [02:24<07:58,  1.33s/it] 24%|██▍       | 112/471 [02:26<07:58,  1.33s/it] 24%|██▍       | 113/471 [02:27<07:55,  1.33s/it] 24%|██▍       | 114/471 [02:28<07:55,  1.33s/it] 24%|██▍       | 115/471 [02:30<07:54,  1.33s/it] 25%|██▍       | 116/471 [02:31<07:52,  1.33s/it] 25%|██▍       | 117/471 [02:32<07:51,  1.33s/it] 25%|██▌       | 118/471 [02:34<07:50,  1.33s/it] 25%|██▌       | 119/471 [02:35<07:49,  1.33s/it] 25%|██▌       | 120/471 [02:36<07:48,  1.34s/it] 26%|██▌       | 121/471 [02:38<07:47,  1.34s/it] 26%|██▌       | 122/471 [02:39<07:45,  1.33s/it] 26%|██▌       | 123/471 [02:40<07:44,  1.33s/it] 26%|██▋       | 124/471 [02:42<07:43,  1.33s/it] 27%|██▋       | 125/471 [02:43<07:41,  1.33s/it] 27%|██▋       | 126/471 [02:44<07:40,  1.34s/it] 27%|██▋       | 127/471 [02:46<07:39,  1.34s/it] 27%|██▋       | 128/471 [02:47<07:37,  1.33s/it] 27%|██▋       | 129/471 [02:48<07:36,  1.33s/it] 28%|██▊       | 130/471 [02:50<07:34,  1.33s/it] 28%|██▊       | 131/471 [02:51<07:34,  1.34s/it] 28%|██▊       | 132/471 [02:52<07:32,  1.34s/it] 28%|██▊       | 133/471 [02:54<07:31,  1.34s/it] 28%|██▊       | 134/471 [02:55<07:30,  1.34s/it] 29%|██▊       | 135/471 [02:56<07:29,  1.34s/it] 29%|██▉       | 136/471 [02:58<07:27,  1.34s/it] 29%|██▉       | 137/471 [02:59<07:27,  1.34s/it] 29%|██▉       | 138/471 [03:00<07:25,  1.34s/it] 30%|██▉       | 139/471 [03:02<07:23,  1.34s/it] 30%|██▉       | 140/471 [03:03<07:22,  1.34s/it] 30%|██▉       | 141/471 [03:04<07:20,  1.34s/it] 30%|███       | 142/471 [03:06<07:18,  1.33s/it] 30%|███       | 143/471 [03:07<07:17,  1.33s/it] 31%|███       | 144/471 [03:08<07:16,  1.34s/it] 31%|███       | 145/471 [03:10<07:14,  1.33s/it] 31%|███       | 146/471 [03:11<07:14,  1.34s/it] 31%|███       | 147/471 [03:12<07:12,  1.33s/it] 31%|███▏      | 148/471 [03:14<07:11,  1.34s/it] 32%|███▏      | 149/471 [03:15<07:11,  1.34s/it] 32%|███▏      | 150/471 [03:16<07:10,  1.34s/it] 32%|███▏      | 151/471 [03:18<07:08,  1.34s/it] 32%|███▏      | 152/471 [03:19<07:07,  1.34s/it] 32%|███▏      | 153/471 [03:20<07:06,  1.34s/it] 33%|███▎      | 154/471 [03:22<07:04,  1.34s/it] 33%|███▎      | 155/471 [03:23<07:03,  1.34s/it] 33%|███▎      | 156/471 [03:24<07:01,  1.34s/it] 33%|███▎      | 157/471 [03:26<06:59,  1.34s/it] 34%|███▎      | 158/471 [03:27<06:58,  1.34s/it] 34%|███▍      | 159/471 [03:28<06:57,  1.34s/it] 34%|███▍      | 160/471 [03:30<06:56,  1.34s/it] 34%|███▍      | 161/471 [03:31<06:55,  1.34s/it] 34%|███▍      | 162/471 [03:32<06:54,  1.34s/it] 35%|███▍      | 163/471 [03:34<06:53,  1.34s/it] 35%|███▍      | 164/471 [03:35<06:51,  1.34s/it] 35%|███▌      | 165/471 [03:36<06:50,  1.34s/it] 35%|███▌      | 166/471 [03:38<06:49,  1.34s/it] 35%|███▌      | 167/471 [03:39<06:48,  1.34s/it] 36%|███▌      | 168/471 [03:40<06:46,  1.34s/it] 36%|███▌      | 169/471 [03:42<06:45,  1.34s/it] 36%|███▌      | 170/471 [03:43<06:44,  1.34s/it] 36%|███▋      | 171/471 [03:44<06:42,  1.34s/it] 37%|███▋      | 172/471 [03:46<06:41,  1.34s/it] 37%|███▋      | 173/471 [03:47<06:40,  1.34s/it] 37%|███▋      | 174/471 [03:48<06:39,  1.34s/it] 37%|███▋      | 175/471 [03:50<06:38,  1.35s/it] 37%|███▋      | 176/471 [03:51<06:36,  1.34s/it] 38%|███▊      | 177/471 [03:52<06:35,  1.35s/it] 38%|███▊      | 178/471 [03:54<06:34,  1.35s/it] 38%|███▊      | 179/471 [03:55<06:33,  1.35s/it] 38%|███▊      | 180/471 [03:57<06:32,  1.35s/it] 38%|███▊      | 181/471 [03:58<06:29,  1.34s/it] 39%|███▊      | 182/471 [03:59<06:29,  1.35s/it] 39%|███▉      | 183/471 [04:01<06:27,  1.35s/it] 39%|███▉      | 184/471 [04:02<06:26,  1.35s/it] 39%|███▉      | 185/471 [04:03<06:24,  1.35s/it] 39%|███▉      | 186/471 [04:05<06:24,  1.35s/it] 40%|███▉      | 187/471 [04:06<06:23,  1.35s/it] 40%|███▉      | 188/471 [04:07<06:22,  1.35s/it] 40%|████      | 189/471 [04:09<06:20,  1.35s/it] 40%|████      | 190/471 [04:10<06:18,  1.35s/it] 41%|████      | 191/471 [04:11<06:18,  1.35s/it] 41%|████      | 192/471 [04:13<06:16,  1.35s/it] 41%|████      | 193/471 [04:14<06:15,  1.35s/it] 41%|████      | 194/471 [04:15<06:14,  1.35s/it] 41%|████▏     | 195/471 [04:17<06:13,  1.35s/it] 42%|████▏     | 196/471 [04:18<06:11,  1.35s/it] 42%|████▏     | 197/471 [04:19<06:09,  1.35s/it] 42%|████▏     | 198/471 [04:21<06:08,  1.35s/it] 42%|████▏     | 199/471 [04:22<06:07,  1.35s/it] 42%|████▏     | 200/471 [04:24<06:06,  1.35s/it] 43%|████▎     | 201/471 [04:25<06:04,  1.35s/it] 43%|████▎     | 202/471 [04:26<06:03,  1.35s/it] 43%|████▎     | 203/471 [04:28<06:01,  1.35s/it] 43%|████▎     | 204/471 [04:29<06:00,  1.35s/it] 44%|████▎     | 205/471 [04:30<05:58,  1.35s/it] 44%|████▎     | 206/471 [04:32<05:57,  1.35s/it] 44%|████▍     | 207/471 [04:33<05:56,  1.35s/it] 44%|████▍     | 208/471 [04:34<05:54,  1.35s/it] 44%|████▍     | 209/471 [04:36<05:52,  1.35s/it] 45%|████▍     | 210/471 [04:37<05:51,  1.35s/it] 45%|████▍     | 211/471 [04:38<05:50,  1.35s/it] 45%|████▌     | 212/471 [04:40<05:48,  1.35s/it] 45%|████▌     | 213/471 [04:41<05:47,  1.35s/it] 45%|████▌     | 214/471 [04:42<05:46,  1.35s/it] 46%|████▌     | 215/471 [04:44<05:44,  1.35s/it] 46%|████▌     | 216/471 [04:45<05:43,  1.35s/it] 46%|████▌     | 217/471 [04:46<05:42,  1.35s/it] 46%|████▋     | 218/471 [04:48<05:41,  1.35s/it] 46%|████▋     | 219/471 [04:49<05:40,  1.35s/it] 47%|████▋     | 220/471 [04:50<05:38,  1.35s/it] 47%|████▋     | 221/471 [04:52<05:37,  1.35s/it] 47%|████▋     | 222/471 [04:53<05:35,  1.35s/it] 47%|████▋     | 223/471 [04:55<05:33,  1.35s/it] 48%|████▊     | 224/471 [04:56<05:32,  1.35s/it] 48%|████▊     | 225/471 [04:57<05:31,  1.35s/it] 48%|████▊     | 226/471 [04:59<05:30,  1.35s/it] 48%|████▊     | 227/471 [05:00<05:28,  1.35s/it] 48%|████▊     | 228/471 [05:01<05:27,  1.35s/it] 49%|████▊     | 229/471 [05:03<05:26,  1.35s/it] 49%|████▉     | 230/471 [05:04<05:24,  1.35s/it] 49%|████▉     | 231/471 [05:05<05:23,  1.35s/it] 49%|████▉     | 232/471 [05:07<05:21,  1.35s/it] 49%|████▉     | 233/471 [05:08<05:20,  1.35s/it] 50%|████▉     | 234/471 [05:09<05:18,  1.35s/it] 50%|████▉     | 235/471 [05:11<05:18,  1.35s/it] 50%|█████     | 236/471 [05:12<05:16,  1.34s/it] 50%|█████     | 237/471 [05:13<05:14,  1.35s/it] 51%|█████     | 238/471 [05:15<05:13,  1.35s/it] 51%|█████     | 239/471 [05:16<05:12,  1.35s/it] 51%|█████     | 240/471 [05:17<05:10,  1.35s/it] 51%|█████     | 241/471 [05:19<05:09,  1.35s/it] 51%|█████▏    | 242/471 [05:20<05:07,  1.34s/it] 52%|█████▏    | 243/471 [05:21<05:07,  1.35s/it] 52%|█████▏    | 244/471 [05:23<05:05,  1.35s/it] 52%|█████▏    | 245/471 [05:24<05:04,  1.35s/it] 52%|█████▏    | 246/471 [05:25<05:02,  1.35s/it] 52%|█████▏    | 247/471 [05:27<05:01,  1.34s/it] 53%|█████▎    | 248/471 [05:28<05:00,  1.35s/it] 53%|█████▎    | 249/471 [05:30<04:58,  1.35s/it] 53%|█████▎    | 250/471 [05:31<04:57,  1.35s/it] 53%|█████▎    | 251/471 [05:32<04:55,  1.34s/it] 54%|█████▎    | 252/471 [05:34<04:54,  1.34s/it] 54%|█████▎    | 253/471 [05:35<04:52,  1.34s/it] 54%|█████▍    | 254/471 [05:36<04:52,  1.35s/it] 54%|█████▍    | 255/471 [05:38<04:50,  1.34s/it] 54%|█████▍    | 256/471 [05:39<04:48,  1.34s/it] 55%|█████▍    | 257/471 [05:40<04:47,  1.34s/it] 55%|█████▍    | 258/471 [05:42<04:46,  1.35s/it] 55%|█████▍    | 259/471 [05:43<04:45,  1.35s/it] 55%|█████▌    | 260/471 [05:44<04:43,  1.35s/it] 55%|█████▌    | 261/471 [05:46<04:42,  1.35s/it] 56%|█████▌    | 262/471 [05:47<04:40,  1.34s/it] 56%|█████▌    | 263/471 [05:48<04:39,  1.34s/it] 56%|█████▌    | 264/471 [05:50<04:38,  1.34s/it] 56%|█████▋    | 265/471 [05:51<04:37,  1.34s/it] 56%|█████▋    | 266/471 [05:52<04:35,  1.35s/it] 57%|█████▋    | 267/471 [05:54<04:34,  1.35s/it] 57%|█████▋    | 268/471 [05:55<04:33,  1.35s/it] 57%|█████▋    | 269/471 [05:56<04:31,  1.35s/it] 57%|█████▋    | 270/471 [05:58<04:30,  1.35s/it] 58%|█████▊    | 271/471 [05:59<04:29,  1.35s/it] 58%|█████▊    | 272/471 [06:00<04:27,  1.35s/it] 58%|█████▊    | 273/471 [06:02<04:26,  1.35s/it] 58%|█████▊    | 274/471 [06:03<04:24,  1.34s/it] 58%|█████▊    | 275/471 [06:04<04:23,  1.34s/it] 59%|█████▊    | 276/471 [06:06<04:22,  1.34s/it] 59%|█████▉    | 277/471 [06:07<04:20,  1.35s/it] 59%|█████▉    | 278/471 [06:09<04:19,  1.35s/it] 59%|█████▉    | 279/471 [06:10<04:18,  1.35s/it] 59%|█████▉    | 280/471 [06:11<04:16,  1.34s/it] 60%|█████▉    | 281/471 [06:13<04:16,  1.35s/it] 60%|█████▉    | 282/471 [06:14<04:13,  1.34s/it] 60%|██████    | 283/471 [06:15<04:12,  1.34s/it] 60%|██████    | 284/471 [06:17<04:11,  1.34s/it] 61%|██████    | 285/471 [06:18<04:10,  1.34s/it] 61%|██████    | 286/471 [06:19<04:08,  1.35s/it] 61%|██████    | 287/471 [06:21<04:07,  1.35s/it] 61%|██████    | 288/471 [06:22<04:06,  1.35s/it] 61%|██████▏   | 289/471 [06:23<04:04,  1.34s/it] 62%|██████▏   | 290/471 [06:25<04:03,  1.34s/it] 62%|██████▏   | 291/471 [06:26<04:01,  1.34s/it] 62%|██████▏   | 292/471 [06:27<03:59,  1.34s/it] 62%|██████▏   | 293/471 [06:29<03:58,  1.34s/it] 62%|██████▏   | 294/471 [06:30<03:57,  1.34s/it] 63%|██████▎   | 295/471 [06:31<03:55,  1.34s/it] 63%|██████▎   | 296/471 [06:33<03:54,  1.34s/it] 63%|██████▎   | 297/471 [06:34<03:53,  1.34s/it] 63%|██████▎   | 298/471 [06:35<03:52,  1.34s/it] 63%|██████▎   | 299/471 [06:37<03:50,  1.34s/it] 64%|██████▎   | 300/471 [06:38<03:49,  1.34s/it] 64%|██████▍   | 301/471 [06:39<03:48,  1.34s/it] 64%|██████▍   | 302/471 [06:41<03:46,  1.34s/it] 64%|██████▍   | 303/471 [06:42<03:44,  1.34s/it] 65%|██████▍   | 304/471 [06:43<03:43,  1.34s/it] 65%|██████▍   | 305/471 [06:45<03:42,  1.34s/it] 65%|██████▍   | 306/471 [06:46<03:40,  1.34s/it] 65%|██████▌   | 307/471 [06:47<03:39,  1.34s/it] 65%|██████▌   | 308/471 [06:49<03:38,  1.34s/it] 66%|██████▌   | 309/471 [06:50<03:37,  1.34s/it] 66%|██████▌   | 310/471 [06:51<03:35,  1.34s/it] 66%|██████▌   | 311/471 [06:53<03:34,  1.34s/it] 66%|██████▌   | 312/471 [06:54<03:32,  1.34s/it] 66%|██████▋   | 313/471 [06:55<03:31,  1.34s/it] 67%|██████▋   | 314/471 [06:57<03:29,  1.34s/it] 67%|██████▋   | 315/471 [06:58<03:28,  1.34s/it] 67%|██████▋   | 316/471 [06:59<03:27,  1.34s/it] 67%|██████▋   | 317/471 [07:01<03:26,  1.34s/it] 68%|██████▊   | 318/471 [07:02<03:24,  1.34s/it] 68%|██████▊   | 319/471 [07:03<03:23,  1.34s/it] 68%|██████▊   | 320/471 [07:05<03:22,  1.34s/it] 68%|██████▊   | 321/471 [07:06<03:20,  1.34s/it] 68%|██████▊   | 322/471 [07:08<03:19,  1.34s/it] 69%|██████▊   | 323/471 [07:09<03:18,  1.34s/it] 69%|██████▉   | 324/471 [07:10<03:16,  1.34s/it] 69%|██████▉   | 325/471 [07:12<03:15,  1.34s/it] 69%|██████▉   | 326/471 [07:13<03:14,  1.34s/it] 69%|██████▉   | 327/471 [07:14<03:12,  1.33s/it] 70%|██████▉   | 328/471 [07:16<03:11,  1.34s/it] 70%|██████▉   | 329/471 [07:17<03:09,  1.34s/it] 70%|███████   | 330/471 [07:18<03:08,  1.33s/it] 70%|███████   | 331/471 [07:20<03:06,  1.33s/it] 70%|███████   | 332/471 [07:21<03:05,  1.33s/it] 71%|███████   | 333/471 [07:22<03:03,  1.33s/it] 71%|███████   | 334/471 [07:24<03:02,  1.33s/it] 71%|███████   | 335/471 [07:25<03:01,  1.34s/it] 71%|███████▏  | 336/471 [07:26<03:00,  1.33s/it] 72%|███████▏  | 337/471 [07:28<02:58,  1.33s/it] 72%|███████▏  | 338/471 [07:29<02:57,  1.33s/it] 72%|███████▏  | 339/471 [07:30<02:56,  1.33s/it] 72%|███████▏  | 340/471 [07:32<02:54,  1.33s/it] 72%|███████▏  | 341/471 [07:33<02:53,  1.33s/it] 73%|███████▎  | 342/471 [07:34<02:51,  1.33s/it] 73%|███████▎  | 343/471 [07:36<02:50,  1.33s/it] 73%|███████▎  | 344/471 [07:37<02:48,  1.33s/it] 73%|███████▎  | 345/471 [07:38<02:47,  1.33s/it] 73%|███████▎  | 346/471 [07:40<02:46,  1.33s/it] 74%|███████▎  | 347/471 [07:41<02:44,  1.33s/it] 74%|███████▍  | 348/471 [07:42<02:43,  1.33s/it] 74%|███████▍  | 349/471 [07:44<02:42,  1.33s/it] 74%|███████▍  | 350/471 [07:45<02:40,  1.33s/it] 75%|███████▍  | 351/471 [07:46<02:39,  1.33s/it] 75%|███████▍  | 352/471 [07:47<02:38,  1.33s/it] 75%|███████▍  | 353/471 [07:49<02:36,  1.33s/it] 75%|███████▌  | 354/471 [07:50<02:35,  1.33s/it] 75%|███████▌  | 355/471 [07:51<02:34,  1.33s/it] 76%|███████▌  | 356/471 [07:53<02:33,  1.33s/it] 76%|███████▌  | 357/471 [07:54<02:31,  1.33s/it] 76%|███████▌  | 358/471 [07:55<02:30,  1.33s/it] 76%|███████▌  | 359/471 [07:57<02:29,  1.33s/it] 76%|███████▋  | 360/471 [07:58<02:27,  1.33s/it] 77%|███████▋  | 361/471 [07:59<02:26,  1.33s/it] 77%|███████▋  | 362/471 [08:01<02:25,  1.33s/it] 77%|███████▋  | 363/471 [08:02<02:23,  1.33s/it] 77%|███████▋  | 364/471 [08:03<02:22,  1.33s/it] 77%|███████▋  | 365/471 [08:05<02:21,  1.33s/it] 78%|███████▊  | 366/471 [08:06<02:19,  1.33s/it] 78%|███████▊  | 367/471 [08:07<02:18,  1.33s/it] 78%|███████▊  | 368/471 [08:09<02:17,  1.33s/it] 78%|███████▊  | 369/471 [08:10<02:15,  1.33s/it] 79%|███████▊  | 370/471 [08:11<02:14,  1.33s/it] 79%|███████▉  | 371/471 [08:13<02:13,  1.33s/it] 79%|███████▉  | 372/471 [08:14<02:11,  1.33s/it] 79%|███████▉  | 373/471 [08:15<02:10,  1.33s/it] 79%|███████▉  | 374/471 [08:17<02:09,  1.33s/it] 80%|███████▉  | 375/471 [08:18<02:07,  1.33s/it] 80%|███████▉  | 376/471 [08:19<02:06,  1.33s/it] 80%|████████  | 377/471 [08:21<02:04,  1.33s/it] 80%|████████  | 378/471 [08:22<02:03,  1.33s/it] 80%|████████  | 379/471 [08:23<02:02,  1.33s/it] 81%|████████  | 380/471 [08:25<02:01,  1.33s/it] 81%|████████  | 381/471 [08:26<01:59,  1.33s/it] 81%|████████  | 382/471 [08:27<01:58,  1.33s/it] 81%|████████▏ | 383/471 [08:29<01:57,  1.34s/it] 82%|████████▏ | 384/471 [08:30<01:56,  1.34s/it] 82%|████████▏ | 385/471 [08:31<01:54,  1.34s/it] 82%|████████▏ | 386/471 [08:33<01:53,  1.34s/it] 82%|████████▏ | 387/471 [08:34<01:52,  1.34s/it] 82%|████████▏ | 388/471 [08:35<01:51,  1.34s/it] 83%|████████▎ | 389/471 [08:37<01:49,  1.34s/it] 83%|████████▎ | 390/471 [08:38<01:48,  1.34s/it] 83%|████████▎ | 391/471 [08:39<01:47,  1.34s/it] 83%|████████▎ | 392/471 [08:41<01:45,  1.34s/it] 83%|████████▎ | 393/471 [08:42<01:44,  1.34s/it] 84%|████████▎ | 394/471 [08:44<01:43,  1.34s/it] 84%|████████▍ | 395/471 [08:45<01:41,  1.34s/it] 84%|████████▍ | 396/471 [08:46<01:40,  1.34s/it] 84%|████████▍ | 397/471 [08:48<01:39,  1.34s/it] 85%|████████▍ | 398/471 [08:49<01:37,  1.34s/it] 85%|████████▍ | 399/471 [08:50<01:36,  1.34s/it] 85%|████████▍ | 400/471 [08:52<01:35,  1.34s/it] 85%|████████▌ | 401/471 [08:53<01:33,  1.34s/it] 85%|████████▌ | 402/471 [08:54<01:32,  1.34s/it] 86%|████████▌ | 403/471 [08:56<01:31,  1.34s/it] 86%|████████▌ | 404/471 [08:57<01:29,  1.34s/it] 86%|████████▌ | 405/471 [08:58<01:28,  1.34s/it] 86%|████████▌ | 406/471 [09:00<01:27,  1.34s/it] 86%|████████▋ | 407/471 [09:01<01:25,  1.34s/it] 87%|████████▋ | 408/471 [09:02<01:24,  1.34s/it] 87%|████████▋ | 409/471 [09:04<01:23,  1.35s/it] 87%|████████▋ | 410/471 [09:05<01:21,  1.34s/it] 87%|████████▋ | 411/471 [09:06<01:20,  1.34s/it] 87%|████████▋ | 412/471 [09:08<01:19,  1.34s/it] 88%|████████▊ | 413/471 [09:09<01:17,  1.34s/it] 88%|████████▊ | 414/471 [09:10<01:16,  1.35s/it] 88%|████████▊ | 415/471 [09:12<01:15,  1.34s/it] 88%|████████▊ | 416/471 [09:13<01:14,  1.35s/it] 89%|████████▊ | 417/471 [09:14<01:12,  1.34s/it] 89%|████████▊ | 418/471 [09:16<01:11,  1.35s/it] 89%|████████▉ | 419/471 [09:17<01:09,  1.34s/it] 89%|████████▉ | 420/471 [09:18<01:08,  1.34s/it] 89%|████████▉ | 421/471 [09:20<01:07,  1.34s/it] 90%|████████▉ | 422/471 [09:21<01:05,  1.34s/it] 90%|████████▉ | 423/471 [09:22<01:04,  1.34s/it] 90%|█████████ | 424/471 [09:24<01:03,  1.34s/it] 90%|█████████ | 425/471 [09:25<01:01,  1.34s/it] 90%|█████████ | 426/471 [09:26<01:00,  1.34s/it] 91%|█████████ | 427/471 [09:28<00:59,  1.34s/it] 91%|█████████ | 428/471 [09:29<00:57,  1.34s/it] 91%|█████████ | 429/471 [09:31<00:56,  1.34s/it] 91%|█████████▏| 430/471 [09:32<00:55,  1.34s/it] 92%|█████████▏| 431/471 [09:33<00:53,  1.34s/it] 92%|█████████▏| 432/471 [09:35<00:52,  1.34s/it] 92%|█████████▏| 433/471 [09:36<00:51,  1.34s/it] 92%|█████████▏| 434/471 [09:37<00:49,  1.34s/it] 92%|█████████▏| 435/471 [09:39<00:48,  1.34s/it] 93%|█████████▎| 436/471 [09:40<00:46,  1.34s/it] 93%|█████████▎| 437/471 [09:41<00:45,  1.34s/it] 93%|█████████▎| 438/471 [09:43<00:44,  1.34s/it] 93%|█████████▎| 439/471 [09:44<00:42,  1.34s/it] 93%|█████████▎| 440/471 [09:45<00:41,  1.34s/it] 94%|█████████▎| 441/471 [09:47<00:40,  1.34s/it] 94%|█████████▍| 442/471 [09:48<00:38,  1.34s/it] 94%|█████████▍| 443/471 [09:49<00:37,  1.34s/it] 94%|█████████▍| 444/471 [09:51<00:36,  1.34s/it] 94%|█████████▍| 445/471 [09:52<00:34,  1.34s/it] 95%|█████████▍| 446/471 [09:53<00:33,  1.34s/it] 95%|█████████▍| 447/471 [09:55<00:32,  1.34s/it] 95%|█████████▌| 448/471 [09:56<00:30,  1.34s/it] 95%|█████████▌| 449/471 [09:57<00:29,  1.34s/it] 96%|█████████▌| 450/471 [09:59<00:28,  1.34s/it] 96%|█████████▌| 451/471 [10:00<00:26,  1.34s/it] 96%|█████████▌| 452/471 [10:01<00:25,  1.34s/it] 96%|█████████▌| 453/471 [10:03<00:24,  1.34s/it] 96%|█████████▋| 454/471 [10:04<00:22,  1.34s/it] 97%|█████████▋| 455/471 [10:05<00:21,  1.34s/it] 97%|█████████▋| 456/471 [10:07<00:20,  1.34s/it] 97%|█████████▋| 457/471 [10:08<00:18,  1.34s/it] 97%|█████████▋| 458/471 [10:09<00:17,  1.34s/it] 97%|█████████▋| 459/471 [10:11<00:16,  1.33s/it] 98%|█████████▊| 460/471 [10:12<00:14,  1.33s/it] 98%|█████████▊| 461/471 [10:13<00:13,  1.34s/it] 98%|█████████▊| 462/471 [10:15<00:12,  1.33s/it] 98%|█████████▊| 463/471 [10:16<00:10,  1.34s/it] 99%|█████████▊| 464/471 [10:17<00:09,  1.34s/it] 99%|█████████▊| 465/471 [10:19<00:08,  1.33s/it] 99%|█████████▉| 466/471 [10:20<00:06,  1.34s/it] 99%|█████████▉| 467/471 [10:21<00:05,  1.34s/it] 99%|█████████▉| 468/471 [10:23<00:04,  1.34s/it]100%|█████████▉| 469/471 [10:24<00:02,  1.34s/it]100%|█████████▉| 470/471 [10:25<00:01,  1.34s/it]100%|██████████| 471/471 [10:26<00:00,  1.23s/it]100%|██████████| 471/471 [10:26<00:00,  1.33s/it]
{'eval_loss': 2.2785136699676514, 'eval_model_preparation_time': 0.0115, 'eval_acc': 0.3909984067976633, 'eval_runtime': 628.078, 'eval_samples_per_second': 11.992, 'eval_steps_per_second': 0.75}
ROUND:19
CLIENT:83
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:22,  2.12s/it]                                              {'loss': 1.7883, 'grad_norm': 10.265981674194336, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:22,  2.12s/it]  5%|▌         | 2/40 [00:04<01:23,  2.20s/it]                                              {'loss': 1.9065, 'grad_norm': 12.333539009094238, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.20s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 1.2956, 'grad_norm': 11.856958389282227, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 2.4371, 'grad_norm': 21.98508071899414, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:10<01:17,  2.20s/it]                                              {'loss': 2.2868, 'grad_norm': 15.471708297729492, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:17,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 1.775, 'grad_norm': 23.552997589111328, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 2.3367, 'grad_norm': 19.898292541503906, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:50,  1.56s/it]                                              {'loss': 0.0084, 'grad_norm': 0.535298228263855, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 0.5551, 'grad_norm': 7.303603172302246, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it]                                               {'loss': 0.38, 'grad_norm': 4.78888463973999, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.91s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 1.0246, 'grad_norm': 10.456755638122559, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.10s/it]                                               {'loss': 1.0031, 'grad_norm': 10.174676895141602, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.10s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 0.6921, 'grad_norm': 6.973359107971191, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 0.5345, 'grad_norm': 7.589675426483154, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it]                                               {'loss': 0.2748, 'grad_norm': 5.872402667999268, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.20s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.0201, 'grad_norm': 1.853310465812683, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it]                                               {'loss': 0.1555, 'grad_norm': 3.7560572624206543, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 0.4584, 'grad_norm': 9.928854942321777, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it]                                               {'loss': 0.3541, 'grad_norm': 7.885996341705322, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it] 50%|█████     | 20/40 [00:40<00:42,  2.11s/it]                                               {'loss': 0.241, 'grad_norm': 5.9001874923706055, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.11s/it] 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it]                                               {'loss': 0.2194, 'grad_norm': 3.2102034091949463, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.1875, 'grad_norm': 3.6033811569213867, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.4525, 'grad_norm': 8.240550994873047, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.046, 'grad_norm': 2.5609686374664307, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.82s/it]                                               {'loss': 0.1654, 'grad_norm': 4.715686321258545, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it]                                               {'loss': 0.0731, 'grad_norm': 2.5622503757476807, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it]                                               {'loss': 0.0724, 'grad_norm': 2.8703250885009766, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it] 70%|███████   | 28/40 [00:56<00:25,  2.13s/it]                                               {'loss': 0.1671, 'grad_norm': 3.7500686645507812, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.13s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.18s/it]                                               {'loss': 0.1168, 'grad_norm': 2.9824609756469727, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.18s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it]                                               {'loss': 0.1382, 'grad_norm': 3.0915164947509766, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it]                                               {'loss': 0.0533, 'grad_norm': 1.8375754356384277, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.23s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.0111, 'grad_norm': 0.6366387009620667, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it]                                               {'loss': 0.1126, 'grad_norm': 8.592107772827148, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.83s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.98s/it]                                               {'loss': 0.0675, 'grad_norm': 3.598433256149292, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.98s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it]                                               {'loss': 0.1924, 'grad_norm': 6.047976970672607, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it]                                               {'loss': 0.0426, 'grad_norm': 1.1933449506759644, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.14s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it]                                               {'loss': 0.0808, 'grad_norm': 2.1171789169311523, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.19s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it]                                               {'loss': 0.1118, 'grad_norm': 3.4363462924957275, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.27s/it]                                               {'loss': 0.0403, 'grad_norm': 1.1675548553466797, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.27s/it]100%|██████████| 40/40 [01:20<00:00,  1.64s/it]                                               {'loss': 0.0392, 'grad_norm': 4.1422529220581055, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.64s/it]                                               {'train_runtime': 80.6009, 'train_samples_per_second': 7.01, 'train_steps_per_second': 0.496, 'train_loss': 0.5479418176691979, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.64s/it]100%|██████████| 40/40 [01:20<00:00,  2.01s/it]
CLIENT:1
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:22,  2.11s/it]                                              {'loss': 1.8063, 'grad_norm': 9.463826179504395, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:22,  2.11s/it]  5%|▌         | 2/40 [00:04<01:21,  2.14s/it]                                              {'loss': 1.6691, 'grad_norm': 10.516057014465332, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:21,  2.14s/it]  8%|▊         | 3/40 [00:06<01:20,  2.18s/it]                                              {'loss': 2.4191, 'grad_norm': 14.145044326782227, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.18s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 2.5142, 'grad_norm': 18.611764907836914, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it]                                              {'loss': 1.7393, 'grad_norm': 19.474220275878906, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.23s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 2.4815, 'grad_norm': 16.197465896606445, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 1.8016, 'grad_norm': 15.982109069824219, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 1.0624, 'grad_norm': 60.43751907348633, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 1.6137, 'grad_norm': 18.158157348632812, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 1.4008, 'grad_norm': 15.743471145629883, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 0.9051, 'grad_norm': 10.182975769042969, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.10s/it]                                               {'loss': 0.7189, 'grad_norm': 9.062933921813965, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.10s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it]                                               {'loss': 0.7631, 'grad_norm': 8.138972282409668, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it]                                               {'loss': 0.8062, 'grad_norm': 7.9422712326049805, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.20s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.22s/it]                                               {'loss': 0.6226, 'grad_norm': 12.96899700164795, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.22s/it] 40%|████      | 16/40 [00:31<00:38,  1.61s/it]                                               {'loss': 0.1736, 'grad_norm': 6.969907283782959, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.61s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.83s/it]                                               {'loss': 0.3315, 'grad_norm': 8.077425003051758, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.83s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it]                                               {'loss': 0.446, 'grad_norm': 5.944637298583984, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.96s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it]                                               {'loss': 0.5724, 'grad_norm': 18.895854949951172, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it] 50%|█████     | 20/40 [00:40<00:42,  2.13s/it]                                               {'loss': 0.614, 'grad_norm': 8.511537551879883, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.13s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.20s/it]                                               {'loss': 0.2592, 'grad_norm': 4.327731132507324, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.20s/it] 55%|█████▌    | 22/40 [00:45<00:40,  2.23s/it]                                               {'loss': 0.3238, 'grad_norm': 5.51331901550293, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:40,  2.23s/it] 57%|█████▊    | 23/40 [00:47<00:38,  2.26s/it]                                               {'loss': 0.2635, 'grad_norm': 4.748951435089111, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:38,  2.26s/it] 60%|██████    | 24/40 [00:48<00:26,  1.65s/it]                                               {'loss': 0.0078, 'grad_norm': 0.48936817049980164, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.65s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.85s/it]                                               {'loss': 0.4389, 'grad_norm': 8.161598205566406, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.85s/it] 65%|██████▌   | 26/40 [00:52<00:27,  2.00s/it]                                               {'loss': 0.2063, 'grad_norm': 4.059179306030273, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  2.00s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.10s/it]                                               {'loss': 0.0947, 'grad_norm': 4.470232009887695, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.10s/it] 70%|███████   | 28/40 [00:57<00:26,  2.18s/it]                                               {'loss': 0.5396, 'grad_norm': 6.130817413330078, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:26,  2.18s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.22s/it]                                               {'loss': 0.1936, 'grad_norm': 2.503148078918457, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.22s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.26s/it]                                               {'loss': 0.1103, 'grad_norm': 2.88724946975708, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.26s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.28s/it]                                               {'loss': 0.0775, 'grad_norm': 2.105128526687622, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.28s/it] 80%|████████  | 32/40 [01:04<00:13,  1.65s/it]                                               {'loss': 0.0015, 'grad_norm': 0.1252872347831726, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.65s/it] 82%|████████▎ | 33/40 [01:07<00:13,  1.87s/it]                                               {'loss': 0.0901, 'grad_norm': 2.674398899078369, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:13,  1.87s/it] 85%|████████▌ | 34/40 [01:09<00:12,  2.02s/it]                                               {'loss': 0.0243, 'grad_norm': 0.6070382595062256, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:12,  2.02s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.12s/it]                                               {'loss': 0.096, 'grad_norm': 2.740694999694824, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.12s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.20s/it]                                               {'loss': 0.2953, 'grad_norm': 3.7112274169921875, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.20s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.24s/it]                                               {'loss': 0.0462, 'grad_norm': 2.0482962131500244, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.24s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it]                                               {'loss': 1.0014, 'grad_norm': 8.014418601989746, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.26s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]                                               {'loss': 0.0645, 'grad_norm': 2.4609787464141846, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.29s/it]100%|██████████| 40/40 [01:21<00:00,  1.66s/it]                                               {'loss': 0.223, 'grad_norm': 12.189287185668945, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.66s/it]                                               {'train_runtime': 81.6606, 'train_samples_per_second': 6.919, 'train_steps_per_second': 0.49, 'train_loss': 0.7204693070147187, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.66s/it]100%|██████████| 40/40 [01:21<00:00,  2.04s/it]
CLIENT:55
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:26,  2.23s/it]                                              {'loss': 1.5053, 'grad_norm': 9.010214805603027, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:26,  2.23s/it]  5%|▌         | 2/40 [00:04<01:23,  2.19s/it]                                              {'loss': 2.9108, 'grad_norm': 14.579306602478027, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.19s/it]  8%|▊         | 3/40 [00:06<01:21,  2.19s/it]                                              {'loss': 1.8894, 'grad_norm': 13.7470703125, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.19s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 1.2245, 'grad_norm': 11.510225296020508, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it]                                              {'loss': 2.2665, 'grad_norm': 13.79711627960205, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 0.9588, 'grad_norm': 10.783072471618652, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it]                                              {'loss': 2.2446, 'grad_norm': 18.61846923828125, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.23s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 0.3312, 'grad_norm': 21.22926139831543, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.79s/it]                                              {'loss': 1.3054, 'grad_norm': 16.485107421875, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it]                                               {'loss': 0.6873, 'grad_norm': 15.399637222290039, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.93s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 0.4597, 'grad_norm': 9.67786979675293, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 0.9123, 'grad_norm': 8.839232444763184, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it]                                               {'loss': 1.0395, 'grad_norm': 9.019061088562012, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.16s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it]                                               {'loss': 0.5128, 'grad_norm': 5.9465718269348145, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.23s/it]                                               {'loss': 0.4087, 'grad_norm': 5.530638694763184, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.23s/it] 40%|████      | 16/40 [00:31<00:38,  1.61s/it]                                               {'loss': 0.2847, 'grad_norm': 11.25540542602539, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.61s/it] 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it]                                               {'loss': 0.1655, 'grad_norm': 4.37587308883667, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:41,  1.81s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.2826, 'grad_norm': 4.235358715057373, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.07s/it]                                               {'loss': 0.3577, 'grad_norm': 5.97365140914917, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.07s/it] 50%|█████     | 20/40 [00:40<00:42,  2.13s/it]                                               {'loss': 0.2774, 'grad_norm': 12.770687103271484, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.13s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it]                                               {'loss': 0.259, 'grad_norm': 4.225866317749023, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.18s/it] 55%|█████▌    | 22/40 [00:45<00:40,  2.23s/it]                                               {'loss': 0.8988, 'grad_norm': 11.342955589294434, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:40,  2.23s/it] 57%|█████▊    | 23/40 [00:47<00:38,  2.26s/it]                                               {'loss': 0.1833, 'grad_norm': 5.417720317840576, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:38,  2.26s/it] 60%|██████    | 24/40 [00:48<00:26,  1.64s/it]                                               {'loss': 0.0102, 'grad_norm': 0.7578311562538147, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.64s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it]                                               {'loss': 0.1072, 'grad_norm': 1.7872862815856934, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it]                                               {'loss': 0.2957, 'grad_norm': 5.97808837890625, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it]                                               {'loss': 0.2276, 'grad_norm': 3.14001727104187, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it] 70%|███████   | 28/40 [00:57<00:25,  2.15s/it]                                               {'loss': 0.2792, 'grad_norm': 24.71220588684082, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.15s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.21s/it]                                               {'loss': 0.2675, 'grad_norm': 6.318869590759277, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.21s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.25s/it]                                               {'loss': 0.0743, 'grad_norm': 1.7906898260116577, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.25s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.26s/it]                                               {'loss': 0.085, 'grad_norm': 3.4859580993652344, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.26s/it] 80%|████████  | 32/40 [01:04<00:13,  1.64s/it]                                               {'loss': 0.0342, 'grad_norm': 1.9549579620361328, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.64s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.85s/it]                                               {'loss': 0.1546, 'grad_norm': 8.300887107849121, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.85s/it] 85%|████████▌ | 34/40 [01:09<00:11,  1.99s/it]                                               {'loss': 0.0214, 'grad_norm': 0.5212613940238953, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  1.99s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it]                                               {'loss': 0.1313, 'grad_norm': 7.23137092590332, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.17s/it]                                               {'loss': 0.0518, 'grad_norm': 1.214294195175171, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.17s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.21s/it]                                               {'loss': 0.0262, 'grad_norm': 0.5616363286972046, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.21s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.24s/it]                                               {'loss': 0.0236, 'grad_norm': 0.5224307775497437, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.24s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.28s/it]                                               {'loss': 0.0599, 'grad_norm': 3.055964231491089, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.28s/it]100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'loss': 0.0225, 'grad_norm': 1.7410024404525757, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'train_runtime': 81.2772, 'train_samples_per_second': 6.952, 'train_steps_per_second': 0.492, 'train_loss': 0.5809488367056475, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.65s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
CLIENT:9
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:23,  2.14s/it]                                              {'loss': 1.4661, 'grad_norm': 10.679910659790039, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:23,  2.14s/it]  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]                                              {'loss': 1.5098, 'grad_norm': 12.248093605041504, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]  8%|▊         | 3/40 [00:06<01:21,  2.20s/it]                                              {'loss': 1.3188, 'grad_norm': 12.597203254699707, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.20s/it] 10%|█         | 4/40 [00:08<01:18,  2.19s/it]                                              {'loss': 1.5083, 'grad_norm': 15.14896011352539, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.19s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.20s/it]                                              {'loss': 2.1305, 'grad_norm': 19.698129653930664, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 1.8395, 'grad_norm': 15.575193405151367, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 2.1487, 'grad_norm': 19.48448944091797, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.58s/it]                                              {'loss': 0.3572, 'grad_norm': 19.445722579956055, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.58s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it]                                              {'loss': 0.7214, 'grad_norm': 9.859131813049316, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.76s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.6647, 'grad_norm': 8.972360610961914, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 0.4022, 'grad_norm': 10.092449188232422, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.7489, 'grad_norm': 8.15078067779541, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it]                                               {'loss': 0.1701, 'grad_norm': 3.7104156017303467, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it]                                               {'loss': 0.5684, 'grad_norm': 8.32730770111084, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it]                                               {'loss': 0.4284, 'grad_norm': 8.276388168334961, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.21s/it] 40%|████      | 16/40 [00:31<00:38,  1.60s/it]                                               {'loss': 0.72, 'grad_norm': 29.96159553527832, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.60s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it]                                               {'loss': 0.1704, 'grad_norm': 6.266157627105713, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it]                                               {'loss': 0.0588, 'grad_norm': 1.4088530540466309, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.95s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it]                                               {'loss': 0.0549, 'grad_norm': 1.5058842897415161, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it] 50%|█████     | 20/40 [00:40<00:42,  2.10s/it]                                               {'loss': 0.2274, 'grad_norm': 4.224929332733154, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.10s/it] 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it]                                               {'loss': 0.2236, 'grad_norm': 10.131963729858398, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it]                                               {'loss': 0.1157, 'grad_norm': 2.3745837211608887, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.0898, 'grad_norm': 2.2039482593536377, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.005, 'grad_norm': 0.28852248191833496, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it]                                               {'loss': 0.0123, 'grad_norm': 0.3344154357910156, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.83s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.99s/it]                                               {'loss': 0.0381, 'grad_norm': 0.7353313565254211, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.99s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.08s/it]                                               {'loss': 0.0834, 'grad_norm': 0.7011347413063049, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.08s/it] 70%|███████   | 28/40 [00:56<00:25,  2.14s/it]                                               {'loss': 0.1504, 'grad_norm': 2.0121395587921143, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.20s/it]                                               {'loss': 0.0321, 'grad_norm': 0.8085908889770508, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.20s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it]                                               {'loss': 0.0253, 'grad_norm': 0.8487921953201294, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.25s/it]                                               {'loss': 0.0269, 'grad_norm': 0.8087765574455261, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.25s/it] 80%|████████  | 32/40 [01:04<00:13,  1.64s/it]                                               {'loss': 0.0004, 'grad_norm': 0.021362867206335068, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.64s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.86s/it]                                               {'loss': 0.008, 'grad_norm': 0.15964725613594055, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.86s/it] 85%|████████▌ | 34/40 [01:08<00:11,  2.00s/it]                                               {'loss': 0.0806, 'grad_norm': 8.544883728027344, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  2.00s/it] 88%|████████▊ | 35/40 [01:11<00:10,  2.10s/it]                                               {'loss': 0.0205, 'grad_norm': 1.3783283233642578, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:11<00:10,  2.10s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.18s/it]                                               {'loss': 0.0936, 'grad_norm': 9.517669677734375, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.18s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.22s/it]                                               {'loss': 0.024, 'grad_norm': 0.8635943531990051, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.22s/it] 95%|█████████▌| 38/40 [01:18<00:04,  2.27s/it]                                               {'loss': 0.0109, 'grad_norm': 0.3076637089252472, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:18<00:04,  2.27s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.30s/it]                                               {'loss': 0.0717, 'grad_norm': 6.976871967315674, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.30s/it]100%|██████████| 40/40 [01:20<00:00,  1.69s/it]                                               {'loss': 0.0011, 'grad_norm': 0.09488600492477417, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.69s/it]                                               {'train_runtime': 81.3037, 'train_samples_per_second': 6.949, 'train_steps_per_second': 0.492, 'train_loss': 0.45819557789873216, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.69s/it]100%|██████████| 40/40 [01:21<00:00,  2.03s/it]
CLIENT:31
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.20s/it]                                              {'loss': 1.2355, 'grad_norm': 10.202387809753418, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.20s/it]  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]                                              {'loss': 1.424, 'grad_norm': 12.09546184539795, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:24,  2.22s/it]  8%|▊         | 3/40 [00:06<01:22,  2.22s/it]                                              {'loss': 1.0893, 'grad_norm': 11.383386611938477, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:22,  2.22s/it] 10%|█         | 4/40 [00:08<01:20,  2.23s/it]                                              {'loss': 2.5305, 'grad_norm': 15.653979301452637, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:20,  2.23s/it] 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it]                                              {'loss': 2.9421, 'grad_norm': 19.61132049560547, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:11<01:17,  2.22s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it]                                              {'loss': 2.6795, 'grad_norm': 20.326480865478516, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.23s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it]                                              {'loss': 1.8103, 'grad_norm': 18.73313331604004, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.24s/it] 20%|██        | 8/40 [00:15<00:50,  1.59s/it]                                              {'loss': 0.126, 'grad_norm': 6.924027919769287, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it]                                              {'loss': 0.5023, 'grad_norm': 10.324605941772461, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:18<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 0.6667, 'grad_norm': 10.010930061340332, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:22<00:59,  2.04s/it]                                               {'loss': 0.5941, 'grad_norm': 7.6036787033081055, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:59,  2.04s/it] 30%|███       | 12/40 [00:24<00:59,  2.12s/it]                                               {'loss': 0.6267, 'grad_norm': 5.980132102966309, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:59,  2.12s/it] 32%|███▎      | 13/40 [00:27<00:58,  2.18s/it]                                               {'loss': 1.5179, 'grad_norm': 12.00394058227539, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:27<00:58,  2.18s/it] 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it]                                               {'loss': 1.2705, 'grad_norm': 11.896124839782715, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:57,  2.21s/it] 38%|███▊      | 15/40 [00:31<00:55,  2.24s/it]                                               {'loss': 0.7765, 'grad_norm': 8.132826805114746, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:55,  2.24s/it] 40%|████      | 16/40 [00:31<00:38,  1.62s/it]                                               {'loss': 1.0843, 'grad_norm': 56.278221130371094, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.62s/it] 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it]                                               {'loss': 0.0403, 'grad_norm': 0.8136619329452515, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:34<00:42,  1.83s/it] 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it]                                               {'loss': 0.4962, 'grad_norm': 6.17003059387207, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:43,  1.97s/it] 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it]                                               {'loss': 0.2212, 'grad_norm': 2.4264135360717773, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:43,  2.06s/it] 50%|█████     | 20/40 [00:41<00:43,  2.15s/it]                                               {'loss': 0.1078, 'grad_norm': 2.8407468795776367, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:41<00:43,  2.15s/it] 52%|█████▎    | 21/40 [00:43<00:41,  2.20s/it]                                               {'loss': 0.0747, 'grad_norm': 2.049567461013794, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:43<00:41,  2.20s/it] 55%|█████▌    | 22/40 [00:45<00:40,  2.25s/it]                                               {'loss': 0.0745, 'grad_norm': 2.4220025539398193, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:40,  2.25s/it] 57%|█████▊    | 23/40 [00:48<00:38,  2.27s/it]                                               {'loss': 0.1776, 'grad_norm': 3.2618799209594727, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:48<00:38,  2.27s/it] 60%|██████    | 24/40 [00:48<00:26,  1.64s/it]                                               {'loss': 0.0037, 'grad_norm': 0.41121479868888855, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:48<00:26,  1.64s/it] 62%|██████▎   | 25/40 [00:50<00:27,  1.86s/it]                                               {'loss': 0.1716, 'grad_norm': 6.27440071105957, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:50<00:27,  1.86s/it] 65%|██████▌   | 26/40 [00:53<00:28,  2.01s/it]                                               {'loss': 0.2247, 'grad_norm': 9.514137268066406, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:53<00:28,  2.01s/it] 68%|██████▊   | 27/40 [00:55<00:27,  2.10s/it]                                               {'loss': 0.092, 'grad_norm': 2.7715444564819336, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:55<00:27,  2.10s/it] 70%|███████   | 28/40 [00:57<00:25,  2.16s/it]                                               {'loss': 0.1918, 'grad_norm': 3.928039312362671, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:57<00:25,  2.16s/it] 72%|███████▎  | 29/40 [01:00<00:24,  2.21s/it]                                               {'loss': 0.0181, 'grad_norm': 0.45975372195243835, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [01:00<00:24,  2.21s/it] 75%|███████▌  | 30/40 [01:02<00:22,  2.25s/it]                                               {'loss': 0.0171, 'grad_norm': 0.5495936274528503, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:02<00:22,  2.25s/it] 78%|███████▊  | 31/40 [01:04<00:20,  2.29s/it]                                               {'loss': 0.0305, 'grad_norm': 1.8225895166397095, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:04<00:20,  2.29s/it] 80%|████████  | 32/40 [01:04<00:13,  1.67s/it]                                               {'loss': 0.0002, 'grad_norm': 0.013660671189427376, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:04<00:13,  1.67s/it] 82%|████████▎ | 33/40 [01:07<00:13,  1.87s/it]                                               {'loss': 0.0205, 'grad_norm': 0.5289800763130188, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:07<00:13,  1.87s/it] 85%|████████▌ | 34/40 [01:09<00:11,  2.00s/it]                                               {'loss': 0.1267, 'grad_norm': 12.040531158447266, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:09<00:11,  2.00s/it] 88%|████████▊ | 35/40 [01:12<00:10,  2.11s/it]                                               {'loss': 0.0299, 'grad_norm': 1.1320507526397705, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:12<00:10,  2.11s/it] 90%|█████████ | 36/40 [01:14<00:08,  2.20s/it]                                               {'loss': 0.0125, 'grad_norm': 0.3007071912288666, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:14<00:08,  2.20s/it] 92%|█████████▎| 37/40 [01:16<00:06,  2.25s/it]                                               {'loss': 0.022, 'grad_norm': 0.5581561326980591, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:16<00:06,  2.25s/it] 95%|█████████▌| 38/40 [01:19<00:04,  2.28s/it]                                               {'loss': 0.0986, 'grad_norm': 4.884782791137695, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:19<00:04,  2.28s/it] 98%|█████████▊| 39/40 [01:21<00:02,  2.31s/it]                                               {'loss': 0.0117, 'grad_norm': 0.2359483689069748, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:21<00:02,  2.31s/it]100%|██████████| 40/40 [01:21<00:00,  1.68s/it]                                               {'loss': 0.0073, 'grad_norm': 0.5627251267433167, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:21<00:00,  1.68s/it]                                               {'train_runtime': 82.081, 'train_samples_per_second': 6.883, 'train_steps_per_second': 0.487, 'train_loss': 0.5786843730449618, 'epoch': 5.0}
100%|██████████| 40/40 [01:22<00:00,  1.68s/it]100%|██████████| 40/40 [01:22<00:00,  2.05s/it]
CLIENT:28
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:25,  2.20s/it]                                              {'loss': 1.2056, 'grad_norm': 8.819942474365234, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:25,  2.20s/it]  5%|▌         | 2/40 [00:04<01:23,  2.21s/it]                                              {'loss': 0.9591, 'grad_norm': 8.900835037231445, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:23,  2.21s/it]  8%|▊         | 3/40 [00:06<01:21,  2.21s/it]                                              {'loss': 1.7188, 'grad_norm': 11.795334815979004, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.21s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 1.6629, 'grad_norm': 16.769268035888672, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it]                                              {'loss': 2.5857, 'grad_norm': 27.097637176513672, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it]                                              {'loss': 1.8523, 'grad_norm': 17.149152755737305, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.19s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.3543, 'grad_norm': 30.31953239440918, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 3.7142, 'grad_norm': 35.668434143066406, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 0.6227, 'grad_norm': 8.047588348388672, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.5325, 'grad_norm': 7.281589031219482, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.4429, 'grad_norm': 5.93619966506958, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.07s/it]                                               {'loss': 0.7009, 'grad_norm': 9.568401336669922, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.07s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 0.5359, 'grad_norm': 7.309970855712891, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it]                                               {'loss': 0.7037, 'grad_norm': 10.08637809753418, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:56,  2.16s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.341, 'grad_norm': 6.923743724822998, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.61s/it]                                               {'loss': 0.2281, 'grad_norm': 11.952280044555664, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.61s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it]                                               {'loss': 0.1612, 'grad_norm': 3.246546506881714, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.80s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it]                                               {'loss': 0.3891, 'grad_norm': 7.301702499389648, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.94s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it]                                               {'loss': 0.0476, 'grad_norm': 1.0129019021987915, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.04s/it] 50%|█████     | 20/40 [00:40<00:42,  2.12s/it]                                               {'loss': 0.0757, 'grad_norm': 1.420976161956787, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it]                                               {'loss': 0.0265, 'grad_norm': 0.8001236319541931, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it]                                               {'loss': 0.3111, 'grad_norm': 5.580505847930908, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.19s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it]                                               {'loss': 0.1467, 'grad_norm': 4.248151779174805, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it] 60%|██████    | 24/40 [00:47<00:25,  1.62s/it]                                               {'loss': 0.1409, 'grad_norm': 9.997281074523926, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.82s/it]                                               {'loss': 0.0267, 'grad_norm': 0.634427011013031, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it]                                               {'loss': 0.2015, 'grad_norm': 3.7293972969055176, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.96s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it]                                               {'loss': 0.0271, 'grad_norm': 0.8668367266654968, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.07s/it] 70%|███████   | 28/40 [00:56<00:25,  2.14s/it]                                               {'loss': 0.0432, 'grad_norm': 1.0760538578033447, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it]                                               {'loss': 0.0448, 'grad_norm': 1.6867538690567017, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it]                                               {'loss': 0.1745, 'grad_norm': 3.7938954830169678, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.23s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.26s/it]                                               {'loss': 0.0828, 'grad_norm': 3.1129884719848633, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.26s/it] 80%|████████  | 32/40 [01:03<00:13,  1.64s/it]                                               {'loss': 0.0396, 'grad_norm': 2.4644253253936768, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:13,  1.64s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.85s/it]                                               {'loss': 0.0499, 'grad_norm': 1.7222822904586792, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.85s/it] 85%|████████▌ | 34/40 [01:08<00:12,  2.00s/it]                                               {'loss': 0.0216, 'grad_norm': 0.5428332090377808, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:12,  2.00s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.10s/it]                                               {'loss': 0.0163, 'grad_norm': 0.45815181732177734, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.10s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it]                                               {'loss': 0.0431, 'grad_norm': 2.251408100128174, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.21s/it]                                               {'loss': 0.0133, 'grad_norm': 0.29108092188835144, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.21s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.25s/it]                                               {'loss': 0.0194, 'grad_norm': 0.5069270133972168, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.25s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.27s/it]                                               {'loss': 0.0117, 'grad_norm': 0.26944130659103394, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.27s/it]100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'loss': 0.0007, 'grad_norm': 0.03814493492245674, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.65s/it]                                               {'train_runtime': 80.7968, 'train_samples_per_second': 6.993, 'train_steps_per_second': 0.495, 'train_loss': 0.53188803892117, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.65s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:96
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.16s/it]                                              {'loss': 2.6103, 'grad_norm': 12.553962707519531, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.16s/it]  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]                                              {'loss': 2.2401, 'grad_norm': 15.765089988708496, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]  8%|▊         | 3/40 [00:06<01:21,  2.20s/it]                                              {'loss': 2.4608, 'grad_norm': 15.637832641601562, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:21,  2.20s/it] 10%|█         | 4/40 [00:08<01:19,  2.20s/it]                                              {'loss': 1.7363, 'grad_norm': 24.66134262084961, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:19,  2.20s/it] 12%|█▎        | 5/40 [00:10<01:17,  2.21s/it]                                              {'loss': 1.8756, 'grad_norm': 20.42014503479004, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:17,  2.21s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it]                                              {'loss': 1.7193, 'grad_norm': 19.374698638916016, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.21s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 0.8413, 'grad_norm': 11.096237182617188, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.57s/it]                                              {'loss': 1.2527, 'grad_norm': 69.71697235107422, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.57s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it]                                              {'loss': 0.4343, 'grad_norm': 11.478071212768555, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.9705, 'grad_norm': 11.691060066223145, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 1.1768, 'grad_norm': 13.670019149780273, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.548, 'grad_norm': 7.423827648162842, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it]                                               {'loss': 0.3535, 'grad_norm': 8.015522003173828, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.14s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 0.3044, 'grad_norm': 6.805063724517822, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.3269, 'grad_norm': 7.271941661834717, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:38,  1.59s/it]                                               {'loss': 0.1907, 'grad_norm': 16.538869857788086, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:38,  1.59s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it]                                               {'loss': 0.1914, 'grad_norm': 6.804824352264404, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.78s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it]                                               {'loss': 0.1325, 'grad_norm': 4.359055995941162, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.93s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it]                                               {'loss': 0.3832, 'grad_norm': 6.023678302764893, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.03s/it] 50%|█████     | 20/40 [00:40<00:42,  2.12s/it]                                               {'loss': 0.3077, 'grad_norm': 7.443793296813965, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:42,  2.12s/it] 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it]                                               {'loss': 0.2825, 'grad_norm': 6.897530555725098, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:41,  2.17s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it]                                               {'loss': 0.1043, 'grad_norm': 2.2466132640838623, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.21s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it]                                               {'loss': 0.2404, 'grad_norm': 2.4918224811553955, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.22s/it] 60%|██████    | 24/40 [00:47<00:25,  1.61s/it]                                               {'loss': 0.0127, 'grad_norm': 0.6000204682350159, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.61s/it] 62%|██████▎   | 25/40 [00:49<00:27,  1.82s/it]                                               {'loss': 0.094, 'grad_norm': 2.7033379077911377, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:27,  1.82s/it] 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it]                                               {'loss': 0.0355, 'grad_norm': 1.4489362239837646, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:52<00:27,  1.97s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it]                                               {'loss': 0.0847, 'grad_norm': 2.224047899246216, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.05s/it] 70%|███████   | 28/40 [00:56<00:25,  2.14s/it]                                               {'loss': 0.0641, 'grad_norm': 2.5270793437957764, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.14s/it] 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it]                                               {'loss': 0.3738, 'grad_norm': 3.180335760116577, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:59<00:24,  2.19s/it] 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it]                                               {'loss': 0.0734, 'grad_norm': 2.058304786682129, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:22,  2.21s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it]                                               {'loss': 0.0569, 'grad_norm': 1.244401216506958, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.24s/it] 80%|████████  | 32/40 [01:03<00:12,  1.62s/it]                                               {'loss': 0.0003, 'grad_norm': 0.027667613700032234, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.62s/it] 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it]                                               {'loss': 0.1691, 'grad_norm': 6.005452632904053, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:06<00:12,  1.82s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.0534, 'grad_norm': 3.2921226024627686, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it]                                               {'loss': 0.0606, 'grad_norm': 2.703310966491699, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.07s/it] 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it]                                               {'loss': 0.0563, 'grad_norm': 1.6304885149002075, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:13<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it]                                               {'loss': 0.2996, 'grad_norm': 5.372932434082031, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.24s/it]                                               {'loss': 0.0856, 'grad_norm': 2.310344696044922, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.24s/it] 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]                                               {'loss': 0.0904, 'grad_norm': 2.7405874729156494, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:20<00:02,  2.25s/it]100%|██████████| 40/40 [01:20<00:00,  1.66s/it]                                               {'loss': 0.0001, 'grad_norm': 0.009927243925631046, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.66s/it]                                               {'train_runtime': 80.6997, 'train_samples_per_second': 7.001, 'train_steps_per_second': 0.496, 'train_loss': 0.5573417994652118, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.66s/it]100%|██████████| 40/40 [01:20<00:00,  2.02s/it]
CLIENT:29
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:26,  2.21s/it]                                              {'loss': 1.7504, 'grad_norm': 11.379410743713379, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:26,  2.21s/it]  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]                                              {'loss': 1.1147, 'grad_norm': 10.794121742248535, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.18s/it]  8%|▊         | 3/40 [00:06<01:20,  2.18s/it]                                              {'loss': 2.445, 'grad_norm': 16.445064544677734, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.18s/it] 10%|█         | 4/40 [00:08<01:18,  2.19s/it]                                              {'loss': 1.6277, 'grad_norm': 15.992015838623047, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:18,  2.19s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.20s/it]                                              {'loss': 2.0849, 'grad_norm': 22.840394973754883, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it]                                              {'loss': 1.5817, 'grad_norm': 14.105587005615234, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:15,  2.22s/it] 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it]                                              {'loss': 1.9814, 'grad_norm': 15.314239501953125, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:13,  2.22s/it] 20%|██        | 8/40 [00:15<00:50,  1.59s/it]                                              {'loss': 2.3248, 'grad_norm': 64.68269348144531, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:50,  1.59s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.79s/it]                                              {'loss': 0.122, 'grad_norm': 2.7501091957092285, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.79s/it] 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it]                                               {'loss': 0.54, 'grad_norm': 9.355445861816406, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:57,  1.92s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 0.3141, 'grad_norm': 8.045206069946289, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.09s/it]                                               {'loss': 0.5046, 'grad_norm': 7.990622520446777, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.09s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 0.7436, 'grad_norm': 59.993412017822266, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it]                                               {'loss': 0.9066, 'grad_norm': 26.919906616210938, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:29<00:56,  2.18s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it]                                               {'loss': 0.5327, 'grad_norm': 9.555760383605957, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.19s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 4.0298, 'grad_norm': 87.65414428710938, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it]                                               {'loss': 0.1474, 'grad_norm': 2.8087992668151855, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:41,  1.79s/it] 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it]                                               {'loss': 0.106, 'grad_norm': 2.9460608959198, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:36<00:42,  1.92s/it] 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it]                                               {'loss': 0.6439, 'grad_norm': 12.121997833251953, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:38<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.10s/it]                                               {'loss': 0.1846, 'grad_norm': 5.592447757720947, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.10s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it]                                               {'loss': 0.2626, 'grad_norm': 6.362494468688965, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.15s/it] 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it]                                               {'loss': 0.071, 'grad_norm': 3.2922704219818115, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:45<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it]                                               {'loss': 0.2054, 'grad_norm': 5.383507251739502, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.20s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0196, 'grad_norm': 1.257500171661377, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it]                                               {'loss': 0.0739, 'grad_norm': 2.5001158714294434, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.78s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.1696, 'grad_norm': 2.7086544036865234, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it]                                               {'loss': 0.064, 'grad_norm': 1.570549726486206, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.04s/it] 70%|███████   | 28/40 [00:56<00:25,  2.12s/it]                                               {'loss': 0.0359, 'grad_norm': 1.0892748832702637, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.12s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it]                                               {'loss': 0.1096, 'grad_norm': 3.6950743198394775, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.16s/it] 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it]                                               {'loss': 0.0468, 'grad_norm': 2.2927792072296143, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:01<00:21,  2.20s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it]                                               {'loss': 0.2665, 'grad_norm': 7.884888648986816, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.21s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.0466, 'grad_norm': 3.1439592838287354, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0111, 'grad_norm': 0.3066618740558624, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it]                                               {'loss': 0.0147, 'grad_norm': 0.5208814740180969, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.95s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.6582, 'grad_norm': 4.585081100463867, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it]                                               {'loss': 0.0327, 'grad_norm': 0.9545404314994812, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.13s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it]                                               {'loss': 0.0389, 'grad_norm': 1.0206326246261597, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.16s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it]                                               {'loss': 0.0336, 'grad_norm': 1.2281129360198975, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.20s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]                                               {'loss': 0.0162, 'grad_norm': 0.46522849798202515, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.22s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0049, 'grad_norm': 0.3781954348087311, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 80.0072, 'train_samples_per_second': 7.062, 'train_steps_per_second': 0.5, 'train_loss': 0.6467006321647204, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.61s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:86
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:24,  2.16s/it]                                              {'loss': 2.1169, 'grad_norm': 10.425061225891113, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:24,  2.16s/it]  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]                                              {'loss': 1.6961, 'grad_norm': 12.095362663269043, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:21,  2.15s/it]  8%|▊         | 3/40 [00:06<01:19,  2.15s/it]                                              {'loss': 1.4129, 'grad_norm': 10.17707633972168, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:19,  2.15s/it] 10%|█         | 4/40 [00:08<01:17,  2.17s/it]                                              {'loss': 1.0235, 'grad_norm': 9.265168190002441, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.17s/it] 12%|█▎        | 5/40 [00:10<01:17,  2.20s/it]                                              {'loss': 1.9212, 'grad_norm': 16.233091354370117, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:17,  2.20s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it]                                              {'loss': 2.1747, 'grad_norm': 19.117450714111328, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.20s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 2.0174, 'grad_norm': 9.958245277404785, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.55s/it]                                              {'loss': 4.4664, 'grad_norm': 67.71235656738281, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.55s/it] 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it]                                              {'loss': 0.3585, 'grad_norm': 7.027640342712402, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:54,  1.77s/it] 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it]                                               {'loss': 0.4535, 'grad_norm': 4.7736124992370605, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:19<00:56,  1.89s/it] 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it]                                               {'loss': 0.6716, 'grad_norm': 10.167254447937012, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:57,  2.00s/it] 30%|███       | 12/40 [00:24<00:57,  2.06s/it]                                               {'loss': 0.1817, 'grad_norm': 3.312230110168457, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:57,  2.06s/it] 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it]                                               {'loss': 0.5467, 'grad_norm': 6.1305317878723145, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:57,  2.13s/it] 35%|███▌      | 14/40 [00:28<00:56,  2.17s/it]                                               {'loss': 0.6248, 'grad_norm': 8.112462043762207, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:56,  2.17s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it]                                               {'loss': 0.6334, 'grad_norm': 5.121945858001709, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.18s/it] 40%|████      | 16/40 [00:31<00:37,  1.58s/it]                                               {'loss': 0.0434, 'grad_norm': 2.122769355773926, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.58s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.2815, 'grad_norm': 5.365164756774902, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:42,  1.91s/it]                                               {'loss': 0.0696, 'grad_norm': 1.4205522537231445, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:42,  1.91s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it]                                               {'loss': 0.3143, 'grad_norm': 2.430295705795288, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.07s/it]                                               {'loss': 0.4422, 'grad_norm': 9.209158897399902, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.07s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it]                                               {'loss': 0.0799, 'grad_norm': 3.0225579738616943, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.14s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it]                                               {'loss': 0.0318, 'grad_norm': 0.6483703255653381, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it]                                               {'loss': 0.2164, 'grad_norm': 4.153461933135986, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.23s/it] 60%|██████    | 24/40 [00:47<00:25,  1.62s/it]                                               {'loss': 0.0029, 'grad_norm': 0.15014387667179108, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.62s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it]                                               {'loss': 0.0157, 'grad_norm': 0.33016109466552734, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.95s/it]                                               {'loss': 0.0848, 'grad_norm': 1.2537139654159546, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.95s/it] 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it]                                               {'loss': 0.0238, 'grad_norm': 0.6553218960762024, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:54<00:26,  2.06s/it] 70%|███████   | 28/40 [00:56<00:25,  2.13s/it]                                               {'loss': 0.0243, 'grad_norm': 0.44484010338783264, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.13s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.18s/it]                                               {'loss': 0.0595, 'grad_norm': 1.2373851537704468, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.18s/it] 75%|███████▌  | 30/40 [01:00<00:22,  2.22s/it]                                               {'loss': 0.2986, 'grad_norm': 1.3893029689788818, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:22,  2.22s/it] 78%|███████▊  | 31/40 [01:03<00:20,  2.25s/it]                                               {'loss': 0.0418, 'grad_norm': 1.5108063220977783, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:20,  2.25s/it] 80%|████████  | 32/40 [01:03<00:13,  1.63s/it]                                               {'loss': 0.0355, 'grad_norm': 1.9597009420394897, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:13,  1.63s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.84s/it]                                               {'loss': 0.0071, 'grad_norm': 0.15933726727962494, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.84s/it] 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it]                                               {'loss': 0.0985, 'grad_norm': 1.318719506263733, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:08<00:11,  1.97s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.08s/it]                                               {'loss': 0.0557, 'grad_norm': 1.0289487838745117, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.08s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.15s/it]                                               {'loss': 0.0211, 'grad_norm': 0.9302686452865601, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.15s/it] 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it]                                               {'loss': 0.0613, 'grad_norm': 8.92922306060791, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:15<00:06,  2.20s/it] 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it]                                               {'loss': 0.0406, 'grad_norm': 1.074859380722046, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:17<00:04,  2.23s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.26s/it]                                               {'loss': 0.0283, 'grad_norm': 0.7791094183921814, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.26s/it]100%|██████████| 40/40 [01:19<00:00,  1.64s/it]                                               {'loss': 0.0086, 'grad_norm': 0.5733984708786011, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.64s/it]                                               {'train_runtime': 80.1851, 'train_samples_per_second': 7.046, 'train_steps_per_second': 0.499, 'train_loss': 0.5671597977285273, 'epoch': 5.0}
100%|██████████| 40/40 [01:20<00:00,  1.64s/it]100%|██████████| 40/40 [01:20<00:00,  2.00s/it]
CLIENT:63
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  logging_steps=1)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:26,  2.22s/it]                                              {'loss': 1.9458, 'grad_norm': 10.436705589294434, 'learning_rate': 0.001, 'epoch': 0.12}
  2%|▎         | 1/40 [00:02<01:26,  2.22s/it]  5%|▌         | 2/40 [00:04<01:22,  2.17s/it]                                              {'loss': 1.7307, 'grad_norm': 10.93309211730957, 'learning_rate': 0.001, 'epoch': 0.25}
  5%|▌         | 2/40 [00:04<01:22,  2.17s/it]  8%|▊         | 3/40 [00:06<01:20,  2.17s/it]                                              {'loss': 1.1636, 'grad_norm': 11.69474983215332, 'learning_rate': 0.001, 'epoch': 0.38}
  8%|▊         | 3/40 [00:06<01:20,  2.17s/it] 10%|█         | 4/40 [00:08<01:17,  2.16s/it]                                              {'loss': 2.8006, 'grad_norm': 16.112756729125977, 'learning_rate': 0.001, 'epoch': 0.5}
 10%|█         | 4/40 [00:08<01:17,  2.16s/it] 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it]                                              {'loss': 1.5729, 'grad_norm': 16.845643997192383, 'learning_rate': 0.001, 'epoch': 0.62}
 12%|█▎        | 5/40 [00:10<01:16,  2.18s/it] 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it]                                              {'loss': 1.8963, 'grad_norm': 18.840774536132812, 'learning_rate': 0.001, 'epoch': 0.75}
 15%|█▌        | 6/40 [00:13<01:14,  2.18s/it] 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it]                                              {'loss': 1.3349, 'grad_norm': 17.094114303588867, 'learning_rate': 0.001, 'epoch': 0.88}
 18%|█▊        | 7/40 [00:15<01:12,  2.20s/it] 20%|██        | 8/40 [00:15<00:49,  1.56s/it]                                              {'loss': 4.3578, 'grad_norm': 84.05485534667969, 'learning_rate': 0.001, 'epoch': 1.0}
 20%|██        | 8/40 [00:15<00:49,  1.56s/it] 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it]                                              {'loss': 0.5368, 'grad_norm': 8.982880592346191, 'learning_rate': 0.001, 'epoch': 1.12}
 22%|██▎       | 9/40 [00:17<00:55,  1.78s/it] 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it]                                               {'loss': 0.4024, 'grad_norm': 6.551641464233398, 'learning_rate': 0.001, 'epoch': 1.25}
 25%|██▌       | 10/40 [00:20<00:58,  1.94s/it] 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it]                                               {'loss': 0.3334, 'grad_norm': 7.393143177032471, 'learning_rate': 0.001, 'epoch': 1.38}
 28%|██▊       | 11/40 [00:22<00:58,  2.02s/it] 30%|███       | 12/40 [00:24<00:58,  2.08s/it]                                               {'loss': 0.2635, 'grad_norm': 6.284274101257324, 'learning_rate': 0.001, 'epoch': 1.5}
 30%|███       | 12/40 [00:24<00:58,  2.08s/it] 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it]                                               {'loss': 0.4782, 'grad_norm': 11.575811386108398, 'learning_rate': 0.001, 'epoch': 1.62}
 32%|███▎      | 13/40 [00:26<00:56,  2.10s/it] 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it]                                               {'loss': 0.5127, 'grad_norm': 10.692239761352539, 'learning_rate': 0.001, 'epoch': 1.75}
 35%|███▌      | 14/40 [00:28<00:55,  2.13s/it] 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it]                                               {'loss': 0.793, 'grad_norm': 33.43038558959961, 'learning_rate': 0.001, 'epoch': 1.88}
 38%|███▊      | 15/40 [00:31<00:54,  2.17s/it] 40%|████      | 16/40 [00:31<00:37,  1.57s/it]                                               {'loss': 2.6486, 'grad_norm': 53.0725212097168, 'learning_rate': 0.001, 'epoch': 2.0}
 40%|████      | 16/40 [00:31<00:37,  1.57s/it] 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it]                                               {'loss': 0.2299, 'grad_norm': 6.780975818634033, 'learning_rate': 0.001, 'epoch': 2.12}
 42%|████▎     | 17/40 [00:33<00:40,  1.76s/it] 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it]                                               {'loss': 0.2453, 'grad_norm': 7.467303276062012, 'learning_rate': 0.001, 'epoch': 2.25}
 45%|████▌     | 18/40 [00:35<00:41,  1.90s/it] 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it]                                               {'loss': 0.3154, 'grad_norm': 4.584879398345947, 'learning_rate': 0.001, 'epoch': 2.38}
 48%|████▊     | 19/40 [00:37<00:42,  2.01s/it] 50%|█████     | 20/40 [00:40<00:41,  2.08s/it]                                               {'loss': 0.0868, 'grad_norm': 1.8461205959320068, 'learning_rate': 0.001, 'epoch': 2.5}
 50%|█████     | 20/40 [00:40<00:41,  2.08s/it] 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it]                                               {'loss': 0.3969, 'grad_norm': 4.7448930740356445, 'learning_rate': 0.001, 'epoch': 2.62}
 52%|█████▎    | 21/40 [00:42<00:40,  2.13s/it] 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it]                                               {'loss': 0.1407, 'grad_norm': 2.7714786529541016, 'learning_rate': 0.001, 'epoch': 2.75}
 55%|█████▌    | 22/40 [00:44<00:39,  2.18s/it] 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it]                                               {'loss': 0.1706, 'grad_norm': 4.212195873260498, 'learning_rate': 0.001, 'epoch': 2.88}
 57%|█████▊    | 23/40 [00:47<00:37,  2.21s/it] 60%|██████    | 24/40 [00:47<00:25,  1.60s/it]                                               {'loss': 0.0936, 'grad_norm': 5.327146053314209, 'learning_rate': 0.001, 'epoch': 3.0}
 60%|██████    | 24/40 [00:47<00:25,  1.60s/it] 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it]                                               {'loss': 0.049, 'grad_norm': 1.9651556015014648, 'learning_rate': 0.001, 'epoch': 3.12}
 62%|██████▎   | 25/40 [00:49<00:26,  1.80s/it] 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it]                                               {'loss': 0.1912, 'grad_norm': 2.1628258228302, 'learning_rate': 0.001, 'epoch': 3.25}
 65%|██████▌   | 26/40 [00:51<00:27,  1.93s/it] 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it]                                               {'loss': 0.0488, 'grad_norm': 1.4337654113769531, 'learning_rate': 0.001, 'epoch': 3.38}
 68%|██████▊   | 27/40 [00:53<00:26,  2.02s/it] 70%|███████   | 28/40 [00:56<00:25,  2.10s/it]                                               {'loss': 0.0498, 'grad_norm': 1.1835200786590576, 'learning_rate': 0.001, 'epoch': 3.5}
 70%|███████   | 28/40 [00:56<00:25,  2.10s/it] 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it]                                               {'loss': 0.0507, 'grad_norm': 2.5154285430908203, 'learning_rate': 0.001, 'epoch': 3.62}
 72%|███████▎  | 29/40 [00:58<00:23,  2.15s/it] 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it]                                               {'loss': 0.0323, 'grad_norm': 0.8544434905052185, 'learning_rate': 0.001, 'epoch': 3.75}
 75%|███████▌  | 30/40 [01:00<00:21,  2.19s/it] 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it]                                               {'loss': 0.0966, 'grad_norm': 3.179368019104004, 'learning_rate': 0.001, 'epoch': 3.88}
 78%|███████▊  | 31/40 [01:03<00:19,  2.22s/it] 80%|████████  | 32/40 [01:03<00:12,  1.61s/it]                                               {'loss': 0.0079, 'grad_norm': 0.588973879814148, 'learning_rate': 0.001, 'epoch': 4.0}
 80%|████████  | 32/40 [01:03<00:12,  1.61s/it] 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it]                                               {'loss': 0.0194, 'grad_norm': 0.7470434904098511, 'learning_rate': 0.001, 'epoch': 4.12}
 82%|████████▎ | 33/40 [01:05<00:12,  1.80s/it] 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it]                                               {'loss': 0.0355, 'grad_norm': 1.0615062713623047, 'learning_rate': 0.001, 'epoch': 4.25}
 85%|████████▌ | 34/40 [01:07<00:11,  1.94s/it] 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it]                                               {'loss': 0.016, 'grad_norm': 0.40172436833381653, 'learning_rate': 0.001, 'epoch': 4.38}
 88%|████████▊ | 35/40 [01:10<00:10,  2.05s/it] 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it]                                               {'loss': 0.0398, 'grad_norm': 1.5138517618179321, 'learning_rate': 0.001, 'epoch': 4.5}
 90%|█████████ | 36/40 [01:12<00:08,  2.12s/it] 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it]                                               {'loss': 0.0202, 'grad_norm': 0.49550577998161316, 'learning_rate': 0.001, 'epoch': 4.62}
 92%|█████████▎| 37/40 [01:14<00:06,  2.17s/it] 95%|█████████▌| 38/40 [01:16<00:04,  2.21s/it]                                               {'loss': 0.0155, 'grad_norm': 0.5169265866279602, 'learning_rate': 0.001, 'epoch': 4.75}
 95%|█████████▌| 38/40 [01:16<00:04,  2.21s/it] 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]                                               {'loss': 0.0167, 'grad_norm': 0.49285024404525757, 'learning_rate': 0.001, 'epoch': 4.88}
 98%|█████████▊| 39/40 [01:19<00:02,  2.23s/it]100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'loss': 0.0039, 'grad_norm': 0.24052287638187408, 'learning_rate': 0.001, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]                                               {'train_runtime': 79.6434, 'train_samples_per_second': 7.094, 'train_steps_per_second': 0.502, 'train_loss': 0.6285904446966015, 'epoch': 5.0}
100%|██████████| 40/40 [01:19<00:00,  1.61s/it]100%|██████████| 40/40 [01:19<00:00,  1.99s/it]
/home/suxiaoxin/Paper/Fed_LLM/fed_trainer.py:388: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  do_eval=True, seed=self.args.random_seed)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/471 [00:00<?, ?it/s]  0%|          | 2/471 [00:01<05:00,  1.56it/s]  1%|          | 3/471 [00:02<07:04,  1.10it/s]  1%|          | 4/471 [00:03<08:11,  1.05s/it]  1%|          | 5/471 [00:05<08:48,  1.13s/it]  1%|▏         | 6/471 [00:06<09:11,  1.19s/it]  1%|▏         | 7/471 [00:07<09:28,  1.22s/it]  2%|▏         | 8/471 [00:09<09:38,  1.25s/it]  2%|▏         | 9/471 [00:10<09:44,  1.26s/it]  2%|▏         | 10/471 [00:11<09:48,  1.28s/it]  2%|▏         | 11/471 [00:12<09:50,  1.28s/it]  3%|▎         | 12/471 [00:14<09:53,  1.29s/it]  3%|▎         | 13/471 [00:15<09:54,  1.30s/it]  3%|▎         | 14/471 [00:16<09:55,  1.30s/it]  3%|▎         | 15/471 [00:18<09:54,  1.30s/it]  3%|▎         | 16/471 [00:19<09:55,  1.31s/it]  4%|▎         | 17/471 [00:20<09:55,  1.31s/it]  4%|▍         | 18/471 [00:22<09:55,  1.31s/it]  4%|▍         | 19/471 [00:23<09:54,  1.32s/it]  4%|▍         | 20/471 [00:24<09:53,  1.32s/it]  4%|▍         | 21/471 [00:26<09:53,  1.32s/it]  5%|▍         | 22/471 [00:27<09:53,  1.32s/it]  5%|▍         | 23/471 [00:28<09:52,  1.32s/it]  5%|▌         | 24/471 [00:30<09:52,  1.33s/it]  5%|▌         | 25/471 [00:31<09:52,  1.33s/it]  6%|▌         | 26/471 [00:32<09:51,  1.33s/it]  6%|▌         | 27/471 [00:34<09:51,  1.33s/it]  6%|▌         | 28/471 [00:35<09:50,  1.33s/it]  6%|▌         | 29/471 [00:36<09:50,  1.34s/it]  6%|▋         | 30/471 [00:38<09:50,  1.34s/it]  7%|▋         | 31/471 [00:39<09:50,  1.34s/it]  7%|▋         | 32/471 [00:40<09:49,  1.34s/it]  7%|▋         | 33/471 [00:42<09:46,  1.34s/it]  7%|▋         | 34/471 [00:43<09:46,  1.34s/it]  7%|▋         | 35/471 [00:44<09:47,  1.35s/it]  8%|▊         | 36/471 [00:46<09:46,  1.35s/it]  8%|▊         | 37/471 [00:47<09:46,  1.35s/it]  8%|▊         | 38/471 [00:48<09:46,  1.35s/it]  8%|▊         | 39/471 [00:50<09:44,  1.35s/it]  8%|▊         | 40/471 [00:51<09:44,  1.36s/it]  9%|▊         | 41/471 [00:53<09:44,  1.36s/it]  9%|▉         | 42/471 [00:54<09:44,  1.36s/it]  9%|▉         | 43/471 [00:55<09:42,  1.36s/it]  9%|▉         | 44/471 [00:57<09:42,  1.36s/it] 10%|▉         | 45/471 [00:58<09:42,  1.37s/it] 10%|▉         | 46/471 [00:59<09:41,  1.37s/it] 10%|▉         | 47/471 [01:01<09:40,  1.37s/it] 10%|█         | 48/471 [01:02<09:39,  1.37s/it] 10%|█         | 49/471 [01:03<09:39,  1.37s/it] 11%|█         | 50/471 [01:05<09:38,  1.37s/it] 11%|█         | 51/471 [01:06<09:37,  1.38s/it] 11%|█         | 52/471 [01:08<09:36,  1.38s/it] 11%|█▏        | 53/471 [01:09<09:36,  1.38s/it] 11%|█▏        | 54/471 [01:10<09:35,  1.38s/it] 12%|█▏        | 55/471 [01:12<09:33,  1.38s/it] 12%|█▏        | 56/471 [01:13<09:33,  1.38s/it] 12%|█▏        | 57/471 [01:15<09:32,  1.38s/it] 12%|█▏        | 58/471 [01:16<09:30,  1.38s/it] 13%|█▎        | 59/471 [01:17<09:30,  1.38s/it] 13%|█▎        | 60/471 [01:19<09:28,  1.38s/it] 13%|█▎        | 61/471 [01:20<09:27,  1.38s/it] 13%|█▎        | 62/471 [01:21<09:26,  1.38s/it] 13%|█▎        | 63/471 [01:23<09:24,  1.38s/it] 14%|█▎        | 64/471 [01:24<09:23,  1.38s/it] 14%|█▍        | 65/471 [01:26<09:21,  1.38s/it] 14%|█▍        | 66/471 [01:27<09:20,  1.38s/it] 14%|█▍        | 67/471 [01:28<09:19,  1.39s/it] 14%|█▍        | 68/471 [01:30<09:17,  1.38s/it] 15%|█▍        | 69/471 [01:31<09:16,  1.38s/it] 15%|█▍        | 70/471 [01:33<09:15,  1.38s/it] 15%|█▌        | 71/471 [01:34<09:14,  1.39s/it] 15%|█▌        | 72/471 [01:35<09:12,  1.38s/it] 15%|█▌        | 73/471 [01:37<09:10,  1.38s/it] 16%|█▌        | 74/471 [01:38<09:08,  1.38s/it] 16%|█▌        | 75/471 [01:39<09:07,  1.38s/it] 16%|█▌        | 76/471 [01:41<09:05,  1.38s/it] 16%|█▋        | 77/471 [01:42<09:04,  1.38s/it] 17%|█▋        | 78/471 [01:44<09:02,  1.38s/it] 17%|█▋        | 79/471 [01:45<09:01,  1.38s/it] 17%|█▋        | 80/471 [01:46<09:00,  1.38s/it] 17%|█▋        | 81/471 [01:48<08:58,  1.38s/it] 17%|█▋        | 82/471 [01:49<08:57,  1.38s/it] 18%|█▊        | 83/471 [01:50<08:55,  1.38s/it] 18%|█▊        | 84/471 [01:52<08:53,  1.38s/it] 18%|█▊        | 85/471 [01:53<08:52,  1.38s/it] 18%|█▊        | 86/471 [01:55<08:51,  1.38s/it] 18%|█▊        | 87/471 [01:56<08:48,  1.38s/it] 19%|█▊        | 88/471 [01:57<08:46,  1.38s/it] 19%|█▉        | 89/471 [01:59<08:45,  1.37s/it] 19%|█▉        | 90/471 [02:00<08:44,  1.38s/it] 19%|█▉        | 91/471 [02:01<08:42,  1.37s/it] 20%|█▉        | 92/471 [02:03<08:40,  1.37s/it] 20%|█▉        | 93/471 [02:04<08:39,  1.38s/it] 20%|█▉        | 94/471 [02:06<08:37,  1.37s/it] 20%|██        | 95/471 [02:07<08:36,  1.37s/it] 20%|██        | 96/471 [02:08<08:34,  1.37s/it] 21%|██        | 97/471 [02:10<08:33,  1.37s/it] 21%|██        | 98/471 [02:11<08:31,  1.37s/it] 21%|██        | 99/471 [02:12<08:30,  1.37s/it] 21%|██        | 100/471 [02:14<08:28,  1.37s/it] 21%|██▏       | 101/471 [02:15<08:27,  1.37s/it] 22%|██▏       | 102/471 [02:17<08:26,  1.37s/it] 22%|██▏       | 103/471 [02:18<08:25,  1.37s/it] 22%|██▏       | 104/471 [02:19<08:24,  1.38s/it] 22%|██▏       | 105/471 [02:21<08:24,  1.38s/it] 23%|██▎       | 106/471 [02:22<08:21,  1.37s/it] 23%|██▎       | 107/471 [02:23<08:19,  1.37s/it] 23%|██▎       | 108/471 [02:25<08:18,  1.37s/it] 23%|██▎       | 109/471 [02:26<08:15,  1.37s/it] 23%|██▎       | 110/471 [02:28<08:13,  1.37s/it] 24%|██▎       | 111/471 [02:29<08:13,  1.37s/it] 24%|██▍       | 112/471 [02:30<08:12,  1.37s/it] 24%|██▍       | 113/471 [02:32<08:10,  1.37s/it] 24%|██▍       | 114/471 [02:33<08:10,  1.37s/it] 24%|██▍       | 115/471 [02:34<08:09,  1.37s/it] 25%|██▍       | 116/471 [02:36<08:07,  1.37s/it] 25%|██▍       | 117/471 [02:37<08:06,  1.38s/it] 25%|██▌       | 118/471 [02:39<08:05,  1.38s/it] 25%|██▌       | 119/471 [02:40<08:03,  1.37s/it] 25%|██▌       | 120/471 [02:41<08:03,  1.38s/it] 26%|██▌       | 121/471 [02:43<08:01,  1.38s/it] 26%|██▌       | 122/471 [02:44<08:00,  1.38s/it] 26%|██▌       | 123/471 [02:45<07:58,  1.37s/it] 26%|██▋       | 124/471 [02:47<07:57,  1.38s/it] 27%|██▋       | 125/471 [02:48<07:56,  1.38s/it] 27%|██▋       | 126/471 [02:50<07:54,  1.38s/it] 27%|██▋       | 127/471 [02:51<07:53,  1.38s/it] 27%|██▋       | 128/471 [02:52<07:51,  1.37s/it] 27%|██▋       | 129/471 [02:54<07:49,  1.37s/it] 28%|██▊       | 130/471 [02:55<07:48,  1.37s/it] 28%|██▊       | 131/471 [02:56<07:46,  1.37s/it] 28%|██▊       | 132/471 [02:58<07:45,  1.37s/it] 28%|██▊       | 133/471 [02:59<07:43,  1.37s/it] 28%|██▊       | 134/471 [03:01<07:43,  1.37s/it] 29%|██▊       | 135/471 [03:02<07:41,  1.37s/it] 29%|██▉       | 136/471 [03:03<07:40,  1.37s/it] 29%|██▉       | 137/471 [03:05<07:39,  1.37s/it] 29%|██▉       | 138/471 [03:06<07:37,  1.37s/it] 30%|██▉       | 139/471 [03:07<07:36,  1.37s/it] 30%|██▉       | 140/471 [03:09<07:34,  1.37s/it] 30%|██▉       | 141/471 [03:10<07:32,  1.37s/it] 30%|███       | 142/471 [03:12<07:31,  1.37s/it] 30%|███       | 143/471 [03:13<07:29,  1.37s/it] 31%|███       | 144/471 [03:14<07:29,  1.37s/it] 31%|███       | 145/471 [03:16<07:26,  1.37s/it] 31%|███       | 146/471 [03:17<07:25,  1.37s/it] 31%|███       | 147/471 [03:18<07:24,  1.37s/it] 31%|███▏      | 148/471 [03:20<07:22,  1.37s/it] 32%|███▏      | 149/471 [03:21<07:21,  1.37s/it] 32%|███▏      | 150/471 [03:23<07:21,  1.37s/it] 32%|███▏      | 151/471 [03:24<07:19,  1.37s/it] 32%|███▏      | 152/471 [03:25<07:16,  1.37s/it] 32%|███▏      | 153/471 [03:27<07:16,  1.37s/it] 33%|███▎      | 154/471 [03:28<07:13,  1.37s/it] 33%|███▎      | 155/471 [03:29<07:13,  1.37s/it] 33%|███▎      | 156/471 [03:31<07:10,  1.37s/it] 33%|███▎      | 157/471 [03:32<07:09,  1.37s/it] 34%|███▎      | 158/471 [03:33<07:07,  1.36s/it] 34%|███▍      | 159/471 [03:35<07:05,  1.36s/it] 34%|███▍      | 160/471 [03:36<07:04,  1.36s/it] 34%|███▍      | 161/471 [03:38<07:02,  1.36s/it] 34%|███▍      | 162/471 [03:39<07:01,  1.36s/it] 35%|███▍      | 163/471 [03:40<07:00,  1.36s/it] 35%|███▍      | 164/471 [03:42<06:58,  1.36s/it] 35%|███▌      | 165/471 [03:43<06:56,  1.36s/it] 35%|███▌      | 166/471 [03:44<06:55,  1.36s/it] 35%|███▌      | 167/471 [03:46<06:54,  1.36s/it] 36%|███▌      | 168/471 [03:47<06:52,  1.36s/it] 36%|███▌      | 169/471 [03:48<06:51,  1.36s/it] 36%|███▌      | 170/471 [03:50<06:49,  1.36s/it] 36%|███▋      | 171/471 [03:51<06:47,  1.36s/it] 37%|███▋      | 172/471 [03:52<06:45,  1.36s/it] 37%|███▋      | 173/471 [03:54<06:44,  1.36s/it] 37%|███▋      | 174/471 [03:55<06:42,  1.36s/it] 37%|███▋      | 175/471 [03:57<06:41,  1.36s/it] 37%|███▋      | 176/471 [03:58<06:39,  1.36s/it] 38%|███▊      | 177/471 [03:59<06:37,  1.35s/it] 38%|███▊      | 178/471 [04:01<06:36,  1.35s/it] 38%|███▊      | 179/471 [04:02<06:34,  1.35s/it] 38%|███▊      | 180/471 [04:03<06:33,  1.35s/it] 38%|███▊      | 181/471 [04:05<06:31,  1.35s/it] 39%|███▊      | 182/471 [04:06<06:31,  1.35s/it] 39%|███▉      | 183/471 [04:07<06:29,  1.35s/it] 39%|███▉      | 184/471 [04:09<06:27,  1.35s/it] 39%|███▉      | 185/471 [04:10<06:25,  1.35s/it] 39%|███▉      | 186/471 [04:11<06:24,  1.35s/it] 40%|███▉      | 187/471 [04:13<06:23,  1.35s/it] 40%|███▉      | 188/471 [04:14<06:22,  1.35s/it] 40%|████      | 189/471 [04:15<06:19,  1.35s/it] 40%|████      | 190/471 [04:17<06:18,  1.35s/it] 41%|████      | 191/471 [04:18<06:17,  1.35s/it] 41%|████      | 192/471 [04:19<06:15,  1.35s/it] 41%|████      | 193/471 [04:21<06:13,  1.34s/it] 41%|████      | 194/471 [04:22<06:12,  1.34s/it] 41%|████▏     | 195/471 [04:24<06:11,  1.34s/it] 42%|████▏     | 196/471 [04:25<06:09,  1.34s/it] 42%|████▏     | 197/471 [04:26<06:07,  1.34s/it] 42%|████▏     | 198/471 [04:28<06:05,  1.34s/it] 42%|████▏     | 199/471 [04:29<06:04,  1.34s/it] 42%|████▏     | 200/471 [04:30<06:03,  1.34s/it] 43%|████▎     | 201/471 [04:32<06:00,  1.34s/it] 43%|████▎     | 202/471 [04:33<05:59,  1.34s/it] 43%|████▎     | 203/471 [04:34<05:58,  1.34s/it] 43%|████▎     | 204/471 [04:36<05:57,  1.34s/it] 44%|████▎     | 205/471 [04:37<05:55,  1.34s/it] 44%|████▎     | 206/471 [04:38<05:54,  1.34s/it] 44%|████▍     | 207/471 [04:40<05:53,  1.34s/it] 44%|████▍     | 208/471 [04:41<05:50,  1.33s/it] 44%|████▍     | 209/471 [04:42<05:49,  1.33s/it] 45%|████▍     | 210/471 [04:44<05:47,  1.33s/it] 45%|████▍     | 211/471 [04:45<05:46,  1.33s/it] 45%|████▌     | 212/471 [04:46<05:45,  1.33s/it] 45%|████▌     | 213/471 [04:48<05:44,  1.33s/it] 45%|████▌     | 214/471 [04:49<05:42,  1.33s/it] 46%|████▌     | 215/471 [04:50<05:41,  1.33s/it] 46%|████▌     | 216/471 [04:52<05:40,  1.34s/it] 46%|████▌     | 217/471 [04:53<05:39,  1.34s/it] 46%|████▋     | 218/471 [04:54<05:37,  1.33s/it] 46%|████▋     | 219/471 [04:56<05:36,  1.34s/it] 47%|████▋     | 220/471 [04:57<05:35,  1.34s/it] 47%|████▋     | 221/471 [04:58<05:34,  1.34s/it] 47%|████▋     | 222/471 [05:00<05:32,  1.33s/it] 47%|████▋     | 223/471 [05:01<05:30,  1.33s/it] 48%|████▊     | 224/471 [05:02<05:29,  1.33s/it] 48%|████▊     | 225/471 [05:04<05:27,  1.33s/it] 48%|████▊     | 226/471 [05:05<05:26,  1.33s/it] 48%|████▊     | 227/471 [05:06<05:24,  1.33s/it] 48%|████▊     | 228/471 [05:08<05:23,  1.33s/it] 49%|████▊     | 229/471 [05:09<05:22,  1.33s/it] 49%|████▉     | 230/471 [05:10<05:22,  1.34s/it] 49%|████▉     | 231/471 [05:12<05:20,  1.33s/it] 49%|████▉     | 232/471 [05:13<05:18,  1.33s/it] 49%|████▉     | 233/471 [05:14<05:16,  1.33s/it] 50%|████▉     | 234/471 [05:16<05:15,  1.33s/it] 50%|████▉     | 235/471 [05:17<05:14,  1.33s/it] 50%|█████     | 236/471 [05:18<05:12,  1.33s/it] 50%|█████     | 237/471 [05:20<05:10,  1.33s/it] 51%|█████     | 238/471 [05:21<05:09,  1.33s/it] 51%|█████     | 239/471 [05:22<05:08,  1.33s/it] 51%|█████     | 240/471 [05:24<05:07,  1.33s/it] 51%|█████     | 241/471 [05:25<05:06,  1.33s/it] 51%|█████▏    | 242/471 [05:26<05:04,  1.33s/it] 52%|█████▏    | 243/471 [05:28<05:03,  1.33s/it] 52%|█████▏    | 244/471 [05:29<05:01,  1.33s/it] 52%|█████▏    | 245/471 [05:30<05:00,  1.33s/it] 52%|█████▏    | 246/471 [05:32<04:58,  1.33s/it] 52%|█████▏    | 247/471 [05:33<04:57,  1.33s/it] 53%|█████▎    | 248/471 [05:34<04:56,  1.33s/it] 53%|█████▎    | 249/471 [05:36<04:55,  1.33s/it] 53%|█████▎    | 250/471 [05:37<04:54,  1.33s/it] 53%|█████▎    | 251/471 [05:38<04:52,  1.33s/it] 54%|█████▎    | 252/471 [05:39<04:51,  1.33s/it] 54%|█████▎    | 253/471 [05:41<04:50,  1.33s/it] 54%|█████▍    | 254/471 [05:42<04:49,  1.33s/it] 54%|█████▍    | 255/471 [05:43<04:47,  1.33s/it] 54%|█████▍    | 256/471 [05:45<04:46,  1.33s/it] 55%|█████▍    | 257/471 [05:46<04:45,  1.33s/it] 55%|█████▍    | 258/471 [05:47<04:44,  1.33s/it] 55%|█████▍    | 259/471 [05:49<04:43,  1.34s/it] 55%|█████▌    | 260/471 [05:50<04:41,  1.33s/it] 55%|█████▌    | 261/471 [05:51<04:39,  1.33s/it] 56%|█████▌    | 262/471 [05:53<04:38,  1.33s/it] 56%|█████▌    | 263/471 [05:54<04:37,  1.33s/it] 56%|█████▌    | 264/471 [05:55<04:35,  1.33s/it] 56%|█████▋    | 265/471 [05:57<04:34,  1.33s/it] 56%|█████▋    | 266/471 [05:58<04:33,  1.34s/it] 57%|█████▋    | 267/471 [06:00<04:32,  1.34s/it] 57%|█████▋    | 268/471 [06:01<04:31,  1.34s/it] 57%|█████▋    | 269/471 [06:02<04:30,  1.34s/it] 57%|█████▋    | 270/471 [06:04<04:28,  1.34s/it] 58%|█████▊    | 271/471 [06:05<04:26,  1.33s/it] 58%|█████▊    | 272/471 [06:06<04:25,  1.34s/it] 58%|█████▊    | 273/471 [06:08<04:24,  1.34s/it] 58%|█████▊    | 274/471 [06:09<04:22,  1.33s/it] 58%|█████▊    | 275/471 [06:10<04:21,  1.34s/it] 59%|█████▊    | 276/471 [06:12<04:20,  1.34s/it] 59%|█████▉    | 277/471 [06:13<04:19,  1.34s/it] 59%|█████▉    | 278/471 [06:14<04:18,  1.34s/it] 59%|█████▉    | 279/471 [06:16<04:16,  1.34s/it] 59%|█████▉    | 280/471 [06:17<04:15,  1.34s/it] 60%|█████▉    | 281/471 [06:18<04:13,  1.34s/it] 60%|█████▉    | 282/471 [06:20<04:12,  1.34s/it] 60%|██████    | 283/471 [06:21<04:11,  1.34s/it] 60%|██████    | 284/471 [06:22<04:09,  1.34s/it] 61%|██████    | 285/471 [06:24<04:08,  1.34s/it] 61%|██████    | 286/471 [06:25<04:07,  1.34s/it] 61%|██████    | 287/471 [06:26<04:05,  1.34s/it] 61%|██████    | 288/471 [06:28<04:04,  1.34s/it] 61%|██████▏   | 289/471 [06:29<04:03,  1.34s/it] 62%|██████▏   | 290/471 [06:30<04:01,  1.34s/it] 62%|██████▏   | 291/471 [06:32<04:00,  1.34s/it] 62%|██████▏   | 292/471 [06:33<03:59,  1.34s/it] 62%|██████▏   | 293/471 [06:34<03:57,  1.34s/it] 62%|██████▏   | 294/471 [06:36<03:56,  1.34s/it] 63%|██████▎   | 295/471 [06:37<03:55,  1.34s/it] 63%|██████▎   | 296/471 [06:38<03:54,  1.34s/it] 63%|██████▎   | 297/471 [06:40<03:52,  1.34s/it] 63%|██████▎   | 298/471 [06:41<03:51,  1.34s/it] 63%|██████▎   | 299/471 [06:42<03:50,  1.34s/it] 64%|██████▎   | 300/471 [06:44<03:49,  1.34s/it] 64%|██████▍   | 301/471 [06:45<03:47,  1.34s/it] 64%|██████▍   | 302/471 [06:46<03:46,  1.34s/it] 64%|██████▍   | 303/471 [06:48<03:44,  1.34s/it] 65%|██████▍   | 304/471 [06:49<03:43,  1.34s/it] 65%|██████▍   | 305/471 [06:50<03:42,  1.34s/it] 65%|██████▍   | 306/471 [06:52<03:41,  1.34s/it] 65%|██████▌   | 307/471 [06:53<03:40,  1.34s/it] 65%|██████▌   | 308/471 [06:54<03:38,  1.34s/it] 66%|██████▌   | 309/471 [06:56<03:37,  1.34s/it] 66%|██████▌   | 310/471 [06:57<03:36,  1.34s/it] 66%|██████▌   | 311/471 [06:58<03:34,  1.34s/it] 66%|██████▌   | 312/471 [07:00<03:33,  1.34s/it] 66%|██████▋   | 313/471 [07:01<03:32,  1.34s/it] 67%|██████▋   | 314/471 [07:02<03:30,  1.34s/it] 67%|██████▋   | 315/471 [07:04<03:28,  1.34s/it] 67%|██████▋   | 316/471 [07:05<03:27,  1.34s/it] 67%|██████▋   | 317/471 [07:06<03:26,  1.34s/it] 68%|██████▊   | 318/471 [07:08<03:25,  1.34s/it] 68%|██████▊   | 319/471 [07:09<03:23,  1.34s/it] 68%|██████▊   | 320/471 [07:10<03:22,  1.34s/it] 68%|██████▊   | 321/471 [07:12<03:21,  1.34s/it] 68%|██████▊   | 322/471 [07:13<03:20,  1.35s/it] 69%|██████▊   | 323/471 [07:14<03:18,  1.34s/it] 69%|██████▉   | 324/471 [07:16<03:17,  1.34s/it] 69%|██████▉   | 325/471 [07:17<03:16,  1.34s/it] 69%|██████▉   | 326/471 [07:19<03:14,  1.34s/it] 69%|██████▉   | 327/471 [07:20<03:13,  1.34s/it] 70%|██████▉   | 328/471 [07:21<03:12,  1.34s/it] 70%|██████▉   | 329/471 [07:23<03:11,  1.35s/it] 70%|███████   | 330/471 [07:24<03:09,  1.34s/it] 70%|███████   | 331/471 [07:25<03:07,  1.34s/it] 70%|███████   | 332/471 [07:27<03:06,  1.34s/it] 71%|███████   | 333/471 [07:28<03:05,  1.34s/it] 71%|███████   | 334/471 [07:29<03:03,  1.34s/it] 71%|███████   | 335/471 [07:31<03:02,  1.34s/it] 71%|███████▏  | 336/471 [07:32<03:00,  1.34s/it] 72%|███████▏  | 337/471 [07:33<02:59,  1.34s/it] 72%|███████▏  | 338/471 [07:35<02:58,  1.34s/it] 72%|███████▏  | 339/471 [07:36<02:57,  1.34s/it] 72%|███████▏  | 340/471 [07:37<02:56,  1.34s/it] 72%|███████▏  | 341/471 [07:39<02:54,  1.34s/it] 73%|███████▎  | 342/471 [07:40<02:52,  1.34s/it] 73%|███████▎  | 343/471 [07:41<02:51,  1.34s/it] 73%|███████▎  | 344/471 [07:43<02:50,  1.34s/it] 73%|███████▎  | 345/471 [07:44<02:48,  1.34s/it] 73%|███████▎  | 346/471 [07:45<02:47,  1.34s/it] 74%|███████▎  | 347/471 [07:47<02:45,  1.34s/it] 74%|███████▍  | 348/471 [07:48<02:44,  1.34s/it] 74%|███████▍  | 349/471 [07:49<02:43,  1.34s/it] 74%|███████▍  | 350/471 [07:51<02:42,  1.34s/it] 75%|███████▍  | 351/471 [07:52<02:40,  1.34s/it] 75%|███████▍  | 352/471 [07:53<02:39,  1.34s/it] 75%|███████▍  | 353/471 [07:55<02:38,  1.34s/it] 75%|███████▌  | 354/471 [07:56<02:36,  1.34s/it] 75%|███████▌  | 355/471 [07:57<02:35,  1.34s/it] 76%|███████▌  | 356/471 [07:59<02:34,  1.34s/it] 76%|███████▌  | 357/471 [08:00<02:32,  1.34s/it] 76%|███████▌  | 358/471 [08:01<02:31,  1.34s/it] 76%|███████▌  | 359/471 [08:03<02:29,  1.34s/it] 76%|███████▋  | 360/471 [08:04<02:28,  1.34s/it] 77%|███████▋  | 361/471 [08:05<02:27,  1.34s/it] 77%|███████▋  | 362/471 [08:07<02:25,  1.34s/it] 77%|███████▋  | 363/471 [08:08<02:24,  1.33s/it] 77%|███████▋  | 364/471 [08:09<02:22,  1.34s/it] 77%|███████▋  | 365/471 [08:11<02:21,  1.34s/it] 78%|███████▊  | 366/471 [08:12<02:20,  1.34s/it] 78%|███████▊  | 367/471 [08:13<02:19,  1.34s/it] 78%|███████▊  | 368/471 [08:15<02:17,  1.34s/it] 78%|███████▊  | 369/471 [08:16<02:15,  1.33s/it] 79%|███████▊  | 370/471 [08:17<02:14,  1.34s/it] 79%|███████▉  | 371/471 [08:19<02:13,  1.34s/it] 79%|███████▉  | 372/471 [08:20<02:12,  1.34s/it] 79%|███████▉  | 373/471 [08:21<02:10,  1.34s/it] 79%|███████▉  | 374/471 [08:23<02:09,  1.33s/it] 80%|███████▉  | 375/471 [08:24<02:08,  1.33s/it] 80%|███████▉  | 376/471 [08:25<02:06,  1.33s/it] 80%|████████  | 377/471 [08:27<02:05,  1.33s/it] 80%|████████  | 378/471 [08:28<02:03,  1.33s/it] 80%|████████  | 379/471 [08:29<02:02,  1.33s/it] 81%|████████  | 380/471 [08:31<02:01,  1.33s/it] 81%|████████  | 381/471 [08:32<02:00,  1.33s/it] 81%|████████  | 382/471 [08:33<01:58,  1.33s/it] 81%|████████▏ | 383/471 [08:35<01:57,  1.33s/it] 82%|████████▏ | 384/471 [08:36<01:56,  1.34s/it] 82%|████████▏ | 385/471 [08:37<01:54,  1.34s/it] 82%|████████▏ | 386/471 [08:39<01:53,  1.33s/it] 82%|████████▏ | 387/471 [08:40<01:52,  1.33s/it] 82%|████████▏ | 388/471 [08:41<01:50,  1.33s/it] 83%|████████▎ | 389/471 [08:43<01:49,  1.33s/it] 83%|████████▎ | 390/471 [08:44<01:48,  1.33s/it] 83%|████████▎ | 391/471 [08:45<01:46,  1.34s/it] 83%|████████▎ | 392/471 [08:47<01:45,  1.33s/it] 83%|████████▎ | 393/471 [08:48<01:43,  1.33s/it] 84%|████████▎ | 394/471 [08:49<01:42,  1.34s/it] 84%|████████▍ | 395/471 [08:51<01:41,  1.33s/it] 84%|████████▍ | 396/471 [08:52<01:40,  1.33s/it] 84%|████████▍ | 397/471 [08:53<01:38,  1.33s/it] 85%|████████▍ | 398/471 [08:55<01:37,  1.33s/it] 85%|████████▍ | 399/471 [08:56<01:36,  1.33s/it] 85%|████████▍ | 400/471 [08:57<01:34,  1.33s/it] 85%|████████▌ | 401/471 [08:59<01:33,  1.33s/it] 85%|████████▌ | 402/471 [09:00<01:31,  1.33s/it] 86%|████████▌ | 403/471 [09:01<01:30,  1.33s/it] 86%|████████▌ | 404/471 [09:03<01:29,  1.33s/it] 86%|████████▌ | 405/471 [09:04<01:27,  1.33s/it] 86%|████████▌ | 406/471 [09:05<01:26,  1.33s/it] 86%|████████▋ | 407/471 [09:07<01:25,  1.33s/it] 87%|████████▋ | 408/471 [09:08<01:23,  1.33s/it] 87%|████████▋ | 409/471 [09:09<01:22,  1.33s/it] 87%|████████▋ | 410/471 [09:11<01:21,  1.33s/it] 87%|████████▋ | 411/471 [09:12<01:19,  1.33s/it] 87%|████████▋ | 412/471 [09:13<01:18,  1.33s/it] 88%|████████▊ | 413/471 [09:15<01:17,  1.33s/it] 88%|████████▊ | 414/471 [09:16<01:15,  1.33s/it] 88%|████████▊ | 415/471 [09:17<01:14,  1.33s/it] 88%|████████▊ | 416/471 [09:19<01:13,  1.33s/it] 89%|████████▊ | 417/471 [09:20<01:11,  1.33s/it] 89%|████████▊ | 418/471 [09:21<01:10,  1.33s/it] 89%|████████▉ | 419/471 [09:23<01:09,  1.33s/it] 89%|████████▉ | 420/471 [09:24<01:07,  1.33s/it] 89%|████████▉ | 421/471 [09:25<01:06,  1.33s/it] 90%|████████▉ | 422/471 [09:27<01:05,  1.33s/it] 90%|████████▉ | 423/471 [09:28<01:03,  1.33s/it] 90%|█████████ | 424/471 [09:29<01:02,  1.33s/it] 90%|█████████ | 425/471 [09:31<01:01,  1.33s/it] 90%|█████████ | 426/471 [09:32<00:59,  1.33s/it] 91%|█████████ | 427/471 [09:33<00:58,  1.33s/it] 91%|█████████ | 428/471 [09:35<00:57,  1.33s/it] 91%|█████████ | 429/471 [09:36<00:55,  1.33s/it] 91%|█████████▏| 430/471 [09:37<00:54,  1.33s/it] 92%|█████████▏| 431/471 [09:39<00:53,  1.33s/it] 92%|█████████▏| 432/471 [09:40<00:51,  1.33s/it] 92%|█████████▏| 433/471 [09:41<00:50,  1.33s/it] 92%|█████████▏| 434/471 [09:43<00:49,  1.33s/it] 92%|█████████▏| 435/471 [09:44<00:47,  1.33s/it] 93%|█████████▎| 436/471 [09:45<00:46,  1.33s/it] 93%|█████████▎| 437/471 [09:47<00:45,  1.33s/it] 93%|█████████▎| 438/471 [09:48<00:43,  1.33s/it] 93%|█████████▎| 439/471 [09:49<00:42,  1.33s/it] 93%|█████████▎| 440/471 [09:51<00:41,  1.33s/it] 94%|█████████▎| 441/471 [09:52<00:39,  1.33s/it] 94%|█████████▍| 442/471 [09:53<00:38,  1.33s/it] 94%|█████████▍| 443/471 [09:55<00:37,  1.33s/it] 94%|█████████▍| 444/471 [09:56<00:35,  1.33s/it] 94%|█████████▍| 445/471 [09:57<00:34,  1.33s/it] 95%|█████████▍| 446/471 [09:59<00:33,  1.33s/it] 95%|█████████▍| 447/471 [10:00<00:31,  1.33s/it] 95%|█████████▌| 448/471 [10:01<00:30,  1.33s/it] 95%|█████████▌| 449/471 [10:03<00:29,  1.33s/it] 96%|█████████▌| 450/471 [10:04<00:27,  1.33s/it] 96%|█████████▌| 451/471 [10:05<00:26,  1.33s/it] 96%|█████████▌| 452/471 [10:07<00:25,  1.33s/it] 96%|█████████▌| 453/471 [10:08<00:23,  1.33s/it] 96%|█████████▋| 454/471 [10:09<00:22,  1.33s/it] 97%|█████████▋| 455/471 [10:11<00:21,  1.33s/it] 97%|█████████▋| 456/471 [10:12<00:19,  1.33s/it] 97%|█████████▋| 457/471 [10:13<00:18,  1.33s/it] 97%|█████████▋| 458/471 [10:15<00:17,  1.33s/it] 97%|█████████▋| 459/471 [10:16<00:15,  1.33s/it] 98%|█████████▊| 460/471 [10:17<00:14,  1.33s/it] 98%|█████████▊| 461/471 [10:19<00:13,  1.33s/it] 98%|█████████▊| 462/471 [10:20<00:11,  1.33s/it] 98%|█████████▊| 463/471 [10:21<00:10,  1.33s/it] 99%|█████████▊| 464/471 [10:23<00:09,  1.33s/it] 99%|█████████▊| 465/471 [10:24<00:07,  1.33s/it] 99%|█████████▉| 466/471 [10:25<00:06,  1.33s/it] 99%|█████████▉| 467/471 [10:27<00:05,  1.33s/it] 99%|█████████▉| 468/471 [10:28<00:04,  1.33s/it]100%|█████████▉| 469/471 [10:29<00:02,  1.33s/it]100%|█████████▉| 470/471 [10:31<00:01,  1.33s/it]100%|██████████| 471/471 [10:32<00:00,  1.22s/it]100%|██████████| 471/471 [10:32<00:00,  1.34s/it]
{'eval_loss': 2.210258722305298, 'eval_model_preparation_time': 0.0105, 'eval_acc': 0.4070631970260223, 'eval_runtime': 633.2965, 'eval_samples_per_second': 11.893, 'eval_steps_per_second': 0.744}
